"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6333376,6184354,6332401,6332044,6296535,6332322,6329297,6330094,6236215,6293841,6299924,6299920,6322258,6322585,6314121,6313816,6309082,6310455,6310651,6287359,6287389,6309124,6284951,6281186,6284174,6282245,6281194,6310664,6279964,6275180,6301810,6303086,6295593,6300492,6299516,6299094,6298188,6298824,6297257,6295755,6270030,6270028,6270217,6294323,6294368,6289984,6289101,6291535,6263058,6290309,6290743,6289243,6284978,6281322,6284096,6280208,6270396,6269602,6269609,6185691,6266858,6266857,6266850,6266855,6251192,6260835,6260967,6171157,6256352,6222007,6252548,6252449,6249939,6252363,6252500,6249322,6249413,6247048,6240501,6240371,6200298,6236544,6235497,6232916,6232894,6233960,6233354,6231411,6230786,6227968,6227872,6227966,6227910,6226774,6225095,6227055,6223192,6217246,6217248,6218230",2017/05/04 23:38:13
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Machine Learning Methodology for Enhancing Automated Process in IT Incident Management","H. Li; Z. Zhan","State Key Lab. of Networking & Switching, Beijing Univ. of Posts & Telecommun., Beijing, China","2012 IEEE 11th International Symposium on Network Computing and Applications","20120913","2012","","","191","194","Operating system experienced a rise in number of incidents in recent years. Analysis and reemployment of past solution therefore may make a contribution in reducing service interrupt time and minimizing business losses. The training and retaining of human resources is another primary disbursement source for enterprise. Thus, it is of great significance for enterprises to find reasonable solutions automatically. Combined with keyword tokenization, data mining, numerical optimization and neural network, this paper presents a system that compares and finds the most similar incident solution in the past, based on the description provided by customers in natural language. We try to improve the automated process by increasing the efficiency and accuracy through machine learning methodology and also devote to presenting a practical decision support method.","","Electronic:978-0-7695-4773-2; POD:978-1-4673-2214-0","10.1109/NCA.2012.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6299094","IT incident management;data mining;neural network;numerical optimization;tokenize","Accuracy;Biological neural networks;Computer architecture;Machine learning;Optimization;Training","business data processing;data mining;human resource management;learning (artificial intelligence);natural language processing;neural nets","IT incident management;automated process;business loss;data mining;decision support method;enterprise;human resource retaining;human resource training;keyword tokenization;machine learning methodology;natural language;neural network;numerical optimization;operating system;service interrupt time","","1","","8","","","23-25 Aug. 2012","","IEEE","IEEE Conference Publications"
"Classification of HTTP traffic based on C5.0 Machine Learning Algorithm","T. Bujlow; T. Riaz; J. M. Pedersen","Section for Networking and Security, Department of Electronic Systems, Aalborg University, DK-9220 Aalborg East, Denmark","2012 IEEE Symposium on Computers and Communications (ISCC)","20120726","2012","","","000882","000887","Our previous work demonstrated the possibility of distinguishing several kinds of applications with accuracy of over 99%. Today, most of the traffic is generated by web browsers, which provide different kinds of services based on the HTTP protocol: web browsing, file downloads, audio and voice streaming through third-party plugins, etc. This paper suggests and evaluates two approaches to distinguish various HTTP content: distributed among volunteers' machines and centralized running in the core of the network. We also assess accuracy of the global classifier for both HTTP and non-HTTP traffic. We achieved accuracy of 94%, which supposed to be even higher in real-life usage. Finally, we provided graphical characteristics of different kinds of HTTP traffic.","1530-1346;15301346","Electronic:978-1-4673-2713-8; POD:978-1-4673-2712-1; USB:978-1-4673-2711-4","10.1109/ISCC.2012.6249413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249413","C5.0;HTTP traffic;Machine Learning Algorithms (MLAs);browser traffic;computer networks;performance monitoring;traffic classification","Accuracy;Browsers;Computer networks;Multimedia communication;Quality of service;Streaming media;Training","Internet;learning (artificial intelligence);pattern classification;transport protocols","C5.0 machine learning algorithm;HTTP content;HTTP protocol;HTTP traffic classification;Web browser;Web browsing;audio streaming;file download;global classifier;hypertext transfer protocol;nonHTTP traffic;third-party plugins;voice streaming","","5","","","","","1-4 July 2012","","IEEE","IEEE Conference Publications"
"Point stabilization of two-wheeled vehicle based on machine learning","D. Toishi; E. Konaka","Meijo University, Japan","2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012)","20120903","2012","","","175","180","The configuration of a two-wheeled vehicle, such as a Segway, involves non-holonomic constraints, and thus it cannot be stabilized by continuous and time-invariant state feedback. Because of the nonlinear nature of the nonholonomic constraints, the realization of a model predictive control (MPC) algorithm for this class of vehicles is a difficult task. This paper proposes an MPC method that can achieve a long prediction horizon and has a short computation time. First, the optimization of an input (i.e., velocity and steering) sequence is formulated as a graph search problem by restricting the inputs to discrete values. Next, the optimized control result is learned by a machine learning method, such as support vector machine (SVM). Compared to nonlinear optimization, a longer horizon MPC can be realized. The advantages of the proposed method are demonstrated with simulation and experimental results.","","Electronic:978-1-4673-0993-6; POD:978-1-4673-0992-9","10.1109/ICVES.2012.6294323","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6294323","","Optimization;Performance analysis;Prediction algorithms;Support vector machines;Training data;Vectors;Vehicles","control engineering computing;electric vehicles;graph theory;learning (artificial intelligence);optimisation;predictive control;search problems;state feedback;support vector machines","MPC algorithm;MPC method;SVM;Segway;continuous state feedback;graph search problem;horizon MPC;input sequence;machine learning method;model predictive control algorithm;nonholonomic constraints;nonlinear nature;nonlinear optimization;optimized control;point stabilization;support vector machine;time-invariant state feedback;two-wheeled vehicle","","1","","10","","","24-27 July 2012","","IEEE","IEEE Conference Publications"
"Learning and Relearning in Boltzmann Machines","M. I. Jordan; T. J. Sejnowski","","Graphical Models:Foundations of Neural Computation","20121008","2001","","","45","76","This chapter contains sections titled: Relaxation Searches, Easy and Hard Learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, An Example of the Effects of Damage, Conclusion, Acknowledgments, Appendix: Derivation of the Learning Algorithm, References","","97802622912","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6299924.pdf&bkn=6276852&pdfType=chapter","","","","","","","","","2001","","","","MIT Press","MIT Press eBook Chapters"
"Automatic software architecture recovery: A machine learning approach","H. Sajnani","University of California Irvine, Irvine, California 92697","2012 20th IEEE International Conference on Program Comprehension (ICPC)","20120716","2012","","","265","268","Automatically recovering functional architecture of the software can facilitate the developer's understanding of how the system works. In legacy systems, original source code is often the only available source of information about the system and it is very time consuming to understand source code. Current architecture recovery techniques either require heavy human intervention or fail to recover quality components. To alleviate these shortcomings, we propose use of machine learning techniques which use structural, runtime behavioral, domain, textual and contextual (e.g. code authorship, line co-change) features. These techniques will allow us to experiment with a large number of features of the software artifacts without having to establish a priori our own insights about what is important and what is not important. We believe this is a promising approach that may finally start to produce usable solutions to this elusive problem.","1092-8138;10928138","Electronic:978-1-4673-1216-5; POD:978-1-4673-1213-4; USB:978-1-4673-1215-8","10.1109/ICPC.2012.6240501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240501","","Clustering algorithms;Computer architecture;Documentation;Feature extraction;Machine learning;Software;Software algorithms","learning (artificial intelligence);object-oriented programming;software architecture;software maintenance;software quality","automatic functional architecture recovery;automatic software architecture recovery;contextual features;contextual textual;domain features;legacy systems;machine learning;quality component recovery;runtime behavioral;software artifacts;source code;structural features;textual features","","1","","34","","","11-13 June 2012","","IEEE","IEEE Conference Publications"
"Bimanual regrasping from unimanual machine learning","B. Balaguer; S. Carpin","School of Engineering, University of California, Merced, USA","2012 IEEE International Conference on Robotics and Automation","20120628","2012","","","3264","3270","While unimanual regrasping has been studied extensively, either by regrasping in-hand or by placing the object on a surface, bimanual regrasping has seen little attention. The recent popularity of simple end-effectors and dual-manipulator platforms makes bimanual regrasping an important behavior for service robots to possess. We solve the challenge of bimanual regrasping by casting it as an optimization problem, where the objective is to minimize execution time. The optimization problem is supplemented by image processing and a unimanual grasping algorithm based on machine learning that jointly identify two good grasping points on the object and the proper orientations for each end-effector. The optimization algorithm exploits this data by finding the proper regrasp location and orientation to minimize execution time. Influenced by human bimanual manipulation, the algorithm only requires a single stereo image as input. The efficacy of the method we propose is demonstrated on a dual manipulator torso equipped with Barrett WAM arms and Barrett Hands.","1050-4729;10504729","Electronic:978-1-4673-1405-3; POD:978-1-4673-1403-9; USB:978-1-4673-1404-6","10.1109/ICRA.2012.6225095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6225095","","Grasping;Humans;Image processing;Machine learning algorithms;Manipulators;Optimization","end effectors;grippers;learning (artificial intelligence);optimisation;service robots;stereo image processing","Barrett WAM arms;Barrett hnds;bimanual regrasping;dual manipulator torso;dual-manipulator platforms;end-effectors;grasping points;human bimanual manipulation;image processing;in-hand regrasping;optimization algorithm;optimization problem;regrasp location;regrasp orientation;service robots;single stereo image;unimanual grasping algorithm;unimanual machine learning;unimanual regrasping","","3","","20","","","14-18 May 2012","","IEEE","IEEE Conference Publications"
"Extreme learning machines for intrusion detection","Chi Cheng; Wee Peng Tay; G. B. Huang","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","8","We consider the problem of intrusion detection in a computer network, and investigate the use of extreme learning machines (ELMs) to classify and detect the intrusions. With increasing connectivity between networks, the risk of information systems to external attacks or intrusions has increased tremendously. Machine learning methods like support vector machines (SVMs) and neural networks have been widely used for intrusion detection. These methods generally suffer from long training times, require parameter tuning, or do not perform well in multi-class classification. We propose a basic ELM method based on random features, and a kernel based ELM method for classification. We compare our methods with commonly used SVM techniques in both binary and multi-class classifications. Simulation results show that the proposed basic ELM approach outperforms SVM in training and testing speed, while the proposed kernel based ELM achieves higher detection accuracy than SVM in multi-class classification case.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252449","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252449","Extreme Learning Machines;Support Vector Machines;intrusion detection;random features","Computer crime;Feature extraction;Intrusion detection;Kernel;Neurons;Support vector machines;Training","computer network security;feature extraction;learning (artificial intelligence);neural nets;pattern classification;risk analysis;support vector machines;tuning","SVM techniques;computer network;extreme learning machines;information systems;intrusion detection;intrusions classification;kernel-based ELM method;machine learning methods;multiclass classifications;networks connectivity;neural networks;parameter tuning;support vector machines;testing speed;training speed;training times","","11","","25","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Machine learning approaches for electric appliance classification","D. Zufferey; C. Gisler; Omar Abou Khaled; J. Hennebert","Dept. of Inf. (DIUF), Univ. of Fribourg, Fribourg, Switzerland","2012 11th International Conference on Information Science, Signal Processing and their Applications (ISSPA)","20120924","2012","","","740","745","We report on the development of an innovative system which can automatically recognize home appliances based on their electric consumption profiles. The purpose of our system is to apply adequate rules to control electric appliance in order to save energy and money. The novelty of our approach is in the use of plug-based low-end sensors that measure the electric consumption at low frequency, typically every 10 seconds. Another novelty is the use of machine learning approaches to perform the classification of the appliances. In this paper, we present the system architecture, the data acquisition protocol and the evaluation framework. More details are also given on the feature extraction and classification models being used. The evaluation showed promising results with a correct rate of identification of 85%.","","Electronic:978-1-4673-0382-8; POD:978-1-4673-0381-1; USB:978-1-4673-0380-4","10.1109/ISSPA.2012.6310651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6310651","Signal processing;energy consumption;energy efficiency;machine learning algorithms;power system analysis computing;sustainable development","Electricity;Feature extraction;Home appliances;Monitoring;Sensors;Training;Vectors","data acquisition;domestic appliances;feature extraction;innovation management;learning (artificial intelligence);object recognition;power consumption;power system analysis computing;power system control;sensors","classification models;data acquisition protocol;electric appliance classification;electric appliance control;electric consumption profiles;evaluation framework;feature extraction;home appliance recognition;innovative system;machine learning approaches;plug-based low-end sensors;power system analysis computing;system architecture","","8","","14","","","2-5 July 2012","","IEEE","IEEE Conference Publications"
"General Signal Processing and Machine Learning Tools for BCI Analysis","G. Dornhege; J. del R. Millán; T. Hinterberger; D. J. McFarland; K. R. Müller","","Toward Brain-Computer Interfacing","20120924","2007","","","207","233","This chapter discusses signal processing and machine learning techniques and their application to brain-computer interfacing. A broader overview of the general signal processing and classification methods as used in single-trial EEG analysis is given. For more specialized algorithms, the reader is referred to the original publications. Furthermore, validation techniques and robustification are discussed briefly.","","97802622560","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6281186.pdf&bkn=6267251&pdfType=chapter","","","","","","","","","2007","","","","MIT Press","MIT Press eBook Chapters"
"The Improved Fast Gauss Transform with Applications to Machine Learning","L. Bottou; O. Chapelle; D. DeCoste; J. Weston","","Large-Scale Kernel Machines","20120924","2007","","","175","201","This chapter contains sections titled: Computational Curse of Nonparametric Methods, Bottleneck Computational Primitive: Weighted Superposition of Kernels, Structured Matrices and ∈-Exact Approximation, Motivating Example: Polynomial Kernel, Sum of Gaussian Kernels: The Discrete Gauss Transform, Bringing Computational Tractability to the Discrete Gauss Transform, Multi-index Notation, The Improved Fast Gauss Transform, IFGT vs. FGT, Numerical Experiments, Fast Multivariate Kernel Density Estimation, Conclusions, Appendix","","97802622557","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6279964.pdf&bkn=6267226&pdfType=chapter","","","","","","","","","2007","","","","MIT Press","MIT Press eBook Chapters"
"Bidirectional Extreme Learning Machine for Regression Problem and Its Learning Effectiveness","Y. Yang; Y. Wang; X. Yuan","College of Electrical and Information Engineering, Hunan University, Changsha, China","IEEE Transactions on Neural Networks and Learning Systems","20120801","2012","23","9","1498","1505","It is clear that the learning effectiveness and learning speed of neural networks are in general far slower than required, which has been a major bottleneck for many applications. Recently, a simple and efficient learning method, referred to as extreme learning machine (ELM), was proposed by Huang , which has shown that, compared to some conventional methods, the training time of neural networks can be reduced by a thousand times. However, one of the open problems in ELM research is whether the number of hidden nodes can be further reduced without affecting learning effectiveness. This brief proposes a new learning algorithm, called bidirectional extreme learning machine (B-ELM), in which some hidden nodes are not randomly selected. In theory, this algorithm tends to reduce network output error to 0 at an extremely early learning stage. Furthermore, we find a relationship between the network output error and the network output weights in the proposed B-ELM. Simulation results demonstrate that the proposed method can be tens to hundreds of times faster than other incremental ELM algorithms.","2162-237X;2162237X","","10.1109/TNNLS.2012.2202289","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6222007","Feedforward neural network;learning effectiveness;number of hidden nodes;universal approximation","Computer architecture;Equations;Helium;Learning systems;Machine learning;Testing;Training","learning (artificial intelligence);neural nets;regression analysis","B-ELM;bidirectional extreme learning machine;learning effectiveness;neural networks;regression problem","1","38","","13","","20120620","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"A Comparative Assessment of Ranking Accuracies of Conventional and Machine-Learning-Based Scoring Functions for Protein-Ligand Binding Affinity Prediction","H. M. Ashtawy; N. R. Mahapatra","Michigan State University, East Lansing","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20120803","2012","9","5","1301","1313","Accurately predicting the binding affinities of large sets of protein-ligand complexes efficiently is a key challenge in computational biomolecular science, with applications in drug discovery, chemical biology, and structural biology. Since a scoring function (SF) is used to score, rank, and identify drug leads, the fidelity with which it predicts the affinity of a ligand candidate for a protein's binding site has a significant bearing on the accuracy of virtual screening. Despite intense efforts in developing conventional SFs, which are either force-field based, knowledge-based, or empirical, their limited ranking accuracy has been a major roadblock toward cost-effective drug discovery. Therefore, in this work, we explore a range of novel SFs employing different machine-learning (ML) approaches in conjunction with a variety of physicochemical and geometrical features characterizing protein-ligand complexes. We assess the ranking accuracies of these new ML-based SFs as well as those of conventional SFs in the context of the 2007 and 2010 PDBbind benchmark data sets on both diverse and protein-family-specific test sets. We also investigate the influence of the size of the training data set and the type and number of features used on ranking accuracy. Within clusters of protein-ligand complexes with different ligands bound to the same target protein, we find that the best ML-based SF is able to rank the ligands correctly based on their experimentally determined binding affinities 62.5 percent of the time and identify the top binding ligand 78.1 percent of the time. For this SF, the Spearman correlation coefficient between ranks of ligands ordered by predicted and experimentally determined binding affinities is 0.771. Given the challenging nature of the ranking problem and that SFs are used to screen millions of ligands, this represents a significant improvement over the best conventional SF we studied, for which the corresponding ranking performance values are 57.8- percent, 73.4 percent, and 0.677.","1545-5963;15455963","","10.1109/TCBB.2012.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171157","Drug discovery;machine learning;protein-ligand binding affinity;ranking power;scoring function;virtual screening.","Accuracy;Databases;Drugs;Feature extraction;Proteins;Three dimensional displays;Training","biochemistry;biology computing;drugs;learning (artificial intelligence);molecular biophysics;proteins","2007 PDBbind benchmark data sets;2010 PDBbind benchmark data sets;Spearman correlation coefficient;comparative assessment;computational biomolecular science;drug discovery;geometrical feature;machine-learning-based scoring functions;physicochemical feature;protein-family-specific test sets;protein-ligand binding affinity prediction;protein-ligand complexes;training data set","Algorithms;Artificial Intelligence;Binding Sites;Ligands;Protein Conformation;Proteins","7","","40","","20120319","Sept.-Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Automatic feature selection for BCI: An analysis using the davies-bouldin index and extreme learning machines","G. P. Coelho; C. C. Barbante; L. Boccato; R. R. F. Attux; J. R. Oliveira; F. J. Von Zuben","School of Technology (FT), University of Campinas (UNICAMP), Limeira, Brazil","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","8","In this work, we present a novel framework for automatic feature selection in brain-computer interfaces (BCIs). The proposal, which manipulates features generated in the frequency domain by an estimate of the power spectral density of the EEG signals, is based on feature optimization (with both binary and real coding) using a state-of-the-art artificial immune network, the cob-aiNet. In order to analyze the performance of the proposed framework, two approaches are adopted: a direct use of the Davies-Bouldin index and the use of metrics associated with the operation of an extreme learning machine (ELM) in the role of a classifier. The results reveal that the proposal has the potential of improving the performance of a BCI system, and also provide elements for an analysis of the spectral content of EEG signals and of the performance of ELMs in motor imagery paradigms.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252500","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252500","Artificial Immune Systems;Brain Computer Interfaces;Davies-Bouldin Index;Extreme Learning Machines;Feature Selection","Electroencephalography;Feature extraction;Filtering algorithms;Indexes;Machine learning;Optimization;Training","artificial immune systems;brain-computer interfaces;electroencephalography;frequency-domain analysis;learning (artificial intelligence);optimisation;pattern classification","BCI system;Davies-Bouldin index machine;EEG signals;artificial immune network;automatic feature selection;brain-computer interfaces;cob-aiNet;extreme learning machines;feature optimization;frequency domain;power spectral density","","5","","17","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Reaching optimally over the workspace: A machine learning approach","D. Marin; O. Sigaud","Universit&#x00E9; Pierre et Marie Curie, Institut des Syst&#x00E8;mes Intelligents et de Robotique - CNRS UMR 7222 Pyramide Tour 55 - Bo&#x00EE;te Courrier 173 4 Place Jussieu, 75252 Paris CEDEX 5, France","2012 4th IEEE RAS & EMBS International Conference on Biomedical Robotics and Biomechatronics (BioRob)","20120830","2012","","","1128","1133","Recent theories of Human Motor Control explain our outstanding coordination capabilities by calling upon an Optimal Control (OC) framework. But OC methods are generally too expensive to be applied on-line and in realtime as would be required to perform everyday movements. An alternative method consists in obtaining a pre-computed feedback policy that performs optimally while being executed reactively. One way to get such a pre-computed policy consists in tuning a parametrized reactive controller so that it converges to optimal behavior. In this paper, we demonstrate a method to obtain such a reactive controller that (i) adapts the time of movement based on a compromise between the amount of reward and the effort required to get it, (ii) provides an efficient trajectory from any point to any point in the workspace, (iii) learns from demonstrations of optimal trajectories, (iv) is improving its performance over accumulated experience.","2155-1774;21551774","Electronic:978-1-4577-1200-5; POD:978-1-4577-1199-2","10.1109/BioRob.2012.6290743","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6290743","","Aerospace electronics;Machine learning;Noise;Predictive models;Sociology;Statistics;Trajectory","biocontrol;learning (artificial intelligence);optimal control","OC methods;coordination capabilities;human motor control;machine learning approach;optimal control framework;parametrized reactive controller;pre-computed feedback policy","","0","","23","","","24-27 June 2012","","IEEE","IEEE Conference Publications"
"Kernel Classifiers from a Machine Learning Perspective","R. Herbrich","","Learning Kernel Classifiers:Theory and Algorithms","20120924","2001","","","17","71","This chapter contains sections titled: 2.1 The Basic Setting, 2.2 Learning by Risk Minimization, 2.3 Kernels and Linear Classifiers, 2.4 Support Vector Classification Learning, 2.5 Adaptive Margin Machines, 2.6 Bibliographical Remarks","","97802622563","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6284174.pdf&bkn=6267278&pdfType=chapter","","","","","","","","","2001","","","","MIT Press","MIT Press eBook Chapters"
"Extreme Learning Machine based fast object recognition","J. Xu; H. Zhou; G. B. Huang","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798","2012 15th International Conference on Information Fusion","20120830","2012","","","1490","1496","Extreme Learning Machine (ELM) as a type of generalized single-hidden layer feed-forward networks (SLFNs) has demonstrated its good generalization performance with extreme fast learning speed in many benchmark and real applications. This paper further studies the performance of ELM and its variants in object recognition using two different feature extraction methods. The first method extracts texture features, intensity features from Histogram and features from two types of color space: HSV & RGB. The second method extracts shape features based on Radon transform. The classification performances of ELM and its variants are compared with the performance of Support Vector Machines (SVMs). As verified by simulation results, ELM achieves better testing accuracy with much less training time on majority cases than SVM for both feature extraction methods. Besides, the parameter tuning process for ELM is much easier than SVM as well.","","Electronic:978-0-9824438-5-9; POD:978-1-4673-0417-7; USB:978-0-9824438-4-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6289984","Extreme Learning Machine (ELM);Feature Extraction;Object Recognition;Radon Transform;Support Vector Machine (SVM)","Feature extraction;Image color analysis;Kernel;Machine learning;Object recognition;Shape;Support vector machines","Radon transforms;feature extraction;feedforward neural nets;image classification;image colour analysis;image texture;object recognition;support vector machines","ELM;HSV color space;RGB color space;Radon transform;SLFN;extreme learning machine;fast object recognition;generalized single-hidden layer feedforward networks;intensity feature extraction;parameter tuning process;shape feature extraction;support vector machines;texture feature extraction","","0","","31","","","9-12 July 2012","","IEEE","IEEE Conference Publications"
"Sentiment Classification for Microblog by Machine Learning","Z. Niu; Z. Yin; X. Kong","Dept. of Comput. Sci. & Technol., Harbin Inst. of Technol., Harbin, China","2012 Fourth International Conference on Computational and Information Sciences","20120913","2012","","","286","289","With the development of microblog, many studies pay special attention to sentiment classification of the reviews in microblog. This paper summarizes three well-known methods for text classification and then improves one of them for sentiment analysis. We come up with a new model in which we introduce efficient approaches to select features, calculate weights, train samples and evaluate classifier. The new model is based on Bayesian algorithm and machine learning that is one of the most popular methods for sentiment classification. Our model can enhance the overall efficiency of the sentiment classifier.","","Electronic:978-0-7695-4789-3; POD:978-1-4673-2406-9","10.1109/ICCIS.2012.276","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6300492","Naïve Bayesian classifier;machine learning;microblog;sentiment analysis;support vector machine;text classification","Bayesian methods;Feature extraction;Machine learning;Support vector machines;Text categorization;Training","learning (artificial intelligence)","bayesian algorithm;machine learning;microblog;sentiment analysis;sentiment classification;sentiment classifier;text classification","","3","","19","","","17-19 Aug. 2012","","IEEE","IEEE Conference Publications"
"Machine learning models for classification of BGP anomalies","N. M. Al-Rousan; L. Trajković","Simon Fraser University, Vancouver, British Columbia, Canada","2012 IEEE 13th International Conference on High Performance Switching and Routing","20120806","2012","","","103","108","Worms such as Slammer, Nimda, and Code Red I are anomalies that affect performance of the global Internet Border Gateway Protocol (BGP). BGP anomalies also include Internet Protocol (IP) prefix hijacks, miss-configurations, and electrical failures. Statistical and machine learning techniques have been recently deployed to classify and detect BGP anomalies. In this paper, we introduce new classification features and apply Support Vector Machine (SVM) models and Hidden Markov Models (HMMs) to design anomaly detection mechanisms. We apply these multi classification models to correctly classify test datasets and identify the correct anomaly types. The proposed models are tested with collected BGP traffic traces and are employed to successfully classify and detect various BGP anomalies.","2325-5552;23255552","Electronic:978-1-4577-0833-6; POD:978-1-4577-0831-2; USB:978-1-4577-0832-9","10.1109/HPSR.2012.6260835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6260835","","Accuracy;Feature extraction;Grippers;Hidden Markov models;Protocols;Support vector machines;Training","Internet;hidden Markov models;invasive software;protocols;support vector machines","BGP anomalies;Code Red I;Internet border gateway protocol;Internet protocol prefix hijacks;Nimda;Slammer;anomaly detection;classification features;electrical failures;hidden Markov models;machine learning models;multiclassification models;support vector machine models;worms","","9","","15","","","24-27 June 2012","","IEEE","IEEE Conference Publications"
"The partitioned kernel machine algorithm for online learning","J. Rhinelander; X. P. Liu","Department of Systems and Computer Engineering, Carleton University, Ottawa, Ontario, Canada, K1S 5B6","2012 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA) Proceedings","20120816","2012","","","1","6","Kernel machines have been successfully applied to many engineering problems requiring pattern recognition and regression. Kernel machines are a family of machine learning algorithms including support vector machines (SVM) [1], kernel least mean squares adaptive filter (KLMS) [2], and kernel recursive least squares (KRLS) adaptive filter [3] to name a few. In this paper we present the partitioned kernel machine algorithm for use in online learning in virtual environments. The PKM algorithm enhances the accuracy of the computationally efficient KLMS algorithm. The PKM algorithm is an iterative update procedure that focuses on a subset of the stored vectors in the kernel machine buffer. We use a similarity measure for the selection of kernel machine vectors that allow more common vectors to be updated more frequently, and outlier vectors to be updated less frequently. We validate the increased accuracy of our novel algorithm in two separate experimental settings.","2159-1547;21591547","Electronic:978-1-4577-1779-6; POD:978-1-4577-1778-9","10.1109/CIMSA.2012.6269602","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6269602","","Accuracy;Equations;Kernel;Machine learning;Partitioning algorithms;Time series analysis;Vectors","adaptive filters;iterative methods;learning (artificial intelligence);least mean squares methods;recursive estimation;support vector machines","KLMS;KRLS;PKM algorithm;SVM;engineering problems;iterative update procedure;kernel least mean squares adaptive filter;kernel machine buffer;kernel machine vectors selection;kernel recursive least squares adaptive filter;machine learning algorithms;online learning;partitioned kernel machine algorithm;pattern recognition;pattern regression;similarity measure;support vector machines;virtual environments","","1","","22","","","2-4 July 2012","","IEEE","IEEE Conference Publications"
"Foundations of Machine Learning","R. E. Schapire; Y. Freund","","Boosting:Foundations and Algorithms","20120924","2012","","","23","52","This chapter contains sections titled: 2.1 A Direct Approach to Machine Learning, 2.2 General Methods of Analysis, 2.3 A Foundation for the Study of Boosting Algorithms, Summary, Bibliographic Notes, Exercises","","97802623011","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6282245.pdf&bkn=6267536&pdfType=chapter","","","","","","","","","2012","","","","MIT Press","MIT Press eBook Chapters"
"Promoter recognition with machine learning algorithms keREM, RULSE-3 and ANN","G. Karli; A. Nayir","Faculty of Engineering and Information Technology, International Burch Universiy, Sarajevo, BIH","2012 International Symposium on Innovations in Intelligent Systems and Applications","20120723","2012","","","1","4","Data mining has become an important and active area of research because of theoretical challenges and practical applications associated with the problem of discovering interesting and previously unknown knowledge from very large real world database. These databases contain potential gold mine of valuable information, but it is beyond human ability to analyze massive amount of data and elicit meaningful patterns by using conventional techniques. In this study, DNA sequence was analyzed to locate promoter which is a regulatory region of DNA located upstream of a gene, providing a control point for regulated gene transcription. In this study, some supervised learning algorithms such as artificial neural network (ANN), RULES-3 and newly developed keREM rule induction algorithm were used to analyse to DNA sequence. In the experiments different option of keREM, RULES-3 and ANN were used, and according to the empirical comparisons, the algorithms appeared to be comparable to well-known algorithms in terms of the accuracy of the extracted rule in classifying unseen data.","","Electronic:978-1-4673-1448-0; POD:978-1-4673-1446-6","10.1109/INISTA.2012.6247048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6247048","Data mining;classification;machine learning;rule-based algorithms;supervised learning","Algorithm design and analysis;Artificial neural networks;Biological neural networks;Classification algorithms;DNA;Machine learning algorithms;Neurons","DNA;biology computing;data mining;genetics;learning (artificial intelligence);neural nets;pattern classification","ANN algorithm;DNA sequence;RULSE-3 algorithm;artificial neural network;data mining;keREM algorithm;knowledge discovery;machine learning algorithm;promoter recognition;regulated gene transcription;regulatory region;supervised learning algorithm;unseen data classification;very large real world database","","0","","28","","","2-4 July 2012","","IEEE","IEEE Conference Publications"
"Scene-adaptive Moving Detection with Machine Learning Based on Clustering","T. Hu; M. Zheng; J. Li; L. Zhu","Sch. of Inf. Eng., Hubei Univ. for Nat., Enshi, China","2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems","20121018","2012","","","1782","1787","Moving detection is a hot research area. Order to detect flexible and improve the detection accuracy, we propose a scene-adaptive moving detection model with machine learning based on clustering. The model uses a group of testing images to train the camera firstly, which means we can get out accurate parameters for one scene. We design a detection algorithm that used in training process based on clustering. Then it uses the parameters and detection algorithm to detect the changes in monitor scene. The experience shows our model has a high adaptability and accuracy.","","Electronic:978-0-7695-4749-7; POD:978-1-4673-2164-8","10.1109/HPCC.2012.268","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6332401","Clustering;Machine Learning;Moving Detection;Scene-adaptive","Accuracy;Cameras;Clustering algorithms;Detection algorithms;Machine learning;Monitoring;Training","cameras;image motion analysis;learning (artificial intelligence);natural scenes;pattern clustering;training","camera training;clustering-based machine learning;clustering-based training process;detection accuracy;scene monitoring;scene-adaptive moving detection;testing images","","0","","15","","","25-27 June 2012","","IEEE","IEEE Conference Publications"
"Intelligent Hybrid Vehicle Power Control—Part I: Machine Learning of Optimal Vehicle Power","Y. L. Murphey; J. Park; Z. Chen; M. L. Kuang; M. A. Masrur; A. M. Phillips","Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA","IEEE Transactions on Vehicular Technology","20121012","2012","61","8","3519","3530","In this series of two papers, we present our research on intelligent energy management for hybrid electric vehicles (HEVs). These two papers cover the modeling of power flow in HEVs, the mathematical background of optimization in energy management in HEVs, a machine learning framework that combines dynamic programming (DP) with machine learning to learn about roadway-type- and traffic-congestion-level-specific energy optimization, machine learning algorithms, and real-time quasi-optimal control of energy flow in an HEV. This first paper presents our research on machine learning for optimal energy management in HEVs. We will present a machine learning framework ML_EMO_HEV developed for the optimization of energy management in an HEV, machine learning algorithms for predicting driving environments, and the generation of an optimal power split for a given driving environment. Experiments are conducted based on a simulated Ford Escape Hybrid vehicle model provided by Argonne National Laboratory's Powertrain Systems Analysis Toolkit (PSAT). Based on the experimental results on the test data, we can conclude that the neural networks trained under the ML_EMO_HEV framework are effective in predicting roadway type and traffic congestion levels, predicting driving trends, and learning optimal engine speed and optimal battery power from DP.","0018-9545;00189545","","10.1109/TVT.2012.2206064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6236215","Energy optimization;fuel economy;hybrid electric vehicle (HEV) power management;machine learning","Batteries;Energy management;Engines;Fuels;Hybrid electric vehicles;Optimization","control engineering computing;dynamic programming;energy management systems;hybrid electric vehicles;learning (artificial intelligence);power control;power engineering computing","ML_EMO_HEV;PSAT;dynamic programming;hybrid electric vehicles;intelligent energy management;intelligent hybrid vehicle power control;machine learning algorithms;mathematical background;neural networks;optimal battery power;optimal engine speed;optimal power split;optimal vehicle power;power flow;powertrain systems analysis toolkit;roadway-type-energy optimization;traffic-congestion-level-specific energy optimization","","41","","","","20120710","Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Improving efficiency and reliability of building systems using machine learning and automated online evaluation","L. Wu; G. Kaiser; D. Solomon; R. Winter; A. Boulanger; R. Anderson","School of Engineering and Applied Science, Columbia University, New York, NY 10027, USA","2012 IEEE Long Island Systems, Applications and Technology Conference (LISAT)","20120625","2012","","","1","6","A high percentage of newly-constructed commercial office buildings experience energy consumption that exceeds specifications and system failures after being put into use. This problem is even worse for older buildings. We present a new approach, `predictive building energy optimization', which uses machine learning (ML) and automated online evaluation of historical and real-time building data to improve efficiency and reliability of building operations without requiring large amounts of additional capital investment. Our ML approach uses a predictive model to generate accurate energy demand forecasts and automated analyses that can guide optimization of building operations. In parallel, an automated online evaluation system monitors efficiency at multiple stages in the system workflow and provides building operators with continuous feedback. We implemented a prototype of this application in a large commercial building in Manhattan. Our predictive machine learning model applies Support Vector Regression (SVR) to the building's historical energy use and temperature and wet-bulb humidity data from the building's interior and exterior in order to model performance for each day. This predictive model closely approximates actual energy usage values, with some seasonal and occupant-specific variability, and the dependence of the data on day-of-the-week makes the model easily applicable to different types of buildings with minimal adjustment. In parallel, an automated online evaluator monitors the building's internal and external conditions, control actions and the results of those actions. Intelligent real-time data quality analysis components quickly detect anomalies and automatically transmit feedback to building management, who can then take necessary preventive or corrective actions. Our experiments show that this evaluator is responsive and effective in further ensuring reliable and energy-efficient operation of building systems.","","Electronic:978-1-4577-1343-9; POD:978-1-4577-1342-2","10.1109/LISAT.2012.6223192","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6223192","energy efficiency;green buildings;machine learning;prediction methods;reliability;statistical analysis;support vector machines","Buildings;Business;Data models;Meteorology;Predictive models;Reliability;Support vector machines","building management systems;embedded systems;energy conservation;failure analysis;investment;learning (artificial intelligence);optimisation;power consumption;regression analysis;reliability;support vector machines","Intelligent real-time data quality analysis components;ML approach;SVR;anomalies detection;application prototype;automated online evaluation system;automated online evaluator monitors;automatic feedback transmission;building external conditions;building internal conditions;building management;building operations efficiency;building operations reliability;building systems energy-efficient operation;capital investment;control actions;energy demand forecasts;energy usage values;newly-constructed commercial office buildings experience energy consumption;occupant-specific variability;older buildings;predictive building energy optimization;predictive machine learning model;real-time building data;support vector regression;system failures;system workflow;wet-bulb humidity data","","3","","13","","","4-4 May 2012","","IEEE","IEEE Conference Publications"
"A new approach to automatic disc localization in clinical lumbar MRI: Combining machine learning with heuristics","S. Ghosh; M. R. Malgireddy; V. Chaudhary; G. Dhillon","Department of Computer Science and Engineering, State University of New York (SUNY) at Buffalo, Buffalo, NY 14260","2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)","20120712","2012","","","114","117","Lower back pain (LBP) is widely prevalent in people all over the world and negatively affects the quality of life due to chronic pain and change in posture. Automatic localization of intervertebral discs from lumbar MRI is the first step towards computer-aided diagnosis of lower back ailments. Till date, most of the research has been useful in determining a point within each lumbar disc, hence we go one step further and propose a localization method which outputs a tight bounding box for each disc. We use HOG (Histogram of Oriented Gradients) features along with SVM (Support Vector Machine) as classifier and successfully combine these machine learning techniques with heuristics to achieve 99% disc localization accuracy on 53 clinical cases (318 lumbar discs). We also devise our own metrics to evaluate the accuracy and tightness of our disc bounding box and compare our results with previous research.","1945-7928;19457928","Electronic:978-1-4577-1858-8; POD:978-1-4577-1857-1","10.1109/ISBI.2012.6235497","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6235497","Automatic Disc Localization;Lumbar MRI","Accuracy;Feature extraction;Magnetic resonance imaging;Manuals;Measurement;Support vector machines;Training","biomedical MRI;diseases;image segmentation;learning (artificial intelligence);medical image processing;support vector machines","HOG features;SVM;automatic disc localization;chronic pain;clinical lumbar MRI;computer-aided diagnosis;disc bounding box;disc localization accuracy;intervertebral discs;localization method;lower back ailments;lower back pain;lumbar disc;machine learning techniques;support vector machine;tight bounding box","","3","","10","","","2-5 May 2012","","IEEE","IEEE Conference Publications"
"Machine Learning Algorithms in Bipedal Robot Control","S. Wang; W. Chaovalitwongse; R. Babuska","Department of Industrial and Systems Engineering, Rutgers, The State University of New Jersey, New Brunswick, USA","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","20120815","2012","42","5","728","743","Over the past decades, machine learning techniques, such as supervised learning, reinforcement learning, and unsupervised learning, have been increasingly used in the control engineering community. Various learning algorithms have been developed to achieve autonomous operation and intelligent decision making for many complex and challenging control problems. One of such problems is bipedal walking robot control. Although still in their early stages, learning techniques have demonstrated promising potential to build adaptive control systems for bipedal robots. This paper gives a review of recent advances on the state-of-the-art learning algorithms and their applications to bipedal robot control. The effects and limitations of different learning techniques are discussed through a representative selection of examples from the literature. Guidelines for future research on learning control of bipedal robots are provided in the end.","1094-6977;10946977","","10.1109/TSMCC.2012.2186565","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185691","Bipedal walking robots;learning control;reinforcement learning;supervised learning;unsupervised learning","Learning;Legged locomotion;Machine learning algorithms;Robot control;Supervised learning;Unsupervised learning","adaptive control;learning (artificial intelligence);legged locomotion","adaptive control systems;autonomous operation;bipedal walking robot control;intelligent decision making;learning control;machine learning algorithms;reinforcement learning;supervised learning;unsupervised learning","","6","","123","","20120417","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Performance Management of Virtual Machines via Passive Measurement and Machine Learning","T. Hayashi; S. Ohta","Dept. of Inf. Syst. Eng., Toyama Prefectural Univ., Imizu, Japan","2012 9th International Conference on Ubiquitous Intelligence and Computing and 9th International Conference on Autonomic and Trusted Computing","20121018","2012","","","533","538","Virtualization is commonly used to efficiently operate servers in data centers. The autonomic management of virtual machines enhances the advantages of virtualization. For the development of such management, it is important to establish a method to accurately detect performance degradation in virtual machines. This paper proposes a method that detects degradation via the passive measurement of traffic exchanged by virtual machines. Using passive traffic measurement is advantageous because it is robust against heavy loads, nonintrusive to the managed machines, and independent of hardware/software platforms. From the measured traffic metrics, performance state is determined by a machine learning technique that algorithmically determines the complex relationship between traffic metrics and performance degradation from training data. Moreover, the feasibility and effectiveness of the proposed method are confirmed experimentally.","","Electronic:978-0-7695-4843-2; POD:978-1-4673-3084-8","10.1109/UIC-ATC.2012.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6332044","passive measuremen;performance management;server management;traffic;virtualization","Degradation;Machine learning;Measurement;Monitoring;Servers;Training data;Virtual machining","computer centres;learning (artificial intelligence);software fault tolerance;virtual machines;virtualisation","autonomic virtual machine performance management;data centers;hardware-software platforms;machine learning;nonintrusive mechanism;passive traffic measurement;performance degradation detection;traffic exchange;traffic metrics;training data;virtualization","","2","","13","","","4-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"Estimation of turbulence closure coefficients for data centers using machine learning algorithms","S. Yarlanki; B. Rajendran; H. Hamann","IBM Research, 1101 Kitchwan Road, Yorktown Heights, NY, USA, 10598","13th InterSociety Conference on Thermal and Thermomechanical Phenomena in Electronic Systems","20120705","2012","","","38","42","CFD models of data centers often use two equation turbulence models such as the k-ε model. These models are based on closure coefficients or turbulence model constants determined from a combination of scaling/dimensional analysis and experimental measurements of flows in simple configurations. The simple configurations used to derive the turbulence model constants are often two dimensional and do not have many of the complex flow characteristics found in engineering flows. Such models perform poorly, especially in flows with large pressure gradients, swirl and strong three dimensionality, as in the case of data centers. This study attempts to use machine learning algorithms to optimize the model constants of the k-ε turbulence model for a data center by comparing simulated data with experimentally measured temperature values. For a given set of turbulence constants, we determine the Root Mean Square `error' in the model, defined as the difference between experimentally measured temperature from a data center test cell and CFD calculations using the k-ε model. An artificial neural network (ANN) based method for parameter identification is then used to find the optimal values for turbulence constants such that the error is minimized. The optimum turbulence model constants obtained by our study results in lowering the RMS error by 25% and absolute average error by 35% compared to the error obtained by using standard k-ε model constants.","1087-9870;10879870","Electronic:978-1-4244-9532-0; POD:978-1-4244-9533-7; USB:978-1-4244-9531-3","10.1109/ITHERM.2012.6231411","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6231411","CFD;artificial neural network;data center;k-ε model;non-linear constrained minimization;optimal model constants;turbulence","Artificial neural networks;Computational fluid dynamics;Data models;Equations;Mathematical model;Standards;Temperature measurement","computational fluid dynamics;computer centres;gradient methods;learning (artificial intelligence);mean square error methods;minimisation;neural nets;parameter estimation;turbulence","ANN based method;CFD calculations;CFD models;RMS error;absolute average error;artificial neural network;complex flow characteristics;data center test cell;data centers;dimensional analysis;engineering flows;equation turbulence models;error minimisation;experimental measurements;experimentally measured temperature;k-ε turbulence model;machine learning algorithms;optimal values;optimum turbulence model constants;parameter identification;pressure gradients;root mean square error;scaling analysis;simple configurations;simulated data;standard k-ε model constants;temperature values;turbulence closure coefficients estimation;turbulence constants","","4","","11","","","May 30 2012-June 1 2012","","IEEE","IEEE Conference Publications"
"A Machine Learning Approach to Android Malware Detection","J. Sahs; L. Khan","Univ. of Texas at Dallas, Dallas, TX, USA","2012 European Intelligence and Security Informatics Conference","20120913","2012","","","141","147","With the recent emergence of mobile platforms capable of executing increasingly complex software and the rising ubiquity of using mobile platforms in sensitive applications such as banking, there is a rising danger associated with malware targeted at mobile devices. The problem of detecting such malware presents unique challenges due to the limited resources avalible and limited privileges granted to the user, but also presents unique opportunity in the required metadata attached to each application. In this article, we present a machine learning-based system for the detection of malware on Android devices. Our system extracts a number of features and trains a One-Class Support Vector Machine in an offline (off-device) manner, in order to leverage the higher computing power of a server or cluster of servers.","","Electronic:978-0-7695-4782-4; POD:978-1-4673-2358-1","10.1109/EISIC.2012.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6298824","Computer Security;Data Mining;Support Vector Machines","Androids;Data mining;Feature extraction;Humanoid robots;Kernel;Malware;Vectors","feature extraction;invasive software;learning (artificial intelligence);meta data;mobile computing;smart phones;support vector machines","Android device;cluster computing;complex software execution;feature extraction;machine learning;malware detection;metadata;mobile device;support vector machine;ubiquitous computing","","28","","37","","","22-24 Aug. 2012","","IEEE","IEEE Conference Publications"
"Based on Machine Learning of Data Mining to Further Explore","Wu Yuntian","Faculty of Science, Shaanxi University of Science and Technology, Xi'an, China","2012 International Conference on Computer Science and Information Processing (CSIP)","20120924","2012","","","1235","1238","Machine learning and data mining is a powerful tool of the analysis of massive data, is emerging interdisciplinary of computer science and statistics, which plays an important role in the front field of modern science and technology. Introduction of machine learning information technology, further expounds the contact of the machine learning and data mining. Stratified discusses the meaning of data mining, in view of the different professions and different areas, points out how to use the data mining technology, give play to the role of machine learning. The emphasis is on data gathered information, use data information, and development data information resources.","","DVD:978-1-4673-1409-1; Electronic:978-1-4673-1411-4; POD:978-1-4673-1410-7","10.1109/CSIP.2012.6309082","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6309082","Machine learning;data mining;information technology;the development and application","Argon;Machine learning","data mining;learning (artificial intelligence);statistics","computer science;data gathered information;data information resources;data mining;machine learning information technology;statistics","","1","","10","","","24-26 Aug. 2012","","IEEE","IEEE Conference Publications"
"Non-Local Morphological PDEs and <formula formulatype=""inline""> <tex Notation=""TeX"">$p$</tex></formula>-Laplacian Equation on Graphs With Applications in Image Processing and Machine Learning","A. Elmoataz; X. Desquesnes; O. Lezoray","Image Team, Universit&#x00E9; de Caen Basse-Normandie and the ENSICAEN in the GREYC Laboratory, Caen cedex, France","IEEE Journal of Selected Topics in Signal Processing","20121012","2012","6","7","764","779","In this paper, we introduce a new class of non-local <i>p</i>-Laplacian operators that interpolate between non-local Laplacian and infinity Laplacian. These operators are discrete analogous of the game <i>p</i> -laplacian operators on Euclidean spaces, and involve discrete morphological gradient on graphs. We study the Dirichlet problem associated with the new <i>p</i>-Laplacian equation and prove existence and uniqueness of it's solution. We also consider non-local diffusion on graphs involving these operators. Finally, we propose to use these operators as a unified framework for solution of many inverse problems in image processing and machine learning.","1932-4553;19324553","","10.1109/JSTSP.2012.2216504","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6293841","<formula formulatype=""inline""> <tex Notation=""TeX"">$p$</tex></formula>-Laplacian;Image processing;PDEs-based morphology on graphs;machine learning;tug-of-war games","Equations;Games;Image processing;Laplace equations;Machine learning;Manifolds;Morphology","Laplace equations;graphs;image processing;interpolation;learning (artificial intelligence);partial differential equations","Dirichlet problem;Euclidean spaces;discrete morphological gradient;graphs;image processing;infinity Laplacian;interpolation;inverse problems;machine learning;nonlocal diffusion;nonlocal morphological PDE;p-Laplacian equation;p-Laplacian operators;partial differential equation","","11","","67","","20120831","Nov. 2012","","IEEE","IEEE Journals & Magazines"
"A machine learning framework of functional biomarker discovery for different microbial communities based on metagenomic data","W. Fang; X. Chang; X. Su; J. Xu; D. Zhang; K. Ning","Dept. of Preventive Veterinary Med., Northwest A &amp; F Univ., Xi'an, China","2012 IEEE 6th International Conference on Systems Biology (ISB)","20120927","2012","","","106","112","As more than 90% of microbial community could not be isolated and cultivated, the metagenomic methods have been commonly used to analyze the microbial community as a whole. With the fast acumination of metagenomic samples, it is now intriguing to find simple biomarkers, especially functional biomarkers, which could distinguish different metagenomic samples. Next-generation sequencing techniques have enabled the detection of very accurate gene-presence (abundance) values in metagenomic studies. And the presence/absence or different abundance values for a set of genes could be used as appropriate biomarker for identification of the corresponding microbial community's phenotype. However, it is not yet clear how to select such a set of genes (features), and how accurate would it be for such a set of selected genes on prediction of microbial community's phenotype. In this study, we have evaluated different machine learning methods, including feature selection methods and classification methods, for selection of biomarkers that could distinguish different samples. Then we proposed a machine learning framework, which could discover biomarkers for different microbial communities from the mining of metagenomic data. Given a set of features (genes) and their presence values in multiple samples, we first selected discriminative features as candidate by feature selection, and then selected the feature sets with low error rate and classification accuracies as biomarkers by classification method. We have selected whole genome sequencing data from simulation, public domain and in-house metagenomic data generation facilities. We tested the framework on prediction and evaluation of the biomarkers. Results have shown that the framework could select functional biomarkers with very high accuracy. Therefore, this framework would be a suitable tool to discover functional biomarkers to distinguish different microbial communities.","2164-2389;21642389","Electronic:978-1-4673-4398-5; POD:978-1-4673-4396-1; USB:978-1-4673-4397-8","10.1109/ISB.2012.6314121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6314121","ReliefF;biomarker;mRMR;machine learning;metagenomic","Bioinformatics;Communities;Error analysis;Gaussian distribution;Mice;Sensitivity;Systems biology","biology computing;cellular biophysics;data mining;feature extraction;genomics;learning (artificial intelligence);meta data;microorganisms","classification methods;feature selection methods;feature sets;functional biomarker discovery;gene-presence values;genome sequencing data;in-house metagenomic data generation facility;machine learning framework;metagenomic data mining;microbial community phenotype;next-generation sequencing technique;public domain","","0","","","","","18-20 Aug. 2012","","IEEE","IEEE Conference Publications"
"Bcl∷ChemInfo - Qualitative analysis of machine learning models for activation of HSD involved in Alzheimer's Disease","M. Butkiewicz; E. W. Lowe; J. Meiler","Chemistry at Vanderbilt University, Nashville TN, 37232, USA","2012 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20120614","2012","","","329","334","In this case study, a ligand-based virtual high throughput screening suite, bcl::ChemInfo, was applied to screen for activation of the protein target 17-beta hydroxysteroid dehydrogenase type 10 (HSD) involved in Alzheimer's Disease. bcl::ChemInfo implements a diverse set of machine learning techniques such as artificial neural networks (ANN), support vector machines (SVM) with the extension for regression, kappa nearest neighbor (KNN), and decision trees (DT). Molecular structures were converted into a distinct collection of descriptor groups involving 2D- and 3D-autocorrelation, and radial distribution functions. A confirmatory high-throughput screening data set contained over 72,000 experimentally validated compounds, available through PubChem. Here, the systematical model development was achieved through optimization of feature sets and algorithmic parameters resulting in a theoretical enrichment of 11 (44% of maximal enrichment), and an area under the ROC curve (AUC) of 0.75 for the best performing machine learning technique on an independent data set. In addition, consensus combinations of all involved predictors were evaluated and achieved the best enrichment of 13 (50%), and AUC of 0.86. All models were computed in silico and represent a viable option in guiding the drug discovery process through virtual library screening and compound prioritization a priori to synthesis and biological testing. The best consensus predictor will be made accessible for the academic community at www.meilerlab.org.","","Electronic:978-1-4673-1191-5; POD:978-1-4673-1190-8","10.1109/CIBCB.2012.6217248","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6217248","Area under the curve (AUC);Artificial Neural Network (ANN);Decision Trees (DT);Enrichment;Kohonen Network;Machine Learning;Quantitative Structure Activity Relation (QSAR);Receiver Operator Characteristics (ROC);Support Vector Machine (SVM);high-throughput screening (HTS);kappa - Nearest Neighbor (KNN)","Alzheimer's disease;Artificial neural networks;Biology;Compounds;Machine learning;Support vector machines","biochemistry;bioinformatics;decision trees;diseases;drugs;learning (artificial intelligence);medical computing;molecular biophysics;neural nets;optimisation;proteins;regression analysis;support vector machines","17-beta hydroxysteroid dehydrogenase type 10;2D-autocorrelation;3D-autocorrelation;ANN;Alzheimer disease;HSD activation;KNN;PubChem;SVM;algorithmic parameter;artificial neural networks;bcl::ChemInfo suite;compound prioritization;decision trees;descriptor groups;drug discovery process;feature set optimization;kappa nearest neighbor;machine learning model;molecular structures;protein target activation;radial distribution function;regression analysis;support vector machines;systematical model development;virtual high throughput screening suite;virtual library screening","","1","","29","","","9-12 May 2012","","IEEE","IEEE Conference Publications"
"Electricity Price Forecasting With Extreme Learning Machine and Bootstrapping","X. Chen; Z. Y. Dong; K. Meng; Y. Xu; K. P. Wong; H. W. Ngan","Ergon Energy, Brisbane, Australia","IEEE Transactions on Power Systems","20121018","2012","27","4","2055","2062","Artificial neural networks (ANNs) have been widely applied in electricity price forecasts due to their nonlinear modeling capabilities. However, it is well known that in general, traditional training methods for ANNs such as back-propagation (BP) approach are normally slow and it could be trapped into local optima. In this paper, a fast electricity market price forecast method is proposed based on a recently emerged learning method for single hidden layer feed-forward neural networks, the extreme learning machine (ELM), to overcome these drawbacks. The new approach also has improved price intervals forecast accuracy by incorporating bootstrapping method for uncertainty estimations. Case studies based on chaos time series and Australian National Electricity Market price series show that the proposed method can effectively capture the nonlinearity from the highly volatile price data series with much less computation time compared with other methods. The results show the great potential of this proposed approach for online accurate price forecasting for the spot market prices analysis.","0885-8950;08858950","","10.1109/TPWRS.2012.2190627","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184354","Bootstrapping;extreme learning machine;interval forecast;price forecast","Electricity supply industry;Forecasting;Learning systems;Machine learning;Predictive models;Time series analysis","chaos;feedforward neural nets;learning (artificial intelligence);load forecasting;power engineering computing;power markets;time series;training","ANN;Australian National Electricity market price series;ELM;artificial neural networks;chaos time series;electricity market price forecast method;extreme learning machine;incorporating bootstrapping method;nonlinear modeling capabilities;price interval forecasting;single hidden layer feedforward neural networks;spot market prices analysis;training methods;uncertainty estimations;volatile price data series","","55","","40","","20120416","Nov. 2012","","IEEE","IEEE Journals & Magazines"
"Action classification of humanoid soccer robots using machine learning","P. Nasrollahi; S. Jafari; M. Ebrahimi","Department of Computer Science, Shiraz University, Iran","The 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP 2012)","20120927","2012","","","598","603","This paper presents an alternative approach on humanoid soccer robots action classification in order to seize the ball control and better ball possession using machine learning and data mining classification algorithms. Categorizing proper actions regarding to positional and environmental features is a prerequisite for proper acting in robotics. In this paper we present an approach to gather information and extracting useful features out of that information from SimSpark simulation server logs. These gathered data will generate a meaningful multi-class dataset, afterwards data processing and running appropriate data mining algorithms on the dataset and evaluating our experiments are the most important issues in this paper. In order to achieve a model for classifying our multi-class dataset, we applied two well-known applications from the domain of data mining: TANAGRA and WEKA and finally we have visualized our experimental results as far as possible.","","Electronic:978-1-4673-1479-4; POD:978-1-4673-1478-7","10.1109/AISP.2012.6313816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6313816","Action classification;Boosting;Classification algorithms;Data models;Humanoid robots;Machine learning","Accuracy;Bagging;Classification algorithms;Data mining;Robots;Servers;Vegetation","control engineering computing;data mining;humanoid robots;learning (artificial intelligence);multi-robot systems;pattern classification","SimSpark simulation server logs;TANAGRA;WEKA;action classification;ball control;ball possession;data mining classification algorithms;data processing;humanoid soccer robots;machine learning;multiclass dataset","","0","","14","","","2-3 May 2012","","IEEE","IEEE Conference Publications"
"Design and Analysis of Machine Learning Experiments","E. Alpaydin","","Introduction to Machine Learning","20120924","2010","","","475","515","This chapter contains sections titled: 19.1 Introduction, 19.2 Factors, Response, and Strategy of Experimentation, 19.3 Response Surface Design, 19.4 Randomization, Replication, and Blocking, 19.5 Guidelines for Machine Learning Experiments, 19.6 Cross-Validation and Resampling Methods, 19.7 Measuring Classifier Performance, 19.8 Interval Estimation, 19.9 Hypothesis Testing, 19.10 Assessing a Classification Algorithm's Performance, 19.11 Comparing Two Classification Algorithms, 19.12 Comparing Multiple Algorithms: Analysis of Variance, 19.13 Comparison over Multiple Datasets, 19.14 Notes, 19.15 Exercises, 19.16 References","","97802622670","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6284951.pdf&bkn=6267367&pdfType=chapter","","","","","","","","","2010","","","","MIT Press","MIT Press eBook Chapters"
"Online detection of freezing of gait with smartphones and machine learning techniques","S. Mazilu; M. Hardegger; Z. Zhu; D. Roggen; G. Tröster; M. Plotnik; J. M. Hausdorff","Wearable Comput. Lab., Swiss Fed. Inst. of Technol., Zu&#x0308;rich, Switzerland","2012 6th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops","20120716","2012","","","123","130","Freezing of gait (FoG) is a common gait deficit in advanced Parkinson's disease (PD). FoG events are associated with falls, interfere with daily life activities and impair quality of life. FoG is often resistant to pharmacologic treatment; therefore effective non-pharmacologic assistance is needed. We propose a wearable assistant, composed of a smartphone and wearable accelerometers, for online detection of FoG. The system is based on machine learning techniques for automatic detection of FoG episodes. When FoG is detected, the assistant provides rhythmic auditory cueing or vibrotactile feedback that stimulates the patient to resume walking. We tested our solution on more than 8h of recorded lab data from PD patients that experience FoG in daily life. We characterize the system performance on user-dependent and user-independent experiments, with respect to different machine learning algorithms, sensor placement and preprocessing window size. The final system was able to detect FoG events with an average sensitivity and specificity of more than 95%, and mean detection latency of 0.34s in user-dependent settings.","2153-1633;21531633","Electronic:978-1-936968-43-5; POD:978-1-4673-1483-1; USB:978-1-936968-43-5","10.4108/icst.pervasivehealth.2012.248680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240371","","Automatic voltage control;Entropy;Manuals;Optimization;Sensitivity","accelerometers;learning (artificial intelligence);medical computing;sensor placement;smart phones","FoG episodes;Parkinson's disease;automatic detection;freezing of gait;machine learning;non-pharmacologic assistance;online detection;pharmacologic treatment;preprocessing window size;rhythmic auditory;sensor placement;smartphones;vibrotactile feedback;wearable accelerometers","","13","","32","","","21-24 May 2012","","IEEE","IEEE Conference Publications"
"Second-order methods for L1 regularized problems in machine learning","S. Hansen; J. Nocedal","Northwestern University, USA","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","5237","5240","This paper proposes a Hessian-free Newton method for solving large-scale convex functions with an L1 regularization term. These problems arise in supervised machine learning models in which it is important to seek a sparse parameter vector. The proposed method operates in a batch setting, which is well suited for parallel computing environments, and employs sub-sampled Hessian information to accelerate progress of the iteration. The method consists of two phases, an active-set prediction phase that employs first-order and second-order information, and subspace phase that performs a Newton-like step. Numerical results on a speech recognition problem illustrate the practical behavior of the method.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6289101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6289101","Hessian-Free Newton;Iterative Shrinkage;L1 Regularization;Logistic Regression;Newton Method","Machine learning;Minimization;Newton method;OWL;Optimization;Training;Vectors","Newton method;learning (artificial intelligence);speech recognition","Hessian-free Newton method;L1 regularized term problems;active-set prediction phase;first-order information;large-scale convex functions;machine learning;parallel computing environments;second-order information method;sparse parameter vector;speech recognition problem;subsampled Hessian information;supervised machine learning models","","0","","13","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Machine learning for the automatic identification of terrorist incidents in worldwide news media","R. Mason; B. McInnis; S. Dalal","RAND Corporation, Santa Monica, California, USA","2012 IEEE International Conference on Intelligence and Security Informatics","20120827","2012","","","84","89","The RAND Database of Worldwide Terrorism Incidents (RDWTI) seeks to index information about all terrorist incidents that occur and are mentioned in worldwide news media, providing a useful resource for policy researchers and decision makers. We examined automated classification methods that could be used to identify news articles about terrorist incidents, thus enabling analysts to read a smaller number of news articles and maintain the database with less effort and cost. The support vector machine (SVM) and Lasso methods were only modestly successful, but a classifier based on the gradient boosting method (GBM) appeared to be very successful, correctly ranking 80% of the relevant articles at the “top of the pile” for examination by a human analyst.","","Electronic:978-1-4673-2104-4; POD:978-1-4673-2105-1","10.1109/ISI.2012.6284096","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6284096","ElasticNet;Gradient Boosting;Lasso;Support Vector Machine;machine learning;news articles;terrorism","Databases;Humans;Standards;Support vector machines;Terrorism;Training;Training data","database management systems;gradient methods;learning (artificial intelligence);multimedia computing;support vector machines;terrorism","GBM;Lasso methods;RAND database;RDWTI;SVM;automated classification methods;automatic identification;decision makers;gradient boosting method;index information;machine learning;support vector machine;terrorist incidents;top of the pile;worldwide news media;worldwide terrorism incidents","","1","","6","","","11-14 June 2012","","IEEE","IEEE Conference Publications"
"Learning interactions among objects, tools and machines for planning","M. Ersen; S. Sariel-Talay","Artificial Intelligence and Robotics Laboratory, Department of Computer Engineering, Istanbul Technical University, Istanbul, Turkey","2012 IEEE Symposium on Computers and Communications (ISCC)","20120726","2012","","","000361","000366","We propose a method for learning interactions among objects when intermediate state information is not available. Learning is accomplished by observing a given sequence of actions on different objects. We have selected the Incredible Machine game as a suitable domain for analyzing and learning object interactions. We first present how behaviors are represented by finite state machines using the given input. Then, we analyze the impact of the knowledge about relations on the overall performance. Our analysis includes four different types of input: a knowledge base including part relations; spatial information; temporal information; and spatio-temporal information. We show that if a knowledge base about relations is provided, learning is accomplished to a desired extent. Our analysis also indicates that the spatio-temporal approach is superior to the spatial and the temporal approaches and gives close results to that of the knowledge-based approach.","1530-1346;15301346","Electronic:978-1-4673-2713-8; POD:978-1-4673-2712-1; USB:978-1-4673-2711-4","10.1109/ISCC.2012.6249322","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249322","agent-based systems;automated planning;knowledge representation;learning","Games;Knowledge based systems;Machine learning;Mixers;Planning;Switches;Tutorials","computer aided instruction;computer games;finite state machines;knowledge representation;learning (artificial intelligence);planning (artificial intelligence);user interfaces","agent-based systems;automated action planning;finite state machines;incredible machine game;knowledge representation;knowledge-based approach;object interaction analysis;object interaction learning;part relations;spatial information;spatio-temporal information;temporal information","","2","","9","","","1-4 July 2012","","IEEE","IEEE Conference Publications"
"Connective prediction using machine learning for implicit discourse relation classification","Y. Xu; M. Lan; Yue Lu; Z. Y. Niu; C. L. Tan","East China Normal University, China","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","8","Implicit discourse relation classification is a challenge task due to missing discourse connective. Some work directly adopted machine learning algorithms and linguistically informed features to address this task. However, one interesting solution is to automatically predict implicit discourse connective. In this paper, we present a novel two-step machine learning-based approach to implicit discourse relation classification. We first use machine learning method to automatically predict the discourse connective that can best express the implicit discourse relation. Then the predicted implicit discourse connective is used to classify the implicit discourse relation. Experiments on Penn Discourse Treebank 2.0 (PDTB) and Biomedical Discourse Relation Bank (BioDRB) show that our method performs better than the baseline system and previous work.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252548","","Optimization;Support vector machines","learning (artificial intelligence);natural language processing;pattern classification","BioDRB;PDTB;Penn Discourse Treebank 2.0;automatically implicit discourse connective prediction;biomedical discourse relation bank;implicit discourse relation classification;machine learning algorithms;two-step machine learning-based approach","","2","","27","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Dynamic switching and real-time machine learning for improved human control of assistive biomedical robots","P. M. Pilarski; M. R. Dawson; T. Degris; J. P. Carey; R. S. Sutton","Department of Computing Science, University of Alberta, Edmonton, Alberta, T6G 2E8, Canada","2012 4th IEEE RAS & EMBS International Conference on Biomedical Robotics and Biomechatronics (BioRob)","20120830","2012","","","296","302","A general problem for human-machine interaction occurs when a machine's controllable dimensions outnumber the control channels available to its human user. In this work, we examine one prominent example of this problem: amputee switching between the multiple functions of a powered artificial limb. We propose a dynamic switching approach that learns during ongoing interaction to anticipate user behaviour, thereby presenting the most effective control option for a given context or task. Switching predictions are learned in real time using temporal difference methods and reinforcement learning, and demonstrated within the context of a robotic arm and a multifunction myoelectric controller. We find that a learned, dynamic switching order is able to out-perform the best fixed (non-adaptive) switching regime on a standard prosthetic proficiency task, increasing the number of optimal switching suggestions by 23%, and decreasing the expected transition time between degrees of freedom by more than 14%. These preliminary results indicate that real-time machine learning, specifically online prediction and anticipation, may be an important tool for developing more robust and intuitive controllers for assistive biomedical robots. We expect these techniques will transfer well to near-term use by patients. Future work will describe clinical testing of this approach with a population of amputee patients.","2155-1774;21551774","Electronic:978-1-4577-1200-5; POD:978-1-4577-1199-2","10.1109/BioRob.2012.6290309","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6290309","","Electromyography;Humans;Joints;Robots;Switches;Vectors","artificial limbs;electromyography;human-robot interaction;learning (artificial intelligence);manipulators;medical robotics;medical signal processing;time-varying systems;user interfaces","amputee switching;assistive biomedical robots;clinical testing;control channels;dynamic switching;human-machine interaction;improved human control;multifunction myoelectric controller;powered artificial limb;prosthetic proficiency task;real-time machine learning;reinforcement learning;robotic arm;temporal difference methods;user behaviour","","8","","14","","","24-27 June 2012","","IEEE","IEEE Conference Publications"
"Evaluating the Internationalization Success of Companies Through a Hybrid Grouping Harmony Search—Extreme Learning Machine Approach","I. Landa-Torres; E. G. Ortiz-Garcia; S. Salcedo-Sanz; M. J. Segovia-Vargas; S. Gil-Lopez; M. Miranda; J. M. Leiva-Murillo; J. Del Ser","Telecom Unit of Tecnalia Research & Innovation, Zamudio, Bizkaia, Spain","IEEE Journal of Selected Topics in Signal Processing","20120713","2012","6","4","388","398","The internationalization of a company is widely understood as the corporative strategy for growing through external markets. It usually embodies a hard process, which affects diverse activities of the value chain and impacts on the organizational structure of the company. There is not a general model for a successful international company, so the success of an internationalization procedure must be estimated based on different variables addressing the status, strategy and market characteristics of the company at hand. This paper presents a novel hybrid soft-computing approach for evaluating the internationalization success of a company based on existing past data. Specifically, we propose a hybrid algorithm composed by a grouping-based harmony search (HS) approach and an extreme learning machine (ELM) ensemble. The proposed hybrid scheme further incorporates a feature selection method, which is obtained by means of a given group in the HS encoding format, whereas the ELM ensemble renders the final accuracy metric of the model. Practical results for the proposed hybrid technique are obtained in a real application based on the exporting success of Spanish manufacturing companies, which are shown to be satisfactory in comparison with alternative state-of-the-art techniques.","1932-4553;19324553","","10.1109/JSTSP.2012.2199463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200298","Company internationalization;ensembles;exporting performance;extreme learning machines;harmony search (HS);hybrid algorithms","Companies;Economics;Electronic mail;Machine learning;Signal processing algorithms;Training","international trade;learning (artificial intelligence)","Spanish manufacturing company;corporative strategy;diverse activity;exporting;external markets;extreme learning machine ensemble;feature selection method;grouping-based harmony search;hard process;hybrid algorithm;hybrid grouping harmony search-extreme learning machine;hybrid soft computing;international company;internationalization procedure;internationalization success;organizational structure;value chain","","12","","44","","20120515","Aug. 2012","","IEEE","IEEE Journals & Magazines"
"Machine learning approach towards email management","T. Ayodele; G. Akmayeva; C. A. Shoniregun","Machine Learning Lab, Infonetmedia Ltd, Portsmouth, United Kingdom","World Congress on Internet Security (WorldCIS-2012)","20120823","2012","","","106","109","Originally supposed to be a communication application, email is now used for a wide range of functions. Nowadays, it is increasingly becoming very difficult for email users to keep track of their email messages and to organize them such that can be retrieved easily, changed, and managed. Email tools, however have not progressed correspondingly to support users with information management based on users' need. These tools do not understand the information they contain, so they are unable to help user manage it. The goal of this research is to provide a better intelligent email manager that can help to understand, manage, organize and use the overwhelming amount of information received and stored to capture the semantic content relations and also to build intelligent tools to assist with the management of the semantic relations.","","Electronic:978-1-908320-04-9; POD:978-1-4673-1108-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6280208","Intelligent email manager;Intelligent tools;email;email management;email messages;semantic conten;semantic relations","Electronic mail;Humans;Machine learning;Postal services;Semantics;Visualization","electronic mail;learning (artificial intelligence)","email management;email tools;email users;information management;intelligent email manager;machine learning approach;semantic content relations","","0","","8","","","10-12 June 2012","","IEEE","IEEE Conference Publications"
"An Efficient High-Frequency Linear RF Amplifier Synthesis Method Based on Evolutionary Computation and Machine Learning Techniques","B. Liu; N. Deferm; D. Zhao; P. Reynaert; G. G. E. Gielen","Katholieke Universiteit Leuven, Leuven, Belgium","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20120614","2012","31","7","981","993","Existing radio frequency (RF) integrated circuit (IC) design automation methods focus on the synthesis of circuits at a few GHz, typically less than 10 GHz. That framework is difficult to apply to RF IC synthesis at mm-wave frequencies (e.g., 60-100 GHz). In this paper, a new method, called efficient machine learning-based differential evolution, is presented for mm-wave frequency linear RF amplifier synthesis. By using electromagnetic (EM) simulations to evaluate the key passive components, the evaluation of circuit performances is accurate and solves the limitations of parasitic-included equivalent circuit models and predefined layout templates used in the existing synthesis framework. A decomposition method separates the design variables that require expensive EM simulations and the variables that only need cheap circuit simulations. Hence, a low- dimensional expensive optimization problem is generated. By the newly proposed core algorithm integrating adaptive population generation, naive Bayes classification, Gaussian process and differential evolution, the generated low-dimensional expensive optimization problem can be solved efficiently (by the online surrogate model), and global search (by evolutionary computation) can be achieved. A 100 GHz three-stage differential amplifier is synthesized in a 90 nm CMOS technology. The power gain reaches 10 dB with more than 20 GHz bandwidth. The synthesis costs only 25 h, having a comparable result and a nine times speed enhancement compared with directly using the EM simulator and global optimization algorithms.","0278-0070;02780070","","10.1109/TCAD.2012.2187207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6218230","Differential evolution;Gaussian process;efficient global optimization;expensive black-box optimization;mm-wave frequency;radio frequency (RF) circuit synthesis","Computational modeling;Inductors;Integrated circuit modeling;Optimization;Power transmission lines;Radio frequency;Transistors","CMOS integrated circuits;Gaussian processes;HF amplifiers;differential amplifiers;equivalent circuits;evolutionary computation;field effect MIMIC;learning (artificial intelligence);millimetre wave amplifiers","CMOS technology;EM simulator;Gaussian process;adaptive population generation;core algorithm;evolutionary computation;frequency 60 GHz to 100 GHz;gain 10 dB;global optimization algorithm;high frequency linear RF amplifier synthesis;machine learning-based differential evolution;millimeter wave linear RF amplifier synthesis;naive Bayes classification;parasitic-included equivalent circuit models;predefined layout templates;radiofrequency integrated circuit design automation;size 90 nm;three-stage differential amplifier;time 25 h","","9","","32","","","July 2012","","IEEE","IEEE Journals & Magazines"
"Security Enhancement in Wireless Sensor Networks Using Machine Learning","A. B. Raj; M. V. Ramesh; R. V. Kulkarni; H. T.","Amrita Center for Wireless Networks & Applic., Vidyapeetham, India","2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems","20121018","2012","","","1264","1269","Ensuring the security of wireless sensor networks (WSNs) is vital for monitoring real-time systems. One of the major security flaws experienced by WSNs is denial of service (DoS) which can even lead to the breakdown of the complete system or to wrong decisions being made by the system that can cause adverse results. This research work focuses on two techniques for detecting a DoS attack at a medium access control (MAC) layer. Our research compares and evaluates the performance of two major machine learning techniques: neural network (NN) and support vector machine (SVM). Vanderbilt Prowler is used for simulating the scenarios. In the simulations, normalized critical parameters and their corresponding probabilities of DoS attack are computed in 50 trial runs. These normalized critical parameters and their corresponding probabilities of DoS attack are used as training inputs in NN and SVM approaches. The simulation results clearly show that SVM provides better accuracy compared to NN, 97% accuracy by SVM and 91% accuracy by NN. The simulation also shows that SVM takes much less time to detect and determine the probability of a DoS attack, 0.25 seconds by SVM and 0.75 seconds by NN. All these results clearly show that SVM performs better than NN when used for detecting the probability of DoS attack in WSNs.","","Electronic:978-0-7695-4749-7; POD:978-1-4673-2164-8","10.1109/HPCC.2012.186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6332322","Denial of Service;Neural Network;Security;Support Vector Machine;Wireless Sensor Networks","Artificial neural networks;Computer crime;Support vector machines;Training;Vectors;Wireless sensor networks","access protocols;learning (artificial intelligence);neural nets;probability;real-time systems;support vector machines;telecommunication security;wireless sensor networks","DoS attack probability detection;MAC;SVM;WSN;denial of service;machine learning;medium access control;neural network;real-time system monitoring;security enhancement;security flaw;support vector machine;wireless sensor network","","2","","14","","","25-27 June 2012","","IEEE","IEEE Conference Publications"
"Stochastic optimization for learning Non-Convex Linear Support Vector Machines","J. Chen; J. Wang; Y. Zhang; J. Lu; Y. Li","Institute of Command Automation, PLA University of Science and Technology, Nanjing 210007, China","2012 IEEE International Conference on Intelligent Control, Automatic Detection and High-End Equipment","20121015","2012","","","35","39","In this paper, a fast optimization algorithm was proposed to learn the Non-Convex Linear Support Vector Machines (LSVM-NC) based on stochastic optimization, in which the non-convex function, Ramp Loss, was used to suppress the influence of noisy data in the case of large-scale learning problems. As for solving the non-convex linear SVMs, the traditional methods make use of the ConCave-Convex Procedure (CCCP) based on the Sequential Minimal Optimization (SMO) algorithm from dual, which is a time-consuming process and impractical for learning large-scale problems. To tackle this, we resorted to CCCP based on Stochastic Gradient Descent (SGD) algorithm from primal, and experimental results proved that our method could reduce the training time largely and improve the generalization performance.","","Electronic:978-1-4673-1332-2; POD:978-1-4673-1331-5","10.1109/ICADE.2012.6330094","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6330094","Large-Scale Machine Learning;Non-Convex Linear Support Vector Machines;Stochastic Gradient Descent","Machine learning;Machine learning algorithms;Optimization;Stochastic processes;Support vector machines;Testing;Training","gradient methods;learning (artificial intelligence);optimisation;support vector machines","CCCP;LSVM-NC;SGD;SMO;concave-convex procedure;fast optimization algorithm;nonconvex linear support vector machine learning;ramp loss;sequential minimal optimization algorithm;stochastic gradient descent algorithm;stochastic optimization","","0","","12","","","27-29 July 2012","","IEEE","IEEE Conference Publications"
"Cooperative Machine Learning with Information Fusion for Dynamic Decision Making in Diagnostic Applications","D. Vidhate; P. Kulkarni","","2012 International Conference on Advances in Mobile Network, Communication and Its Applications","20120906","2012","","","70","74","In many applications, use of all relevant data to extract more information from multiple sources of information and achieve higher accuracy in prediction is desirable. Cooperative learning is observed in human and some animal societies. Sound knowledge and information acquisition, cooperation in learning amongst multi-agent systems may result in a higher effectiveness compared to individual learning. Cooperative learning in multi agent systems is generally expected to improve both quality & speed of learning. According to survey maximum research papers focus on coordinated approach of agents. Multiple sources of data can be viewed as different, related views of the same learning problem, where dependencies between the views could potentially take on complex structures. This gives rise to interesting and challenging machine learning problems where data sources are combined for learning. This framework encompasses several data fusion tasks and related topics, such as transfer learning, multitask learning, multiview learning, and learning under covariate shift. The advantages of the multiple source learning paradigm is seen in situations where individual data sources are noisy, incomplete, and learning from more than one source can filter out problem-independent noise. Cooperative learning is an approach where one or more team of learners work together towards reaching a better understanding of a specified task. The purpose of this paper is to use this approach to describe a proposal for designing and building a cooperative machine learning system (Multi-Learning system) that contains two or more machine learners that cooperate together.","","Electronic:978-0-7695-4720-6; POD:978-1-4673-1869-3","10.1109/MNCApps.2012.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6295755","Cooperative Decision Making;Information Fusion;Machine Learning;Reinforcement Learning","Computers;Decision making;Educational institutions;Learning;Learning systems;Machine learning;Multiagent systems","decision making;learning (artificial intelligence);sensor fusion","cooperative machine learning system;covariate shift learning;data fusion tasks;data sources;diagnostic applications;dynamic decision making;information acquisition;information fusion;multiagent systems;multiple source learning paradigm;multitask learning;multiview learning;sound knowledge;transfer learning","","2","","43","","","1-2 Aug. 2012","","IEEE","IEEE Conference Publications"
"Machine learning for computational sustainability","T. Dietterich; E. Dereszynski; R. Hutchinson; D. Sheldon","School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, 97331 USA","2012 International Green Computing Conference (IGCC)","20121004","2012","","","1","1","To avoid ecological collapse, we must manage Earth's ecosystems sustainably. Viewed as a control problem, the two central challenges of ecosystem management are to acquire a model of the system that is sufficient to guide good decision making and then optimize the control policy against that model. This paper describes three efforts aimed at addressing the first of these challenges-machine learning methods for modeling ecosystems. The first effort focuses on automated quality control of environmental sensor data. Next, we consider the problem of learning species distribution models from citizen science observational data. Finally, we describe a novel approach to modeling the migration of birds. A major challenge for all of these methods is to scale up to large, spatially-distributed systems.","","Electronic:978-1-4673-2154-9; POD:978-1-4673-2155-6; USB:978-1-4673-2153-2","10.1109/IGCC.2012.6322258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6322258","computational sustainability;dynamical ecosystem models;hidden Markov models;species distribution models","Biological system modeling;Birds;Data models;Ecosystems;Hidden Markov models;Sociology;Statistics","decision making;ecology;learning (artificial intelligence);sustainable development","Earth ecosystem sustainability;automated quality control;bird migration modeling;citizen science observational data;computational sustainability;control policy optimization;decision making;ecological collapse;ecosystem management;ecosystem modeling;environmental sensor data;machine learning;spatially-distributed systems;species distribution model learning","","0","","","","","4-8 June 2012","","IEEE","IEEE Conference Publications"
"A comparison of machine learning techniques for modeling human-robot interaction with children with autism","E. Short; D. Feil-Seifer; M. Matarić","Univ. of Southern California, Dept. of Computer Science, Los Angeles, USA","2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","20120827","2011","","","251","252","Several machine learning techniques are used to model the behavior of children with autism interacting with a humanoid robot, comparing a static model to a dynamic model using hand-coded features. Good accuracy (over 80%) is achieved in predicting child vocalizations; directions for future approaches to modeling the behavior of children with autism are suggested.","2167-2121;21672121","Electronic:978-1-4673-4395-4; POD:978-1-4673-4393-0; USB:978-1-4503-0561-7","10.1145/1957656.1957756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6281322","Human-robot interaction;autism;machine learning","Autism;Computational modeling;Decision trees;Error analysis;Machine learning;Robots;USA Councils","human-robot interaction;learning (artificial intelligence)","autistic children;child vocalizations;dynamic model;hand-coded features;human-robot interaction;humanoid robot;machine learning techniques;static model","","0","","9","","","8-11 March 2011","","IEEE","IEEE Conference Publications"
"Using machine learning to enhance automated requirements model transformation","E. V. Chioaşcă","School of Computer Science University of Manchester","2012 34th International Conference on Software Engineering (ICSE)","20120628","2012","","","1487","1490","Textual specification documents do not represent a suitable starting point for software development. This issue is due to the inherent problems of natural language such as ambiguity, impreciseness and incompleteness. In order to overcome these shortcomings, experts derive analysis models such as requirements models. However, these models are difficult and costly to create manually. Furthermore, the level of abstraction of the models is too low, thus hindering the automated transformation process. We propose a novel approach which uses high abstraction requirements models in the form of Object System Models (OSMs) as targets for the transformation of natural language specifications in conjunction with appropriate text mining and machine learning techniques. OSMs allow the interpretation of the textual specification based on a small set of facts and provide structural and behavioral information. This approach will allow both (1) the enhancement of minimal specifications, and in the case of comprehensive specifications (2) the determination of the most suitable structure of reusable requirements.","0270-5257;02705257","Electronic:978-1-4673-1067-3; POD:978-1-4673-1066-6","10.1109/ICSE.2012.6227055","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227055","Natural language specification;Object System Models;machine learning;text mining","Analytical models;Containers;Natural languages;Object oriented modeling;Object recognition;Unified modeling language","data mining;learning (artificial intelligence);natural language processing;software engineering;text analysis","OSM;automated requirements model transformation;high abstraction requirements models;machine learning;natural language specifications;object system models;software development;text mining;textual specification documents","","2","","13","","","2-9 June 2012","","IEEE","IEEE Conference Publications"
"Dependance of critical dimension on learning machines and ranking methods","D. Suryakumar; A. H. Sung; Q. Liu","Department of Computer Science and Engineering, New Mexico Institute of Mining and Technology, Socorro, USA","2012 IEEE 13th International Conference on Information Reuse & Integration (IRI)","20120917","2012","","","738","739","Feature reduction is a major problem in data mining. Though traditional methods such as feature ranking and subset selection have been widely used, there has been little consideration given to assuring satisfactory performance of a learning machine in relation to the minimum of features required or the “critical dimension”. This critical dimension is unique to a specific dataset, learning machine, and ranking algorithm combination. The empirical methods demonstrate that many datasets show the existence of critical dimension. The dependence of this critical dimension on the learning machines and ranking algorithms could provide newer insights in understanding datasets, machine learning classifiers and ranking algorithms. The preliminary results of analysis show that the critical dimension depends largely on the feature ranking algorithm and that learning machines are less significant in determining the critical dimension.","","Electronic:978-1-4673-2284-3; POD:978-1-4673-2282-9; USB:978-1-4673-2283-6","10.1109/IRI.2012.6303086","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6303086","Feature reduction;machine learning;ranking","Accuracy;Feature extraction;Machine learning;Machine learning algorithms;Niobium;Radio frequency;Support vector machines","data mining;learning (artificial intelligence);pattern classification","critical dimension dependance;data mining;empirical methods;feature ranking algorithm;feature reduction;machine learning classifiers;ranking algorithm combination;ranking methods;subset selection","","0","","4","","","8-10 Aug. 2012","","IEEE","IEEE Conference Publications"
"A mobile expert system for tutoring multiple languages using machine learning","M. Virvou; E. Alepis; C. Troussas","Department of Informatics, University of Piraeus, Piraeus, Greece","2012 International Conference on E-Learning and E-Technologies in Education (ICEEE)","20121018","2012","","","128","133","Towards the creation of a mobile expert tutoring system that teaches multiple languages, we have incorporated machine learning approaches into a sophisticated mobile system. The mobile system provides adaptivity to user needs based on the creation of user models. The resulting superset that consists of all user/student models is further processed by two machine learning approaches in order to create user model clusters and to provide sophisticated data as stereotypes for new potential users.","","Electronic:978-1-4673-1678-1; POD:978-1-4673-1679-8","10.1109/ICeLeTE.2012.6333376","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6333376","k-means algorithm;machine learning;mobile assisted language learning;stereotypes;user modeling","Adaptation models;Biological system modeling;Clustering algorithms;Educational institutions;Machine learning;Mobile communication;Mobile handsets","expert systems;intelligent tutoring systems;mobile computing;natural language processing","machine learning;mobile expert tutoring system;multiple languages;user model clusters","","2","","20","","","24-26 Sept. 2012","","IEEE","IEEE Conference Publications"
"Autonomous robotic ground penetrating radar surveys of ice sheets; Using machine learning to identify hidden crevasses","R. M. Williams; L. E. Ray; J. H. Lever","Thayer School of Engineering, Dartmouth College, Hanover, New Hampshire 03755, USA","2012 IEEE International Conference on Imaging Systems and Techniques Proceedings","20120917","2012","","","7","12","This paper presents methods to continue development of a completely autonomous robotic system employing ground penetrating radar imaging of the glacier sub-surface. We use well established machine learning algorithms and appropriate un-biased processing, particularly those which are also suitable for real-time image analysis and detection. We tested and evaluated three processing schemes in conjunction with a Support Vector Machine (SVM) trained on 15 examples of Antarctic GPR imagery, collected by our robot and a Pisten Bully tractor in 2010 in the shear zone near McMurdo Station. Using a modified cross validation technique, we correctly classified all examples with a radial basis kernel SVM trained and evaluated on down-sampled and texture-mapped GPR images of crevasses, compared to 60% classification rate using raw data. We also test the most successful processing scheme on a larger dataset, comprised of 94 GPR images of crevasse crossings recorded in the same deployment. Our experiments demonstrate the promise and reliability of real-time object detection and classification with robotic GPR imaging surveys.","1558-2809;15582809","Electronic:978-1-4577-1775-8; POD:978-1-4577-1776-5","10.1109/IST.2012.6295593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6295593","","Antarctica;Diffraction;Ground penetrating radar;Real time systems;Robots;Snow;Support vector machines","geophysical image processing;glaciology;ground penetrating radar;image classification;radar imaging;remote sensing by radar","Antarctic GPR imagery;McMurdo Station;Pisten Bully tractor;Support Vector Machine;autonomous robotic ground penetrating radar surveys;classification rate;glacier sub-surface;ground penetrating radar imaging;ice sheets;machine learning algorithms;modified cross validation technique;radial basis kernel SVM;raw data;real-time object classification;real-time object detection;robotic GPR imaging surveys;texture-mapped GPR images","","2","","15","","","16-17 July 2012","","IEEE","IEEE Conference Publications"
"Adaptive sampling in context-aware systems: A machine learning approach","A. L. Wood; G. V. Merrett; S. R. Gunn; B. M. Al-Hashimi; N. R. Shadbolt; W. Hall","Electronics and Computer Science, University of Southampton, UK, SO17 1BJ","IET Conference on Wireless Sensor Systems (WSS 2012)","20120903","2012","","","1","5","As computing systems become ever more pervasive, there is an increasing need for them to understand and adapt to the state of the environment around them: that is, their context. This understanding comes with considerable reliance on a range of sensors. However, portable devices are also very constrained in terms of power, and hence the amount of sensing must be minimised. In this paper, we present a machine learning architecture for context awareness which is designed to balance the sampling rates (and hence energy consumption) of individual sensors with the significance of the input from that sensor. This significance is based on predictions of the likely next context. The architecture is implemented using a selected range of user contexts from a collected data set. Simulation results show reliable context identification results. The proposed architecture is shown to significantly reduce the energy requirements of the sensors with minimal loss of accuracy in context identification.","","Electronic:978-1-84919-625-3","10.1049/cp.2012.0608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6294368","adaptive sampling;context awareness;energy efficiency","","learning (artificial intelligence);mobile computing;software architecture;software reliability","adaptive sampling;context identification reliability;context-aware systems;machine learning architecture;minimal accuracy loss;mobile computing;portable devices","","1","","","","","18-19 June 2012","","IET","IET Conference Publications"
"Computer aided diagnosis system based on machine learning techniques for lung cancer","H. R. H. Al-Absi; B. B. Samir; K. B. Shaban; S. Sulaiman","Dept. of Comput. &amp; Inf. Sci., Univ. Teknol. PETRONAS, Tronoh, Malaysia","2012 International Conference on Computer & Information Science (ICCIS)","20120910","2012","1","","295","300","Cancer is a leading cause of death worldwide. Lung cancer is a type of cancer that is considered as one of the most leading causes of death globally. In Malaysia, it is the 3rd common cancer type and the 2nd type of cancer among men. In this paper, machine learning techniques have been utilized to develop a computer-aided diagnosis system for lung cancer. The system consists of feature extraction phase, feature selection phase and classification phase. For feature extraction/selection, different wavelets functions have been applied in order to find the one that produced the highest accuracy. Clustering-K-nearest-neighbor algorithm has been developed/utilized for classification. Japanese Society of Radiological Technology's standard dataset of lung cancer has been used to test the system. The data set has 154 nodule regions (abnormal) and 92 non-nodule regions (normal). Accuracy levels of over 96% for classification have been achieved which demonstrate the merits of the proposed approach.","","DVD:978-1-4673-1936-2; Electronic:978-1-4673-1938-6; POD:978-1-4673-1937-9","10.1109/ICCISci.2012.6297257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6297257","","Accuracy;Feature extraction;Lead;Lungs","cancer;feature extraction;image classification;medical image processing;patient diagnosis;pattern clustering","Japanese Society of Radiological Technology standard dataset;Malaysia;classification phase;clustering-k-nearest-neighbor algorithm;computer-aided diagnosis system;feature extraction phase;feature selection phase;lung cancer;machine learning techniques","","2","","15","","","12-14 June 2012","","IEEE","IEEE Conference Publications"
"Machine Learning and Adaptivity","M. P. Wellman; A. Greenwald; P. Stone","","Autonomous Bidding Agents:Strategies and Lessons from the Trading Agent Competition","20120924","2007","","","117","142","This chapter contains sections titled: Adaptivity for Last-Moment Bidding, Learning Distributions for Hotel Price Prediction, ATTac-01, ATTac-01 Results, Summary","","97802622859","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6275180.pdf&bkn=6267448&pdfType=chapter","","","","","","","","","2007","","","","MIT Press","MIT Press eBook Chapters"
"Machine learning and software engineering in health informatics","D. A. Clifton; J. Gibbons; J. Davies; L. Tarassenko","Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, UK","2012 First International Workshop on Realizing AI Synergies in Software Engineering (RAISE)","20120702","2012","","","37","41","Health informatics is a field in which the disciplines of software engineering and machine learning necessarily co-exist. This discussion paper considers the interaction of software engineering and machine learning, set within the context of health informatics, where the scale of clinical practice requires new engineering approaches from both disciplines. We introduce applications implemented in large on-going research programmes undertaken between the Departments of Engineering Science and Computer Science at Oxford University, the Oxford University Hospitals NHS Trust, and the Guy's and St Thomas' NHS Foundation Trust, London.","","Electronic:978-1-4673-1753-5; POD:978-1-4673-1752-8","10.1109/RAISE.2012.6227968","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227968","","Bayesian methods;Informatics;Machine learning;Machine learning algorithms;Software;Software algorithms;Software engineering","health care;learning (artificial intelligence);medical information systems;software engineering","clinical practice;health informatics;machine learning;software engineering","","2","","25","","","5-5 June 2012","","IEEE","IEEE Conference Publications"
"Machine learning methods in data fusion systems","R. Nowak; R. Biedrzycki; J. Misiurewicz","Institute of Electronic Systems, Warsaw University of Technology, Poland","2012 13th International Radar Symposium","20120709","2012","","","400","405","In heterogeneous, multisensor and multitarget data fusion systems the notion of “levels” is used in order to divide the complex problem of discovering relationships between objects into parts which are easier to understand. In presented paper we consider classifiers as general feature generators, these algorithms are able to connect data from different sensors and different observations. The classifier increases the level of data abstraction, which simplifies the architecture of following system components in data fusion chain. A data fusion engine named DAFNE uses the presented paradigm in its classifier module. The module was implemented in Python and C++, the Naïve Bayesian and decision tree classifiers were used. The tests on simulated data shows improvement of data quality via fusion. The system design allowed to attain real-time processing with limited data volume.","2155-5745;21555745","Electronic:978-1-4577-1837-3; POD:978-1-4577-1838-0","10.1109/IRS.2012.6233354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233354","applications;classifier;data fusion;machine learning","Decision trees;Humans;Niobium;Sensor phenomena and characterization;Training;Vehicles","C++ listings;belief networks;computerised instrumentation;data structures;decision trees;learning (artificial intelligence);pattern classification;sensor fusion","C++ implementation;DAFNE data fusion engine;Python implementation;data abstraction;data connection;data quality;data volume;decision tree classifier;feature generator;machine learning method;multisensor data fusion system;multitarget data fusion system;naive Bayesian","","0","","15","","","23-25 May 2012","","IEEE","IEEE Conference Publications"
"GUI reverse engineering with machine learning","I. C. Morgado; A. C. R. Paiva; J. P. Faria; R. Camacho","Department of Informatics Engineering, Faculty of Engineering, University of Porto, rua Dr. Roberto Frias, 4200-465 Porto, Portugal","2012 First International Workshop on Realizing AI Synergies in Software Engineering (RAISE)","20120702","2012","","","27","31","This paper proposes a new approach to reduce the effort of building formal models representative of the structure and behaviour of Graphical User Interfaces (GUI). The main goal is to automatically extract the GUI model with a dynamic reverse engineering process, consisting in an exploration phase, that extracts information by interacting with the GUI, and in a model generation phase that, making use of machine learning techniques, uses the extracted information of the first step to generate a state-machine model of the GUI, including guard conditions to remove ambiguity in transitions.","","Electronic:978-1-4673-1753-5; POD:978-1-4673-1752-8","10.1109/RAISE.2012.6227966","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227966","Inductive Logic Programming;Machine Learning;Model-Based Testing;Reverse Engineering","Buildings;Data mining;Encoding;Graphical user interfaces;Logic programming;Machine learning;Reverse engineering","finite state machines;graphical user interfaces;inductive logic programming;information retrieval;learning (artificial intelligence);reverse engineering","GUI model;GUI reverse engineering;dynamic reverse engineering process;exploration phase;formal models;graphical user interfaces;inductive logic programming;information extraction;machine learning techniques;model-based testing;state-machine model generation","","2","1","21","","","5-5 June 2012","","IEEE","IEEE Conference Publications"
"Filtering clones for individual user based on machine learning analysis","J. Yang; K. Hotta; Y. Higo; H. Igaki; S. Kusumoto","Graduate School of Information Science and Technology, Osaka University, 1-5, Yamadaoka, Suita, Osaka, 565-0871, Japan","2012 6th International Workshop on Software Clones (IWSC)","20120702","2012","","","76","77","Results from code clone detectors may contain plentiful useless code clones, and judging whether a code clone is useful varies from user to user based on different purposes of them. We are planing a system to study the judgment of each individual user by applying machine learning algorithms on code clones. We describe the reason why individual judgment should be respected and how in this paper.","","Electronic:978-1-4673-1795-5; POD:978-1-4673-1794-8","10.1109/IWSC.2012.6227872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227872","classify;code clone detector;filtering;judgment of user;machine learning;token-based","Cloning;Detectors;Educational institutions;Electronic mail;Information science;Machine learning;Machine learning algorithms","human computer interaction;learning (artificial intelligence);software engineering","clones filtering;code clones detetector;machine learning analysis;software source code","","4","","3","","","4-4 June 2012","","IEEE","IEEE Conference Publications"
"Statistical Machine Learning and Dissolved Gas Analysis: A Review","P. Mirowski; Y. LeCun","Statistics and Learning Research Department, Alcatel-Lucent Bell Laboratories, Murray Hill, NJ, USA","IEEE Transactions on Power Delivery","20120919","2012","27","4","1791","1799","Dissolved gas analysis (DGA) of the insulation oil of power transformers is an investigative tool to monitor their health and to detect impending failures by recognizing anomalous patterns of DGA concentrations. We handle the failure prediction problem as a simple data-mining task on DGA samples, optionally exploiting the transformer's age, nominal power and voltage, and consider two approaches: 1) binary classification and 2) regression of the time to failure. We propose a simple logarithmic transform to preprocess DGA data in order to deal with long-tail distributions of concentrations. We have reviewed and evaluated 15 standard statistical machine-learning algorithms on that task, and reported quantitative results on a small but published set of power transformers and on proprietary data from thousands of network transformers of a utility company. Our results confirm that nonlinear decision functions, such as neural networks, support vector machines with Gaussian kernels, or local linear regression can theoretically provide slightly better performance than linear classifiers or regressors. Software and part of the data are available at http://www.mirowski.info/pub/dga.","0885-8977;08858977","","10.1109/TPWRD.2012.2197868","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6301810","Artificial intelligence;neural networks;power transformer insulation;prediction methods;statistics;transformers","Dissolved gas analysis;Oil insulation;Pattern recognition;Power transformers;Predictive models;Statistical analysis;Support vector machines","Gaussian processes;data mining;failure analysis;learning (artificial intelligence);neural nets;power engineering computing;power transformer insulation;regression analysis;support vector machines;transformer oil","DGA;Dissolved Gas analysis;Gaussian kernels;anomalous pattern recognition;binary classification;data-mining task;failure detection;insulation oil;local linear regression;logarithmic transform;long-tail distributions;network transformers;neural networks;nonlinear decision functions;power transformers;statistical machine learning;support vector machines;time-to-failure;utility company","","10","","33","","","Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Machine learning for resource management in smart environments","C. Fabbricatore; H. Boley; A. P. Karduck","Furtwangen University, Furtwangen","2012 6th IEEE International Conference on Digital Ecosystems and Technologies (DEST)","20120702","2012","","","1","6","Efficient resource and energy management is a key research and business area in todays IT markets. Cyber-physical ecosystems, like smart homes (SHs) and smart Environments (SEs) get interconnected, the efficient allocation of resources will become essential. Machine Learning and Semantic Web techniques for improving resource allocation and management are the focus of our research. They allow machines to process information on all levels, inferring expressive knowledge from raw data, in particular resource predictions from usage patterns. Our aim is to devise a novel approach for a machine learning (ML) and resource Management (RM) framework in SEs. It combines ML and Semantic Web techniques and integrates user interaction The main objective is to enable the creation of platforms that decrease the overall resource consumption by learning and predicting various usage patterns, and furthermore making decisions based on user-feedback. For this purpose, we evaluate recent research and applications, elicit framework requirements, and present a framework architecture. The approach and components are assessed and a prototype implementation is described.","2150-4938;21504938","Electronic:978-1-4673-1703-0; POD:978-1-4673-1702-3","10.1109/DEST.2012.6227910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227910","ambient assisted living;energy savings;machine learning;resource management;semantic web;smart environment","Cognition;Computer architecture;Educational institutions;Prototypes;Resource management;Semantic Web;Semantics","learning (artificial intelligence);resource allocation;semantic Web;ubiquitous computing","IT market;cyber-physical ecosystem;decision making;energy management;expressive knowledge;framework architecture;framework requirement elicitation;information processing;machine learning;raw data;resource allocation;resource consumption;resource management;resource prediction;semantic Web technique;smart environment;smart home;ubiquitous management;usage pattern;user feedback;user interaction","","2","","23","","","18-20 June 2012","","IEEE","IEEE Conference Publications"
"Machine-Learning Foundations: The Probabilistic Framework","P. Baldi; S. Brunak","","Bioinformatics, second edition:The Machine Learning Approach","20120904","2001","","","47","65","This chapter contains sections titled: Introduction: Bayesian Modeling, The Cox Jaynes Axioms, Bayesian Inference and Induction, Model Structures: Graphical Models and Other Tricks, Summary","","97802622557","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6270030.pdf&bkn=6267217&pdfType=chapter","","","","","","","","","2001","","","","MIT Press","MIT Press eBook Chapters"
"Fundamentals of Whole-System, Systemic, and Multiperspective Machine Learning","P. Kulkarni","","Reinforcement and Systemic Machine Learning for Decision Making","20120814","2012","","","23","56","This chapter contains sections titled: <br> Introduction <br> What Is Systemic Machine Learning? <br> Generalized Systemic Machine-Learning Framework <br> Multiperspective Decision Making and Multiperspective Learning <br> Dynamic and Interactive Decision Making <br> The Systemic Learning Framework <br> System Analysis <br> Case Study: Need of Systemic Learning in the Hospitality Industry <br> Summary <br> References","","97811182665","10.1002/9781118266502.ch2","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6266857.pdf&bkn=6266787&pdfType=chapter","","","","","","","","","2012","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Machine Learning-Based Self-Adjusting Concurrency in Software Transactional Memory Systems","D. Rughetti; P. Di Sanzo; B. Ciciani; F. Quaglia","DIAG, Sapienza Univ. di Roma, Rome, Italy","2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems","20120913","2012","","","278","285","One of the problems of Software-Transactional-Memory (STM) systems is the performance degradation that can be experienced when applications run with a non-optimal concurrency level, namely number of concurrent threads. When this level is too high a loss of performance may occur due to excessive data contention and consequent transaction aborts. Conversely, if concurrency is too low, the performance may be penalized due to limitation of both parallelism and exploitation of available resources. In this paper we propose a machine-learning based approach which enables STM systems to predict their performance as a function of the number of concurrent threads in order to dynamically select the optimal concurrency level during the whole lifetime of the application. In our approach, the STM is coupled with a neural network and an on-line control algorithm that activates or deactivates application threads in order to maximize performance via the selection of the most adequate concurrency level, as a function of the current data access profile. A real implementation of our proposal within the TinySTM open-source package and an experimental study relying on the STAMP benchmark suite are also presented. The experimental data confirm how our self-adjusting concurrency scheme constantly provides optimal performance, thus avoiding performance loss phases caused by non-suited selection of the amount of concurrent threads and associated with the above depicted phenomena.","1526-7539;15267539","Electronic:978-0-7695-4793-0; POD:978-1-4673-2453-3","10.1109/MASCOTS.2012.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6298188","STM systems;concurrency;machine learning","Artificial neural networks;Concurrent computing;Instruction sets;Proposals;Throughput;Training","concurrency control;learning (artificial intelligence);neural nets;storage management","STAMP benchmark suite;STM systems;TinySTM open-source package;concurrent threads;consequent transaction aborts;data access profile;excessive data contention;machine learning;neural network;nonoptimal concurrency level;online control algorithm;performance degradation;self-adjusting concurrency scheme;software transactional memory systems","","14","","21","","","7-9 Aug. 2012","","IEEE","IEEE Conference Publications"
"Empirical study based on machine learning approach to assess the QoS/QoE correlation","M. S. Mushtaq; B. Augustin; A. Mellouk","University of Paris-Est Creteil (UPEC) Val de Marne Image, Signal and Intelligent Systems (LiSSi) Lab, France","2012 17th European Conference on Networks and Optical Communications","20120730","2012","","","1","7","The appearance of new emerging multimedia services have created new challenges for cloud service providers, which have to react quickly to end-users experience and offer a better Quality of Service (QoS). Cloud service providers should use such an intelligent system that can classify, analyze, and adapt to the collected information in an efficient way to satisfy end-users' experience. This paper investigates how different factors contributing the Quality of Experience (QoE), in the context of video streaming delivery over cloud networks. Important parameters which influence the QoE are: network parameters, characteristics of videos, terminal characteristics and types of users' profiles. We describe different methods that are often used to collect QoE datasets in the form of a Mean Opinion Score (MOS). Machine Learning (ML) methods are then used to classify a preliminary QoE dataset collected using these methods. We evaluate six classifiers and determine the most suitable one for the task of QoS/QoE correlation.","","Electronic:978-1-4673-0951-6; POD:978-1-4673-0949-3; USB:978-1-4673-0950-9","10.1109/NOC.2012.6249939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249939","Data classification models;Machine Learning;QoE;QoS","Atmospheric measurements;Delay;Fires;Indexes;Particle measurements;Quality of service","cloud computing;learning (artificial intelligence);multimedia communication;pattern classification;quality of service;video streaming","cloud network;cloud service provider;intelligent system;machine learning approach;mean opinion score;multimedia service;network parameter;preliminary QoE dataset classification;quality of experience correlation;quality of service correlation;terminal characteristics;video characteristics;video streaming delivery","","13","","17","","","20-22 June 2012","","IEEE","IEEE Conference Publications"
"Improved EASI ECG model obtained using various machine learning and regression techniques","W. Oleksy; E. Tkacz; Z. Budzianowski","Institute of Informatics, Faculty of Automatic Control, Electronics and Computer Science at Silesian University of Technology in Gliwice, Poland","2012 35th International Conference on Telecommunications and Signal Processing (TSP)","20120802","2012","","","534","538","Main idea of this study was to increase efficiency of the EASI ECG method introduced by Dover in 1988 using various regression techniques. EASI was proven to have high correlation with standard 12 lead ECG. Apart from that it is less susceptible to artefacts, increase mobility of patients and is easier to use because of smaller number of electrodes. Multilayer Perceptron (Artificial Neural Network), Support Vector Machines, Linear Regression, Pace Regression and Least Median of Squares Regression methods were used to improve the quality of the 12-lead electrocardiogram derived from four (EASI) electrodes.","","Electronic:978-1-4673-1118-2; POD:978-1-4673-1117-5","10.1109/TSP.2012.6256352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6256352","Artificial Neural Network;EASI;ECG;Least Median of Squares Regression;Linear Regression;PACE regression;SVM","Electrocardiography;Electrodes;Kernel;Machine learning;Multilayer perceptrons;Standards;Support vector machines","biomedical electrodes;electrocardiography;medical signal processing;multilayer perceptrons;regression analysis;support vector machines","EASI ECG method;EASI ECG model;EASI electrodes;artificial neural network;electrocardiogram;least median of squares regression;linear regression;machine learning techniques;multilayer perceptron;pace regression;regression techniques;standard 12 lead ECG;support vector machines","","0","","18","","","3-4 July 2012","","IEEE","IEEE Conference Publications"
"Machine learning for user modeling in a multilingual learning system","M. Virvou; C. Troussas; E. Alepis","Department of Informatics, University of Piraeus, Greece","International Conference on Information Society (i-Society 2012)","20120827","2012","","","292","297","Towards the successful creation of user models that can be incorporated into foreign language learning systems, we have used algorithmic approaches residing in the field of machine learning. The creation of user models is even more demanding in the area of Computer Assisted Multilanguage Learning, since modeling is an even more complex process that concurrently handles information from multiple domains. These domains have important similarities but also basic differences. This paper describes the implementation of student modeling through machine learning techniques, which aims to ameliorate future multiple language learning systems. The incorporation of k-means clustering is used to address several barriers posed by the heterogeneous learning audience. The resulting system both generates and discovers user profiles, based on students' characteristics, performance and preferences. Through our system, we promote the adaptivity and individualization to each user that interacts with the application, by providing individualized help, error diagnosis and error proneness along with advice generator components.","","Electronic:978-1-908320-05-6; POD:978-1-4673-0838-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6284978","intelligent tutoring systems;k-means algorithm;language learning;machine learning for user modeling;stereotypes;student modeling","Knowledge based systems","humanities;intelligent tutoring systems;learning (artificial intelligence);natural languages;pattern clustering;user modelling","computer assisted multilanguage learning;concurrent information handling;error diagnosis;error proneness;foreign language learning systems;heterogeneous learning audience;intelligent tutoring systems;k-means clustering;machine learning;multilingual learning system;multiple language learning systems;student modeling;students performance;students preferences;user model creation;user modeling;user profile discovery;user profile generation","","3","","20","","","25-28 June 2012","","IEEE","IEEE Conference Publications"
"Anomaly detection in gamma ray spectra: A machine learning perspective","S. Sharma; C. Bellinger; N. Japkowicz; R. Berg; K. Ungar","School of Electrical Engineering and Computer Science, University of Ottawa","2012 IEEE Symposium on Computational Intelligence for Security and Defence Applications","20120830","2012","","","1","8","With Canadian security and the safety of the general public in mind, physicists at Health Canada (HC) have begun to develop techniques to identify persons concealing radioactive material that may represent a threat to attendees at public gatherings, such as political proceedings and sporting events. To this end, Health Canada has initiated field trials that include the deployment of gamma-ray spectrometers. In particular, a series of these detectors, which take measurements every minute and produce 1,024 channel gamma-ray spectrum, were deployed during the Vancouver 2010 olympics. Simple computerized statistics and human expertise were used as the primary line of defence. More specifically, if a measured spectrum deviated significantly from the background, an internal alarm was sounded and an HC physicist undertook further analysis into the nature of the alarming spectrum. This strategy, however, lead to a significant number of costly and time consuming false positives. This research applies sophisticated machine learning algorithms to reduce the number of false positives to an acceptable level, the results of which are detailed in this paper. In addition, we emphasize the primary findings of our work and highlight avenues available to further improve upon our current results.","2329-6267;23296267","Electronic:978-1-4673-1417-6; POD:978-1-4673-1416-9","10.1109/CISDA.2012.6291535","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6291535","","Isotopes;Machine learning;Machine learning algorithms;Rain;Support vector machines;Testing;Training","alarm systems;gamma-ray detection;gamma-ray spectra;gamma-ray spectrometers;learning (artificial intelligence);public administration;radiation protection;radioactivity;safety;statistical analysis","Canadian security;HC;Health Canada;Vancouver 2010 olympics;alarming spectrum;anomaly detection;computerized statistics;detector;gamma ray spectra;gamma-ray spectrometer;general public safety;human expertise;internal alarm;machine learning algorithm;political proceedings;public gathering;radioactive material;sporting events;threat","","3","","9","","","11-13 July 2012","","IEEE","IEEE Conference Publications"
"Knowledge Augmentation: A Machine Learning Perspective","P. Kulkarni","","Reinforcement and Systemic Machine Learning for Decision Making","20120814","2012","","","209","236","This chapter contains sections titled: <br> Introduction <br> Brief History and Related Work <br> Knowledge Augmentation and Knowledge Elicitation <br> Life Cycle of Knowledge <br> Incremental Knowledge Representation <br> Case-Based Learning and Learning with Reference to Knowledge Loss <br> Knowledge Augmentation: Techniques and Methods <br> Heuristic Learning <br> Systemic Machine Learning and Knowledge Augmentation <br> Knowledge Augmentation in Complex Learning Scenarios <br> Case Studies <br> Summary <br> References","","97811182665","10.1002/9781118266502.ch9","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6266850.pdf&bkn=6266787&pdfType=chapter","","","","","","","","","2012","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Map-Reduce for Machine Learning on Multicore","B. Schölkopf; J. Platt; T. Hofmann","","Advances in Neural Information Processing Systems 19:Proceedings of the 2006 Conference","20120924","2007","","","281","288","We are at the beginning of the multicore era. Computers will have increasingly many cores (processors), but there is still no good programming framework for these architectures, and thus no simple and unified way for machine learning to take advantage of the potential speed up. In this paper, we develop a broadly applicable parallel programming method, one that is easily applied to many different learning algorithms. Our work is in distinct contrast to the tradition in machine learning of designing (often ingenious) ways to speed up a single algorithm at a time. Specifically, we show that algorithms that fit the Statistical Query model [15] can be written in a certain ‘summation form,’ which allows them to be easily parallelized on multicore computers. We adapt Google's map-reduce [7] paradigm to demonstrate this parallel speed up technique on a variety of learning algorithms including locally weighted linear regression (LWLR), k-means, logistic regression (LR), naive Bayes (NB), SVM, ICA, PCA, gaussian discriminant analysis (GDA), EM, and backpropagation (NN). Our experimental results show basically linear speedup with an increasing number of processors.","","97802622569","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6287359.pdf&bkn=6267330&pdfType=chapter","","","","","","","","","2007","","","","MIT Press","MIT Press eBook Chapters"
"GPU-accelerated machine learning techniques enable QSAR modeling of large HTS data","E. W. Lowe; M. Butkiewicz; N. Woetzel; J. Meiler","Chemistry at the Center for Structural Biology at Vanderbilt University, Nashville TN, 37232, USA","2012 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20120614","2012","","","314","320","Quantitative structure activity relationship (QSAR) modeling using high-throughput screening (HTS) data is a powerful technique which enables the construction of predictive models. These models are utilized for the in silico screening of libraries of molecules for which experimental screening methods are both cost- and time-expensive. Machine learning techniques excel in QSAR modeling where the relationship between structure and activity is often complex and non-linear. As these HTS data sets continue to increase in number of compounds screened, extensive feature selection and cross validation becomes computationally expensive. Leveraging massively parallel architectures such as graphics processing units (GPUs) to accelerate the training algorithms for these machine learning techniques is a cost-efficient manner in which to combat this problem. In this work, several machine learning techniques are ported in OpenCL for GPU-acceleration to enable construction of QSAR ensemble models using HTS data. We report computational performance numbers using several HTS data sets freely available from PubChem database. We also report results of a case study using HTS data for a target of pharmacological and pharmaceutical relevance, cytochrome P450 3A4, for which an enrichment of 94% of the theoretical maximum is achieved.","","Electronic:978-1-4673-1191-5; POD:978-1-4673-1190-8","10.1109/CIBCB.2012.6217246","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6217246","GPU-Accelerated;High-throughput screening;Machine learning;OpenCL;quantitative structure activity relationship","Artificial neural networks;Graphics processing unit;High temperature superconductors;Machine learning;Predictive models;Support vector machines;Training","bioinformatics;biological techniques;graphics processing units;learning (artificial intelligence);molecular biophysics;molecular configurations;parallel architectures;proteins","GPU accelerated machine learning techniques;OpenCL;QSAR modeling;computational performance;cross validation;cytochrome P450 3A4;feature selection;graphics processing units;high throughput screening data;in silico molecular library screening;large HTS data;massively parallel architectures;pharmaceutical target;pharmacological target;predictive model construction;quantitative structure activity relationship modeling;training algorithm acceleration","","1","","29","","","9-12 May 2012","","IEEE","IEEE Conference Publications"
"Machine Learning Algorithms","P. Baldi; S. Brunak","","Bioinformatics, second edition:The Machine Learning Approach","20120904","2001","","","81","97","This chapter contains sections titled: Introduction, Dynamic Programming, Gradient Descent, EM/GEM Algorithms, Markov-Chain Monte-Carlo Methods, Simulated Annealing, Evolutionary and Genetic Algorithms, Learning Algorithms: Miscellaneous Aspects","","97802622557","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6270028.pdf&bkn=6267217&pdfType=chapter","","","","","","","","","2001","","","","MIT Press","MIT Press eBook Chapters"
"Attention: A machine learning perspective","L. K. Hansen","DTU Informatics, Technical University of Denmark, DK-2800 Kgs. Lyngby, Denmark","2012 3rd International Workshop on Cognitive Information Processing (CIP)","20120709","2012","","","1","6","We review a statistical machine learning model of top-down task driven attention based on the notion of `gist'. In this framework we consider the task to be represented as a classification problem with two sets of features - a gist of coarse grained global features and a larger set of low-level local features. Attention is modeled as the choice process over the low-level features given the gist. The model takes its departure in a classical information theoretic framework for experimental design. This approach requires the evaluation over marginalized and conditional distributions. By implementing the classifier within a Gaussian Discrete mixture it is straightforward to marginalize and condition, hence, we obtained a relatively simple expression for the feature dependent information gain - the top-down saliency. As the top-down attention mechanism is modeled as a simple classification problem, we can evaluate the strategy simply by estimating error rates on a test data set. We illustrate the attention mechanism on a simple simulated visual domain in which the choice is over nine patches in which a binary pattern has to be classified. The performance of the classifier equipped with the attention mechanism is almost as good as one that has access to all low-level features and clearly improving over a simple `random attention' alternative.","2327-1671;23271671","Electronic:978-1-4673-1878-5; POD:978-1-4673-1877-8","10.1109/CIP.2012.6232894","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6232894","","Computational modeling;Conferences;Error analysis;Information processing;Machine learning;Training;Visualization","classification;information theory;knowledge representation;learning (artificial intelligence);statistical analysis","Gaussian Discrete mixture;binary pattern;classical information theoretic framework;classification problem;coarse grained global features;feature dependent information gain;gist;machine learning perspective;random attention alternative;simulated visual domain;statistical machine learning model;task representation;top-down attention mechanism;top-down task driven attention","","0","","41","","","28-30 May 2012","","IEEE","IEEE Conference Publications"
"The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]","L. Deng","Microsoft Research, Redmond, Washington USA","IEEE Signal Processing Magazine","20121018","2012","29","6","141","142","In this issue, “Best of the Web” presents the modified National Institute of Standards and Technology (MNIST) resources, consisting of a collection of handwritten digit images used extensively in optical character recognition and machine learning research.","1053-5888;10535888","","10.1109/MSP.2012.2211477","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6296535","","Machine learning","handwriting recognition;learning (artificial intelligence);optical character recognition;visual databases","Best of the Web;MNIST database;handwritten digit images;machine learning research;modified national institute of standards and technology;optical character recognition","","22","","7","","","Nov. 2012","","IEEE","IEEE Journals & Magazines"
"Application of parallel distributed genetics-based machine learning to imbalanced data sets","Y. Nojima; S. Mihara; H. Ishibuchi","Department of Computer Science and Intelligent Systems, Osaka Prefecture University, Sakai, Japan","2012 IEEE International Conference on Fuzzy Systems","20120813","2012","","","1","6","Real world data sets are often imbalanced with respect to the class distribution. Classifier design from those data sets is relatively new challenge. The main problem is the lack of positive class patterns in the data sets. To deal with this problem, there are two main approaches. One is to additionally sample minority class patterns (i.e., over-sampling). The other is to sample a part of majority class patterns (i.e., under-sampling). In our previous research, we have proposed a parallel distributed genetics-based machine learning for large data sets. In our method, not only a population but also a training data set is divided into subgroups, respectively. A pair of a sub-population and a training data subset is assigned to an individual CPU core in order to reduce the computation time. In this paper, our parallel distributed approach is applied to imbalanced data sets. The training data subsets are constructed by a composition of subsets divided majority class patterns with the entire set of non-divided minority class patterns. Through computational experiments, we show the effectiveness of our parallel distributed approach with the proposed data subdivision schemes for imbalanced data sets.","1098-7584;10987584","Electronic:978-1-4673-1506-7; POD:978-1-4673-1507-4","10.1109/FUZZ-IEEE.2012.6251192","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6251192","Imbalanced data;classifier design;fuzzy genetics-based machine learning;parallel distributed approach","Computational modeling;Data models;Distributed databases;Fuzzy sets;Machine learning;Training;Training data","data handling;genetic algorithms;learning (artificial intelligence);parallel processing;pattern classification;set theory","CPU core;class distribution;classifier design;data subdivision schemes;imbalanced data sets;nondivided minority class patterns;parallel distributed genetics-based machine learning;subsets divided majority class patterns;training data set","","2","","20","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Introduction to Reinforcement and Systemic Machine Learning","P. Kulkarni","","Reinforcement and Systemic Machine Learning for Decision Making","20120814","2012","","","1","21","This chapter contains sections titled: <br> Introduction <br> Supervised, Unsupervised, and Semisupervised Machine Learning <br> Traditional Learning Methods and History of Machine Learning <br> What Is Machine Learning? <br> Machine-Learning Problem <br> Learning Paradigms <br> Machine-Learning Techniques and Paradigms <br> What Is Reinforcement Learning? <br> Reinforcement Function and Environment Function <br> Need of Reinforcement Learning <br> Reinforcement Learning and Machine Intelligence <br> What Is Systemic Learning? <br> What Is Systemic Machine Learning? <br> Challenges in Systemic Machine Learning <br> Reinforcement Machine Learning and Systemic Machine Learning <br> Case Study Problem Detection in a Vehicle <br> Summary <br> Reference","","97811182665","10.1002/9781118266502.ch1","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6266858.pdf&bkn=6266787&pdfType=chapter","","","","","","","","","2012","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Application of machine learning (reinforcement learning) for routing in Wireless Sensor Networks (WSNs)","K. Kadam; N. Srivastava","BVU, College Of Engineering, Dhanakwadi, Pune, India-411043","2012 1st International Symposium on Physics and Technology of Sensors (ISPTS-1)","20120806","2012","","","349","352","Traditionally, protocols and applications in the networking domain have been designed to work in large-scale heterogeneous, hierarchically organized networks with low failure rate. In a Wireless Sensor Network (WSN) scenario, new problems arise and traditional routing protocols cannot be successfully applied. Additionally, in energy-restricted environments like WSNs the overhead of keeping routing information fresh becomes unbearable. In this problem context problem context, many researchers have turned their attention to the domain of machine learning (ML). The goal of this paper is to analyze the application of the Reinforcement Learning (specifically Q-learning) for an energy- aware routing scenario.","","Electronic:978-1-4673-1043-7; POD:978-1-4673-1040-6","10.1109/ISPTS.2012.6260967","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6260967","Q-Learning","","","","","0","","8","","","7-10 March 2012","","IEEE","IEEE Conference Publications"
"Systemic Machine Learning and Model","P. Kulkarni","","Reinforcement and Systemic Machine Learning for Decision Making","20120814","2012","","","77","98","This chapter contains sections titled: <br> Introduction <br> A Framework for Systemic Learning <br> Capturing the Systemic View <br> Mathematical Representation of System Interactions <br> Impact Function <br> Decision-Impact Analysis <br> Summary","","97811182665","10.1002/9781118266502.ch4","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6266855.pdf&bkn=6266787&pdfType=chapter","","","","","","","","","2012","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Analysis of how the choice of Machine Learning algorithms affects the prediction of a clinical outcome prior to minimally invasive treatments for Benign Pro Static Hyperplasia BPH","D. B. Megherbi; B. Soper","CMINDS Research Center, Department of Electrical and Computer Engineering, University of Massachusetts, Lowell, 01854 USA","2012 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA) Proceedings","20120816","2012","","","47","52","Benign Pro Static Hyperplasia (BPH) is estimated to effect 50% of men by the age of 50, and 75% by the age of 80. Predicting a clinical outcome prior to minimally invasive treatments for BPH would be very useful, but has not been reliable in spite of multiple assessment parameters such as symptom indices and flow rates. I our prior work we have shown the effect of greater impact feature selection has on prediction of the BPH clinical outcomes. In this work we take an in depth look at how changes to the Artificial Intelligence and Machine Learning methods can have an affect on how well the process does at predicting the outcome of the patients in the testing group. The affect of which classifier is used, to predict BPH surgical outcomes, is investigated to see if certain classifiers perform better with the data. The affect of which metric is selected for analyzing the performance of the classifier prediction is also observed. The affect of which features and how many are selected to train and predict the data is observed. Finally, the affect of using the original, unchanged, date versus a discretized version of the data is also observed. The objective in this paper is to determine, in this case, which of the above-mentioned factors affect the outcome of the predictive models, to allow the best factor selection in each case so that the best predictive method of NPH for this data, can be determined. In particular, the data is analyzed to determine if some of these factors have a larger effect on the outcome than others. Through experimental results we show which and how some factors are found to have no real influence on clinical outcome prediction, and show how in some other cases there are a few equally good choices. Here four machine learning algorithms, namely Decision Tree, Naïve Bayes, LDA, and ADABoost are selected and used in the comparison. For prediction performance metrics comparison we use the Area Under the Curve (AUC), Accuracy (ACC), and the Ma- thew Correlation Coefficient (MCC). Both internal cross-validation and external validation are used to analyze the performance and results of the predictive models considered.","2159-1547;21591547","Electronic:978-1-4577-1779-6; POD:978-1-4577-1778-9","10.1109/CIMSA.2012.6269609","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6269609","Artificial Intelligence;Benign Pro Static Hyperplasia;Distributed Systems;Machine learning;Mobile Robotics;Multi-agent systems;Reinforcement Learning","Accuracy;Bladder;Decision trees;Learning systems;Measurement;Surgery","Bayes methods;data analysis;decision trees;learning (artificial intelligence);medical computing;pattern classification;surgery","ADABoost;LDA;Matthew correlation coefficient;area under the curve;artificial intelligence;benign pro static hyperplasia surgical outcome prediction;best factor selection;classifier prediction;clinical outcome prediction;data analysis;decision tree;external validation;impact feature selection;internal cross-validation;machine learning algorithm;minimally invasive treatment;naïve Bayes;prediction performance metrics","","1","","","","","2-4 July 2012","","IEEE","IEEE Conference Publications"
"A Scalable Machine Learning Approach to Go","B. Schölkopf; J. Platt; T. Hofmann","","Advances in Neural Information Processing Systems 19:Proceedings of the 2006 Conference","20120924","2007","","","1521","1528","Go is an ancient board game that poses unique opportunities and challenges for AI and machine learning. Here we develop a machine learning approach to Go, and related board games, focusing primarily on the problem of learning a good evaluation function in a scalable way. Scalability is essential at multiple levels, from the library of local tactical patterns, to the integration of patterns across the board, to the size of the board itself. The system we propose is capable of automatically learning the propensity of local patterns from a library of games. Propensity and other local tactical information are fed into a recursive neural network, derived from a Bayesian network architecture. The network integrates local information across the board and produces local outputs that represent local territory ownership probabilities. The aggregation of these probabilities provides an effective strategic evaluation function that is an estimate of the expected area at the end (or at other stages) of the game. Local area targets for training can be derived from datasets of human games. A system trained using only 9 × 9 amateur game data performs surprisingly well on a test set derived from 19 × 19 professional game data. Possible directions for further improvements are briefly discussed.","","97802622569","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6287389.pdf&bkn=6267330&pdfType=chapter","","","","","","","","","2007","","","","MIT Press","MIT Press eBook Chapters"
"A novel image watermarking scheme using Extreme Learning Machine","A. Mishra; A. Goel; R. Singh; G. Chetty; L. Singh","Department of Electronics, Deendayal Upadhyay College, University of Delhi, New Delhi, India","The 2012 International Joint Conference on Neural Networks (IJCNN)","20120730","2012","","","1","6","In this paper, a novel digital image watermarking algorithm based on a fast neural network known as Extreme Learning Machine (ELM) for two grayscale images is proposed. The ELM algorithm is very fast and completes its training in milliseconds unlike its other counterparts such as BPN. The proposed watermarking algorithm trains the ELM by using low frequency coefficients of the grayscale host image in transform domain. The trained ELM produces a sequence of 1024 real numbers, normalized as per N(0, 1) as an output. This sequence is used as watermark to be embedded within the host image using Cox's formula to obtain the signed image. The visual quality of the signed images is evaluated by PSNR. High PSNR values indicate that the quality of signed images is quite good. The computed high value of SIM (X, X*) establishes that the extraction process is quite successful and overall the algorithm finds good practical applications, especially in situations that warrant meeting time constraints.","2161-4393;21614393","Electronic:978-1-4673-1490-9; POD:978-1-4673-1488-6","10.1109/IJCNN.2012.6252363","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252363","Digital Image Watermarking;Extreme Learning Machine (ELM);Real time applications;SIM(X, X*);Watermark Extraction","Discrete cosine transforms;Machine learning;Mathematical model;Neurons;Training;Vectors;Watermarking","","","","10","","9","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"A machine learning approach to determining tag relevance in geotagged Flickr imagery","M. Hughes; N. E. O'Connor; G. J. F. Jones","CLARITY Centre for Sensor Research, Dublin City University, Ireland","2012 13th International Workshop on Image Analysis for Multimedia Interactive Services","20120628","2012","","","1","4","We present a novel machine learning based approach to determining the semantic relevance of community contributed image annotations for the purposes of image retrieval. Current large scale community image retrieval systems typically rely on human annotated tags which are subjectively assigned and may not provide useful or semantically meaningful labels to the images. Homogeneous tags which fail to distinguish between are a common occurrence, which can lead to poor search effectiveness on this data. We described a method to improve text based image retrieval systems by eliminating generic or non relevant image tags. To classify tag relevance, we propose a novel feature set based on statistical information available for each tag within a collection of geotagged images harvested from Flickr. Using this feature set machine learning models are trained to classify the relevance of each tag to its associated image. The goal of this process is to allow for rich and accurate captioning of these images, with the objective of improving the accuracy of text based image retrieval systems. A thorough evaluation is carried out using a human annotated benchmark collection of Flickr tags.","2158-5873;21585873","Electronic:978-1-4673-0790-1; POD:978-1-4673-0791-8","10.1109/WIAMIS.2012.6226774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226774","","Benchmark testing;Cities and towns;Image retrieval;Machine learning;Measurement;Semantics;Support vector machines","Internet;image retrieval;learning (artificial intelligence);social networking (online);statistical analysis","Internet;determining tag relevance;geotagged Flickr imagery;geotagged images;image annotations;image retrieval;machine learning approach;semantic relevance;social networking;statistical information;tag relevance classification","","0","","6","","","23-25 May 2012","","IEEE","IEEE Conference Publications"
"The Impact of Evasion on the Generalization of Machine Learning Algorithms to Classify VoIP Traffic","R. Alshammari; A. N. Zincir-Heywood","Fac. of Comput. Sci., Dalhousie Univ., Halifax, NS, Canada","2012 21st International Conference on Computer Communications and Networks (ICCCN)","20120830","2012","","","1","8","We propose a novel approach to generate well generalized signatures to classify Skype VoIP traffic using a machine learning based approach. Results show that the performance of the signatures did not degrade significantly when they were evaluated on traffic that was captured from different locations and at different times as well as employed against evasion attacks. Our results on the evasion of Skype classifier demonstrate that the performance of the signatures are very promising even if the user tries maliciously to alter the characteristics of Skype traffic to evade the classifier.","1095-2055;10952055","Electronic:978-1-4673-1544-9; POD:978-1-4673-1543-2","10.1109/ICCCN.2012.6289243","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6289243","","Bit rate;Cryptography;Internet;Payloads;Protocols;Training","Internet telephony;learning (artificial intelligence);pattern classification;telecommunication computing;telecommunication traffic","Skype VoIP traffic;Skype classifier;Skype traffic;VoIP traffic classification;evasion attacks;generalization;machine learning algorithms;well generalized signatures","","0","","35","","","July 30 2012-Aug. 2 2012","","IEEE","IEEE Conference Publications"
"Sensitive Information Acquisition Based on Machine Learning","W. Shang; H. Liu; R. Lv","Sch. of Comput., Commun. Univ. of China, Beijing, China","2012 International Conference on Industrial Control and Electronics Engineering","20121004","2012","","","1117","1119","With the rapid development of Internet, online information has greatly enriched. The Internet becomes a vast treasure of information, but simultaneously it is also flooding various trash information, such as: viruses, Trojans, violence, pornography, gambling and so on. The hostile forces outside of country and criminal elements are using the Internet to engage in illegal activities that endanger national security. So how to recognize this information to find the corresponding website and to carry on the effective supervision has become an urgent problem. For these reasons, this paper designs a new web information extraction system, which calls the extraction rule corresponding to the template by calculating the structural similarity among pages. In addition, a new method based on STU-DOM tree to construct decision tree is proposed. This method can use the classification of decision tree to determine sensitive information node.","","Electronic:978-1-4673-1449-7; POD:978-1-4673-1450-3","10.1109/ICICEE.2012.296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6322585","DOM;information extraction;machine learning;sensitive information","Accuracy;Algorithm design and analysis;Data mining;Databases;Decision trees;Feature extraction;Information retrieval","Internet;Web sites;computer crime;computer viruses;decision trees;information dissemination;information retrieval;information retrieval systems;learning (artificial intelligence);national security;pattern classification","Internet;STU-DOM tree;Trojans;Web information extraction system;Website;criminal elements;decision tree classification;extraction rule;gambling;illegal activities;machine learning;national security;online information;pornography;sensitive information acquisition;structural similarity;trash information;violence;viruses","","0","","6","","","23-25 Aug. 2012","","IEEE","IEEE Conference Publications"
"Two-machine flowshop scheduling with past-sequence-dependent setup times and general learning effects","F. Yuan; Q. Cheng; Y. Yin","State Key Laboratory Breeding Base of Nuclear Resources and Environment, East China Institute of Technology, Nanchang, 330013, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","3009","3012","This paper provides a continuation of ideas presented by Yin et al. [Yin et al., Some scheduling problems with general position-dependent and time-dependent learning effects, Inform. Sci. 179 (2009) 2416-2425]. In this paper, we study a two-machine flowshop scheduling model with proportional job processing times and a general learning effect simultaneously. In particular, we show that the problems to minimize makespan and sum of the kth power of completion times can be solved in polynomial time. We also show that the problems to minimize total weighted completion time, maximum lateness and maximum tardiness can be solved in polynomial time under certain conditions.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233960","Flowshop;Learning effects;Scheduling","Indexes;Job shop scheduling;Machine learning;Optimal scheduling;Polynomials;Single machine scheduling","flow shop scheduling;learning (artificial intelligence);polynomials","general position dependent learning effects;maximum lateness;maximum tardiness;past sequence dependent setup times;polynomial time;proportional job processing times;time dependent learning effects;two machine flowshop scheduling","","0","","8","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Discovery of video websites based on machine learning","Chengqi Zhang; Wenqian Shang","Department of Computer Sciences, Communication University of China, Beijing, China","2012 International Conference on Computer Science and Information Processing (CSIP)","20120924","2012","","","1396","1399","The supervision of video websites has become extremely important with the rapid development of web, The first problem to overcome is automatically detecting of video websites. For the traditional limitations of artificial discrimination, this paper presents a video website discovery method based on machine learning. First we adopt a crawler to crawl video page description information, then we preprocess these text information. After these steps, we adopt a Naïve Bayes classifier to classify this text information. In addition, through the combination of sensitive words matching, we can realize the supervision of sensitive information.","","DVD:978-1-4673-1409-1; Electronic:978-1-4673-1411-4; POD:978-1-4673-1410-7","10.1109/CSIP.2012.6309124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6309124","Text Classification;machine learning;naïve Bayesian algorithm;video websites","Accuracy;Crawlers;YouTube","Bayes methods;Web sites;learning (artificial intelligence);pattern classification;text analysis;video signal processing","Naïve Bayes classifier;machine learning;sensitive words matching;text information;video Website discovery method;video page description information","","1","","5","","","24-26 Aug. 2012","","IEEE","IEEE Conference Publications"
"Robust, reliable and applicable tool wear monitoring and prognostic: Approach based on an improved-extreme learning machine","K. Javed; R. Gouriveau; N. Zerhouni; R. Zemouri; X. Li","FEMTO - ST Institute, 24 rue Alain Savary, 25000 Besan&#x00E7;on, France","2012 IEEE Conference on Prognostics and Health Management","20120913","2012","","","1","9","Although efforts in this field are significant around the world, real prognostics systems are still scarce in industry. Indeed, it is hard to provide efficient approaches that are able to handle with the inherent uncertainty of prognostics and nobody is able to a priori ensure that an accurate prognostic model can be built. As for an example of remaining problems, consider data-driven prognostics approaches: how to ensure that a model will be able to face with inputs variation with respect to those ones that have been learned, how to ensure that a learned-model will face with unknown data, how to ensure convergence of algorithms, etc. In other words, robustness, reliability and applicability of a prognostic approach are still open areas. Following that, the aim of this paper is to address these challenges by proposing a new neural network (structure and algorithm) that enhances reliability of RUL estimates while improving applicability of the approach. Robustness, reliability and applicability aspects are first discussed and defined according to literature. On this basis, a new connexionist system is proposed for prognostics: the Improved-Extreme Learning machine (Imp-ELM). This neural network, based on complex activation functions, enables to reduce the influence of human choices and initial parameterization, while improving accuracy of estimates and speeding the learning phase. The whole proposition is illustrated by performing tests on a real industrial case of cutting tools from a Computer Numerical Control (CNC) machine. This is achieved by predicting tool condition (wear) in terms of remaining cuts successfully made. Thorough comparisons with adaptive neuro fuzzy inference system (ANFIS) and existing ELM algorithm are also given. Results show improved robustness, reliability and applicability performances.","","Electronic:978-1-4673-0358-3; POD:978-1-4673-0356-9","10.1109/ICPHM.2012.6299516","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6299516","","Computer numerical control;Cutting tools;Data models;Machine learning;Neurons;Robustness","computerised numerical control;condition monitoring;cutting tools;fuzzy reasoning;learning (artificial intelligence);neural nets;production engineering computing;reliability;wear","ANFIS;CNC machine;RUL estimation;activation function;adaptive neuro fuzzy inference system;applicability aspect;computer numerical control;cutting tool;data-driven prognostics approach;improved-extreme learning machine;neural network;prognostics system;reliability aspect;remaining useful life;robustness aspect;tool condition prediction;tool wear monitoring;tool wear prognostic","","7","","","","","18-21 June 2012","","IEEE","IEEE Conference Publications"
"A machine learning technique for MRI brain images","H. Mohsen; E. S. A. El-Dahshan; A. B. M. Salem","Faculty of Computers and Information Technology, Future University, 5th Settlement, Cairo, Egypt","2012 8th International Conference on Informatics and Systems (INFOS)","20120712","2012","","","BIO-161","BIO-165","This study presents a proposed hybrid intelligent machine learning technique for Computer-Aided detection system for automatic detection of brain tumor through magnetic resonance images. The technique is based on the following computational methods; the feedback pulse-coupled neural network for image segmentation, the discrete wavelet transform for features extraction, the principal component analysis for reducing the dimensionality of the wavelet coefficients, and the feed forward backpropagation neural network to classify inputs into normal or abnormal. The experiments were carried out on 101 images consisting of 14 normal and 87 abnormal (malignant and benign tumors) from a real human brain MRI dataset. The classification accuracy on both training and test images is 99 % which was significantly good. Moreover, The proposed technique demonstrates its effectiveness compared with the other machine learning recently published techniques.","","Electronic:978-977-403-506-7; POD:978-1-4673-0828-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6236544","Computational Intellegence;Computer-aided detection;Image Processing;MRI brain imaging;Machine learning;Medical Informatics","Biological neural networks;Design automation;Discrete wavelet transforms;Feature extraction;Magnetic resonance imaging;Tumors","backpropagation;biomedical MRI;brain;discrete wavelet transforms;feature extraction;feedforward neural nets;image classification;image segmentation;medical image processing;patient diagnosis;principal component analysis;tumours","MRI brain images;abnormal classification;automatic detection;benign tumors;classification accuracy;computational method;computer-aided detection system;discrete wavelet transform;feature extraction;feedback pulse-coupled neural network;forward backpropagation neural network;hybrid intelligent machine learning;image segmentation;magnetic resonance images;malignant tumors;normal classification;principal component analysis;real human brain MRI dataset;test images;training images;wavelet coefficient dimensionality reduction","","0","","12","","","14-16 May 2012","","IEEE","IEEE Conference Publications"
"Application of entropic value-at-risk in machine learning with corrupted input data","A. Ahmadi-Javid","Dept. of Ind. Eng., Amirkabir Univ. of Technol., Tehran, Iran","2012 11th International Conference on Information Science, Signal Processing and their Applications (ISSPA)","20120924","2012","","","1104","1107","The entropic value-at-risk (EVaR) is a coherent risk measure that is efficiently computable for the sum of independent random variables. This paper shows how this risk measure can be used in machine learning when uncertainty affects the input data. For this purpose, we consider here a support vector machine with corrupted input data.","","Electronic:978-1-4673-0382-8; POD:978-1-4673-0381-1; USB:978-1-4673-0380-4","10.1109/ISSPA.2012.6310455","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6310455","","Linear programming;Machine learning;Optimization;Random variables;Reactive power;Support vector machines;Uncertainty","learning (artificial intelligence);random processes;support vector machines","EVaR;corrupted input data;entropic value-at-risk;machine learning;random variable;risk measure;support vector machine","","0","","8","","","2-5 July 2012","","IEEE","IEEE Conference Publications"
"A comparison of machine learning algorithms applied to hand gesture recognition","P. Trigueiros; F. Ribeiro; L. P. Reis","Departamento de Inform&#x00E1;tica, Instituto Polit&#x00E9;cnico do Porto, Porto, Portugal","7th Iberian Conference on Information Systems and Technologies (CISTI 2012)","20120830","2012","","","1","6","Hand gesture recognition for human computer interaction is an area of active research in computer vision and machine learning. The primary goal of gesture recognition research is to create a system, which can identify specific human gestures and use them to convey information or for device control. This paper presents a comparative study of four classification algorithms for static hand gesture classification using two different hand features data sets. The approach used consists in identifying hand pixels in each frame, extract features and use those features to recognize a specific hand pose. The results obtained proved that the ANN had a very good performance and that the feature selection and data preparation is an important phase in the all process, when using low-resolution images like the ones obtained with the camera in the current work.","2166-0727;21660727","Electronic:978-989-96247-7-1; POD:978-1-4673-2843-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6263058","Machine vision;hand gesture recognition;image processing;machine learning","Artificial neural networks;Classification algorithms;Feature extraction;Gesture recognition;Human computer interaction;Machine learning;Support vector machines","computer vision;feature extraction;gesture recognition;human computer interaction;image classification;image resolution;learning (artificial intelligence);neural nets;pose estimation","ANN;artificial neural networks;classification algorithms;computer vision;data preparation;feature extraction;feature selection;hand features data sets;hand gesture recognition;hand pixel identification;hand pose recognition;human computer interaction;low-resolution images;machine learning algorithms;static hand gesture classification","","2","","25","","","20-23 June 2012","","IEEE","IEEE Conference Publications"
"Support Vector Machine Learning for Interdependent and Structured Output Spaces","G. BakIr; T. Hofmann; B. Schölkopf; A. J. Smola; B. Taskar; S. V. N. Vishwanathan","","Predicting Structured Data","20120904","2007","","","85","103","This chapter contains sections titled: Introduction, A Framework for Structured/Interdependent Output Learning, A Maximum-Margin Formulation, Cutting-Plane Algorithm, Alternative Margin Formulations, Experiments, Conclusions, Proof of Proposition 37","","97802622556","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6270217.pdf&bkn=6267216&pdfType=chapter","","","","","","","","","2007","","","","MIT Press","MIT Press eBook Chapters"
"Content-based subjective quality prediction in stereoscopic videos with machine learning","H. Malekmohamadi; W. A. C. Fernando; A. M. Kondoz","I-Lab Multimedia Communications Research, Centre for Vision Speech and Signal Processing, University of Surrey, Guildford GU2 7XH, United Kingdom","Electronics Letters","20121018","2012","48","21","1344","1346","A model exploiting machine learning and content analysis is proposed to predict the subjective quality of stereoscopic videos. This model offers an automated, accurate and consistent subjective quality prediction. The feasibility and accuracy of the proposed technique has been thoroughly analysed with extensive subjective experiments and simulations. Results illustrate that a performance measure of 0.954 in subjective quality prediction can be achieved with the proposed technique.","0013-5194;00135194","","10.1049/el.2012.2365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6329297","","","learning (artificial intelligence);stereo image processing;video signal processing","content analysis;content-based subjective quality prediction;machine learning;stereoscopic video","","1","","","","","October 11 2012","","IET","IET Journals & Magazines"
"Efficient Learning in Boltzmann Machines Using Linear Response Theory","M. I. Jordan; T. J. Sejnowski","","Graphical Models:Foundations of Neural Computation","20121008","2001","","","121","140","This chapter contains sections titled: Introduction, Boltzmann Machine Learning, The Mean-Field Method and the Linear Response Correction, Results, Discussion, Appendix, Acknowledgments, References","","97802622912","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6299920.pdf&bkn=6276852&pdfType=chapter","","","","","","","","","2001","","","","MIT Press","MIT Press eBook Chapters"
"Game theoretic mechanism design applied to machine learning classification","C. M. Vineyard; G. L. Heileman; S. J. Verzi; R. Jordan","Electrical and Computer Engineering Department, University of New Mexico, Albuquerque, New Mexico 87131-0001","2012 3rd International Workshop on Cognitive Information Processing (CIP)","20120709","2012","","","1","5","The field of machine learning strives to develop algorithms that, through learning, lead to generalization; that is, the ability of a machine to perform a task that it was not explicitly trained for. Numerous approaches have been developed ranging from neural network models striving to replicate neurophysiology to more abstract mathematical manipulations which identify numerical similarities. Nevertheless a common theme amongst the varied approaches is that learning techniques incorporate a strategic component to try and yield the best possible decision or classification. The mathematics of game theory formally analyzes strategic interactions between competing players and is consequently quite appropriate to apply to the field of machine learning with potential descriptive as well as functional insights. Furthermore, game theoretic mechanism design seeks to develop a framework to achieve a desired outcome, and as such is applicable for defining a paradigm capable of performing classification. In this work we present a game theoretic chip-fire classifier which as an iterated game is able to perform pattern classification.","2327-1671;23271671","Electronic:978-1-4673-1878-5; POD:978-1-4673-1877-8","10.1109/CIP.2012.6232916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6232916","","Conferences;Game theory;Games;Lattices;Machine learning;Mathematical model;Support vector machines","game theory;iterative methods;learning (artificial intelligence);neural nets;pattern classification","functional insights;game theoretic mechanism design;iterated game;learning techniques;machine learning classification;mathematical manipulations;neural network models;neurophysiology;numerical similarities;pattern classification;strategic component","","1","","12","","","28-30 May 2012","","IEEE","IEEE Conference Publications"
"The Berlin Brain-Computer Interface: Machine Learning-Based Detection of User Specific Brain States","G. Dornhege; J. del R. Millán; T. Hinterberger; D. J. McFarland; K. R. Müller","","Toward Brain-Computer Interfacing","20120924","2007","","","85","102","The Berlin Brain-Computer Interface (BBCI) project develops an EEG-based BCI system that uses machine learning techniques to adapt to the specific brain signatures of each user. This concept allows to achieve high quality feedback already in the very first session without subject training. Here we present the broad range of investigations and experiments that have been performed within the BBCI project. The first kind of experiments analyzes the predictability of performing limbs from the premovement (readiness) potentials including successful feedback experiments. The limits with respect to the spatial resolution of the somatotopy are explored by contrasting brain patterns of movements of (1) left vs. right foot, (2) index vs. little finger within one hand, and (3) finger vs. wrist vs. elbow vs. shoulder within one arm. A study of phantom movements of patients with traumatic amputations shows the potential applicability of this BCI approach. In a complementary approach, voluntary modulations of sensorimotor rhythms caused by motor imagery (left hand vs. right hand vs. foot) are translated into a proportional feedback signal. We report results of a recent feedback study with six healthy subjects with no or very little experience with BCI control: Half of the subjects achieved an information transfer rate above 35 bits per minute (bpm). Furthermore, one subject used the BBCI to operate a mental typewriter in free spelling mode. The overall spelling speed was 4.5 letters per minute including the time needed for the correction errors. These results are encouraging for an EEG-based BCI system in untrained subjects that is independent of peripheral nervous system activity and does not rely on evoked potentials.","","97802622560","","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=6281194.pdf&bkn=6267251&pdfType=chapter","","","","","","","","","2007","","","","MIT Press","MIT Press eBook Chapters"
"Hyperspectral image compression using 3D discrete cosine transform and support vector machine learning","A. Karami; S. Beheshti; M. Yazdi","Dept. of Commun. & Electron., Shiraz Univ., Shiraz, Iran","2012 11th International Conference on Information Science, Signal Processing and their Applications (ISSPA)","20120924","2012","","","809","812","Hyperspectral images exhibit significant spectral correlation, whose exploitation is crucial for compression. In this paper, an efficient method for hyperspectral image compression is presented using the three-dimensional discrete cosine transform (3D-DCT) and support vector machine (SVM). The core idea behind our proposed technique is to apply SVM on the 3D-DCT coefficients of hyperspectral images in order to determine which coefficients (support vectors) are more critical for being preserved. Our method not only exploits redundancies between the bands, but also uses spatial correlations of every image band. Consequently, as simulation results applied to real hyperspectral images demonstrate, the proposed method leads to a remarkable compression ratio and quality.","","Electronic:978-1-4673-0382-8; POD:978-1-4673-0381-1; USB:978-1-4673-0380-4","10.1109/ISSPA.2012.6310664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6310664","Hyperspectral Images;Image Compression;Support Vector Machine;Three Dimensional Discrete Cosine Transform","Discrete cosine transforms;Hyperspectral imaging;Image coding;Image reconstruction;Support vector machines","data compression;discrete cosine transforms;image coding;learning (artificial intelligence);support vector machines","3D discrete cosine transform;3D-DCT;SVM;hyperspectral image compression;hyperspectral images;support vector machine learning;three-dimensional discrete cosine transform","","1","","14","","","2-5 July 2012","","IEEE","IEEE Conference Publications"
"Dynamic Linear Solver Selection for Transient Simulations Using Machine Learning on Distributed Systems","P. R. Eller; J. R. C. Cheng; R. S. Maier","Corps of Eng., Eng. R&D Center, Inf. Technol. Lab., US Army, Vicksburg, MS, USA","2012 IEEE 26th International Parallel and Distributed Processing Symposium Workshops & PhD Forum","20120820","2012","","","1915","1924","Many transient simulations spend a significant portion of the overall runtime solving a linear system. A wide variety of preconditioned linear solvers have been developed to quickly and accurately solve different types of linear systems, each having options to customize the preconditioned solver for a given linear system. Transient simulations may produce significantly different linear systems as the simulation progresses due to special events occurring that make the linear systems more difficult to solve or the model moving closer to a state of equilibrium where the linear systems are easier to solve. Machine learning algorithms provide the ability to dynamically select the preconditioned linear solver for each linear system produced by a simulation. We can generate databases by computing attributes for each linear system, physical attributes for the transient simulation, computational attributes, and running times for a set of preconditioned solvers on each linear system. Machine learning algorithms can then use these databases to generate classifiers capable of dynamically selecting a preconditioned solver for each linear system given a set of attributes. This allows us to quickly and accurately compute each transient simulation using different preconditioned solvers throughout the simulation. This also provides the potential to produce speedups in comparison with using a single preconditioned solver for an entire transient simulation.","","Electronic:978-0-7695-4676-6; POD:978-1-4673-0974-5","10.1109/IPDPSW.2012.239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6270396","?nite element;ADH;WEKA;linear solvers;machine learning","Computational modeling;Databases;Linear systems;Machine learning;Machine learning algorithms;Numerical models;Transient analysis","data mining;digital simulation;flow simulation;learning (artificial intelligence);physics computing","ADH modeling system;ADaptive Hydraulics modeling system;WEKA;classifier generation;computational attributes;data mining;distributed system;dynamic linear solver selection;equilibrium state;linear system;machine learning algorithm;physical attributes;preconditioned linear solver;transient simulation","","0","","19","","","21-25 May 2012","","IEEE","IEEE Conference Publications"
"Machine learning predictive modelling high-level synthesis design space exploration","B. C. Schafer; K. Wakabayashi","NEC Corporation, System IP Core Laboratory, 1753, Shimonumabe, Nakahara-Ku, Kanagawa, Kawasaki 211-8666, Japan","IET Computers & Digital Techniques","20120705","2012","6","3","153","159","A machine learning-based predictive model design space exploration (DSE) method for high-level synthesis (HLS) is presented. The method creates a predictive model for a training set until a given error threshold is reached and then continues with the exploration using the predictive model avoiding time-consuming synthesis and simulations of new configurations. Results show that the authors' method is on average 1.92 times faster than a genetic-algorithm DSE method generating comparable results, whereas it achieves better results when constraining the DSE runtime. When compared with a previously developed simulated annealer (SA)-based method, the proposed method is on average 2.09 faster, although again achieving comparable results.","1751-8601;17518601","","10.1049/iet-cdt.2011.0115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6230786","","","high level synthesis;learning (artificial intelligence)","design space exploration;error threshold;genetic-algorithm DSE;high-level synthesis;machine learning;predictive modelling;simulated annealer;training set","","5","","","","","May 2012","","IET","IET Journals & Magazines"
