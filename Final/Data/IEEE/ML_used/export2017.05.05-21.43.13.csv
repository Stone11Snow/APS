"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7603420,7604600,7603876,7605090,7603434,7603442,7603694,7603210,7604561,7605450,7594039,7462177,7593138,7547948,7592899,7404283,7563347,7590814,7552514,7591217,7592819,7588894,7589884,7585230,7589798,7589822,7589804,7557054,7586590,7586255,7586373,7585256,7586649,7585238,7586608,7584922,7307142,7582981,7584966,7582660,7583540,7422045,7581519,7584056,7583984,7582748,7360173,7583567,7584132,7583559,7584978,7584954,7575389,7579799,7560644,7529210,7580609,7446317,7502170,7416235,7577032,7577309,7577043,7577694,7577557,7577083,7578859,7577584,7577673,7577067,7577176,7577483,7577569,7565520,7549041,7524771,7574741,7575868,7539552,7571857,7571274,7573770,7571846,7573720,7573227,7572219,7572141,7570916,7569416,7570863,7569355,7569525,7542589,7523420,7568908,7567333,7567331,7568881,7568435,7536193",2017/05/05 21:43:13
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Deep convolutional network for detecting probable emergency situations","O. Maksymiv; T. Rak; O. Menshikova","Lviv State University of Life Safety, 35, Kleparivska str., Lviv, 79007, Ukraine","2016 IEEE First International Conference on Data Stream Mining & Processing (DSMP)","20161006","2016","","","199","202","Paper describes the developed approaches to detecting emergency situations that primed based on color segmentation, frame difference and deep convolutional networks. The main objective was to test the interaction of computer vision traditional methods, combined with modern methods of machine learning. Experimentally proved that detection quality for the combination of such methods is 96.7%. In this work, in particular, was developed own images dataset with emergencies and conducted comparison of neural networks AlexNet and GoogLeNet.","","","10.1109/DSMP.2016.7583540","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583540","convolutional neural network;detection;emergency situations;machine learning","Fires;Image color analysis;Image segmentation;Motion segmentation;Neural networks;Streaming media;Training","computer vision;emergency management;feedforward neural nets;image colour analysis;image segmentation;learning (artificial intelligence);object detection","GoogLeNet;color segmentation;computer vision traditional methods;deep convolutional network;frame difference;image dataset;machine learning;neural networks AlexNet;probable emergency situation detection","","","","","","","23-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"Health risk prediction for treatment of hypertension","G. Sandi; S. H. Supangkat; C. Slamet","Sunan Gunung Djati State Islamic University, Bandung, Indonesia","2016 4th International Conference on Cyber and IT Service Management","20160929","2016","","","1","6","Hypertension is one of the leading causes of human deaths world. Based on data from the WHO in 2013, that there are more than 17 million people worldwide died of cardiovascular disease. While in Indonesia, based on the Basic Health Research in 2013, there were 25.8 percent of Indonesia's population suffering from hypertension [1] [2]. This research is develops a system of prediction of prognosis in treatment of hypertension by using diagnostic data. Prediction of prognosis is used to provide advice to patient about the level of health risks associated with hypertension who suffered. This prediction system to develop business processes in predictive diagnosis of hypertension by adding functionality prognosis. The prediction is developed using methods decicion tree by using C4.5 algorithms for processing health information dataset hypertension. The output of this prediction process is the level of health risk patients. This information will be used by the patient to improve his lifestyle. Predictive testing of the system as much as 1100 instances dataset with details 880 instances as training data and 220 instances as test data. The test results of prediction on the class of hypertension are: the level of precision = 92.4% = 89.3% recall rate and accuracy rate = 94.1%. While testing the predictions of the class of risk are: the level of precision = 80.7% = 75% recall rate and accuracy rate = 80.0%.","","","10.1109/CITSM.2016.7577584","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577584","C4.5;Smart health;data mining;decision tree;hypertension;machine learning","Blood pressure;Data mining;Decision trees;Diseases;Hypertension;Prognostics and health management","cardiovascular system;data mining;decision trees;diseases;learning (artificial intelligence);medical diagnostic computing","Basic Health Research;C4.5 algorithms;business processes;cardiovascular disease;data mining;decicion tree;diagnostic data;functionality prognosis;health information dataset hypertension;health risk patients;health risk prediction;hypertension treatment;predictive diagnosis;predictive testing","","","","","","","26-27 April 2016","","IEEE","IEEE Conference Publications"
"A parallel implementation of reinforced learning model used in analyzing risky decision making","V. B. Gavirangaswamy; A. Gupta; A. Gupta","Computer Science Department, Western Michigan University, Kalamazoo, MI, USA","2016 International Conference on High Performance Computing & Simulation (HPCS)","20160915","2016","","","940","946","Analyzing datasets for Risky Decision Making (RDM) is a challenging task involving the identification of varied decision making patterns and the categorization of individuals. Researchers from various fields as diverse as psychology and marketing are actively working to identify suitable techniques, which will allow understanding decision making processes better. Researchers have commonly used machine learning algorithms to model decision making processes. However, the high computational costs of most machine learning algorithms make such endeavors challenging for increasingly large datasets. One of the most promising approaches is to use ensemble clustering for RDM analysis. Ensemble clustering is computationally intensive and thus we propose to improve its performance. Our study reveals that computational overhead is introduced through the use of dimensions in ensemble cluster RDM analyses. Improving performance requires more than the parallelization of individual clustering techniques of the ensemble. We therefore propose a FIFO queue based implementation for analyzing RDM datasets using a HPC cluster on a distributed system. Our technique is able to achieve almost a linear speedup (e.g. 44.79x using 48 MPI threads). Possible shortcomings of the proposed method, opportunities for future work, and alternative parallelization scenarios are also discussed in this paper.","","Electronic:978-1-5090-2088-1; POD:978-1-5090-2089-8","10.1109/HPCSim.2016.7568435","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568435","MPI;ensemble clustering application;machine learning;multi-objective optimization;parallel distributed processing;risky decision making","","decision making;learning (artificial intelligence);parallel processing;queueing theory","FIFO queue based implementation;HPC cluster;distributed system;ensemble clustering;parallel implementation;reinforced learning;risky decision making","","","","","","","18-22 July 2016","","IEEE","IEEE Conference Publications"
"Chinese traditional Visual Cultural Symbols recognition based on SPM muti-feature extraction","Xiao Tan; Xiaoyu Wu; Cheng Yang; Yinghua Shen","Communication University of China, Beijing, China","2016 International Conference on Image, Vision and Computing (ICIVC)","20160922","2016","","","57","62","Globalization is a historic chance for China development. Moreover, Chinese traditional Visual Cultural Symbols (VCS) is a great tag of China. Image is a carrier of VCS. With the help of machine learning, we can recognize these VCS among numerous images very well. In this paper we propose combining with several features such as SIFT, HOG, RGB, LBP to describe an image and coding these features into higher dimensional vectors. Next, the coded vectors are pooled together. Besides, we also make full use of Bag-of-Words (BOW) and Spatial Pyramid Matching (SPM) theory in order to obtain a more ideal recognition. Experiments show that it's really a feasible approach.","","","10.1109/ICIVC.2016.7571274","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571274","BOW;HOG;LBP;RGB;SPM;SVM;VCS;machine learning;visual cultural symbols classification","Dictionaries;Oils;Visualization","art;feature extraction;image coding;image colour analysis;image matching;learning (artificial intelligence);transforms","BOW;Chinese traditional visual cultural symbols recognition;HOG;LBP;RGB;SIFT;SPM multifeature extraction;SPM theory;VCS;bag-of-words;coded vectors;feature coding;higher dimensional vectors;histogram-of-oriented gradient;image recognition;machine learning;scale-invariant feature transform;spatial pyramid matching","","","","","","","3-5 Aug. 2016","","IEEE","IEEE Conference Publications"
"A Guaranteed Similarity Metric Learning Framework for Biological Sequence Comparison","K. Hua; Q. Yu; R. Zhang","College of Science, Northwest A&F University, Yangling, Shaanxi, China","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20161006","2016","13","5","868","877","Similarity of sequences is a key mathematical notion for Classification and Phylogenetic studies in Biology. The distance and similarity between two sequence are very important and widely studied. During the last decades, Similaritydistance metric learning is one of the hottest topics of machine learning/data mining as well as their applications in the bioinformatics field. It is feasible to introduce machine learning technology to learn similarity metric from biological data. In this paper, we propose a novel framework of guaranteed similarity metric learning GMSL to perform alignment of biology sequences in any feature vector space. It introduces the <inline-formula> <tex-math notation=""LaTeX"">$epsilon, gamma, tau$</tex-math><alternatives> <inline-graphic xlink:type=""simple"" xlink=""zhang-ieq1-2495186.gif""/></alternatives></inline-formula>-goodness similarity theory to Mahalanobis metric learning. As a theoretical guaranteed similarity metric learning approach, GMSL guarantees that the learned similarity function performs well in classification and clustering. Our experiments on the most used datasets demonstrate that our approach outperforms the state-of-the-art biological sequences alignment methods and other similarity metric learning algorithms in both accuracy and stability.","1545-5963;15455963","","10.1109/TCBB.2015.2495186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307142","Similarity metric learning;biological sequence;comparison of sequences;machine learning","Bioinformatics;Biology;Computational biology;Fasteners;Measurement;Particle separators","","","","","","","","20151026","September 1 2016","","IEEE","IEEE Journals & Magazines"
"Multivariate Beta Mixture Model for Automatic Identification of Topical Authoritative Users in Community Question Answering Sites","T. P. Sahu; N. K. Nagwani; S. Verma","Department of Information Technology, NIT Raipur, Raipur, India","IEEE Access","20160928","2016","4","","5343","5355","Community question answering (CQA) site is an online community to provide valuable information in wide variety of topics in question-answer form to users'. The major problem with CQA lies in identifying the authoritative users in the domain of the question so as to route the question to right experts and selecting the best answer etc. The existing work suffers from one or more limitations such as: 1) lack of automatic mechanism to distinguish between authoritative and non-authoritative users in specified topics; 2) the high dependence on its training data in supervised learning which is too time-consuming process to obtain labeled samples of data manually; and 3) some approaches rely on using some cutoff parameters to estimate an authority score. In this paper, a parameterless mixture model approach is proposed to identify topical authoritative users to overcome the above-mentioned limitations. The statistical framework based on multivariate beta mixtures is utilized on feature vector of users' which is composed of information related to user activities on CQA site. The probability density function is therefore devised and the beta mixture component that corresponds to the most authoritative user is identified. The suitability of the proposed approach is illustrated on real data of two CQA sites: StackOverflow and AskUbuntu. The result shows that the proposed model is remarkable in identifying the authoritative users in comparison with conventional classifiers and Gaussian mixture model.","2169-3536;21693536","","10.1109/ACCESS.2016.2609279","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7565520","Authoritative user;beta mixture model;classification;community question answering (CQA);machine learning","Classification;Gaussian mixture model;Knowledge discovery;Machine learning;Mixture models;Probability density control;Questioning answering;Supervised learning;Training data","Web sites;learning (artificial intelligence);mixture models;probability;statistical analysis","AskUbuntu;CQA site;StackOverflow;community question answering sites;multivariate beta mixture model;online community;parameterless mixture model approach;probability density function;statistical framework;supervised learning;topical authoritative user automatic identification;training data;user feature vector","","","","","","20160913","2016","","IEEE","IEEE Journals & Magazines"
"Predicción de Riesgo basado en tiempo y patrones GPS","D. López de Luise; W. Bel; D. Mansilla; A. Lobatos; L. Blanc; R. M. la Rosa","Universidad Aut&#x00F3;noma de Entre R&#x00ED;os (UADER), Concepci&#x00F3;n del Uruguay, Argentina","2016 IEEE Biennial Congress of Argentina (ARGENCON)","20161010","2016","","","1","7","Traffic produces not only pollution but also many incidents producing material lost and human injuries or even persons dead. But not all the incidents involve two cars, it may be pedestrian and any type of cycles (motorcycles, bicycles, tricycles, etc). Most of the approaches try to model traffic accidents using traditional information and avoiding some other like environment elements, driver profile, weather, regulations, eventual circumstances like strikes with roadblocks, street reparations, railroads crossings, etc. This paper presents a model for risk prediction, and the impact of varying geographical information details on the precision of the underlying Inference System (a Soft Computing model with a ruled Expert System and an Harmonic System focused on time patterns of events). Its flexibility and robustness has a price: certain minimal a priori knowledge. This work outlines the working model implemented as a prototype named KRONOS, and a statistical evaluation of its sensibility to dynamic GPS information. Traffic risk requires this type of flexible and adaptive model due to the high number of alternatives to consider.","","","10.1109/ARGENCON.2016.7585256","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7585256","Expert Systems;Harmonic Systems;Machine Learning;Pedestrian Risk;Risk Prediction;Time Mining;Traffic Risk","Adaptation models;Computational modeling;Expert systems;Global Positioning System;Harmonic analysis;Predictive models;Robustness","","","","","","","","","15-17 June 2016","","IEEE","IEEE Conference Publications"
"Self-Adaptive and Online QoS Modeling for Cloud-Based Software Services","T. Chen; R. Bahsoon","T. Chen is with CERCIA, School of Computer Science, University of Birmingham, Birmingham, UK, B15 2TT.(email:t.chen@cs.bham.ac.uk)","IEEE Transactions on Software Engineering","","2016","PP","99","1","1","In the presence of scale, dynamism, uncertainty and elasticity, cloud software engineers faces several challenges when modeling Quality of Service (QoS) for cloud-based software services. These challenges can be best managed through self-adaptivity because engineers’ intervention is difficult, if not impossible, given the dynamic and uncertain QoS sensitivity to the environment and control knobs in the cloud. This is especially true for the shared infrastructure of cloud, where unexpected interference can be caused by co-located software services running on the same virtual machine; and co-hosted virtual machines within the same physical machine. In this paper, we describe the related challenges and present a fully dynamic, self-adaptive and online QoS modeling approach, which grounds on sound information theory and machine learning algorithms, to create QoS model that is capable to predict the QoS value as output over time by using the information on environmental conditions, control knobs and interference as inputs. In particular, we report on in-depth analysis on the correlations of selected inputs to the accuracy of QoS model in cloud. To dynamically selects inputs to the models at runtime and tune accuracy, we design self-adaptive hybrid dual-learners that partition the possible inputs space into two sub-spaces, each of which applies different symmetric uncertainty based selection techniques; the results of sub-spaces are then combined. Subsequently, we propose the use of adaptive multi-learners for building the model. These learners simultaneously allow several learning algorithms to model the QoS function, permitting the capability for dynamically selecting the best model for prediction on the fly. We experimentally evaluate our models in the cloud environment using RUBiS benchmark and realistic FIFA 98 workload. The results show that our approach is more accurate and effective than state-of-the-art modelings.","0098-5589;00985589","","10.1109/TSE.2016.2608826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7572219","Software quality;cloud computing;machine learning;search-based software engineering;self-adaptive systems","Adaptation models;Cloud computing;Interference;Quality of service;Sensitivity;Uncertainty","","","","","","","","20160920","","","IEEE","IEEE Early Access Articles"
"Detecting user actions from HTTP traces: Toward an automatic approach","L. Vassio; I. Drago; M. Mellia","Politecnico di Torino, Italy","2016 International Wireless Communications and Mobile Computing Conference (IWCMC)","20160929","2016","","","50","55","Detecting explicit user actions, i.e., requests for web pages such as hyper-link clicks, from passive traces is fundamental for many applications, such as network forensics or content popularity estimation. Every URL explicitly visited by a user usually triggers further automatic URL requests to obtain all objects that compose the web page. HTTP traces provide a summary of all URLs requested by users, but no information that could be used to separate explicit from automatic requests. Previous works have targeted this problem and ad-hoc heuristics have been proposed. Validation has been typically done using synthetic traces. This paper investigates whether an approach based solely on machine learning can successfully detect user actions from HTTP traces. A machine learning approach would come with many advantages - e.g., it minimizes manual tuning of parameters and can easily adapt to page structure changes. We build both real and synthetic traces to assess the performance and gain insights on the features that bring most advantages in classification. Our results show that machine learning reaches similar or better performance as previous heuristics. Furthermore, we show that models built with machine learning algorithms are robust, presenting consistent performance in different scenarios.","","","10.1109/IWCMC.2016.7577032","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577032","Clickstream;Feature Selection;Machine Learning;Passive Monitoring","Browsers;History;Machine learning algorithms;Selenium;Training;Uniform resource locators;Web pages","Internet;data handling;hypermedia;learning (artificial intelligence);program verification","HTTP traces;ad-hoc heuristics;automatic URL requests;machine learning algorithms;user action detection","","","","","","","5-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Forecasting vegetation index based on vegetation-meteorological factor interactions with artificial neural network","L. Kang; L. Di; M. Deng; E. Yu; Y. Xu","Department of Geography and Geoinformation Science, George Mason University Center for Spatial Information Science and Systems, 4400 University Dr, MSN 6E1, Fairfax, VA 22030","2016 Fifth International Conference on Agro-Geoinformatics (Agro-Geoinformatics)","20160929","2016","","","1","6","Vegetation index derived from remote sensing measurement servers as the significant reference for crop growing monitor and agricultural disaster forecasting. Vegetation index forecasting at long lead time and appropriate spatial scale is critical for decision making to mitigate the impacts from agricultural disaster. In previous studies, vegetation index forecasting has been studied and implemented through different methodologies. Nevertheless, either the accuracy or confidence of forecasting result was affected by model forecasting capability. Artificial neural network (brief as ANN) is capable to model highly complex non-linear patterns of ecological processes. Moreover, its implementation is less restricted by strict assumption regarding variable distribution and model specification. In this paper, an ANN-based forecasting model was proposed to predict the NDVI of grassland within the U.S Great Plains. The forecasting model finds its ground in the historical patterns of lagged correlations between vegetation index and meteorological factors. NDVI forecasting performance at different lead time (i.e., 16, 32, 48 and 64 days) and at different regions (i.e., four ecological zones) is evaluated through cross-validation and comparing with naîve forecasting model. According to forecasting results, the forecasting performance is satisfied with high accuracy. Results of this study will contribute to the knowledge of vegetation stress monitoring and also serve as references for agricultural drought forecasting in the future study.","","","10.1109/Agro-Geoinformatics.2016.7577673","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577673","NDVI;Vegetation index;artificial neural network;forecasting;machine learning","Biological system modeling;Correlation;Forecasting;Indexes;Predictive models;Vegetation;Vegetation mapping","agriculture;crops;environmental monitoring (geophysics);hydrology;neural nets;remote sensing","ANN-based forecasting model;U.S Great Plains;agricultural disaster forecasting;agricultural drought forecasting;artificial neural network;crop growing monitoring;decision making;remote sensing measurement server;vegetation index forecasting;vegetation stress monitoring;vegetation-meteorological factor interaction","","","","","","","18-20 July 2016","","IEEE","IEEE Conference Publications"
"Classification-Based Record Linkage With Pseudonymized Data for Epidemiological Cancer Registries","Y. Siegert; X. Jiang; V. Krieg; S. Bartholomäus","Epidemiological Cancer Registry of North Rhine-Westphalia, M&#x00FC;nster, Germany","IEEE Transactions on Multimedia","20160915","2016","18","10","1929","1941","Cancer is one of the widest spread diseases in human society. Therefore, the need has grown to monitor, evaluate, and predict its development. Cancer registries address this problem by collecting data on cancer cases, striving for high quality, accuracy, and completeness. One of the basic challenges in this context is the linkage of data from multiple sources. In order to link new cancer records with existing ones, the cancer registries typically use an algorithm referred to as record linkage. Although the algorithm has automated a significant amount of the linking process, there still is a certain percentage of records that cannot be linked automatically. This study addresses the problem of reducing the need of manually matching records with machine learning methods. The particular challenge is caused by pseudonymization of the data. The main contribution is thus finding ways to encode the-pseudonymized-data, i.e., feature extraction so that it can be interpreted by a classifier. Three classifiers (neural network, support vector machines, decision tree) manage to achieve at least 93% classification rate on a dataset of 73 000 cancer records extracted from the inventory of a cancer registry. In addition, ensemble techniques boost the performance further to over 95%. We present an in-depth discussion of the experimental results from a perspective of applying the classification-based record linkage in real practice. Two scenarios of translating to practice will be outlined with a potential of reducing the human workload by an order of magnitude of hundreds of hours.","1520-9210;15209210","","10.1109/TMM.2016.2598482","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7536193","Cancer registries;healthcare;machine learning;record linkage;registry integration","Cancer;Couplings;Databases;Diseases;Feature extraction;Joining processes","cancer;decision trees;feature extraction;learning (artificial intelligence);medical information systems;neural nets;pattern classification;support vector machines","classification-based record linkage;data linkage;decision tree classifier;ensemble techniques;epidemiological cancer registry;feature extraction;machine learning methods;neural network classifier;pseudonymized data;support vector machine classifier","","","","","","20160808","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"SpecNN: The specifying neural network","K. Kochetov; E. Putin","Computer Technologies Lab, ITMO University, St. Petersburg, Russia","2016 International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)","20160922","2016","","","1","5","In this paper we present a novel architecture design called SpecNN for artificial neural networks. Our approach allows to consider prior probability distributions and leverage samples similarity to handle the problem of fine-grained samples, thus improving the classification accuracy. We present two different learning algorithms for SpecNN. SpecNN is especially useful in moot cases, when classification is instable. Experiments conducted on several datasets, including MNIST, show that SpecNN outperforms multilayer perceptron.","","","10.1109/INISTA.2016.7571846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571846","fine-grained classification;machine learning;multilayer perceptron;neural network;specifying","Artificial neural networks;Computer architecture;Dogs;Probability distribution;Testing;Training","learning (artificial intelligence);neural nets;pattern classification;statistical distributions","SpecNN;architecture design;artificial neural networks;classification accuracy;learning algorithms;leverage samples similarity;prior probability distributions;specifying neural network","","","","","","","2-5 Aug. 2016","","IEEE","IEEE Conference Publications"
"Deep learning code fragments for code clone detection","M. White; M. Tufano; C. Vendome; D. Poshyvanyk","Department of Computer Science, College of William and Mary, Williamsburg, Virginia, USA","2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)","20161006","2016","","","87","98","Code clone detection is an important problem for software maintenance and evolution. Many approaches consider either structure or identifiers, but none of the existing detection techniques model both sources of information. These techniques also depend on generic, handcrafted features to represent code fragments. We introduce learning-based detection techniques where everything for representing terms and fragments in source code is mined from the repository. Our code analysis supports a framework, which relies on deep learning, for automatically linking patterns mined at the lexical level with patterns mined at the syntactic level. We evaluated our novel learning-based approach for code clone detection with respect to feasibility from the point of view of software maintainers. We sampled and manually evaluated 398 file- and 480 method-level pairs across eight real-world Java systems; 93% of the file- and method-level samples were evaluated to be true positives. Among the true positives, we found pairs mapping to all four clone types. We compared our approach to a traditional structure-oriented technique and found that our learning-based approach detected clones that were either undetected or suboptimally reported by the prominent tool Deckard. Our results affirm that our learning-based approach is suitable for clone detection and a tenable technique for researchers.","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582748","abstract syntax trees;code clone detection;deep learning;language models;machine learning;neural networks","Cloning;Feature extraction;Machine learning;Programming;Software;Syntactics;Transforms","Java;learning (artificial intelligence);software maintenance;source code (software)","Deckard tool;Java systems;code clone detection;deep learning code fragments;pattern mined linking;software evolution;software maintenance;source code","","","","","","","3-7 Sept. 2016","","IEEE","IEEE Conference Publications"
"Sparse Graph Embedding Unsupervised Feature Selection","S. Wang; W. Zhu","Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou 350116, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2016","PP","99","1","13","High dimensionality is quite commonly encountered in data mining problems, and hence dimensionality reduction becomes an important task in order to improve the efficiency of learning algorithms. As a widely used technique of dimensionality reduction, feature selection is about selecting a feature subset being guided by certain criterion. In this paper, three unsupervised feature selection algorithms are proposed and addressed from the viewpoint of sparse graph embedding learning. First, using the self-characterization of the given data, we view the data themselves as a dictionary, conduct sparse coding and propose the sparsity preserving feature selection (SPFS) algorithm. Second, considering the locality preservation of neighborhoods for the data, we study a special case of the SPFS problem, namely, neighborhood preserving feature selection problem, and come up with a suitable algorithm. Third, we incorporate sparse coding and feature selection into one unified framework, and propose a neighborhood embedding feature selection (NEFS) criterion. Drawing support from nonnegative matrix factorization, the corresponding algorithm for NEFS is presented and its convergence is proved. Finally, the three proposed algorithms are validated with the use of eight publicly available real-world datasets from machine learning repository. Extensive experimental results demonstrate the superiority of the proposed algorithms over four compared state-of-the-art unsupervised feature selection methods.","2168-2216;21682216","","10.1109/TSMC.2016.2605132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592899","Feature selection;machine learning;nonnegative matrix factorization;sparse coding;unsupervised learning","Algorithm design and analysis;Clustering algorithms;Dictionaries;Encoding;Machine learning algorithms;Optimization;Sparse matrices","","","","","","","","20161019","","","IEEE","IEEE Early Access Articles"
"Real time facial expression recognition app development on mobile phones","H. Alshamsi; H. Meng; M. Li","Dept. Electronic and Computer Engineering, Brunel University London, UB8 3PH, UK","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1750","1755","Facial expression has made significant progress in recent years with many commercial systems are available for real-world applications. It gains strong interest to implement a facial expression system on a portable device such as tablet and smart phone device using the camera already integrated in the devices. It is very common to see face recognition phone unlocking app in new smart phones which are proven to be hassle free way to unlock a phone. Implementation a facial expression system in a smart phone would provide fun applications that can be used to measure the mood of the user in their daily life or as a tool for their daily monitoring of the motion in phycology studies. However, traditional facial expression algorithms are normally computing extensive and can only be implemented offline at a computer. In this paper, a novel automatic system has been proposed to recognize emotions from face images on a smart phone in real-time. In our system, the camera of the smart phone is used to capture the face image, BRIEF features are extracted and k-nearest neighbor algorithm is implemented for the classification. The experimental results demonstrate that the proposed facial expression recognition on mobile phone is successful and it gives up to 89.5% recognition accuracy.","","","10.1109/FSKD.2016.7603442","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603442","facial expression;image processing;machine learning;mobile computing","Classification algorithms;Databases;Face;Face recognition;Feature extraction;Smart phones;Testing","emotion recognition;face recognition;feature extraction;human factors;image classification;psychology;smart phones","BRIEF feature extraction;automatic system;camera;emotion recognition;face images;face recognition phone unlocking app;k-nearest neighbor algorithm;mobile phones;portable device;real time facial expression recognition app development;smart phones;user mood","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Effort estimation models using evolutionary learning algorithms for software development","G. Gabrani; N. Saini","Department of Computer Engineering, BML Munjal University, Gurgaon, India","2016 Symposium on Colossal Data Analysis and Networking (CDAN)","20160919","2016","","","1","6","Software effort estimation is a complicated task being carried out by software developers as very little information is available to them in the early phases of software development. The information collected about various attributes of software needs to be subjective, which otherwise can lead to uncertainty. Inaccurate software effort estimation can be disastrous as both underestimation and overestimation may result in schedule overruns and incorrect estimation of budget. This paper focuses on the comparative study of various non-algorithmic techniques used for estimating the software effort by empirical evaluation of five different evolutionary learning algorithms. The accuracy of these algorithms is found out and the behavior of these algorithms is analyzed with respect to the size and the type of data. All the five techniques are applied on three different datasets and various paramenters such as MMRE, PRED(25), PRED(50), PRED(75) are calculated. The proposed results are compared to other machine learning methods like SVR, ANFIS etc. The results show that evolutionary learning algorithms give more accurate results than machine learning algorithms.","","","10.1109/CDAN.2016.7570916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7570916","Evolutionary Learning Algorithms;Machine Learning Algorithms;Mean Magnitude of the Relative Error MMRE;Percentage of Predictions(x) PRED(x);Software Effort Estimation","Algorithm design and analysis;Data models;Estimation;Machine learning algorithms;Prediction algorithms;Software;Software algorithms","evolutionary computation;learning (artificial intelligence);software cost estimation","MMRE calculation;PRED(25) calculation;PRED(50) calculation;PRED(75) calculation;evolutionary learning algorithms;incorrect budget estimation;magnitude of the relative error calculation;nonalgorithmic techniques;percentage of predictions calculation;software attributes;software development;software effort estimation models","","","","","","","18-19 March 2016","","IEEE","IEEE Conference Publications"
"Compressed Signal Processing on Nyquist-Sampled Signals","J. Lu; N. Verma; N. K. Jha","Department of Electrical Engineering, Princeton University, Princeton, NJ","IEEE Transactions on Computers","20161006","2016","65","11","3293","3303","Pattern-recognition algorithms from the domain of machine learning play a prominent role in embedded sensing systems, in order to derive inferences from sensor data. Very often, such systems face severe energy constraints. The focus of this work is to mitigate the computational energy by exploiting a form of compression which preserves a similarity metric widely used for pattern recognition. The form of compression is random projection, and the similarity metric is inner products between source vectors. Given the prominence of random projections within compressive sensing, previous research has explored this idea for application to compressively-sensed signals. In this work, we analyze the error sources faced by such approaches and show that the compressive-sensing setting itself introduces a significant source of feature-computation error (<inline-formula><tex-math notation=""LaTeX""> $sim$</tex-math><alternatives><inline-graphic xlink:type=""simple"" xlink:href=""lu-ieq1-2532861.gif""/></alternatives> </inline-formula>30 percent). We show that random projections can be exploited more generally without compressive sensing, enabling significant reduction in computational energy, and avoiding a significant source of error. The approach is referred to as <italic>compressed signal processing (CSP)</italic>, and it applies to Nyquist-sampled signals. We validate the CSP approach through two case studies. The first focuses on seizure detection using spectral-energy features extracted from electroencephalograms. We show that at a 32<inline-formula> <tex-math notation=""LaTeX"">$times$</tex-math><alternatives> <inline-graphic xlink:type=""simple"" xlink:href=""lu-ieq2-2532861.gif""/></alternatives></inline-formula> compression ratio, the number of multiply-accumulate (MAC) and operand-access operations required is reduced by 21.2<inline-formula> <tex-math notation=""LaTeX"">$times$</tex-math><alternatives> <inline-graphic xlink:type=""simple"" xlink:href=""lu-ieq3-2532861.gif""/></alter- atives></inline-formula>, while achieving a sensitivity of 100 percent, latency of 4.33 sec, and false alarm rate of 0.22/hr; this compares to a baseline performance of 100 percent, 4.37 sec, and 0.12/hr, respectively. The second case study focuses on neural prosthesis based on extracting wavelet features from a set of detected spikes. We show that at a 32<inline-formula><tex-math notation=""LaTeX""> $times$</tex-math><alternatives><inline-graphic xlink:type=""simple"" xlink:href=""lu-ieq4-2532861.gif""/></alternatives> </inline-formula> compression ratio, the number of MAC and operand access computations required is reduced by 3.3 <inline-formula><tex-math notation=""LaTeX"">$times$</tex-math><alternatives> <inline-graphic xlink:type=""simple"" xlink:href=""lu-ieq5-2532861.gif""/></alternatives></inline-formula>, while spike sorting performance can be maintained within an average error of 4.89 percent for spike count, 3.42 percent for coefficient of variance, and 4.90 percent for firing rate; this compares with a baseline average error of 4.00, 2.75, and 4.00 percent for spike count, coefficient of variance, and firing rate, respectively.","0018-9340;00189340","","10.1109/TC.2016.2532861","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422045","Classification;Nyquist domain;compressed signal processing;machine learning;random projections","Convolution;Data acquisition;Embedded systems;Feature extraction;Machine learning;Measurement;Pattern recognition;Signal processing algorithms","","","","","","","","20160229","Nov. 1 2016","","IEEE","IEEE Journals & Magazines"
"Parallel Processing Systems for Big Data: A Survey","Y. Zhang; T. Cao; S. Li; X. Tian; L. Yuan; H. Jia; A. V. Vasilakos","State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","Proceedings of the IEEE","20161019","2016","104","11","2114","2136","The volume, variety, and velocity properties of big data and the valuable information it contains have motivated the investigation of many new parallel data processing systems in addition to the approaches using traditional database management systems (DBMSs). MapReduce pioneered this paradigm change and rapidly became the primary big data processing system for its simplicity, scalability, and fine-grain fault tolerance. However, compared with DBMSs, MapReduce also arouses controversy in processing efficiency, low-level abstraction, and rigid dataflow. Inspired by MapReduce, nowadays the big data systems are blooming. Some of them follow MapReduce's idea, but with more flexible models for general-purpose usage. Some absorb the advantages of DBMSs with higher abstraction. There are also specific systems for certain applications, such as machine learning and stream data processing. To explore new research opportunities and assist users in selecting suitable processing systems for specific applications, this survey paper will give a high-level overview of the existing parallel data processing systems categorized by the data input as batch processing, stream processing, graph processing, and machine learning processing and introduce representative projects in each category. As the pioneer, the original MapReduce system, as well as its active variants and extensions on dataflow, data access, parameter tuning, communication, and energy optimizations will be discussed at first. System benchmarks and open issues for big data processing will also be studied in this survey.","0018-9219;00189219","","10.1109/JPROC.2016.2591592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547948","Big data;MapReduce;SQL;machine learning;parallel processing;survey","Benchmark testing;Big data;Computer applications;Data models;Machine learning;Parallel processing;Programming;Structured Query Language","database management systems;fault tolerance;parallel processing","DBMS;MapReduce system;batch processing;database management system;energy optimization;fine-grain fault tolerance;graph processing;low-level abstraction;machine learning processing;parallel data processing system;rigid dataflow;stream data processing","","1","","","","20160819","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Detection of sunn pests using sound signal processing methods","B. G. Yazgaç; M. Kırcı; M. Kıvan","Department of Electronics and Communication Engineering, Istanbul Technical University, Electrical and Electronics Engineering Faculty, Maslak, Istanbul, Turkey","2016 Fifth International Conference on Agro-Geoinformatics (Agro-Geoinformatics)","20160929","2016","","","1","6","Extensive consumption of cereals as food in different domestic cousins places great demand the detection of cereal pest and struggle against them. Sunn pests such as Eurygaster integriceps, Eurygaster austriaca, Aelia rostrata and Aelia acuminata are insects with similar seasonal behaviors and dominant threat to the cereal plantations of Turkey. In this work, a microphone which works in acoustic and ultrasonic sound levels with the ability of making recordings with high frequency rate is used. Following the recording of sunn pest sounds with laboratory and outdoor conditions, the sound feature vectors are obtained with the application of different methods such as Linear Predictive Cepstral Coefficients (LPCC), Line Spectral Frequencies (LSF) and Mel Frequency Cepstral Coefficients (MFCC). By analyzing different kNN models it is shown that the automatic detection of sunn pests is possible with sound processing and machine learning methods. The best results is achieved with the overall accuracy of 93.6% using the combination of MFCC and LSF methods.","","","10.1109/Agro-Geoinformatics.2016.7577694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577694","Cereals;LPCC;LSF;MFCC;feature extraction;kNN;machine learning;signal processing;sound processing;sunn pests","Agriculture;Feature extraction;Insects;Mel frequency cepstral coefficient;Microphones","acoustic signal processing;agriculture;audio signal processing;learning (artificial intelligence);microphones;pest control","Aelia acuminata;Aelia rostrata;Eurygaster austriaca;Eurygaster integriceps;LPCC;LSF;MFCC;Mel frequency cepstral coefficients;Turkey;cereal pest;cereal plantations;domestic cousins;kNN models;line spectral frequencies;linear predictive cepstral coefficients;machine learning methods;microphone;seasonal behaviors;sound feature vectors;sound signal processing methods;sunn pests;ultrasonic sound levels","","","","","","","18-20 July 2016","","IEEE","IEEE Conference Publications"
"Impacts of Intelligent Automated Quality Control on a Small Animal APD-Based Digital PET Scanner","J. Charest; J. F. Beaudoin; M. Bergeron; J. Cadorette; L. Arpin; R. Lecomte; C. A. Brunet; R. Fontaine","Institut Interdisciplinaire d&#8217;Innovation Technologique (3IT), Universit&#x00E9; de Sherbrooke, Sherbrooke, QC, Canada","IEEE Transactions on Nuclear Science","20161012","2016","63","5","2550","2557","Stable system performance is mandatory to warrant the accuracy and reliability of biological results relying on small animal positron emission tomography (PET) imaging studies. This simple requirement sets the ground for imposing routine quality control (QC) procedures to keep PET scanners at a reliable optimal performance level. However, such procedures can become burdensome to implement for scanner operators, especially taking into account the increasing number of data acquisition channels in newer generation PET scanners. In systems using pixel detectors to achieve enhanced spatial resolution and contrast-to-noise ratio (CNR), the QC workload rapidly increases to unmanageable levels due to the number of independent channels involved. An artificial intelligence based QC system, referred to as Scanner Intelligent Diagnosis for Optimal Performance (SIDOP), was proposed to help reducing the QC workload by performing automatic channel fault detection and diagnosis. SIDOP consists of four high-level modules that employ machine learning methods to perform their tasks: Parameter Extraction, Channel Fault Detection, Fault Prioritization, and Fault Diagnosis. Ultimately, SIDOP submits a prioritized faulty channel list to the operator and proposes actions to correct them. To validate that SIDOP can perform QC procedures adequately, it was deployed on a LabPET™ scanner and multiple performance metrics were extracted. After multiple corrections on sub-optimal scanner settings, a 8.5% (with a 95% confidence interval (CI) of [7.6, 9.3]) improvement in the CNR, a 17.0% (CI: [15.3, 18.7]) decrease of the uniformity percentage standard deviation, and a 6.8% gain in global sensitivity were observed. These results confirm that SIDOP can indeed be of assistance in performing QC procedures and restore performance to optimal figures.","0018-9499;00189499","","10.1109/TNS.2016.2605060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557054","Artificial intelligence (AI);biomedical imaging;expert systems;fault diagnosis;fuzzy logic;machine learning;positron emission tomography (PET)","Avalanche photodiodes;Crystals;Fault detection;Fault diagnosis;Image quality;Phantoms;Positron emission tomography","avalanche photodiodes;data acquisition;image resolution;learning (artificial intelligence);medical image processing;positron emission tomography;quality control","CNR;LabPET scanner;SIDOP;artificial intelligence;automatic channel fault detection;avalanche photodiodes;contrast-noise ratio;data acquisition channels;enhanced spatial resolution;fault diagnosis;fault prioritization;global sensitivity;intelligent automated quality control;machine learning;optimal performance;parameter extraction;pixel detectors;positron emission tomography;scanner intelligent diagnosis;small animal APD-based digital PET scanner","","","","","","20160831","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"A 3D serious game for medical students training in clinical cases","R. M. de Lima; A. de Medeiros Santos; F. M. M. Neto; A. F. de Sousa Neto; F. C. P. Leão; F. T. de Macedo; A. M. de Paula Canuto","Department of Exact and Natural Sciences, Rural Federal University of the Semiarid, Mossor&#x00F3; - RN, Brazil","2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH)","20161010","2016","","","1","9","This paper describes an auxiliary environment in the process of teaching and learning for students and professors of medicine. The environment has a serious game available in various computing devices to simulate clinical cases in order to assess students' knowledge. Diagnostics are simulated using 3D environment, mobile application using voice synthesizer and immersion through virtual reality goggles. The environment has gamification features as a motivational mechanism for users. Within the 3D environment, medical subjects are offered by the NPCs (Non Playable Characters), in order to provide auxiliary knowledge to facilitate the identification of diseases in patients or medical issues in general. Professors can check the score of their students and take extra steps in class to clarify doubts. The system has a multi-agent system and machine learning for disease classification offered by virtual patients.","","","10.1109/SeGAH.2016.7586255","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586255","gamification;machine learning;multi-agent system;simulators for clinical case;virtual environment;virtual glasses;voice synthesizer","Computers;Games;Medical diagnostic imaging;Three-dimensional displays;Training;Virtual reality","computer aided instruction;learning (artificial intelligence);medical diagnostic computing;multi-agent systems;serious games (computing);virtual reality","3D environment;3D serious game;NPC;clinical cases;computing devices;disease classification;learning;machine learning;medical students training;mobile application;motivational mechanism;multi-agent system;nonplayable characters;teaching;virtual patients;virtual reality goggles;voice synthesizer","","","","","","","11-13 May 2016","","IEEE","IEEE Conference Publications"
"Face recognition based on stretchy regression","K. A. Toh","School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea 120-749","2016 IEEE 11th Conference on Industrial Electronics and Applications (ICIEA)","20161024","2016","","","819","824","In this paper, an asymmetric kernel is proposed for extracting sparse features from two-dimensional visual face images for identity recognition. Essentially, the kernel consists of an inner product of two vectors where one of them has been raised to power terms element-wise. The impact of such a power term is suppression of less influential features where only relevant ones are used for estimation. Our experiments on public data sets show encouraging results regarding the potential of such an asymmetric kernel.","","","10.1109/ICIEA.2016.7603694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603694","Machine learning;kernel method;linear regression;pattern recognition","Estimation;Face;Face recognition;Kernel;Training;Training data;Visualization","face recognition;regression analysis","face recognition;identity recognition;influential features;public data sets;sparse feature extraction;stretchy regression;two-dimensional visual face images","","","","","","","5-7 June 2016","","IEEE","IEEE Conference Publications"
"An under-sampling imbalanced learning of data gravitation based classification","L. Peng; B. Yang; Y. Chen; X. Zhou","Shandong Provincial Key Laboratory of Network Based Intelligent Computing, University of Jinan, Jinan, 250022, P. R. China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","419","425","With one class outnumbering another, many real classification tasks show imbalanced class distributions, which brings big trouble to standard classification models: they usually intend to recognize a minority instance as a majority one. The data gravitation based classification (DGC) model, a newly developed physical-inspired supervised learning model, has been proven effective for standard supervised learning tasks. However, DGC is not able to get high performances for imbalanced data sets, like most other standard learning algorithms do. Thus, to address the problem, an under-sampling technique, together with an ensemble technique, has been designed to adapt the standard DGC model for imbalanced learning tasks. The new adapted DGC model is called UI-DGC. 22 low imbalanced and 22 high imbalanced data sets are selected for the experimental study. UI-DGC is compared with standard and imbalanced learning algorithms. Empirical studies suggest that the UI-DGC model can get high imbalanced classification performances, especially for high imbalanced tasks.","","","10.1109/FSKD.2016.7603210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603210","Data gravitation;Imbalanced learning;Machine learning;Under sampling","Adaptation models;Algorithm design and analysis;Computational modeling;Data models;Standards;Testing;Training","data analysis;learning (artificial intelligence)","UI-DGC model;data gravitation based classification;imbalanced data sets;physical-inspired supervised learning model;standard supervised learning tasks;under-sampling imbalanced learning","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Identification of blood biomarkers for use in point of care diagnosis tool for Alzheimer's disease","E. Jammeh; P. Zhao; C. Carroll; S. Pearson; E. Ifeachor","","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","2415","2418","Early diagnosis of Alzheimer's Disease (AD) is widely regarded as necessary to allow treatment to be started before irreversible damage to the brain occur and for patients to benefit from new therapies as they become available. Low-cost point-of-care (PoC) diagnostic tools that can be used to routinely diagnose AD in its early stage would facilitate this, but such tools require reliable and accurate biomarkers. However, traditional biomarkers for AD use invasive cerebrospinal fluid (CSF) analysis and/or expensive neuroimaging techniques together with neuropsychological assessments. Blood-based PoC diagnostics tools may provide a more cost and time efficient way to assess AD to complement CSF and neuroimaging techniques. However, evidence to date suggests that only a panel of biomarkers would provide the diagnostic accuracy needed in clinical practice and that the number of biomarkers in such panels can be large. In addition, the biomarkers in a panel vary from study to study. These issues make it difficult to realise a PoC device for diagnosis of AD. An objective of this paper is to find an optimum number of blood biomarkers (in terms of number of biomarkers and sensitivity/specificity) that can be used in a handheld PoC device for AD diagnosis. We used the Alzheimer's disease Neuroimaging Initiative (ADNI) database to identify a small number of blood biomarkers for AD. We identified a 6-biomarker panel (which includes A1Micro, A2Macro, AAT, ApoE, complement C3 and PPP), which when used with age as covariate, was able to discriminate between AD patients and normal subjects with a sensitivity of 85.4% and specificity of 78.6%.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7591217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591217","AD;ADNI;Classification;Machine Learning","Blood;Databases;Dementia;Proteomics;Sensitivity;Sensitivity and specificity","brain;diseases;neurophysiology;patient diagnosis","Alzheimer's disease neuroimaging initiative database;blood biomarker identification;invasive cerebrospinal fluid analysis;point of care diagnosis","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Discrete-event simulation framework tor developing methods for low voltage network observability enhancement","M. Lisowski; R. Maśnicki; J. Mindykowski","Gdynia Maritime University, Morska 81-87, 81-225 Gdynia, Poland","2016 Second International Conference on Event-based Control, Communication, and Signal Processing (EBCCSP)","20161024","2016","","","1","6","With the considerable volume of data obtained by a Smart Grid management system, modern statistical and machine learning approaches can be used to extract useful information about the energy distribution network. This paper introduces the PLC smart meter communication crosstalk problem in low-voltage electric energy distribution network, and a software simulation framework, which can facilitate the search for a solution. Each piece of data arriving from the Smart Grids is treated as a discrete event. The data is then analyzed by a process-based discrete-event simulation framework to infer information that is directly unobservable, and in turn yield results that effectively solve the crosstalk problem. An example simulation is described in detail, along with its results.","","","10.1109/EBCCSP.2016.7605090","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7605090","discrete-event simulation;low-voltage network;machine learning;observability enhancement;power line communication;smart grid","Crosstalk;Data models;Energy measurement;Mathematical model;Smart grids;Smart meters;Transient analysis","carrier transmission on power lines;discrete event simulation;distribution networks;learning (artificial intelligence);observability;smart meters;smart power grids","PLC smart meter communication crosstalk problem;low voltage network observability enhancement;low-voltage electric energy distribution network;machine learning;power line communication;process-based discrete-event simulation framework;smart grid management system;software simulation framework;statistical learning","","","","","","","13-15 June 2016","","IEEE","IEEE Conference Publications"
"Big vehicular traffic Data mining: Towards accident and congestion prevention","H. Al Najada; I. Mahgoub","Computer & Electrical Engineering & Computer Science Department, Florida Atlantic University, 777 Glades Road, Boca Raton, 33431 USA","2016 International Wireless Communications and Mobile Computing Conference (IWCMC)","20160929","2016","","","256","261","In 2013, 32,719 people died in traffic crashes in the USA. Almost 90 people on average lose their lives every day and more than 250 are injured every hour. Road safety could be enhanced by decreasing the traffic crashes. Traffic crashes cause traffic congestion as well, which has become unbearable, especially in mega-cities In addition, direct and indirect loss from traffic congestion only is over $124 billion. The existence of the Big Data of traffic crashes, as well as the availability of Big Data analytics tools can help us gain useful insights to enhance road safety and decrease traffic crashes. In this paper we use H2O and WEKA mining tools. We apply the feature selection techniques to find the most important predictors. In addition, we tackle the problem of class imbalance by employing bagging and using different quality measures. Furthermore, we evaluate the performance of five classifiers to: (1) Conduct Big Data analysis on a big traffic accidents dataset of 146322 examples, find useful insight and patterns from the data, and forecast possible accidents in advance (2) Conduct Big Data analysis on a big vehicular casualties dataset of 194477 examples, to study the driver's behavior on the road. From the driver's behavior mining we can predict the driver age, sex as well as the accident severity. The aforementioned analyses, can be used by decision makers and practitioners to develop new traffic rules and policies, in order to prevent accidents, and increase roadway safety.","","","10.1109/IWCMC.2016.7577067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577067","Big Data;Intelligent Transportation System (ITS);Machine Learning and Data Mining;Traffic Engineering;Vehicular Ad-hoc Network (VANET)","Accidents;Big data;Computer crashes;Data mining;Roads;Vehicles","Big Data;data mining;road accidents;road safety;traffic engineering computing","H2O mining tool;WEKA mining tool;accident prevention;big data analytics tool;big vehicular traffic data mining;class imbalance;driver behavior mining;feature selection;road safety;traffic congestion prevention;traffic crashes","","1","","","","","5-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Online voltage stability monitoring of distribution system using optimized Support Vector Machine","A. Shukla; K. Verma; R. Kumar","Department of Electrical Engineering, MNIT Jaipur-302017, India","2016 IEEE 6th International Conference on Power Systems (ICPS)","20161006","2016","","","1","6","Voltage stability monitoring plays a significant role in secure and reliable operation of modern power systems. In this paper, two methods, (i) Particle Swarm Optimization (PSO) based Support Vector Machine (PSO-SVM) and (ii) Genetic Algorithm (GA) based Support Vector Machine (GA-SVM) is proposed for online voltage stability monitoring of distribution system. The optimal values of SVM parameters are obtained using PSO and GA algorithms. Comparison between proposed PSO-SVM and GA-SVM model are investigated on IEEE 33-bus radial distribution system. The results show that the PSO-SVM model for online voltage stability monitoring is more precise than GA-SVM.","","","10.1109/ICPES.2016.7584132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584132","distribution system;genetic algorithm;machine learning;particle swarm optimization;support vector machine;voltage stability","Genetic algorithms;Loading;Power system stability;Stability criteria;Support vector machines;Thermal stability","genetic algorithms;particle swarm optimisation;power distribution reliability;power engineering computing;support vector machines","GA-SVM model;GA-based support vector machine;IEEE 33-bus radial distribution system;PSO-SVM model;PSO-based support vector machine;distribution system;genetic algorithm;online voltage stability monitoring;optimized support vector machine;particle swarm optimization;power system operation reliability","","","","","","","4-6 March 2016","","IEEE","IEEE Conference Publications"
"Comparison deep learning method to traditional methods using for network intrusion detection","B. Dong; X. Wang","Computing Center of Liaoning University, Shenyang, China","2016 8th IEEE International Conference on Communication Software and Networks (ICCSN)","20161010","2016","","","581","585","Recently, deep learning has gained prominence due to the potential it portends for machine learning. For this reason, deep learning techniques have been applied in many fields, such as recognizing some kinds of patterns or classification. Intrusion detection analyses got data from monitoring security events to get situation assessment of network. Lots of traditional machine learning method has been put forward to intrusion detection, but it is necessary to improvement the detection performance and accuracy. This paper discusses different methods which were used to classify network traffic. We decided to use different methods on open data set and did experiment with these methods to find out a best way to intrusion detection.","","","10.1109/ICCSN.2016.7586590","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586590","classifier machine learning;deep learning;intrusion detection;network security","Communication networks;Feature extraction;Hardware;Intrusion detection;Machine learning;Software","computer network security;learning (artificial intelligence);pattern classification","comparison deep learning method;deep learning techniques;intrusion detection analysis;machine learning;network intrusion detection;network traffic classification","","","","","","","4-6 June 2016","","IEEE","IEEE Conference Publications"
"A cascade deep neuro-fuzzy system for high-dimensional online possibilistic fuzzy clustering","Z. Hu; Y. V. Bodyanskiy; O. K. Tyshchenko","School of Educational Information Technology, Central China Normal University, Wuhan, China","2016 XIth International Scientific and Technical Conference Computer Sciences and Information Technologies (CSIT)","20161013","2016","","","119","122","A cascade deep learning system (based on neuro-fuzzy nodes) and its online learning procedure are proposed in this paper. The system is based on nodes of a special type. A goal function of a special type is used for possibilistic high-dimensional fuzzy clustering. To estimate a clustering quality of data processing, an optimal value of a cluster validity index is used.","","","10.1109/STC-CSIT.2016.7589884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7589884","Computational Intelligence;Data Stream Processing;Evolving System;Fuzzy Clustering;Machine Learning;Neuro-Fuzzy System","Adaptive systems;Clustering algorithms;Computer architecture;Fuzzy systems;Indexes;Machine learning;Neural networks","fuzzy neural nets;fuzzy set theory;learning (artificial intelligence);pattern clustering;possibility theory","cascade deep learning system;cascade deep neuro-fuzzy system;cluster validity index;clustering quality;data processing;goal function;high-dimensional online possibilistic fuzzy clustering;online learning procedure","","","","","","","6-10 Sept. 2016","","IEEE","IEEE Conference Publications"
"Learning Rotation-Invariant Convolutional Neural Networks for Object Detection in VHR Optical Remote Sensing Images","G. Cheng; P. Zhou; J. Han","School of Automation, Northwestern Polytechnical University, Xi&#x0027;an, China","IEEE Transactions on Geoscience and Remote Sensing","20160930","2016","54","12","7405","7415","Object detection in very high resolution optical remote sensing images is a fundamental problem faced for remote sensing image analysis. Due to the advances of powerful feature representations, machine-learning-based object detection is receiving increasing attention. Although numerous feature representations exist, most of them are handcrafted or shallow-learning-based features. As the object detection task becomes more challenging, their description capability becomes limited or even impoverished. More recently, deep learning algorithms, especially convolutional neural networks (CNNs), have shown their much stronger feature representation power in computer vision. Despite the progress made in nature scene images, it is problematic to directly use the CNN feature for object detection in optical remote sensing images because it is difficult to effectively deal with the problem of object rotation variations. To address this problem, this paper proposes a novel and effective approach to learn a rotation-invariant CNN (RICNN) model for advancing the performance of object detection, which is achieved by introducing and learning a new rotation-invariant layer on the basis of the existing CNN architectures. However, different from the training of traditional CNN models that only optimizes the multinomial logistic regression objective, our RICNN model is trained by optimizing a new objective function via imposing a regularization constraint, which explicitly enforces the feature representations of the training samples before and after rotating to be mapped close to each other, hence achieving rotation invariance. To facilitate training, we first train the rotation-invariant layer and then domain-specifically fine-tune the whole RICNN network to further boost the performance. Comprehensive evaluations on a publicly available ten-class object detection data set demonstrate the effectiveness of the proposed method.","0196-2892;01962892","","10.1109/TGRS.2016.2601622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560644","Convolutional neural networks (CNNs);machine learning;object detection;remote sensing images;rotation-invariant CNN (RICNN)","Computer architecture;Feature extraction;Object detection;Optical imaging;Optical sensors;Remote sensing;Training","image processing;learning (artificial intelligence);neural nets;object detection;remote sensing","convolutional neural networks;deep learning algorithm;learning rotation-invariant CNN model;machine learning;multinomial logistic regression;nature scene image;object detection;remote sensing image analysis;rotation-invariant layer;shallow-learning-based feature;very-high-resolution optical remote sensing image","","","","","","20160905","Dec. 2016","","IEEE","IEEE Journals & Magazines"
"A novel cognitive architecture for QoS/QoE management in NextG Networks based on Q-learning and R-MLP approaches","A. Ben Zineb; M. Ayadi; S. Tabbane","Higher School of Communications, (Sup'Com) Tunis-Tunisia","2016 International Wireless Communications and Mobile Computing Conference (IWCMC)","20160929","2016","","","892","897","Next Generation Networks (NGN) principle or 5G technology, is based on the integration of heterogeneous wireless systems and cognitive networks. NGN is expected to have Quality of Service (QoS) as the major challenging issue. More specifically, NGN aims at providing guaranteed QoS levels and Quality of Experience (QoE), especially for multimedia services. However, with the increase in number of connections, services and data amounts, it becomes crucial to ensure an intelligent network management to ensure target goals. This paper proposes a novel cognitive radio network architecture for the management of cognitive networks and 5G technology. The goal of the proposed architecture consists on using artificial intelligence with learning capabilities to optimize network management decisions. The proposed architecture consists of 4 main states: sensing, decision management, action, and learning. It provides the functionality to manage cognitive components and facilitate the interfaces between the network and its surrounding environment. In order to demonstrate the functionality of the proposed architecture, we present simulation results and comparison with existing load balancing method in terms of throughput, latency and QoE.","","","10.1109/IWCMC.2016.7577176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577176","5G;Cognitive cycle;Cognitive radio;QoS/QoE;decision management;machine learning;sensing","Cognition;Cognitive radio;Computer architecture;Engines;Next generation networking;Quality of service;Sensors","5G mobile communication;artificial intelligence;cognitive radio;multilayer perceptrons;next generation networks;quality of experience;quality of service;telecommunication computing;telecommunication network management","5G technology;NextG networks;Q-learning;QoS-QoE management;R-MLP;artificial intelligence;cognitive networks;cognitive radio network architecture;heterogeneous wireless systems;intelligent network management;multimedia services;next generation networks;quality of experience;quality of service;reverse multilayered perceptron","","","","","","","5-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"A case study of optimal decision tree construction for RFKON database","S. B. Keser; U. Yayan","Dept. of Computer Engineering, Eskisehir Osmangazi University, Eskisehir, Turkiye","2016 International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)","20160922","2016","","","1","6","The estimation of user position in indoor environment using WLAN technology based on Received Signal Strength (RSS) is becoming increasingly important in recent years. Various indoor positioning techniques are proposed in the literature. Fingerprint positioning technique is the most promising one that consists of radio frequency (RF) map construction and location estimation phases. Machine learning algorithms are used in the location estimation phase. Decision Tree algorithm is one of the most commonly applied ML algorithm that is used to infer user position by researchers. In this case study, we analyze decision tree algorithm parameters to find an optimal decision tree for indoor positioning system. The accuracy of this optimal tree is analyzed in the experiments.","","","10.1109/INISTA.2016.7571857","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571857","Indoor positioning systems;WLAN-based positioning;decision tree;fingerprint positioning technique;machine learning;radio frequency;received signal strength","Algorithm design and analysis;Databases;Decision trees;Fingerprint recognition;IEEE 802.11 Standard;Machine learning algorithms;Servers","RSSI;database management systems;decision trees;estimation theory;learning (artificial intelligence);wireless LAN","RFKON database;RSS;WLAN technology;fingerprint positioning;indoor environment;indoor positioning;location estimation phases;machine learning algorithms;optimal decision tree construction;radio frequency map construction;received signal strength;user position estimation","","","","","","","2-5 Aug. 2016","","IEEE","IEEE Conference Publications"
"An approach to identifying cryptographic algorithm from ciphertext","C. Tan; Q. Ji","Science and Technology on Communication Security Laboratory, Chengdu, Sichuan Province, China","2016 8th IEEE International Conference on Communication Software and Networks (ICCSN)","20161010","2016","","","19","23","Cryptographic algorithm plays a significant role in a cryptosystem, which protects those sensitive and private data from been obtained by some malicious attackers. Actually, the details about the cryptographic algorithm applied in a cryptosystem are often unknown to one cryptanalyst. When a cryptanalyst works on cryptanalysis, he will have much trouble if he doesn't know anything about the used cryptographic algorithm. In this paper, we introduce an approach to identifying the cryptographic algorithm with no other information but ciphertext. Firstly, we present the whole implementation architecture of our identification system. Then we apply our identification system in identifying 5 common block ciphers, namely AES, Blowfish, 3DES, RC5 and DES. Through analyzing the experiment results, we conclude that the identification rate can obtain around 90% if keys are the same for training and testing ciphertexts. When we use different keys for training and testing ciphertexts, we can still identify AES from anyone of the other 4 cryptographic algorithms with a high identification rate in one to one identification.","","","10.1109/ICCSN.2016.7586649","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586649","SVM classifier;cryptographic algorithm identification;identification system;machine learning","Ciphers;Classification algorithms;Support vector machines;Testing;Three-dimensional displays;Training","cryptography;data privacy","3DES;AES;Blowfish;DES;RC5;block ciphers;ciphertext;cryptanalyst;cryptographic algorithm;cryptosystem;identification rate;malicious attackers;private data;sensitive data","","","","","","","4-6 June 2016","","IEEE","IEEE Conference Publications"
"In-Vivo Automatic Nuclear Cataract Detection and Classification in an Animal Model by Ultrasounds","M. Caixinha; J. Amaro; M. Santos; F. Perdigão; M. Gomes; J. Santos","Department of Electrical and Computer Engineering, University of Coimbra, Coimbra, Portugal","IEEE Transactions on Biomedical Engineering","20161019","2016","63","11","2326","2335","Objective: To early detect nuclear cataract in vivo and automatically classify its severity degree, based on the ultrasound technique, using machine learning. Methods: A 20-MHz ophthalmic ultrasound probe with a focal length of 8.9 mm and an active diameter of 3 mm was used. Twenty-seven features in time and frequency domain were extracted for cataract detection and classification with support vector machine (SVM), Bayes, multilayer perceptron, and random forest classifiers. Fifty rats were used: 14 as control and 36 as study group. An animal model for nuclear cataract was developed. Twelve rats with incipient, 13 with moderate, and 11 with severe cataract were obtained. The hardness of the nucleus and the cortex regions was objectively measured in 12 rats using the NanoTest. Results: Velocity, attenuation, and frequency downshift significantly increased with cataract formation (P <; 0.001). The SVM classifier showed the higher performance for the automatic classification of cataract severity, with a precision, sensitivity, and specificity of 99.7% (relative absolute error of 0.4%). A statistically significant difference was found for the hardness of the different cataract degrees (P = 0.016). The nucleus showed a higher hardness increase with cataract formation (P = 0.049). A moderate-to-good correlation between the features and the nucleus hardness was found in 23 out of the 27 features. Conclusion: The developed methodology made possible detecting the nuclear cataract in-vivo in early stages, classifying automatically its severity degree and estimating its hardness. Significance: Based on this work, a medical prototype will be developed for early cataract detection, classification, and hardness estimation.","0018-9294;00189294","","10.1109/TBME.2016.2527787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404283","Cataract;classification;hardness;machine learning;ultrasound","Biological system modeling;Lenses;Probes;Rats;Surgery;Ultrasonic imaging","biomedical ultrasonics;eye;feature extraction;image classification;learning (artificial intelligence);medical image processing;support vector machines","Bayes classifiers;NanoTest;SVM classifier;animal model;cataract degrees;cataract severity;cortex regions;feature extraction;focal length;frequency 20 MHz;frequency domain;in-vivo automatic nuclear cataract classification;in-vivo automatic nuclear cataract detection;machine learning;moderate-to-good correlation;multilayer perceptron;nucleus hardness;ophthalmic ultrasound probe;random forest classifiers;support vector machine","","","","","","20160211","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Towards Data Analytics of Pathogen-Host Protein-Protein Interaction: A Survey","H. Chen; J. Shen; L. Wang; J. Song","Sch. of Comput. & Inf. Technol., Univ. of Wollongong, Wollongong, NSW, Australia","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","377","388","""Big Data"" is immersed in many disciplines, including computer vision, economics, online resources, bioinformatics and so on. Increasing researches are conducted on data mining and machine learning for uncovering and predicting related domain knowledge. Protein-protein interaction is one of the main areas in bioinformatics as it is the basis of the biological functions. However, most pathogen-host protein-protein interactions, which would be able to reveal much more infectious mechanisms between pathogen and host, are still up for further investigation. Considering a decent feature representation of pathogen-host protein-protein interactions (PHPPI), currently there is not a well structured database for research purposes, not even for infection mechanism studies for different species of pathogens. In this paper, we will survey the PHPPI researches and construct a public PHPPI dataset by ourselves for future research. It results in an utterly big and imbalanced data set associated with high dimension and large quantity. Several machine learning methodologies are also discussed in this paper to imply possible analytics solutions in near future. This paper contributes to a new, yet challenging, research area in applying data analytic technologies in bioinformatics, by learning and predicting pathogen-host protein-protein interactions.","","","10.1109/BigDataCongress.2016.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584966","PHPPI;big data;bioinformatics;machine learning","Amino acids;Bioinformatics;Pathogens;Protein engineering;Protein sequence","bioinformatics;data analysis;data mining;learning (artificial intelligence);proteins","big data;bioinformatics;biological function;data analytic technology;data analytics;data mining;machine learning;pathogen-host protein-protein interaction","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Detecting DGA malware traffic through behavioral models","M. J. Erquiaga; C. Catania; S. García","CTU University, ATG Group, Prague, Czech Republic","2016 IEEE Biennial Congress of Argentina (ARGENCON)","20161010","2016","","","1","6","Some botnets use special algorithms to generate the domain names they need to connect to their command and control servers. They are refereed as Domain Generation Algorithms. Domain Generation Algorithms generate domain names and tries to resolve their IP addresses. If the domain has an IP address, it is used to connect to that command and control server. Otherwise, the DGA generates a new domain and keeps trying to connect. In both cases it is possible to capture and analyze the special behavior shown by those DNS packets in the network. The behavior of Domain Generation Algorithms is difficult to automatically detect because each domain is usually randomly generated and therefore unpredictable. Hence, it is challenging to separate the DNS traffic generated by malware from the DNS traffic generated by normal computers. In this work we analyze the use of behavioral detection approaches based on Markov Models to differentiate Domain Generation Algorithms traffic from normal DNS traffic. The evaluation methodology of our detection models has focused on a real-time approach based on the use of time windows for reporting the alerts. All the detection models have shown a clear differentiation between normal and malicious DNS traffic and most have also shown a good detection rate. We believe this work is a further step in using behavioral models for network detection and we hope to facilitate the development of more general and better behavioral detection methods of malware traffic.","","","10.1109/ARGENCON.2016.7585238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7585238","Botnet Detection;DGA;Machine Learning;Malware Detection;Network Flows;Network Traffic","Feature extraction;IP networks;Malware;Markov processes;Servers;Terrestrial atmosphere;Training","","","","","","","","","15-17 June 2016","","IEEE","IEEE Conference Publications"
"SeLINA: A Self-Learning Insightful Network Analyzer","D. Apiletti; E. Baralis; T. Cerquitelli; P. Garza; D. Giordano; M. Mellia; L. Venturini","Dipartimento di Automatica e Informatica, Politecnico di Torino, Turin, Italy","IEEE Transactions on Network and Service Management","20160930","2016","13","3","696","710","Understanding the behavior of a network from a large scale traffic dataset is a challenging problem. Big data frameworks offer scalable algorithms to extract information from raw data, but often require a sophisticated fine-tuning and a detailed knowledge of machine learning algorithms. To streamline this process, we propose self-learning insightful network analyzer (SeLINA), a generic, self-tuning, simple tool to extract knowledge from network traffic measurements. SeLINA includes different data analytics techniques providing self-learning capabilities to state-of-the-art scalable approaches, jointly with parameter auto-selection to off-load the network expert from parameter tuning. We combine both unsupervised and supervised approaches to mine data with a scalable approach. SeLINA embeds mechanisms to check if the new data fits the model, to detect possible changes in the traffic, and to, possibly automatically, trigger model rebuilding. The result is a system that offers human-readable models of the data with minimal user intervention, supporting domain experts in extracting actionable knowledge and highlighting possibly meaningful interpretations. SeLINA's current implementation runs on Apache Spark. We tested it on large collections of real-world passive network measurements from a nationwide ISP, investigating YouTube, and P2P traffic. The experimental results confirmed the ability of SeLINA to provide insights and detect changes in the data that suggest further analyses.","1932-4537;19324537","","10.1109/TNSM.2016.2597443","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529210","Mining and statistical methods;machine learning;network data analysis","Algorithm design and analysis;Analytical models;Buildings;Clustering algorithms;Computational modeling;Data mining;Data models","Big Data;Internet;data analysis;data mining;telecommunication traffic;unsupervised learning","Apache Spark;Big data frameworks;ISP;P2P traffic;SeLINA;YouTube;data analytics;data mining;human-readable models;knowledge extraction;large scale traffic dataset;machine learning;network traffic measurements;parameter tuning;self-learning insightful network analyzer","","1","","","","20160802","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Computationally Intelligent Sensor System for Microwave Characterization of Dielectric Sheets","S. Panda; N. K. Tiwari; M. J. Akhtar","Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India","IEEE Sensors Journal","20160916","2016","16","20","7483","7493","An automated RF sensor system for accurate determination of complex permittivity of thin samples and dielectric sheets is proposed. The proposed system is computationally intelligent making use of the machine learning algorithm along with the artificial neural network (ANN) architecture and employs a coplanar waveguide sensor for the measurement of scattering coefficients of test specimens in order to obtain their dielectric properties. Different heuristics are followed for the design of the ANN-based system. The applicability of the proposed sensor system for practical usage is increased by taking into account the effect of possible air gap between the device and test specimen. This is facilitated by developing a multilayered analytical model, and combining it with the ANN-based system. The complete procedure, comprising of ANN algorithms and the analytical formulation, is implemented in MATLAB. The proposed automated standalone sensor system is validated by testing a number of standard samples in the designated frequency bands.","1530-437X;1530437X","","10.1109/JSEN.2016.2599856","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542589","Artificial neural network (ANN);complex permittivity;coplanar waveguide;curve fitting;dielectric constant;loss tangent;machine learning (ML)","Air gaps;Artificial neural networks;Coplanar waveguides;Dielectrics;Permittivity;Sensor systems","coplanar waveguides;intelligent sensors;learning (artificial intelligence);microwave measurement;neural nets;permittivity measurement","MATLAB;artificial neural network;automated RF sensor;computationally intelligent sensor system;coplanar waveguide sensor;dielectric sheets;machine learning algorithm;microwave characterization;scattering coefficients","","1","","","","20160812","Oct.15, 2016","","IEEE","IEEE Journals & Magazines"
"Application of Artificial Metaplasticity fundamentals to WBCD Breast Cancer Database classification method","J. Fombellida; I. Martín-Rubio; D. Andina","Group for Automation in Signals and Communications, Technical University of Madrid, 28040, Spain","2016 World Automation Congress (WAC)","20161006","2016","","","1","5","The Metaplasticity is an inherent property of the Biological neuron connections that consists in the capacity of modifying the learning mechanism using the information present in the network itself during the training. This concept can be applied to Artificial Learning Algorithms using a technique called Artificial Metaplasticity. The idea is to improve the results in Machine Learning taking as the base the hypothesis studied by Metaplasticity in Biological Learning. This paper presents and discuss the results of applying an Artificial Metaplasticity implementation based on the information present at the output of the network in Multilayer Perceptrons at artificial neuron learning level. The objective of this study is a state-of-the-art research: the diagnosis of breast cancer data from the Wisconsin Breast Cancer Database.","","","10.1109/WAC.2016.7582981","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582981","AMP;Artificial Neural Network;Deep Learning;Feature Extraction;MLP;MMLP;Machine Learning;Metaplasticity;Plasticity;WBCD","Breast cancer;Databases;Estimation;Neurons;Training","biology computing;cancer;classification;database management systems;learning (artificial intelligence);multilayer perceptrons","WBCD;Wisconsin Breast Cancer Database;artificial learning algorithms;artificial metaplasticity;artificial neuron learning level;biological learning;biological neuron connections;database classification;machine learning;multilayer perceptrons","","","","","","","July 31 2016-Aug. 4 2016","","IEEE","IEEE Conference Publications"
"Measurement and analysis of human micro-Doppler features in foliaged environments","W. Troy; D. Lin; M. Thompson; Yang Li","Baylor University, Waco, Texas, 76706, United States of America","2016 Texas Symposium on Wireless and Microwave Circuits and Systems (WMCS)","20160929","2016","","","1","4","The focus of this work is on measuring and classifying human micro-Doppler features in forested environments. As a first step, measurements of human motion activities are performed in an open space environment to establish the baseline of this study. Next, forest measurements were taken at two locations in a local park for: different frequencies, activities, and number of subjects. Each experimental trial was measured for 20 seconds using a vector network analyzer (VNA) and post-processed into spectrograms, from which features are extracted to classify human motion activities.","","","10.1109/WMCaS.2016.7577483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577483","Doppler Radar;Doppler measurement;Machine learning;Radar measurements","Doppler effect;Feature extraction;Legged locomotion;Radar;Spectrogram;Support vector machines;Temperature measurement","electromagnetic wave scattering;feature extraction;forestry;geophysical image processing;image motion analysis;network analysers;remote sensing;vegetation","feature extraction;foliaged environments;forest measurements;human microDoppler features;human motion activities;open space environment;spectrograms;time 20 s;vector network analyzer","","","","","","","March 31 2016-April 1 2016","","IEEE","IEEE Conference Publications"
"Opinion mining on Twitter microblogging using Support Vector Machine: Public opinion about State Islamic University of Bandung","Jumadi; D. S. Maylawati; B. Subaeki; T. Ridwan","Department of Informatics, State Islamic University of Sunan Gunung Djati Bandung, Bandung, Indonesia","2016 4th International Conference on Cyber and IT Service Management","20160929","2016","","","1","6","Tweet data on Twitter as microblogging can be processed to be an important and useful information. We propose opinion mining with Support Vector Machine (SVM) algorithm to classify tweet opinion data which is a huge data. This opinion mining will be used to get insight of public opinion about State Islamic University of Sunan Gunung Djati Bandung which is one of large university in Indonesia. We have two classes for opinion classification that is negative and positive opinions. Pre-processing phase before classifying consists of cleaning data, emotion tokenizing, case folding, stop words removal, and stemming process. The result of this research is 0.838 precision value and 0.76 recall for positive class. Then, 0.78 precision value and 0.853 recall for negative class. Opinion classification with SVM of this research has accuracy 78.75%.","","","10.1109/CITSM.2016.7577569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577569","Opinion mining;machine learning;pre-processing;support vector machine;twitter","Classification algorithms;Data mining;Data models;Support vector machines;Testing;Training;Twitter","data handling;data mining;educational institutions;pattern classification;social networking (online);support vector machines","Indonesia;SVM;State Islamic University;Sunan Gunung Djati Bandung;Twitter microblogging;case folding;data cleaning;emotion tokenizing;negative opinions;opinion mining;positive opinions;preprocessing phase;stemming process;stop word removal;support vector machine;tweet opinion data classification","","","","","","","26-27 April 2016","","IEEE","IEEE Conference Publications"
"Detecting work stress in offices by combining unobtrusive sensors","S. Koldijk; M. A. Neerincx; W. Kraaij","Saskia Koldijk is with Intelligent Systems, Radboud University & TNO, The Netherlands.(email:s.koldijk@cs.ru.nl)","IEEE Transactions on Affective Computing","","2016","PP","99","1","1","Employees often report the experience of stress at work. In the SWELL project we investigate how new context aware pervasive systems can support knowledge workers to diminish stress. The focus of this paper is on developing automatic classiers to infer working conditions and stress related mental states from a multimodal set of sensor data (computer logging, facial expressions, posture and physiology). We address two methodological and applied machine learning challenges: 1) Detecting work stress using several (physically) unobtrusive sensors, and 2) Taking into account individual dierences. A comparison of several classication approaches showed that, for our SWELL-KW dataset, neutral and stressful working conditions can be distinguished with 90% accuracy by means of SVM. Posture yields most valuable information, followed by facial expressions. Furthermore, we found that the subjective variable `mental eort' can be better predicted from sensor data than e.g. `perceived stress'. A comparison of several regression approaches showed that mental eort can be predicted best by a decision tree (correlation of 0.82). Facial expressions yield most valuable information, followed by posture. We nd that especially for estimating mental states it makes sense to address individual dierences. When we train models on particular subgroups of similar users, (in almost all cases) a specialized model performs equally well or better than a generic model.","1949-3045;19493045","","10.1109/TAFFC.2016.2610975","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7572141","Machine learning;computer logging;facial expressions;individual dierences;mental state inference;physiology;posture;stress","Computational modeling;Computers;Context;Sensors;Stress;Stress measurement;Support vector machines","","","","","","","","20160920","","","IEEE","IEEE Early Access Articles"
"Towards Black-Box Anomaly Detection in Virtual Network Functions","C. Sauvanaud; K. Lazri; M. Kaâniche; K. Kanoun","LAAS, Univ. de Toulouse, Toulouse, France","2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshop (DSN-W)","20161003","2016","","","254","257","The maturity of hardware virtualization has motivated communication service providers to apply this paradigm to network services. Virtual Network Functions (VNFs) come from this motivation and refer to any virtual execution environment configured to provide a given network service. VNFs constitute a new paradigm and related dependability evaluation mechanisms are still not thoroughly defined. In this paper we propose a preliminary evaluation of an anomaly detection approach applied to VNFs. Our approach uses a supervised machine learning algorithm. It notably relies on data provided by the underlying hypervisor of the VMs hosting the VNF, making it a black-box approach. Such an approach is actually well suited for infrastructure or telecommunication service providers willing to deploy tools that are easily configurable while reducing deployment costs. We validate our approach with the case study of the vIMS (IP Multimedia Subsystem) implemented by the Clearwater project.","","Electronic:978-1-5090-3688-2; POD:978-1-5090-3689-9","10.1109/DSN-W.2016.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7575389","VNF;black-box;fault injection;machine learning","Benchmark testing;Cloud computing;Hardware;Monitoring;Packet loss;Servers;Virtualization","IP networks;computer networks;learning (artificial intelligence)","IP multimedia subsystem;VNF;black-box anomaly detection;clearwater project;communication service providers;computer networks;dependability evaluation mechanisms;deploy tools;hardware virtualization;network services;supervised machine learning algorithm;telecommunication service providers;virtual execution environment;virtual network functions","","","","","","","June 28 2016-July 1 2016","","IEEE","IEEE Conference Publications"
"A hybrid method based on MLFS approach to analyze students' academic achievement","W. X. Liu; C. H. Cheng","Department of Information Management, National Yunlin University of Science and Technology, Yunlin, Taiwan","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1625","1630","How to get the information we need from the existing data, even extract the hidden message, and then transform them into knowledge, is an important skill we must learn in this era. Data mining technology in recent years is increasing attention in various fields, because of its extraordinary process. Usually, when we find more unexpected information, it may have the higher the value. This paper proposed Machine Learning Feature Selection (MLFS) combined with Support Vector Machine (SVM) method to extract and verify the key features that influence students' academic achievement in a Taiwan elementary school, and compare with the listing machine learning algorithms. The collected dataset include the students' graduated grades as decision features, and 15 condition features come from two databases “Student Profile” and “Tutorship Record”. After experiment, we found that when deleting five low influential features the quality and effectiveness of model is better than other conditions. Therefore, the proposed method is effective to enhance the accuracy and the quality of model. Finally, we use other classification algorithms to compare with the proposed method, and having the more accuracy (92.39%).","","","10.1109/FSKD.2016.7603420","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603420","Machine Learning Feature Selection;Support Vector Machine;academic achievement;data mining","Data mining;Decision trees;Education;Feature extraction;Machine learning algorithms;Prediction algorithms;Support vector machines","data mining;educational administrative data processing;educational institutions;further education;support vector machines","MLFS;Taiwan elementary school;data mining technology;decision features;hidden message;machine learning feature selection;student academic achievement analysis;student graduated grades;student profile databases;support vector machine;tutorship record databases","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Using a Distributed Representation of Words in Localizing Relevant Files for Bug Reports","Y. Uneno; O. Mizuno; E. H. Choi","Kyoto Inst. of Technol., Kyoto, Japan","2016 IEEE International Conference on Software Quality, Reliability and Security (QRS)","20161013","2016","","","183","190","Once a bug in software is reported, developers have to determine which source files are related to the bug. This process is referred to as bug localization, and an automatic way of bug localization is important to improve developers' productivity. This paper proposes an approach called DrewBL to efficiently localize faulty files for a given bug report using a natural language processing tool, word2vec. In DrewBL, we first build a vector space model named semantic-VSM which represents a distributed representation of words in the bug report and source code files and next compute the relevance between them by feeding the constructed model to word2vec. We also present an approach called CombBL to further improve the accuracy of bug localization which employs not only the proposed DrewBL but also existing bug localization techniques, such as BugLocator based on textual similarity and Bugspots based on bug-fixing history, in a combinational manner. This paper gives our early experimental results to show the effectiveness and efficiency of the proposed approaches using two open source projects.","","","10.1109/QRS.2016.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7589798","Bug localization;Bug report;Information Retrieval;Machine learning;Natural language processing;Vector space model","Computational modeling;Computer bugs;Feature extraction;History;Java;Natural language processing;Software","information retrieval;natural language processing;program debugging","BugLocator;Bugspots;CombBL;DrewBL;bug localization;bug-fixing history;distributed representation;natural language processing tool;semantic-VSM;software buy;textual similarity;vector space model;word2vec","","","","","","","1-3 Aug. 2016","","IEEE","IEEE Conference Publications"
"Asymmetry in Coevolving Adversarial Systems","R. Colbaugh; K. Glass","Periander Ltd., London, UK","2016 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)","20160922","2016","","","360","367","Asymmetries in adversarial systems arise from differences in the ""situations"" of attackers and defenders, for instance corresponding to differences in information access or cost/benefit tradeoffs. While numerous studies have shown that asymmetry is important, less has been done to rigorously characterize its impact or specify methods by which it can be leveraged by defenders. This paper presents a formal framework for analyzing the origins and roles of asymmetric advantage in coevolving adversarial systems, and uses this framework to develop quantitative tools for understanding and exploiting asymmetry. The proposed framework explains why asymmetry has such profound impact on the behavior of coevolving systems, and reveals a key feature of these systems: they can be reverse-engineered using only limited measurements. The analysis yields several new results, including 1.) a demonstration that machine learning systems increasingly deployed to harden vulnerabilities in essential systems are themselves highly vulnerable, and 2.) a methodology for designing ""predictability-oriented"" defenses that shifts advantages of asymmetry toward defenders. An empirical case study involving detection of money-laundering activity within the global interbank transactions system illustrates the utility of the proposed analytic framework in a high-consequence setting.","","","10.1109/QRS-C.2016.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573770","adversarial systems;asymmetry;cyber security;machine learning","Conferences;Security;Software quality;Software reliability","bank data processing;globalisation;learning (artificial intelligence);security of data","coevolving adversarial system asymmetry;coevolving system behavior impact;cyber security;formal framework;global interbank transactions system;information access;machine learning systems;money-laundering activity detection;predictability-oriented defense design;reverse engineering;system vulnerabilities","","","","","","","1-3 Aug. 2016","","IEEE","IEEE Conference Publications"
"Real time recursive preference learning to rank from data stream","L. Lyubchyk; G. Grinberg","National Technical University &#x201C;Kharkiv Polytechnic Institute&#x201D;, Frunze str. 21, Kharkiv, 61002, Ukraine","2016 IEEE First International Conference on Data Stream Mining & Processing (DSMP)","20161006","2016","","","280","285","Dynamic ranking learning problem is considered when the training sample is a data stream, consisting of a sequence of a series of objects characterized by a set of features and relative ranks within each series. The problem is reduced to preference learning to rank on clusters in the feature space of ranked objects, while aggregated training dataset is formed from the centers of clusters and estimates of the average rank of the objects from the cluster. Real-time preference function identification algorithm is proposed based on training data stream includes successive estimates of cluster parameter as well as average cluster ranks updating and recurrent kernel-based nonparametric estimation of preference model.","","","10.1109/DSMP.2016.7583559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583559","data stream;kernel methods;machine learning;preference function;ranking;recurrent estimation;support vector machine","Clustering algorithms;Data models;Kernel;Optimization;Real-time systems;Training;Training data","data handling;estimation theory;learning (artificial intelligence);nonparametric statistics;parameter estimation;pattern clustering","aggregated training dataset;average cluster ranks;cluster parameter estimation;data stream;dynamic ranking learning problem;ranked objects feature space;real time recursive preference learning to rank;real-time preference function identification algorithm;recurrent kernel-based nonparametric estimation","","","","","","","23-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"CogKnife: Food recognition from their cutting sounds","T. Kojima; T. Ijiri; J. White; H. Kataoka; A. Hirabayashi","College of Information Science and Technology, Ritsumeikan University, Japan","2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","20160926","2016","","","1","6","In this study, we present “CogKnife”, a knife device which can identify food. For this, a small microphone is attached to a knife, which records the cutting sound of food. We extract spectrograms from the cutting sounds and use them as feature vectors to train a classifier. This study used the k-Nearest Neighbor method (k-NN), the support vector machine (SVM) and the convolutional neural network (CNN) to verify differences of the classification methods. To evaluate the accuracy of our technique, we performed classification experiments with six kinds of foods (apples, bananas, cabbages, leeks and peppers) in a laboratory environment. From 20-fold cross validation, we confirmed high recognition accuracies, such as 83% with k-NN, 95% with SVM and 89% with CNN.","","","10.1109/ICMEW.2016.7574741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574741","cooking support;food recognition;machine learning;pattern recognition;sound recognition","Feature extraction;Intelligent sensors;Microphones;Monitoring;Spectrogram;Support vector machines","acoustic signal processing;feature extraction;food products;microphones;neural nets;signal classification;support vector machines","CogKnife;apples;bananas;cabbages;classification methods;convolutional neural network;cutting sounds;feature vectors;food recognition;k-nearest neighbor method;knife device;leeks;peppers;sound recognition;support vector machine","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Automatic Localization of Bugs to Faulty Components in Large Scale Software Systems Using Bayesian Classification","L. Jonsson; D. Broman; M. Magnusson; K. Sandahl; M. Villani; S. Eldh","","2016 IEEE International Conference on Software Quality, Reliability and Security (QRS)","20161013","2016","","","423","430","We suggest a Bayesian approach to the problem of reducing bug turn-around time in large software development organizations. Our approach is to use classification to predict where bugs are located in components. This classification is a form of automatic fault localization (AFL) at the component level. The approach only relies on historical bug reports and does not require detailed analysis of source code or detailed test runs. Our approach addresses two problems identified in user studies of AFL tools. The first problem concerns the trust in which the user can put in the results of the tool. The second problem concerns understanding how the results were computed. The proposed model quantifies the uncertainty in its predictions and all estimated model parameters. Additionally, the output of the model explains why a result was suggested. We evaluate the approach on more than 50000 bugs.","","","10.1109/QRS.2016.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7589822","Fault Detection;Fault Location;Machine Learning;Software Debugging;Software Engineering;Software Maintenance","Bayes methods;Computational modeling;Computer bugs;Organizations;Predictive models;Software;Uncertainty","Bayes methods;pattern classification;program debugging;program testing;software maintenance;source code (software)","AFL tools;Bayesian classification;automatic bugs localization;automatic fault localization;bug turn-around time reduction;faulty components;large scale software systems;large software development organizations;source code","","","","","","","1-3 Aug. 2016","","IEEE","IEEE Conference Publications"
"Deep learning with ensemble classification method for sensor sampling decisions","S. Taleb; A. Al Sallab; H. Hajj; Z. Dawy; R. Khanna; A. Keshavamurthy","Department of Electrical and Computer Engineering, American University of Beirut, Lebanon","2016 International Wireless Communications and Mobile Computing Conference (IWCMC)","20160929","2016","","","114","119","Modern mobile pervasive applications focus on context awareness that monitors a diverse range of personal domains. In order to infer contextual information, most of these applications require the collection of raw data from sensors which are either embedded in personal smartphones or worn by the user. Critical context-aware applications rely on continuous accurate monitoring of the user's current context. Continuous sensing mechanisms in sensors cost high energy consumption to support accurate contextual detection. Hence, there is a trade-off between the classification accuracy and the energy consumption. In this paper, we exploit the advantages of Deep Neural Network (DNN) with ensemble classification of other complementary machine learning approaches to determine the best sensor sampling frequency for the recognition of a given context. DNN relies on raw data for classification while the other complementary methods (such as Decision Tree and Naïve Bayes) use feature recognition to classify data. Therefore, our approach provides a range of granularity from raw data. We prove the robustness of our approach in experiments which show high accuracy in context recognition. In addition, real experiments demonstrate the energy gains of the proposed algorithm which reach 87% reduction in energy consumption when compared to continuous sensing.","","","10.1109/IWCMC.2016.7577043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577043","Mobile sensing;context-awareness;deep learning;energy efficient sensing;machine learning","Context;Energy consumption;Machine learning;Mobile handsets;Monitoring;Niobium;Sensors","mobile computing;smart phones","DNN;complementary machine learning;context awareness;context recognition;context-aware applications;contextual information;continuous sensing mechanisms;deep learning;deep neural network;energy consumption;ensemble classification method;feature recognition;mobile pervasive applications;personal domains;personal smartphones;raw data;sensor sampling decisions;sensors","","","","","","","5-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Efficiency of QoE-driven network management in adaptive streaming over HTTP","T. Phan-Xuan; E. Kamioka","Graduate School of Engineering and Science, Shibaura Institute of Technology, Tokyo, Japan","2016 22nd Asia-Pacific Conference on Communications (APCC)","20161006","2016","","","517","522","HTTP adaptive streaming (HAS) technology has been widely implemented in entertainment industries. It allows users to smoothly access representations of content when the network work conditions frequently fluctuate. This mechanism not only improves the perceived quality of user but also benefits the network resource utilization. However, the frequent adaption of bit rate may cause the instability of Quality of Experience (QoE) to premium users who are willing to pay for high and stable perceived quality. Therefore, recently an appropriate network management scheme has been explored in order to control streaming behaviors with respect to the requirements of various types of users. In our previous study, a machine learning based network management system has been proposed as a relevant approach to manage QoE of HAS. In this paper, the performance of the proposed system will be clarified in dealing with a practical problem of bandwidth competition between a HAS player and other application clients.","","","10.1109/APCC.2016.7581519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581519","HAS;QoE;bandwidth competition;machine learning","Bandwidth;Bit rate;Estimation;Quality assessment;Quality of service;Streaming media;Video recording","client-server systems;computer network management;hypermedia;learning (artificial intelligence);quality of experience;resource allocation;transport protocols;video streaming","HAS technology;HTTP adaptive streaming;QoE-driven network management;bit rate adaption;content representations;entertainment industries;machine learning;network resource utilization;perceived quality;quality of experience;streaming behavior control","","","","","","","25-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"Multimode Energy Management for Plug-In Hybrid Electric Buses Based on Driving Cycles Prediction","Z. Chen; L. Li; B. Yan; C. Yang; C. Marina Martínez; D. Cao","School of Sciences, State Key Laboratory of Automotive Safety and Energy, Ningbo University of Technology, Tsinghua University, Ningbo, Beijing, ChinaChina","IEEE Transactions on Intelligent Transportation Systems","20160930","2016","17","10","2811","2821","Driving cycles and road slope are two important factors affecting fuel saving performance of plug-in hybrid electric buses (PHEBs) in Chinese cities. Moreover, onboard auxiliary equipment (e.g., Global Position System receiver and General Packet Radio Service (GPRS) wireless module) of PHEB may provide potential means to communicate with the control center of the bus company, allowing for driving cycle prediction through data communication between foregoing buses and the control center. With this general approach in mind, and by utilizing driving data clustering and driving cycle classifier, this paper presents a multimode switched logic control strategy, targeting fuel economy improvement of the PHEB team for a particular city bus route. First, the normal feature parameters are extracted from the sampled driving history cycles, and the composed feature parameters are given by a mapping of normal feature parameters in this approach. A novel improved hierarchical clustering algorithm is applied for driving cycles' data clustering into four groups. Then, on the basis of the clustering results, support vector machine method is used to predict the current driving cycle. Finally, a switched driving controller is presented according to current type of driving cycle and slope information. Simulation results are compared with those of traditional methods in the given real-world driving cycles of city bus, showing significant improvement, which may offer a theoretical solution with engineering application. Experimental results also demonstrate that the proposed control approach is feasible in the tested bus routes.","1524-9050;15249050","","10.1109/TITS.2016.2527244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416235","Energy management;driving cycle prediction;machine learning;plug-in hybrid electric bus;single-shaft parallel hybrid powertrain;statistical feature","Acceleration;Batteries;Cities and towns;Energy management;Feature extraction;Roads;Vehicles","energy management systems;feature extraction;fuel economy;hybrid electric vehicles;pattern classification;pattern clustering;road traffic control;support vector machines;switching systems (control);traffic engineering computing","Chinese cities;GPRS;Global Position System receiver;PHEBs;city bus route;control center;data communication;driving cycle classifier;driving cycle data clustering;driving cycle prediction;fuel economy;general packet radio service wireless module;improved hierarchical clustering algorithm;multimode energy management;multimode switched logic control strategy;normal feature parameter extraction;onboard auxiliary equipment;plug-in hybrid electric buses;road slope;sampled driving history cycles;support vector machine method;switched driving controller","","3","","","","20160223","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"Dimensionality Reduction with a Composite-Selective Strategy in Documents with a Hybrid Content","S. Raheel","Comput. Sci. Dept. Ashrafieh, American Univ. of Sci. & Technol., Beirut, Lebanon","2015 3rd International Conference on Artificial Intelligence, Modelling and Simulation (AIMS)","20161024","2015","","","113","116","Feature selection is the process of choosing a subset of the available features or attributes from a certain dataset in order to render the process of building a predictive model more efficient and accurate. The selection of attributes is, in most of the times, done sequentially. In this paper we propose a new filtering strategy that selects the attributes in a composite way rather than sequential. The advantage of this approach is that it allows for an important number of features that are highly relevant to their classes but statistically insignificant to participate in the learning process of the classifier. Results show that this new approach is promising and as good as the traditional one. Higher accuracy is reached when the number of the infrequent features increases. This approach is useful when we need for the infrequent features to be part of the predictive model since this, in turn, enforces the subjectivity of the decision made by the classifier.","","","10.1109/AIMS.2015.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7604561","Data Mining;Dimensionality Reduction;Feature Selection;Machine Learning","Computational modeling;Computer science;Predictive models;Support vector machines;Text categorization","Bayes methods;document handling;feature selection;learning (artificial intelligence);pattern classification;support vector machines","SVM;chi square;classifier learning process;composite attribute selection;composite-selective strategy;dimensionality reduction;document hybrid content;feature selection;filtering strategy;information gain;naive Bayes classifier;predictive model;support vector machine","","","","","","","2-4 Dec. 2015","","IEEE","IEEE Conference Publications"
"Don't Fire Me, a Kernel Autoregressive Hybrid Model for Optimal Layoff Plan","Z. Luo; Y. Li; R. Fu; J. Yin","Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","470","477","Job cutting occurs when a modern service enterprise reduces the employing labour cost by firing some staffs. Making an appropriate layoff plan is always quite difficult since a bad job cutting has a serious impact on not only the organization but also the business process executing efficiency. Therefore, in this paper, we address the problem of making an optimal layoff plan with the least influence on the executing of the business process. The key challenge is estimating the process throughput under a layoff plan. We overcome this challenge by two steps: regressing the activity throughput by the stuff number and inferring process throughput by the maximum flow or minimum cut algorithm on the Directed Acyclic Graph of process. In the regressing step, a kernel autoregressive hybrid model is proposed, whose MSE is 30% lower than SVM. After that, an augmenting path based algorithm is introduced to make an optimal layoff plan. To evaluate the accuracy of our model, we conduct an external experiment on a real dataset from the workflow system employed in the government of Hangzhou City in China, which results in 9750969 logs from 2050 activities and 16295 employees in two years.","","","10.1109/BigDataCongress.2016.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584978","Autoregressive Model;Kernel Method;Layoff;Machine Learning","Computer science;Electronic mail;Government;Kernel;Throughput","autoregressive processes;business data processing;directed graphs;government data processing;workflow management software","WfMS;business process execution;directed acyclic graph;government department;kernel autoregressive hybrid model;optimal layoff plan;workflow management system","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"A Pattern-Based Approach for Sarcasm Detection on Twitter","M. Bouazizi; T. Otsuki Ohtsuki","Graduate School of Science and Technology, Keio University, Yokohama, Japan","IEEE Access","20160928","2016","4","","5477","5488","Sarcasm is a sophisticated form of irony widely used in social networks and microblogging websites. It is usually used to convey implicit information within the message a person transmits. Sarcasm might be used for different purposes, such as criticism or mockery. However, it is hard even for humans to recognize. Therefore, recognizing sarcastic statements can be very useful to improve automatic sentiment analysis of data collected from microblogging websites or social networks. Sentiment Analysis refers to the identification and aggregation of attitudes and opinions expressed by Internet users toward a specific topic. In this paper, we propose a pattern-based approach to detect sarcasm on Twitter. We propose four sets of features that cover the different types of sarcasm we defined. We use those to classify tweets as sarcastic and non-sarcastic. Our proposed approach reaches an accuracy of 83.1% with a precision equal to 91.1%. We also study the importance of each of the proposed sets of features and evaluate its added value to the classification. In particular, we emphasize the importance of pattern-based features for the detection of sarcastic statements.","2169-3536;21693536","","10.1109/ACCESS.2016.2594194","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549041","Twitter;machine learning;sarcasm detection;sentiment analysis","Feature extraction;Machine learning;Sentiment analysis;Twitter","Web sites;sentiment analysis","Twitter;automatic sentiment analysis;microblogging Websites;pattern-based approach;sarcasm detection;social networks","","","","","","20160824","2016","","IEEE","IEEE Journals & Magazines"
"Spiking Neural Networks for Crop Yield Estimation Based on Spatiotemporal Analysis of Image Time Series","P. Bose; N. K. Kasabov; L. Bruzzone; R. N. Hartono","Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IEEE Transactions on Geoscience and Remote Sensing","20160927","2016","54","11","6563","6573","This paper presents spiking neural networks (SNNs) for remote sensing spatiotemporal analysis of image time series, which make use of the highly parallel and low-power-consuming neuromorphic hardware platforms possible. This paper illustrates this concept with the introduction of the first SNN computational model for crop yield estimation from normalized difference vegetation index image time series. It presents the development and testing of a methodological framework which utilizes the spatial accumulation of time series of Moderate Resolution Imaging Spectroradiometer 250-m resolution data and historical crop yield data to train an SNN to make timely prediction of crop yield. The research work also includes an analysis on the optimum number of features needed to optimize the results from our experimental data set. The proposed approach was applied to estimate the winter wheat (Triticum aestivum L.) yield in Shandong province, one of the main winter-wheat-growing regions of China. Our method was able to predict the yield around six weeks before harvest with a very high accuracy. Our methodology provided an average accuracy of 95.64%, with an average error of prediction of 0.236 t/ha and correlation coefficient of 0.801 based on a nine-feature model.","0196-2892;01962892","","10.1109/TGRS.2016.2586602","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7524771","Crop yield forecasting;Moderate Resolution Imaging Spectroradiometer (MODIS);estimation;machine learning;normalized difference vegetation index (NDVI);remote sensing;spiking neural networks (SNNs)","Agriculture;Data models;MODIS;Remote sensing;Spatiotemporal phenomena;Time series analysis;Vegetation mapping","agricultural engineering;agriculture;crops;image processing;neural nets;productivity;time series;vegetation mapping","China;SNN;Shandong province;Triticum aestivum L;crop yield estimation;image time series;moderate resolution imaging spectroradiometer;remote sensing spatiotemporal analysis;spiking neural networks;winter wheat","","","","","","20160728","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"On the Usability of Clustering for Topic-Oriented Multi-level Security Models","P. E. Engelstad","Norwegian Defense Res. Establishement, Akershus Univ. Coll., Oslo, Norway","2015 IEEE European Modelling Symposium (EMS)","20161003","2015","","","14","20","Security levels used in organizations today are typically course-grained, broad and distinct, using security levels such as ""Confidential"" and Secret"". However, current research is advocating a move towards more fine-grained security models, e.g. Such as Attribute-Based Access Control, where information objects and end-users are characterized in terms of complex meta-data. One idea promoted is a topic-oriented approach where information objects are characterized in terms of fine-grained descriptions of the topics of its content. It will lead to higher flexibility, but will also rely on a policy-database to assign a specific security policy to topics and subtopics. Due to increased complexity, it will also require automatic or semi-automatic tools for determining the topics and sub-topics of information objects, and the tools should extract topics that are easily understood by humans, since humans need to control the policy. This paper studies the feasibility of using clustering techniques to help humans in extracting the topics from information objects. A number of clustering methods are discussed, including k-means, Ward's hierarchical agglomerative clustering, Correlated Topic Models (CTM) and Latent Dirichlet Allocation (LDA). To the best of our knowledge, an in-depth analysis on the feasibility of using clustering for this problem has not been presented in previous work. Our analysis points out challenges with clustering in particular, which must be addressed before realizing the general vision of topic-oriented policy-driven security models.","","","10.1109/EMS.2015.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7579799","Multi-level security;cross-domain information exchange;machine learning;policy-driven;topical clustering","Clustering methods;Data mining;Distortion;Electronic mail;Labeling;Security;Training","pattern clustering;security of data;text analysis","CTM;LDA;automatic tools;clustering techniques;correlated topic models;fine-grained meta-data;fine-grained topics descriptions;hierarchical agglomerative clustering;k-means clustering;latent Dirichlet allocation;policy database;security policy;semiautomatic tools;topic-oriented multilevel security models;topic-oriented policy-driven security models","","","","","","","6-8 Oct. 2015","","IEEE","IEEE Conference Publications"
"DT-CGRA: Dual-track coarse-grained reconfigurable architecture for stream applications","Xitian Fan; Huimin Li; Wei Cao; Lingli Wang","State Key Laboratory of ASIC and System, Fudan University, No. 825 Zhangheng Road, Shanghai, 201203, China","2016 26th International Conference on Field Programmable Logic and Applications (FPL)","20160929","2016","","","1","9","This paper presents a new type of coarse-grained reconfigurable architecture (CGRA) for the object inference domain in machine learning. The proposed CGRA is optimized for stream processing and a correspondent programming model called dual-track model is proposed. The CGRA is realized in Verilog HDL and implemented in SMIC 55 nm process, with the footprint of 3.79 mm<sup>2</sup> and consuming 1.79 W at 500 MHz. To evaluate the performance, eight machine-learning algorithms including HOG, CNN, k-means, PCA, SPM, linear-SVM, Softmax and Joint-Bayesian are selected as benchmarks. These algorithms cover a general machine learning flow in object inference domain: feature extraction, feature selection and inference. The experimental results show that the proposed CGRA can gain 1443× average energy efficiency comparing to the Intel i7-3770 CPU and 7.82× energy efficiency comparing to a high performance FPGA solution [19].","","","10.1109/FPL.2016.7577309","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577309","coarse-grained reconfigurable architecture;domain-specific computing;machine learning;object inference","Arrays;Context;Energy efficiency;Kernel;Programming;Reconfigurable architectures","Bayes methods;feature selection;hardware description languages;inference mechanisms;learning (artificial intelligence);pattern clustering;principal component analysis;reconfigurable architectures;support vector machines","CNN;DT-CGRA optimization;HOG;PCA;SMIC;SPM;Softmax;Verilog HDL;average energy efficiency;dual-track coarse-grained reconfigurable architecture;dual-track model;feature extraction;feature selection;joint-Bayesian method;k-means algorithm;linear-SVM;machine learning;object inference domain;performance evaluation;programming model;stream application","","","","","","","Aug. 29 2016-Sept. 2 2016","","IEEE","IEEE Conference Publications"
"Recognition based segmentation of connected characters in text based CAPTCHAs","R. Hussain; H. Gao; R. A. Shaikh; S. P. Soomro","School of Computer Science and Engineering, University of Electronics Science and Technology of China, Chengdu 611731, China","2016 8th IEEE International Conference on Communication Software and Networks (ICCSN)","20161010","2016","","","673","676","Text based CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) is the most widely used mechanism adopted by numerous popular web sites in order to differentiate between machines and humans, however due to extensive research carried out by computer vision researchers, it is now a days vulnerable against automated attacks. Segmentation is the most difficult task in automatic recognition of CAPTCHAs, therefore contemporary Text based CAPTCHAs try to combine the characters together in order to make them as segmentation resistant against these attacks as possible. In this research, we have found vulnerabilities in such CAPTCHAs, a novel mechanism, i.e. the recognition based segmentation is applied to crop such connected characters, a sliding window based neural network classifier is used to recognize and segment the connected characters. Experimental results have proved 95.5% recognition success rate and 58.25% segmentation success rate on our dataset of tmall CAPTCHAs, this algorithm is further tested on two other datasets of slightly different implementations and promising results were achieved.","","","10.1109/ICCSN.2016.7586608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586608","CAPTCHA;computer vision;image processing;intelligent character recognition;machine learning;pattern recognition","Algorithm design and analysis;CAPTCHAs;Character recognition;Image recognition;Image segmentation;Neural networks;Text recognition","character recognition;computer vision;image segmentation;learning (artificial intelligence)","completely automated public turing test to tell computers and humans apart;computer vision;recognition based segmentation;sliding window based neural network classifier;text based CAPTCHA","","","","","","","4-6 June 2016","","IEEE","IEEE Conference Publications"
"Road Surface Recognition Using Laser Radar for Automatic Platooning","M. Aki; T. Rojanaarpa; K. Nakano; Y. Suda; N. Takasuka; T. Isogai; T. Kawai","Department of Mechanical Science, Institute of Industrial Science, The University of Tokyo, Nagoya University, Tokyo, Aichi, JapanJapan","IEEE Transactions on Intelligent Transportation Systems","20160930","2016","17","10","2800","2810","This paper proposes a road surface recognition system based on a “laser radar” (LIDER), which is used to detect a lane markings for application to an automatic platooning system for trucks. To ensure the safety of automatic driving, there is a need to recognize the road surface conditions (dry, wet, etc.). This system proposes an integrated system that is not only capable of recognizing lane markings but also monitors the road surface using a laser radar scanning system. Our road surface recognition method relies on the multiple reflection intensities of laser radar and a machine learning algorithm. By using multiple reflection intensities, the recognition rate is improved. Moreover, to improve the recognition rate, an additional feature variable, called the “roughness index,” is proposed. In this paper, the concept of a road surface recognition system is proposed and six road surface conditions (dry old asphalt, moist old asphalt, flooded old asphalt, dry new asphalt, moist new asphalt, and flooded new asphalt) are recognized by the proposed algorithm. The quality of the road surface recognition is examined through comparison with long-term measurement data. The proposed method exhibits a high level of road surface recognition performance.","1524-9050;15249050","","10.1109/TITS.2016.2528892","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7446317","Automatic platooning;condition monitoring;field operation test;laser radar;machine learning;road surface recognition;safety","Laser radar;Roads;Rough surfaces;Surface emitting lasers;Surface roughness;Surface waves","learning (artificial intelligence);object recognition;optical radar;traffic engineering computing","LIDER;automatic driving safety;automatic platooning system;lane marking detection;lane marking recognition;laser radar scanning system;machine learning algorithm;multiple reflection intensity;recognition rate;road surface conditions;road surface recognition system;roughness index;trucks","","","","","","20160404","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"DOLPHIn—Dictionary Learning for Phase Retrieval","A. M. Tillmann; Y. C. Eldar; J. Mairal","TU Darmstadt, Research Group Optimization, Darmstadt, Germany","IEEE Transactions on Signal Processing","20161019","2016","64","24","6485","6500","We propose a new algorithm to learn a dictionary for reconstructing and sparsely encoding signals from measurements without phase. Specifically, we consider the task of estimating a two-dimensional image from squared-magnitude measurements of a complex-valued linear transformation of the original image. Several recent phase retrieval algorithms exploit underlying sparsity of the unknown signal in order to improve recovery performance. In this work, we consider such a sparse signal prior in the context of phase retrieval, when the sparsifying dictionary is not known in advance. Our algorithm jointly reconstructs the unknown signal-possibly corrupted by noise-and learns a dictionary such that each patch of the estimated image can be sparsely represented. Numerical experiments demonstrate that our approach can obtain significantly better reconstructions for phase retrieval problems with noise than methods that cannot exploit such “hidden” sparsity. Moreover, on the theoretical side, we provide a convergence result for our method.","1053-587X;1053587X","","10.1109/TSP.2016.2607180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7563347","Image reconstruction;machine learning;signal reconstruction","Approximation algorithms;Dictionaries;Dolphins;Image reconstruction;Noise measurement;Signal processing algorithms;Signal reconstruction","image coding;image reconstruction","DOLPHIn-dictionary learning;complex-valued linear transformation;hidden sparsity;phase retrieval algorithm;signal reconstruction;signal sparse encoding;sparsifying dictionary;squared-magnitude measurements;theoretical side;two-dimensional image estimation","","1","","","","20160908","Dec.15, 15 2016","","IEEE","IEEE Journals & Magazines"
"Kvasir: Scalable Provision of Semantically Relevant Web Content on Big Data Framework","L. Wang; S. Tasoulis; T. Roos; J. Kangasharju","University of Cambridge, Cambridge, United Kingdom","IEEE Transactions on Big Data","20161020","2016","2","3","219","233","The Internet is overloading its users with excessive information flows, so that effective content-based filtering becomes crucial in improving user experience and work efficiency. Latent semantic analysis has long been demonstrated as a promising information retrieval technique to search for relevant articles from large text corpora. We build Kvasir, a semantic recommendation system, on top of latent semantic analysis and other state-of-the-art technologies to seamlessly integrate an automated and proactive content provision service into web browsing. We utilize the processing power of Apache Spark to scale up Kvasir into a practical Internet service. In addition, we improve the classic randomized partition tree to support efficient indexing and searching of millions of documents. Herein we present the architectural design of Kvasir, the core algorithms, along with our solutions to the technical challenges in the actual system implementation.","","","10.1109/TBDATA.2016.2557348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7462177","Apache Spark;Web application;information retrieval;machine learning;random projection;semantic search","Big data;Indexing;Information retrieval;Internet;Scalability;Semantics;Sparks","Big Data;content-based retrieval;indexing;recommender systems;semantic Web;trees (mathematics)","Apache Spark;Big Data framework;Internet service;Kvasir architectural design;Web browsing;automated content provision service;classic randomized partition tree;content-based filtering;document indexing;document searching;information flows;information retrieval technique;large text corpora;latent semantic analysis;proactive content provision service;semantic recommendation system;semantic relevant Web content;work efficiency","","","","","","20160428","Sept. 1 2016","","IEEE","IEEE Journals & Magazines"
"Excavation Equipment Recognition Based on Novel Acoustic Statistical Features","J. Cao; W. Wang; J. Wang; R. Wang","Key Laboratory for IOT and Information Fusion Technology of Zhejiang, Hangzhou Dianzi University, Hangzhou 310018, China and also with the Institute of Information and Control, Hangzhou Dianzi University, Hangzhou 310018, China.","IEEE Transactions on Cybernetics","","2016","PP","99","1","13","Excavation equipment recognition attracts increasing attentions in recent years due to its significance in underground pipeline network protection and civil construction management. In this paper, a novel classification algorithm based on acoustics processing is proposed for four representative excavation equipments. New acoustic statistical features, namely, the short frame energy ratio, concentration of spectrum amplitude ratio, truncated energy range, and interval of pulse are first developed to characterize acoustic signals. Then, probability density distributions of these acoustic features are analyzed and a novel classifier is presented. Experiments on real recorded acoustics of the four excavation devices are conducted to demonstrate the effectiveness of the proposed algorithm. Comparisons with two popular machine learning methods, support vector machine and extreme learning machine, combined with the popular linear prediction cepstral coefficients are provided to show the generalization capability of our method. A real surveillance system using our algorithm is developed and installed in a metro construction site for real-time recognition performance validation.","2168-2267;21682267","","10.1109/TCYB.2016.2609999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7580609","Acoustic statistical feature;cascade classifier;excavation equipments recognition;extreme learning machine","Acoustics;Engines;Monitoring;Performance evaluation;Pipelines;Support vector machines;Vehicles","","","","","","","","20160930","","","IEEE","IEEE Early Access Articles"
"Smart Experts for Network State Estimation","Y. Edalat; J. S. Ahn; K. Obraczka","Department of Computer Engineering, University of California at Santa Cruz, Santa Cruz, CA, USA","IEEE Transactions on Network and Service Management","20160930","2016","13","3","622","635","Several network protocols, services, and applications adjust their operation dynamically based on current network conditions. Consequently, keeping accurate estimates of the network and its performance as it fluctuates over time is critical. For example, both TCP and IEEE 802.11 periodically adapt some of their key operating parameters, namely, the retransmission timeout and the contention window size based on the average round trip time and the number of collisions, respectively. In this paper, we present a novel mechanism to estimate “near-future” network performance based on past network conditions. We call our approach to network performance estimation as smart experts for network state estimation (SENSE). SENSE uses a simple, yet effective, algorithm combining a machine learning method known as fixed-share with exponentially weighted moving average (EWMA). SENSE also introduces novel techniques that improve the predictability of the fixed-share framework without increasing computational complexity. SENSE is thus able to respond to network dynamics at different time scales, i.e., long- and medium-term fluctuations as well as short-lived variations. We evaluate SENSE's performance using synthetic and real datasets. Our experimental results show that, when compared to fixed-share and EWMA, SENSE yields higher estimation accuracy for all datasets due to its ability to more closely track data fluctuations.","1932-4537;19324537","","10.1109/TNSM.2016.2586506","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7502170","Machine learning;computation intelligence;network performance;network state estimation","Correlation;Heuristic algorithms;IEEE 802.11 Standard;Matched filters;Prediction algorithms;Protocols;State estimation","computer network performance evaluation;learning (artificial intelligence);moving average processes;state estimation;telecommunication computing","SENSE performance;computational complexity;exponentially weighted moving average;fixed-share method;long-term fluctuations;machine learning;medium-term fluctuations;network dynamics;network performance estimation;network protocols;short-lived variations;smart experts for network state estimation","","","","","","20160630","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Online forecasting of electrical load for distributed management of plug-in electric vehicles","K. Basu; A. Ovalle; B. Guo; A. Hably; S. Bacha; K. Hajar","Univ. Grenoble Alpes, GIPSA-Lab F-38000 Grenoble, France","2016 3rd International Conference on Renewable Energies for Developing Countries (REDEC)","20160929","2016","","","1","8","The paper aims at making online forecast of electrical load at the MV-LV transformer level. Optimal management of the Plug-in Electric Vehicles (PEV) charging requires the forecast of the electrical load for future hours. The forecasting module needs to be online (i.e update and make forecast for the future hours, every hour). The inputs to the predictor are historical electrical and weather data. Various data driven machine learning algorithms are compared to derive the most suitable model. The results indicate that an online forecasting method has an error between 2-5% for the future 24-hour. The decentralized management system works well with the forecasting data.","","","10.1109/REDEC.2016.7577557","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577557","Short term load forecasting;machine learning;plug-in electric vehicles;smart gird;support vector machines","Forecasting;Heuristic algorithms;Load forecasting;Load modeling;Predictive models;Support vector machines;Time series analysis","electric vehicles;learning (artificial intelligence);load forecasting;load management","MV-LV transformer level;PEV charging;decentralized management system;distributed management;electrical load;machine learning algorithm;online forecasting;plug-in electric vehicle","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"An OWL Ontology Representation for Machine-Learned Functions Using Linked Data","J. Xu; H. Wang; H. Trimbach","Dept. of EECS, Oregon State Univ., Corvallis, OR, USA","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","319","322","This paper proposes a method to represent classifiers or learned regression functions using an OWL ontology. Also proposed are methods for finding an appropriate learned function to answer a simple query. The ontology standardizes variable names and dependence properties, so that feature values can be given by users or found on the semantic web.","","","10.1109/BigDataCongress.2016.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584954","OWL;RDF;data representation;linked data;machine learning;ontology;semantic web","Linear regression;OWL;Ontologies;Prediction algorithms;Resource description framework;Semantics","knowledge representation languages;learning (artificial intelligence);ontologies (artificial intelligence);pattern classification;regression analysis;semantic Web","OWL ontology representation;classifiers;dependence properties;learned regression functions;linked data;machine-learned functions;semantic Web","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Can your smartphone detect your emotion?","D. Dai; Q. Liu; H. Meng","Chongqing Key Laboratory of Computational Intelligence, Chongqing, China","2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","20161024","2016","","","1704","1709","The smartphone has become an indispensable part in people's life. Identifying the user's emotional state according to the usage of smartphone is a new way to improve the human-computer interaction and user experience. In this paper, we present an attempt to recognize emotional states by using finger-stroke pattern. Firstly, International Affective Picture System (IAPS) were used to design the emotion inducing experiment. Then finger-stroke features under different emotional categories were extracted and analyzed. Ultimately, we used machine learning algorithms to identify three basic emotional states including positive, neutral, and negative. The experiment results show that the stroke exists some specific behavioral patterns between different people. For all 24 subjects, the average classification accuracy rate reached 85.1%, and we got the average recognition accuracy at 72.3%, 74.6% and 69.6% for male, female and all subjects.","","","10.1109/FSKD.2016.7603434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603434","Emotion recognition;Human-computer interaction;Machine learning;Smartphone","Emotion recognition;Feature extraction;Fingers;Tactile sensors","emotion recognition;human computer interaction;learning (artificial intelligence);smart phones","IAPS;emotional categories;emotional state recognition;finger-stroke pattern;human-computer interaction;international affective picture system;machine learning algorithms;negative emotional state;neutral emotional state;positive emotional state;smartphone;user emotional state detection;user experience","","","","","","","13-15 Aug. 2016","","IEEE","IEEE Conference Publications"
"Automated Bug Triaging in an Industrial Context","V. Dedík; B. Rossi","Fac. of Inf., Masaryk Univ., Brno, Czech Republic","2016 42th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)","20161018","2016","","","363","367","There is an increasing need to introduce some formof automation within the bug triaging process, so that no time is wasted on the initial assignment of issues. However, there is agap in current research, as most of the studies deal with open source projects, ignoring the industrial context and needs. In this paper, we report our experience in dealing with the automation of the bug triaging process within a research-industry cooperation. After reporting the requirements and needs that were set within the industrial project, we compare the analysis results with those from an open source project used frequently in related research (Firefox). In spite of the fact that the projects have different size and development process, the data distributions are similar and the best models as well. We found out that more easily configurable models (such as SVM+TF -- IDF) are preferred, and that top-x recommendations, number of issues per developers, and online learning can all be relevant factors when dealing with an industrial collaboration.","2376-9505;23769505","","10.1109/SEAA.2016.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592819","Bug Assignment;Bug Reports;Industrial Scale;Machine Learning;Software Bug Triaging;Text Classification","Companies;Computer bugs;Context;Sociology;Statistics;Support vector machines;Training","learning (artificial intelligence);program debugging;public domain software","SVM+TF-IDF;automated bug triaging;bug triaging process automation;industrial collaboration;industrial context;industrial needs;online learning;open source project;open source projects;research-industry cooperation;top-x recommendations","","1","","","","","Aug. 31 2016-Sept. 2 2016","","IEEE","IEEE Conference Publications"
"2PS: A novel swarm based selection algorithm for ensemble learning problem","Z. S. Taghavi; M. N. Torshiz; A. Fardad","Young Researchers and Elite Club, Qazvin Branch, Islamic Azad University, Qazvin, Iran","2015 International Congress on Technology, Communication and Knowledge (ICTCK)","20161006","2015","","","143","147","Discovering the effective subset of models in a pool of classifiers is an important and remarkable topic in ensemble learning scope. Using meticulously selected subset instead of entire ensemble leads to more efficient and effective results. This paper introduces a novel hybrid ensemble selection method of firefly and forward search algorithms. Because of the two different selection phases in the proposed method, it is called 2PS (Two-Phase Selection) method. Empirical comparisons of the method 2PS and two similar methods are performed on ten standard machine learning problems. The results show that the method 2PS leads to 5.63% average accuracy improvement compared to rivals. This great success is due to diversity balancing and then error correcting capability of 2PS, which is due to the nature of its firefly algorithm. Moreover, 2PS achieves second great success in overhead reduction by excluding redundant and weaker models in prediction which is due to its forward search algorithm.","","","10.1109/ICTCK.2015.7582660","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582660","Machine learning;classification;ensemble learning method;firefly algorithm;forward search","Classification algorithms;Clustering algorithms;Machine learning algorithms;Phased arrays;Prediction algorithms;Sociology;Statistics","learning (artificial intelligence);pattern classification;search problems","2PS;classifier pool;diversity balancing;ensemble learning problem;ensemble learning scope;error correcting capability;firefly search algorithms;forward search algorithms;hybrid ensemble selection method;overhead reduction;standard machine learning problems;subset selection;swarm based selection algorithm;two-phase selection method","","","","","","","11-12 Nov. 2015","","IEEE","IEEE Conference Publications"
"Data-driven estimation of blood pressure using photoplethysmographic signals","S. C. Gao; P. Wittek; L. Zhao; W. J. Jiang","Tsinghua University","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","20161018","2016","","","766","769","Noninvasive measurement of blood pressure by optical methods receives considerable interest, but the complexity of the measurement and the difficulty of adjusting parameters restrict applications. We develop a method for estimating the systolic and diastolic blood pressure using a single-point optical recording of a photoplethysmographic (PPG) signal. The estimation is data-driven, we use automated machine learning algorithms instead of mathematical models. Combining supervised learning with a discrete wavelet transform, the method is insensitive to minor irregularities in the PPG waveform, hence both pulse oximeters and smartphone cameras can record the signal. We evaluate the accuracy of the estimation on 78 samples from 65 subjects (40 male, 25 female, age 29±7) with no history of cardiovascular disease. The estimate for systolic blood pressure has a mean error 4.9±4.9 mm Hg, and 4.3±3.7 mm Hg for diastolic blood pressure when using the oximeter-obtained PPG. The same values are 5.1±4.3 mm Hg and 4.6±4.3 mm Hg when using the phone-obtained PPG, comparing with A&D UA-767PBT result as gold standard. The simplicity of the method encourages ambulatory measurement, and given the ease of sharing the measured data, we expect a shift to data-oriented approaches deriving insight from ubiquitous mobile devices that will yield more accurate machine learning models in monitoring blood pressure.","1557-170X;1557170X","Electronic:978-1-4577-0220-4; POD:978-1-4577-0219-8","10.1109/EMBC.2016.7590814","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590814","Big Data;Blood Pressure;Discrete Wavelet Transform;Machine Learning;Mobile Health","Biomedical monitoring;Blood pressure;Cameras;Discrete wavelet transforms;Mercury (metals);Support vector machines","blood pressure measurement;cameras;cardiovascular system;discrete wavelet transforms;diseases;learning (artificial intelligence);medical signal processing;oximetry;patient monitoring;photoplethysmography;smart phones","PPG signal;PPG waveform;ambulatory measurement;automated machine learning algorithms;blood pressure measurement;blood pressure monitoring;cardiovascular disease;data-driven estimation;diastolic blood pressure;discrete wavelet transform;optical method;oximeter-obtained PPG;phone-obtained PPG;photoplethysmographic signal;photoplethysmography;pulse oximeter;single-point optical recording;smartphone camera;supervised learning;systolic blood pressure;ubiquitous mobile device","","","","","","","16-20 Aug. 2016","","IEEE","IEEE Conference Publications"
"Network function computation as a service in future 5G machine type communications","D. Vukobratovic; D. Jakovetic; V. Skachek; D. Bajovic; D. Sejdinovic","Faculty of Technical Sciences, University of Novi Sad, Serbia","2016 9th International Symposium on Turbo Codes and Iterative Information Processing (ISTC)","20161020","2016","","","365","369","The 3GPP machine type communications (MTC) service is expected to contribute a dominant share of the IoT traffic via the upcoming fifth generation (5G) mobile cellular systems. MTC has ambition to connect billions of devices to communicate their data to MTC applications for further processing and data analysis. However, for majority of the applications, collecting all the MTC generated data is inefficient as the data is typically fed into application-dependent functions whose outputs determine the application actions. In this paper, we present a novel MTC architecture that, instead of collecting raw large-volume MTC data, offers the network function computation (NFC) as a service. For a given application demand (function to be computed), different modules (atomic nodes) of the communication infrastructure are orchestrated into a (reconfigurable) directed network topology, and each module is assigned an appropriately defined (reconfigurable) atomic function over the input data, such that the desired global network function is evaluated over the MTC data and a requested MTC-NFC service is delivered. We detail practical viability of incorporating MTC-NFC within the existing 3GPP architecture relying on emerging concepts of Network Function Virtualization and Software Defined Networking. Finally, throughout the paper, we point to the theoretical foundations that inspired the presented architecture highlighting challenges and future directions for designing 3GPP MTC-NFC service.","","","10.1109/ISTC.2016.7593138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7593138","Big Data;Internet of Things (IoT);Machine learning;Network Coding;Network Function Computation","Artificial neural networks","3G mobile communication;5G mobile communication;Internet of Things;software defined networking;telecommunication network topology;telecommunication traffic;virtualisation","3GPP MTC-NFC service;3GPP machine type communication;5G machine type communication;5G mobile cellular system;application-dependent function;data analysis;data processing;directed network topology;fifth generation mobile cellular system;loT traffic;network function computation;network function virtualization;software defined networking","","","","","","","5-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"Predictive Modeling in a Big Data Distributed Setting: A Scalable Bias Correction Approach","G. Bontempi; Y. A. L. Borgne","Fac. of Sci., Comput. Sci. Dept., Machine Learning Group, Univ. Libre de Bruxelles, Brussels, Belgium","2016 IEEE International Congress on Big Data (BigData Congress)","20161006","2016","","","68","74","Massive datasets are becoming pervasive in computational sciences. Though this opens new perspectives for discovery and an increasing number of processing and storage solutions is available, it is still an open issue how to transpose machine learning and statistical procedures to distributed settings. Big datasets are no guarantee for optimal modeling since they do not automatically solve the issues of model design, validation and selection. At the same time conventional techniques of cross-validation and model assessment are computationally prohibitive when the size of the dataset explodes. This paper claims that the main benefit of a massive dataset is not related to the size of the training set but to the possibility of assessing in an accurate and scalable manner the properties of the learner itself (e.g. bias and variance). Accordingly, the paper proposes a scalable implementation of a bias correction strategy to improve the accuracy of learning techniques for regression in a big data setting. An analytical derivation and an experimental study show the potential of the approach.","","","10.1109/BigDataCongress.2016.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584922","Scalable machine learning;big data","Big data;Data models;Estimation;Manganese;Predictive models;Sparks;Training","Big Data;distributed processing;learning (artificial intelligence);regression analysis","Big Data distributed setting;big datasets;cross-validation techniques;machine learning;model assessment;predictive modeling;regression;scalable bias correction approach;statistical procedures","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Expectation Maximization of Frequent Patterns, a Specific, Local, Pattern-Based Biclustering Algorithm for Biological Datasets","E. J. Moore; T. Bourlai","Lane Department of Computer Science and Electrical Engineering, Statler College of Engineering, West Virginia University, Morgantown, WV","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20161006","2016","13","5","812","824","Currently, binary biclustering algorithms are too slow and non-specific to handle biological datasets that have a large number of attributes, which is essential for the computational biology problem of microarray analysis. Specialized computers may be needed to execute an algorithm, and may fail to produce a solution, due to its large resource needs. The biclusters also include too many false positives, the type I error, which hinders biological discovery. We propose an algorithm that can analyze datasets with a large attribute set at different densities, and can operate on a laptop, which makes it accessible to practitioners. EMFP produces biclusters that have a very low Root Mean Squared Error and false positive rate, with very few type II errors. Our binary biclustering algorithm is a hybrid, axis-parallel, pattern-based algorithm that finds multiple, non-overlapping, near-constant, deterministic, binary submatricies, with a variable confidence threshold, and the novel use of local density comparisons versus the standard global threshold. EMFP introduces a new, and intuitive way to calculate internal measures for binary biclustering methods. We also introduce a framework to ease comparison with other algorithms, and compare to both binary and general biclustering algorithms using two real, and 80 synthetic databases.","1545-5963;15455963","","10.1109/TCBB.2015.2510011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360173","DNA;Knowledge discovery;association rules;biclustering;bioinformatics;biomedical informatics;computational biology;data mining;machine learning;nanobiotechnology;pattern recognition;unsupervised learning","Algorithm design and analysis;Clustering algorithms;DNA;Databases;Machine learning algorithms;Standards","biology computing;data mining;expectation-maximisation algorithm;mean square error methods;parallel algorithms;pattern clustering","binary biclustering algorithms;biological datasets;computational biology problem;expectation maximization;hybrid axis-parallel pattern-based algorithm;microarray analysis;pattern-based algorithm;pattern-based biclustering algorithm;root mean squared error;type-I error;type-II error","","","","","","20151217","September 1 2016","","IEEE","IEEE Journals & Magazines"
"Statistical identification and classification of potential islanding precursors in a grid-connected Solar Photo Voltaic system","S. Vyas; R. Kumar; R. Kavasseri","Centre for Energy and Environment, Malaviya National Institute of Technology, Jaipur, India 302017","2016 IEEE 6th International Conference on Power Systems (ICPS)","20161006","2016","","","1","6","Impacts of unintentional islanding will be more pronounced in the scenario of rising distributed-generation penetration especially on distribution grids. Solar photo voltaic generation is the forerunner technology whose grid-integration is increasing significantly. This paper explores unique anomalies occurring in a solar photo voltaic system integrated with a distribution network that can potentially cause unintentional islanding and applies statistical and machine learning techniques to identify them in real time. Grid-side disturbances and complete power-balance between the inverter and loads are the conditions deemed to occur frequently in a high penetration case. These have been simulated on a modified IEEE feeder and the resulting anomalies cross-verified in emulation and real-time simulation. Multivariate statistical techniques and a support vector classifier have been applied to identify the explored anomalous currents. The classification results show promising application towards a new predictive islanding detection logic inside solar inverters however the actual relay delay in tripping a breaker and the inverter's capability to trip before it on sensing a potential precursor to accidental islanding needs to be tested in real time.","","","10.1109/ICPES.2016.7584056","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7584056","Classification;inverters;islanding;machine learning;power system","Inverters;Islanding;Load modeling;Mathematical model;Real-time systems;Support vector machines","distributed power generation;invertors;learning (artificial intelligence);pattern classification;photovoltaic power systems;power distribution faults;power engineering computing;power generation protection;power grids;power system identification;real-time systems;statistical analysis;support vector machines","anomalous current identification;breaker tripping;distributed-generation penetration;distribution grids;distribution network;grid-connected solar photovoltaic system;grid-side disturbances;islanding precursor classification;machine learning;modified IEEE feeder;multivariate statistical techniques;power-balance;predictive islanding detection logic;real time identification;relay delay;solar inverters;solar photovoltaic generation;statistical identification;support vector classifier;unintentional islanding impacts","","","","","","","4-6 March 2016","","IEEE","IEEE Conference Publications"
"Test-Suite Reduction Does Not Necessarily Require Executing the Program under Test","H. Felbinger; F. Wotawa; M. Nica","Inst. of Software Technol., Graz Univ. of Technol., Graz, Austria","2016 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)","20160922","2016","","","23","30","Removing redundancies from test-suites is an important task of software testing in order to keep test-suites as small as possible, but not to harm the test-suite's fault detection capabilities. A straightforward algorithm for test-suite reduction would select elements of the test-suite randomly and remove them if and only if the reduced test-suite fulfills the same or similar coverage or mutation score. Such algorithms rely on the execution of the program and the repeated computation of coverage or mutation score. In this paper, we present an alternative approach that purely relies on a model learned from the original test-suite without requiring the execution of the program under test. The idea is to remove those tests that do not change the learned model. In order to evaluate the approach we carried out an experimental study showing that reductions of 60-99% are possible while still keeping coverage and mutation score almost the same.","","","10.1109/QRS-C.2016.8","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573720","Coverage;Machine learning;Mutation Score;Redundancy;Software testing","Computational modeling;Decision trees;Electronic mail;Indexes;Redundancy;Syntactics;Testing","fault diagnosis;program testing;redundancy","mutation score;redundancies removal;software testing;straightforward algorithm;test-suite fault detection capabilities;test-suite reduction","","","","","","","1-3 Aug. 2016","","IEEE","IEEE Conference Publications"
"Detecting and diagnosing anomalies in cellular networks using Random Neural Networks","P. Casas; A. D'Alconzo; P. Fiadino; C. Callegari","AIT Austrian Institute of Technology, Austria","2016 International Wireless Communications and Mobile Computing Conference (IWCMC)","20160929","2016","","","351","356","Despite a large body of literature and methods devoted to the analysis of network traffic, the automatic detection and classification of network traffic anomalies still represents a major issue for network operators. The problem becomes even more challenging for cellular ISPs, both due to the ever growing number of connected devices and to the constant deployment of new applications and services prone to performance issues. In this paper we tackle this problem using Machine Learning (ML) approaches: in particular, we devise a system based on Neural Networks to unveil the relations between several monitored traffic features and network anomalies impacting a large number of customers in an operational cellular network. By training a model based on Random Neural Networks (RNN), we provide a fast and accurate anomaly detector and classifier, capable to pinpoint anomalies without assuming any specific traffic model or particular network behavior. The proposed solution is evaluated using synthetically generated data from an operational cellular ISP, drawn from real traffic statistics to resemble the real cellular network traffic. Our RNN model is capable to detect and classify different classes of anomalies with high accuracy and low false alarm rates, even when the volume of such anomalies is small.","","","10.1109/IWCMC.2016.7577083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577083","Anomaly Detection;Cellular ISP;DNS Traffic;Machine Learning;Network Measurements;Random Neural Networks","Biological neural networks;Context;Detectors;Electronic mail;Neurons;Recurrent neural networks","cellular radio;learning (artificial intelligence);neural nets;telecommunication computing;telecommunication traffic","ISP;cellular networks;machine learning;network traffic;random neural networks","","1","","","","","5-9 Sept. 2016","","IEEE","IEEE Conference Publications"
"A survey on detection and classification of rice plant diseases","J. P. Shah; H. B. Prajapati; V. K. Dabhi","Department of Information Technology, Dharmsinh Desai University, Nadiad, Gujarat, India","2016 IEEE International Conference on Current Trends in Advanced Computing (ICCTAC)","20160915","2016","","","1","8","Identifying disease from the images of the plant is one of the interesting research areas in computer and agriculture field. This paper presents a survey of different image processing and machine-learning techniques used in the identification of rice plant diseases based on images of disease infected rice plants. This paper presents not only survey of various techniques but also concisely discusses important concepts of image processing and machine learning applied to plant disease detection and classification. We carry out detailed study of 19 papers, covering the work on rice plant diseases and other different plants and fruits, and present a survey of these papers based on important criteria. These criteria include size of image dataset, no. of classes(diseases), preprocessing, segmentation techniques, types of classifiers, accuracy of classifiers etc. We utilize our survey and study to propose and design our work on detection and classification of rice plant diseases.","","","10.1109/ICCTAC.2016.7567333","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7567333","classification;clustering;disease classification;disease detection;image processing;machine learning","Agriculture;Diseases;Feature extraction;Image color analysis;Image segmentation;Shape","agriculture;crops;feature extraction;image classification;image segmentation;learning (artificial intelligence);plant diseases","agriculture;image processing;image segmentation;machine learning;rice plant disease classification;rice plant disease detection","","","","","","","10-11 March 2016","","IEEE","IEEE Conference Publications"
"Automated Eddy Current non-destructive testing through low definition lissajous figures","G. D'Angelo; M. Laracca; S. Rampone","University of Sannio, Dept. of Science and Technology, Benevento, Italy","2016 IEEE Metrology for Aerospace (MetroAeroSpace)","20160922","2016","","","280","285","In the framework of Eddy Current Testing (ECT), this work presents an automated non-destructive testing method based on Eddy Currents which uses few geometric features of low definition Lissajous figures. A features vector representing the shape of the ECT magnetic field response represented in the complex plane is used as signature to recognize specific defects of aerospace structures. In order to evaluate the proposed method, the accuracy, specificity, sensitivity, precision, F-Measure, AUC, and Matthews correlation coefficient are used to rate the following classifiers: J48, multi-layer neural network and Naïve Bayes. The used data set is carried out by lab experiments performed on an aircraft test-piece with several well-known defects. The results show the usefulness of the proposed approach to be used as an aided tool for ECT data analysis. It allows both an easier and shorten data interpretation by the qualified inspectors, and an increase in the diagnosis quality.","","","10.1109/MetroAeroSpace.2016.7573227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573227","J48;Lissajous figures;Naïve Bayes classifier;Non destructive testing (NDT);content based image retrieval (CBIR);eddy current testing (ECT);machine learning;neural network","Feature extraction;Impedance;Magnetic field measurement;Magnetic fields;Probes;Shape;Testing","Bayes methods;aircraft testing;automatic testing;data analysis;eddy current testing;neural nets;vectors","AUC;ECT data analysis;ECT magnetic field;F-measure coefficient;J48 classifier;Matthews correlation coefficient;Naïve Bayes classifier;aerospace structure;aircraft test-piece;automated eddy current nondestructive testing;data interpretation;feature vector representation;low definition Lissajous figure;multilayer neural network classifier","","","","","","","22-23 June 2016","","IEEE","IEEE Conference Publications"
"Exploiting Data Analytics for Home Automation Services","F. Ramparany; M. Thalgott; S. Bolle; S. Martin","Orange Labs., Meylan, France","2016 IEEE 4th International Conference on Future Internet of Things and Cloud (FiCloud)","20160926","2016","","","228","234","The Internet of Thing generates data at an unprecedented pace. This is due to the ever increasing number of connected devices being deployed as well as their volubility. There's a huge potential in exploiting this mass of data. In particular collecting, storing this data over time, and analyzing the resulting deposit offline, enables the extraction of information and discovering of patterns, which can then be transformed into executable structures and new services. This approach can apply to a range of application domains including Smart Home, Smart City, Smart Energy services. In this paper we show how Data Analytics (DA) can leverage such data deposit and produce insights which can then be transformed into enhanced services that will bring the user experience to the next level. Our approach has been assessed in the domain of the Smart Home with real data provided by Orange Homelive solution through the implementation of the MACLEOD system.","","","10.1109/FiCloud.2016.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7575868","data analytics;data mining;internet of things;machine learning;smart home","Context;Data analysis;Data mining;Data visualization;Intelligent sensors;Internet of things;Smart homes","Internet of Things;data analysis;data mining;home automation;smart cities","DA;Internet of Thing;MACLEOD system;data analytics;home automation services;information extraction;pattern discovery;smart city;smart energy services;smart home","","","","","","","22-24 Aug. 2016","","IEEE","IEEE Conference Publications"
"Electroencephalogram (EEG) based authentication leveraging visual evoked potentials (VEP) resulting from exposure to emotionally significant images","R. J. Rodriguez","System Architecture, Design, and Integration Directorate, Raytheon - Integrated Defense Systems, Sudbury, United States","2016 IEEE Symposium on Technologies for Homeland Security (HST)","20160915","2016","","","1","6","Encephalogram (EEG) devices are one of the active research areas in human-computer interaction (HCI). They provide a unique brain-machine interface (BMI) for interacting with a growing number of applications. EEG devices interface with computational systems requiring access control. These controls rely on a number of authenticators, including “what you know”, “what you have”, and “what you are”. The “what you are” authenticator, formally known as a biometrics authenticator, is increasingly gaining acceptance. An emerging approach in physiological biometrics is cognitive biometrics, which measures brain's response to stimuli. These stimuli can be measured by a number of devices, including EEG systems. This work shows an approach to authenticate users interacting with their computational devices through the use of EEG devices. The results demonstrate the feasibility of using a unique hard-to-forge trait as an absolute biometrics authenticator by exploiting the signals generated by different areas of the brain when exposed to visual stimuli. The outcome of this research highlights the importance of the prefrontal cortex and temporal lobes to capture unique responses to images that trigger emotional responses. Additionally, the utilization of logarithmic band power processing combined with LDA as the machine learning algorithm provides higher accuracy when compared against common spatial patterns or windowed means processing in combination with GMM and SVM machine learning algorithms.","","","10.1109/THS.2016.7568908","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568908","BMI;Biometrics;EEG;Machine Learning;Visual Evoked Potential","Access control;Biological system modeling;Brain modeling;Electroencephalography;Feature extraction;Iris recognition","brain-computer interfaces;electroencephalography;human computer interaction;medical signal processing;support vector machines","BMI;EEG devices;EEG devices interface;HCI;SVM machine learning algorithms;VEP;authentication leveraging visual evoked potentials;biometrics authenticator;brain-machine interface;cognitive biometrics;computational systems;electroencephalogram;emotionally significant images;encephalogram;human computer interaction;logarithmic band power processing;physiological biometrics;prefrontal cortex;temporal lobes","","","","","","","10-11 May 2016","","IEEE","IEEE Conference Publications"
"Firewalls for the Web 2.0","R. Rietz; H. König; S. Ullrich; B. Stritter","","2016 IEEE International Conference on Software Quality, Reliability and Security (QRS)","20161013","2016","","","242","253","The widespread use of Web 2.0 technologies yields an increasing threat potential for users and related systems. Modern web applications and online services are nowadays based on Web 2.0 technologies, such as JavaScript and AJAX, and thus on the execution of active content in the browsers of the users. Firewalls are a common practice to securely connecting to the internet. In this paper, we propose a novel perimeter firewall architecture for web applications that addresses the entire process chain starting from the data transfer with HTTP via the analysis of manipulated web documents to the extraction and analysis of active contents. The basic idea is to allow only a restricted set of web applications to pass the firewall based on a model of their HTML and JavaScript structure. We evaluate the capability of the resulting models for identifying the underlying web applications and their ability to ward off additional malicious inputs.","","","10.1109/QRS.2016.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7589804","CSRF;Cross-site request forgery;Cross-site scripting;SVM;WAF;Web 2.0;Web application firewall;Web security;XSS;machine learning","Browsers;Malware;Security;Servers;Service-oriented architecture;Web 2.0;Web pages","Internet;firewalls;transport protocols","AJAX;HTTP;Internet security;JavaScript;Web 2.0 technology;Web applications;firewall architecture;hypertext transfer protocol","","","","","","","1-3 Aug. 2016","","IEEE","IEEE Conference Publications"
"SVM for network anomaly detection using ACO feature subset","T. Mehmood; H. B. M. Rais","Department of Computer and Information Sciences, University Teknologi PETRONAS, Tronoh, Malaysia","2015 International Symposium on Mathematical Sciences and Computing Research (iSMSC)","20161020","2015","","","121","126","Over the past short time, network security facing a lot of challenges. Confidentiality, integrity, and availability are the major concerns of the data. To cope with this problem different systems have been developed and the systems are known as Intrusion detection systems. Intrusion detection system detects the violation of confidentiality, integrity, and availability of the data. Intrusion detection systems are developed on the bases of two different detection techniques, signature-based technique and anomaly-based technique. Classification approach has been widely adopted for the development of the anomaly detection model to classify the data into normal class and attack class. But irrelevant and redundant features are the obstacle for classification algorithm to build an efficient detection model. This paper proposes a detection model, ant system with support vector machine, which uses ant system, a variation of ant colony optimization, to filter out the redundant and irrelevant features for support vector machine classification algorithm. KDD99, which is a benchmark dataset used for anomaly detection, has been adopted here. Each instance in KDD99 has been represented by 41 features which also has some redundant or irrelevant features. Ant system has been used to remove those redundant and irrelevant features. The selected feature subset using ant system is then validated using support vector machine. The experimental results showed that the performance of the classification algorithm, when trained with the reduced feature set, has been improved. The performance measures used in this comparison are true positive rate, false positive rate, and precision.","","","10.1109/ISMSC.2015.7594039","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7594039","anomaly detection;ant colony optimization;intrusion detection system;machine learning;network-based intrusion detection system;support vector machine","Ant colony optimization;Classification algorithms;Data models;Feature extraction;Intrusion detection;Machine learning algorithms;Support vector machines","ant colony optimisation;data integrity;digital signatures;feature selection;learning (artificial intelligence);pattern classification;security of data;set theory;support vector machines","ACO feature subset;KDD99;SVM;anomaly detection model development;anomaly-based technique;ant colony optimization;ant system;attack class;classification approach;confidentiality violation;data availability;data classification;data integrity;detection techniques;false positive rate;intrusion detection systems;irrelevant feature filtering;network anomaly detection;network security;normal class;precision measure;reduced feature set training;redundant feature filtering;signature-based technique;support vector machine classification algorithm;true positive rate","","","","","","","19-20 May 2015","","IEEE","IEEE Conference Publications"
"Reconstruction Attacks Against Mobile-Based Continuous Authentication Systems in the Cloud","M. Al-Rubaie; J. M. Chang","Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA","IEEE Transactions on Information Forensics and Security","20160916","2016","11","12","2648","2663","Continuous authentication for mobile devices using behavioral biometrics is being suggested to complement initial authentication for securing mobile devices, and the cloud services accessed through them. This area has been studied over the past few years, and low error rates were achieved; however, it was based on training and testing using support vector machine (SVM) and other non-privacy-preserving machine learning algorithms. To stress the importance of carefully designed privacy-preserving systems, we investigate the possibility of reconstructing gestures raw data from users' authentication profiles or synthesized samples' testing results. We propose two types of reconstruction attacks based on whether actual user samples are available to the adversary (as in SVM profiles) or not. We also propose two algorithms to reconstruct raw data: a numerical-based algorithm that is specific to one compromised system, and a randomization-based algorithm that can work against almost any compromised system. For our experiments, we selected one compromised and four attacked gesture-based continuous authentication systems from the recent literature. The experiments, performed using a public data set, showed that the attacks were feasible, with a median ranging from 80% to 100% against one attacked system using all types of attacks and algorithms, and a median ranging from 73% to 100% against all attacked systems using the randomization-based algorithm and the negative support vector attack. Finally, we analyze the results, and provide recommendations for building active authentication systems that could resist reconstruction attacks.","1556-6013;15566013","","10.1109/TIFS.2016.2594132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7523420","Mobile devices;continuous authentication;gestures;machine learning;privacy;reconstruction attacks","Algorithm design and analysis;Authentication;Biometrics (access control);Image reconstruction;Mobile handsets;Support vector machines;Testing","cloud computing;mobile computing;security of data;support vector machines","SVM;behavioral biometrics;cloud services;gesture-based continuous authentication systems;mobile-based continuous authentication systems;negative support vector attack;numerical-based algorithm;privacy-preserving system;randomization-based algorithm;reconstruction attacks;support vector machine","","","","","","20160727","Dec. 2016","","IEEE","IEEE Journals & Magazines"
"Building recognition system based on deep learning","P. Bezak","Slovak University of Technology in Bratislava Advanced Technologies Research Institute, MTF Trnava, Slovakia","2016 Third International Conference on Artificial Intelligence and Pattern Recognition (AIPR)","20161013","2016","","","1","5","Deep learning architectures based on convolutional neural networks (CNN) are very successful in image recognition tasks. These architectures use a cascade of convolution layers and activation functions. The setup of the number of layers and the number of neurons in each layer, the choice of activation functions and training optimization algorithm are very important. I present GPU implementation of CNN with feature extractors designed for building recognition, learned in a supervised way and achieve very good results.","","","10.1109/ICAIPR.2016.7585230","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7585230","convolutional neural networks;deep learning;image recognition;machine learning","Biological neural networks;Buildings;Data models;Image recognition;Machine learning;Training","feature extraction;graphics processing units;learning (artificial intelligence);neural net architecture;object recognition","CNN;GPU;building recognition system;convolutional neural networks;deep learning architectures;feature extractors;image recognition","","","","","","","19-21 Sept. 2016","","IEEE","IEEE Conference Publications"
"Social network comment classification using fuzzy based classifier technique","V. Bairagi; N. Tapaswi","Computer Science Department, IES IPS Academy Indore, India","2016 Symposium on Colossal Data Analysis and Networking (CDAN)","20160919","2016","","","1","7","Now in these days use of social networking websites are growing different kinds and natures of user are being utilize this services frequently. In this content the anomalous user can misbehave or can be involved in unsocial activity over the clean environment. Furthermore people frequently use symbolic forms to convert other person by which pattern of unsolicited can be recognized by analysis these content. Therefore in this research paper we are going to investigate the different technique and approaches that recently developed by different researchers. Finally we proposed a model by associating this method for this conversion. Data mining and machine learning, offers to evaluate the data automatically for different applications. In order to perform such task the classification and clustering techniques are used. The classification of data is a supervised learning process thus the technique needs a set of attributes (patterns) and the associated class labels. The algorithm first prepare the mathematical model using the previous patterns of training sets and further these models are used to evaluate the test sets. Thus a two different classifiers namely Bayesian classifier and k-nearest neighbour algorithm is studied. Moreover, some of authors are suggested to implement the fuzzy classification technique for achieving the high accurate results. Therefore a new method using the fuzzy concept is proposed and implemented. Additionally the classical text classification models are used for comparative performance study. The comparative performance study shows the effectiveness of the proposed classification technique and able to produce the more accurate results as compared to traditional classifiers.","","","10.1109/CDAN.2016.7570863","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7570863","data mining;fuzzy logic;machine learning;text mining","Algorithm design and analysis;Classification algorithms;Data analysis;Error analysis;Social network services;Text categorization;Training","Bayes methods;content management;data mining;fuzzy set theory;learning (artificial intelligence);pattern classification;pattern clustering;social networking (online);text analysis","Bayesian classifier;class labels;clustering techniques;content analysis;data classification;data mining;fuzzy based classifier;k-nearest neighbour algorithm;machine learning;mathematical model;social network comment classification;social networking Web sites;supervised learning;text classification models;training set patterns;unsocial activity","","","","","","","18-19 March 2016","","IEEE","IEEE Conference Publications"
"A comparative analysis of SVM and its stacking with other classification algorithm for intrusion detection","N. Chand; P. Mishra; C. R. Krishna; E. S. Pilli; M. C. Govil","Department of Computer Science & Engineering, National Institute of Technical Teachers' Training & Research, Chandigarh, India","2016 International Conference on Advances in Computing, Communication, & Automation (ICACCA) (Spring)","20160929","2016","","","1","6","Network attacks have become more pervasive in the cyber world. There are various attacks such as denial of service, scanning, privilege escalation that is increasing day by day leading towards the requirement of a more robust and adaptable security techniques. Anomaly detection is the main focus of our paper. Support Vector Machine (SVM) is one of the good classification algorithm applied specially for intrusion detection. However, its performance can be significantly improved when it is applied in integration with other classifiers. In this paper, we have performed a comparative analysis of SVM classifier's performance when it is stacked with other classifiers like BayesNet, AdaBoost, Logistic, IBK, J48, RandomForest, JRip, OneR and SimpleCart. Multi-Classifier algorithm have better classification power when compared to a single classifier algorithm specially for detecting low frequency attacks such as guess password, rootkits, spyware etc. Our preliminary analysis over NSL-KDD'99 dataset shows that stacking of SVM and Random Forest provides the best performance with accuracy of around 97.50% which apparently better than SVM (91.81%).","","Electronic:978-1-5090-0673-1; POD:978-1-5090-0674-8","10.1109/ICACCA.2016.7578859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7578859","Intrusion Detection;Machine Learning;Multi-Classifier","Algorithm design and analysis;Data mining;Intrusion detection;Machine learning algorithms;Support vector machines;Training;Vegetation","Internet;computer network security;support vector machines","AdaBoost;BayesNet;IBK;J48;JRip;Logistic;NSL-KDD'99 dataset;OneR;RandomForest;SVM classifier;SimpleCart;anomaly detection;classification power;cyber world;denial of service;guess password;intrusion detection;low frequency attacks;multiclassifier algorithm;network attacks;rootkits;security techniques;spyware;support vector machine","","","","","","","8-9 April 2016","","IEEE","IEEE Conference Publications"
"Automated malware detection using artifacts in forensic memory images","R. Mosli; R. Li; B. Yuan; Y. Pan","College of Computing and Information Science Rochester Institute of Technology Rochester, New York","2016 IEEE Symposium on Technologies for Homeland Security (HST)","20160915","2016","","","1","6","Malware is one of the greatest and most rapidly growing threats to the digital world. Traditional signature-based detection is no longer adequate to detect new variants and highly targeted malware. Furthermore, dynamic detection is often circumvented with anti-VM and/or anti-debugger techniques. Recently heuristic approaches have been explored to enhance detection accuracy while maintaining the generality of a model to detect unknown malware samples. In this paper, we investigate three feature types extracted from memory images - registry activity, imported libraries, and API function calls. After evaluating the importance of the different features, different machine learning techniques are implemented to compare performances of malware detection using the three feature types, respectively. The highest accuracy achieved was 96%, and was reached using a support vector machine model, fitted on data extracted from registry activity.","","","10.1109/THS.2016.7568881","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568881","Cuckoo Sandbox;Machine Learning;Malware;Memory Forensics","Data models;Decision trees;Feature extraction;Forensics;Malware;Support vector machines","application program interfaces;digital forensics;feature extraction;invasive software;learning (artificial intelligence);support vector machines","API function calls;antiVM;antidebugger techniques;automated malware detection;data extraction;dynamic detection;feature extraction;forensic memory images;heuristic approaches;machine learning techniques;registry activity;support vector machine model","","","","","","","10-11 May 2016","","IEEE","IEEE Conference Publications"
"A deep cascade neuro-fuzzy system for high-dimensional online fuzzy clustering","Z. Hu; Y. V. Bodyanskiy; O. K. Tyshchenko","Central China Normal University, 152 Louyu Road, 430079, Wuhan, China","2016 IEEE First International Conference on Data Stream Mining & Processing (DSMP)","20161006","2016","","","318","322","A deep cascade system (based on neuro-fuzzy nodes) and its online learning procedure are proposed in this paper. A number of layers can grow unlimitedly during a self-learning procedure. The system is based on nodes of a special type. A goal function of a special type is used for probabilistic high-dimensional fuzzy clustering. To assess a clustering quality of data processing, a neuron's architecture of a special type is introduced.","","","10.1109/DSMP.2016.7583567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583567","Computational Intelligence;Data Stream Processing;Deep Learning;Machine Learning;Neuro-Fuzzy System;Probabilistic Fuzzy Clustering","Clustering algorithms;Fuzzy systems;Machine learning;Neural networks;Neurons;Probabilistic logic;Quality assessment","cascade systems;data handling;fuzzy neural nets;fuzzy systems;neural net architecture;pattern clustering;probability;unsupervised learning","data processing clustering quality;deep cascade neuro-fuzzy system;neuron architecture;online learning procedure;probabilistic high-dimensional online fuzzy clustering;self-learning procedure","","","","","","","23-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"Mining multi domain text reviews using semi-supervised approach","J. S. Deshmukh; A. K. Tripathy","Department of Computer Engineering, Pacific Academy of Higher Education and Research University, Udaipur, India","2016 IEEE International Conference on Engineering and Technology (ICETECH)","20160919","2016","","","788","791","Opinion mining is growing area as people are sharing their views, opinions & experiences online. Automatic detection and analysis of sentiment around products, brands, political issues etc. is a challenging task. Domain adaptation is an important issue, which aims at transferring knowledge across domains or tasks. The labeling work may be time-consuming and expensive in order to build accurate opinion classifiers because of low generalization ability to new domains of supervised machine learning algorithms. Hence, domain adaptation algorithms are highly desirable to reduce domain dependency and labeling cost. The proposed approach classifies opinion words using maximum entropy and assigns weight using point wise mutual information. Results show that proposed approach performs moderately well compare to baseline method.","","","10.1109/ICETECH.2016.7569355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569355","Data Mining;Machine Learning;Opinion mining","Classification algorithms;Conferences;Data mining;Entropy;Mutual information;Sentiment analysis;Thesauri","data mining;learning (artificial intelligence);maximum entropy methods;sentiment analysis","data mining;domain adaptation;maximum entropy;multidomain text review mining;opinion classifiers;opinion mining;semisupervised approach;supervised machine learning","","","","","","","17-18 March 2016","","IEEE","IEEE Conference Publications"
"Yet Another Cost Aggregation Over Models","O. Choi; H. S. Chang","Department of Electronics Engineering, Incheon National University, Incheon, South Korea","IEEE Transactions on Image Processing","20160926","2016","25","11","5397","5410","In the recent decades, we have witnessed the advent of local or non-local filters for cost aggregation in stereo matching, pushing the envelope of local methods to the degree of global methods, while maintaining the efficiency. A specific filter with a specific parameter setting may have a potential to best work for an image pair, but may not guarantee equally good performance for other image pairs. To address this problem, we propose a mixture-of-experts model, which applies a heterogeneous set of filters on the cost volume and adaptively combines the results. We employ supervised learning to estimate per-pixel mixing coefficients, which are used to adaptively control the weight of the filter responses. Through experiments, we show that the mixture model significantly reduces errors in disparity estimation and even outperforms the strategy of selecting the best per-pixel filter from the pool of filters in the average sense.","1057-7149;10577149","","10.1109/TIP.2016.2599295","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539552","Stereo matching;cost aggregation;machine learning;mixture of experts;random forest;stereo confidence","Adaptation models;Aggregates;Cameras;Computational complexity;Computational modeling;Estimation;Image color analysis","filtering theory;image matching;learning (artificial intelligence);set theory;stereo image processing","cost aggregation;cost volume;degree-of-global methods;disparity estimation;envelope-of-local methods;filter response weight adaptive control;heterogeneous filter set;image pair;local filters;mixture-of-experts model;nonlocal filters;per-pixel mixing coefficient estimation;stereo matching;supervised learning","","","","","","20160810","Nov. 2016","","IEEE","IEEE Journals & Magazines"
"Early Stage Internet Traffic Identification Using Data Gravitation Based Classification","L. Peng; H. Zhang; B. Yang; Y. Chen; X. Zhou","","2016 IEEE 14th Intl Conf on Dependable, Autonomic and Secure Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)","20161013","2016","","","504","511","Traditional machine learning traffic identification techniques usually use the features of a whole Internet flow, which makes such techniques few sense in engineering practices. Therefore, recent years, an increasing number of researchers turn to build effective machine learning models to identify traffics with the few packets at the early stage. In this paper, data gravitation based classification (DGC) model, a supervised learning approach inspired by Newton's universal gravitation law, is applied for early stage traffic identification. In the empirical study, two open data sets and a data set collected in our campus network are employed. Eight widely used supervised learning algorithms are compared with our approach in the identification experiments. Accuracy and Cohen's kappa coefficient are applied to evaluate the performances of compared methods. The experimental results suggest that DGC outperformed the other algorithms for most cases considering both of accuracy and kappa. Thus, DGC is effective for early stage traffic identification.","","","10.1109/DASC-PICom-DataCom-CyberSciTec.2016.98","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7588894","Data gravitation;Machine learning;Traffic identification","Data models;Feature extraction;Internet;Sociology;Statistics;Supervised learning;Testing","","","","","","","","","8-12 Aug. 2016","","IEEE","IEEE Conference Publications"
"A survey on the evolution of various voice conversion techniques","Sathiarekha K; S. Kumaresan","Dept. of CSE, Government College of Technology, Coimbatore, India","2016 3rd International Conference on Advanced Computing and Communication Systems (ICACCS)","20161010","2016","01","","1","5","Voice conversion (VC) is an area of speech processing that deals with the process of hiding a speaker's identity. This area has been gaining a lot of importance in the recent years. In voice conversion, the voice of the source speaker is taken and modified so that it is made to sound as though it was rendered by the target speaker. Several techniques to voice conversion have been presented and this paper is a survey on those various methods to achieve voice conversion. The techniques trace out from the codebook mapping techniques to Hidden Markovian Model to Gaussian Mixture Model and finally have evolved up to the neural networks and machine learning techniques. These methods focus on various tasks such as speech enhancement, emotion conversion and speaking assistance.","","","10.1109/ICACCS.2016.7586373","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586373","Gaussian Mixture Models (GMM);Hidden Markovian Models (HMM);Voice Conversion;codebook mapping;machine learning;static approaches","Gaussian mixture model;Hidden Markov models;Speech;Speech processing;Speech recognition;Vector quantization","Gaussian processes;hidden Markov models;learning (artificial intelligence);mixture models;neural nets;speech processing","Gaussian mixture model;VC;codebook mapping techniques;hidden Markovian Model;machine learning;neural networks;source speaker;speaker identity;speech processing;target speaker;voice conversion","","","","","","","22-23 Jan. 2016","","IEEE","IEEE Conference Publications"
"Assessment of System Vulnerability for Smart Grid Applications","M. Parate; S. Tajane; B. Indi","Dept of Electrical Engg., VJTI, Mumbai, India","2016 IEEE International Conference on Engineering and Technology (ICETECH)","20160919","2016","","","1083","1088","The smart grid is an electrical grid that has a duplex communication. This communication is between the utility and the consumer. Digital system, automation system, computers and control are the various systems of Smart Grid. It finds applications in a wide variety of systems. Some of its applications have been designed to reduce the risk of power system blackout. Dynamic vulnerability assessment is done to identify, quantify, and prioritize the vulnerabilities in a system. This paper presents a novel approach for classifying the data into one of the two classes called vulnerable or non-vulnerable by carrying out Dynamic Vulnerability Assessment (DVA) based on some data mining techniques such as Multichannel Singular Spectrum Analysis (MSSA), and Principal Component Analysis (PCA), and a machine learning tool such as Support Vector Machine Classifier (SVM-C) with learning algorithms that can analyze data. The developed methodology is tested in the IEEE 57 bus, where the cause of vulnerability is transient instability. The results show that data mining tools can effectively analyze the patterns of the electric signals, and SVM-C can use those patterns for analyzing the system data as vulnerable or non-vulnerable and determines System Vulnerability Status.","","","10.1109/ICETECH.2016.7569416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569416","DVA;Data Mining;ICT;MSSA;Machine Learning;PCA;Pattern Recognition;Power System Blackout;SVM;Security;Smart Grids;TSA","Pattern recognition;Power system dynamics;Power system stability;Principal component analysis;Smart grids;Spectral analysis;Voltage measurement","data analysis;data mining;learning (artificial intelligence);pattern classification;power engineering computing;power system reliability;power system transient stability;principal component analysis;smart power grids","DVA;IEEE 57 bus;MSSA;PCA;SVM-C;automation system;data classification;data mining tools;digital system;duplex communication;dynamic vulnerability assessment;electric signals;electrical grid;machine learning tool;multichannel singular spectrum analysis;power system blackout;principal component analysis;smart grid applications;system vulnerability assessment","","","","","","","17-18 March 2016","","IEEE","IEEE Conference Publications"
"Research on torque optimization of the spherical motor based on SVM","L. Ju; Z. Qian; G. Li; R. Zhou","National Engineering Laboratory of Energy-Saving Motor & Control Technology, Hefei, 230601, China","2016 IEEE 11th Conference on Industrial Electronics and Applications (ICIEA)","20161024","2016","","","1786","1790","The magnetic torque model of the permanent magnet spherical motor is established by analyzing the finite element model of it in this paper. Then a support vector machine (SVM) model for the permanent magnet spherical motor is established based on machine learning algorithm. Finally, the optimal parameters of the permanent magnet spherical motor are calculated by using the simulated annealing algorithm and the SVM model which are validated by using the finite element method.","","","10.1109/ICIEA.2016.7603876","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7603876","SVM;machine learning;optimization;permanent magnet spherical motor;simulated annealing algorithm;torque","Nickel;Optimization;Permanent magnet motors;Permanent magnets;Stators;Support vector machines;Torque","finite element analysis;learning (artificial intelligence);permanent magnet motors;simulated annealing;support vector machines;torque","SVM model;finite element model;machine learning algorithm;magnetic torque model;permanent magnet spherical motor;simulated annealing algorithm;support vector machine;torque optimization","","","","","","","5-7 June 2016","","IEEE","IEEE Conference Publications"
"Streaming data classification","P. V. S. Annapoorna; T. T. Mirnalinee","Department of CSE, SSN College of Engineering, Chennai, India","2016 International Conference on Recent Trends in Information Technology (ICRTIT)","20160919","2016","","","1","7","In the evolving technology of big data, high velocity data streams play a vital role since pattern of data is being changed over time. The temporal pattern change in data stream leads to a concept evolution called concept drift where statistical properties of data differs from time to time and the drift is taken into account in order to update old and outdated classifier and make it adaptable to new data arrival and pattern change over. In order to classify the stream data, a scalable efficient classification algorithm is to be designed which perfectly classifies the data with minimizing misclassification rate in presence of concept drift due to high velocity data. Training time of the classifier must be reduced in order to reduce computational complexity. In this work, a novel algorithm has been implemented using Random Forest with stratified random sampling and Bloom filtering in order to reduce the training time and to handle high velocity data. Experimental results are shown by performing classification with sampling, classification with filtering and classification with sampling and filtering. This enhances the performance of the algorithm by decreasing the training time and testing time of the classifier with negligible compromise in accuracy of classification.","","","10.1109/ICRTIT.2016.7569525","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569525","Concept drift;Incremental learning;Machine learning;Model ensembles;Streaming data","Classification algorithms;Data mining;Data models;Decision trees;Filtering;Predictive models;Training","Big Data;data structures;learning (artificial intelligence);pattern classification;random processes;sampling methods","Big Data;Bloom filtering;computational complexity;high velocity data handling;high velocity data streams;misclassification rate minimization;random forest;stratified random sampling;streaming data classification;temporal pattern;training time","","","","","","","8-9 April 2016","","IEEE","IEEE Conference Publications"
"A collaborative filtering recommender system with randomized learning rate and regularized parameter","M. V. V. R. Murali Krishna Rao","ASTROSAT Payload Operation Centre, Computer Centre, IUCAA, Pune, India","2016 IEEE International Conference on Current Trends in Advanced Computing (ICCTAC)","20160915","2016","","","1","5","Recommender systems with the approach of collaborative filtering by using the algorithms of machine learning gives better optimized results. But selecting the appropriate learning rate and regularized parameter is not an easy task. RMSE changes from one set of these values to others. The best set of these parameters has to be selected so that the RMSE must be optimized. In this paper we proposed a method to resolve this problem. Our proposed system selects appropriate learning rate and regularized parameter for given data.","","","10.1109/ICCTAC.2016.7567331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7567331","Collaborative Filtering;Learning Rate;Machine Learning;RMSE;Recommender Systems;Regularized Parameter","Collaboration;Conferences;Data mining;Knowledge based systems;Matrix decomposition;Recommender systems","collaborative filtering;learning (artificial intelligence);recommender systems","RMSE;appropriate learning rate;collaborative filtering recommender system;machine learning algorithms;randomized learning rate;regularized parameter","","","","","","","10-11 March 2016","","IEEE","IEEE Conference Publications"
"Wearable Environmental Sensors and Infrastructure for Mobile Large-Scale Urban Deployment","E. Wilhelm; S. Siby; Y. Zhou; X. J. S. Ashok; M. Jayasuriya; S. Foong; J. Kee; K. L. Wood; N. O. Tippenhauer","Singapore University of Technology and Design, Singapore","IEEE Sensors Journal","20161018","2016","16","22","8111","8123","We present a platform to allow up to 50000 students to simultaneously collect and learn from their personal activity, transportation, and environmental data. The main goals that we met during the design of our sensor platform were to: be low cost; remain powered for the duration of the data collection campaign; robustly sense a wide range of environmental parameters; and be packaged in a form factor conducive to wide-spread adoption and ease of use. We describe and generalize the design methods we applied on the hardware and firmware. Our sensors employ Wi-Fi communication to move data as well as to localize themselves using a radio-map of Singapore. Our system uses embedded as well as server-based machine learning algorithms to perform on-sensor transportation mode identification and state inference. The testing and validation methods that we applied ensured that over 98% of the deployed sensors successfully met all of their design goals. In addition, we summarize the results of a large-scale deployment of our system for a nation-wide experiment in Singapore in 2015, and describe three sample applications of the collected data. We publish sample data sets and algorithm code for researchers to analyze.","1530-437X;1530437X","","10.1109/JSEN.2016.2603158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552514","Internet of things;engineering education;machine learning;state estimation;wearable sensors","Hardware;IEEE 802.11 Standard;Sensor systems;Temperature sensors;Testing;Wireless sensor networks","computerised instrumentation;inference mechanisms;learning (artificial intelligence);pollution measurement;sensors;wireless LAN","Singapore;Wi-Fi communication;data collection campaign;mobile large-scale urban deployment;on-sensor transportation mode identification;radio-map;server-based machine learning algorithm;state inference;wearable environmental sensor","","","","","","20160825","Nov.15, 2016","","IEEE","IEEE Journals & Magazines"
"Automated content based short text classification for filtering undesired posts on Facebook","A. S. Vairagade; R. A. Fadnavis","Dept. of Information Technology, Yeshwantrao Chavan College of Engineering, Nagpur, India","2016 World Conference on Futuristic Trends in Research and Innovation for Social Welfare (Startup Conclave)","20161006","2016","","","1","5","Online Social Networking (OSN) sites are always helpful for being socialized and to get exposed to a social environment. But, privacy and prevention of undesired posts on user wall is the only problem of biggest concern. User should have the ability to control the message posted on their own private wall to avoid undesirable contents to be displayed. The existing OSN sites have very little support regarding this problem. For example, Facebook filters messages on the basis of identity of sender i.e. only friend, friend of friend or group of friends can post any message; no content based preferences are supported. Taking this fact into consideration, the proposed work contributes to address such problem through a machine learning based soft classifier for labeling messages in support of contents of message. This work experimentally evaluates an automated scheme to filter out unwanted messages posted on Facebook walls by assigning a set of categories with each short text message based on its contents.","","","10.1109/STARTUP.2016.7583984","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583984","Content based classification;Machine Learning;OSN;Online Social Networking sites;Short Text Classifier;facebook wall;user profile;wall posts","Facebook;Filtering;Market research;Technological innovation;Text categorization;Web pages","data privacy;pattern classification;social networking (online);text analysis","Facebook walls;OSN sites;automated content based short text classification;machine learning;online social networking;short text message;social environment;soft classifier;undesirable contents;undesired post filtering;unwanted messages","","","","","","","Feb. 29 2016-March 1 2016","","IEEE","IEEE Conference Publications"
"An Incremental Framework for Video-Based Traffic Sign Detection, Tracking, and Recognition","Y. Yuan; Z. Xiong; Q. Wang","School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi'an 710072, China.","IEEE Transactions on Intelligent Transportation Systems","","2016","PP","99","1","12","Video-based traffic sign detection, tracking, and recognition is one of the important components for the intelligent transport systems. Extensive research has shown that pretty good performance can be obtained on public data sets by various state-of-the-art approaches, especially the deep learning methods. However, deep learning methods require extensive computing resources. In addition, these approaches mostly concentrate on single image detection and recognition task, which is not applicable in real-world applications. Different from previous research, we introduce a unified incremental computational framework for traffic sign detection, tracking, and recognition task using the mono-camera mounted on a moving vehicle under non-stationary environments. The main contributions of this paper are threefold: 1) to enhance detection performance by utilizing the contextual information, this paper innovatively utilizes the spatial distribution prior of the traffic signs; 2) to improve the tracking performance and localization accuracy under non-stationary environments, a new efficient incremental framework containing off-line detector, online detector, and motion model predictor together is designed for traffic sign detection and tracking simultaneously; and 3) to get a more stable classification output, a scale-based intra-frame fusion method is proposed. We evaluate our method on two public data sets and the performance has shown that the proposed system can obtain results comparable with the deep learning method with less computing resource in a near-real-time manner.","1524-9050;15249050","","10.1109/TITS.2016.2614548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7605450","ITS.;Machine learning;detection;incremental learning;recognition;tracking;traffic sign","Color;Detectors;Image color analysis;Machine learning;Shape;Target tracking","","","","","","","","20161021","","","IEEE","IEEE Early Access Articles"
"On the Trade-Off between Multi-level Security Classification Accuracy and Training Time","P. Engelstad","Oslo & Akershus Univ. Coll. of Appl. Sci., Oslo, Norway","2015 3rd International Conference on Artificial Intelligence, Modelling and Simulation (AIMS)","20161024","2015","","","349","355","Automatic security classification is a new research area about to emerge. It utilizes machine learning to assist humans in their manual classification. In this paper, we investigate the importance of the training time of the machine learner. To the best of our knowledge, this has not been analyzed in previous works. We compare various machine learning methods, including SVM, LASSO and the ensemble methods Adaboosting and Adabagging, with respect to their performance. The paper demonstrates that the computational cost of a method is an important part of its performance metric.","","","10.1109/AIMS.2015.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7604600","Multi-level security;classification;machine learning","Aging;Learning systems;Measurement;Security;Support vector machines;Training","learning (artificial intelligence);pattern classification;security of data;support vector machines","Adabagging;Adaboosting;LASSO;SVM;automatic security classification;machine learner training time;machine learning;manual classification;multilevel security classification;performance metric","","","","","","","2-4 Dec. 2015","","IEEE","IEEE Conference Publications"
