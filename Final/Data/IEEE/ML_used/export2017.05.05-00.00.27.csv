"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7738900,7738864,7738886,7738848,7738897,7738888,7738850,7738812,7738855,7738904,7738908,7738858,7738861,7738872,7738810,7738835,7738831,7738818,7738869,7738842,7738883,7738827,7738876,7738822,7738891,7738845,7738894,7738902,7738863,7738885,7738847,7738896,7738865,7738849,7738909,7738859,7738811,7738832,7738870,7738828,7738877,7738854,7738903,7738815,7738907,7738866,7738910,7738860,7738829,7738816,7738809,7738867,7738834,7738817,7738868,7528402,7528397,7471082,7471095,7471043,7470981,7470480,7471031,7471002,7471086,7471055,7474316,7471040,7471091,7470994,7424424,7424462,7424379,7424322,7424427,7424284,7424408,7424378,7424486,7424400,7424313,7424456,7424464,7424393,7424348,7424289,7424423,7424444,7424332,7424345,7424354,7424350,7424319,7424386,7424326,7424479,7424293,7424356,7424489,7424371",2017/05/05 00:00:27
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Deep Neural Networks: A Case Study for Music Genre Classification","A. R. Rajanna; K. Aryafar; A. Shokoufandeh; R. Ptucha","Electr. Eng. Dept., Rochester Inst. of Technol., Rochester, NY, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","655","660","Music classification is a challenging problem with many applications in today's large-scale datasets with Gigabytes of music files and associated metadata and online streaming services. Recent success with deep neural network architectures on large-scale datasets has inspired numerous studies in the machine learning community for various pattern recognition and classification tasks such as automatic speech recognition, natural language processing, audio classification and computer vision. In this paper, we explore a two-layer neural network with manifold learning techniques for music genre classification. We compare the classification accuracy rate of deep neural networks with a set of well-known learning models including support vector machines (SVM and '1-SVM), logistic regression and '1-regression in combination with hand-crafted audio features for a genre classification task on a public dataset. Our experimental results show that neural networks are comparable with classic learning models when the data is represented in a rich feature space.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424393","","Feature extraction;Manifolds;Mel frequency cepstral coefficient;Music;Neural networks;Spectrogram;Support vector machines","learning (artificial intelligence);music;neural nets;pattern classification","associated metadata;deep neural network architectures;deep neural networks;machine learning community;manifold learning;music files;music genre classification;online streaming services;pattern recognition task;two-layer neural network","","","","46","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Sparse Markowitz Portfolios","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","Modern portfolio theory originated from the work of Markowitz, who insisted on the fact that returns should be balanced with risk and established the theoretical basis for portfolio optimization according to this principle. Sparse Markowitz portfolios impose an additional requirement of sparsity to the objectives of risk and expected return in traditional Markowitz portfolios. This chapter overviews the Markowitz portfolio formulation and describes its fragility in high-dimensional settings. It argues that sparsity of the portfolio can alleviate many of the shortcomings, and presents an optimization formulation based on convex relaxations. The chapter then introduces sparse portfolio rebalancing and optimal forecast combination. The sparse portfolio methodology has been validated by an empirical exercise. The aim of the empirical exercise was rather to assess the validity of the investment strategy, as it would be carried out by different investors using the same methodology in different years.","","97811187455","10.1002/9781118745540.ch2","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471043.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"An Application of Neural Networks to Predicting Mastery of Learning Outcomes in the Treatment of Autism Spectrum Disorder","E. Linstead; R. German; D. Dixon; D. Granpeesheh; M. Novack; A. Powell","Schmid Coll. of Sci. & Technol., Chapman Univ., Orange, CA, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","414","418","We apply artificial neural networks to the task of predicting the mastery of learning outcomes in response to behavioral therapy for children diagnosed with autism spectrum disorder. We report results for a sample size of 726 children, the largest sample size reported for a study of this nature to date. Our results show that neural networks substantially outperform the linear regression models reported in previous studies, and demonstrate the benefits of leveraging more sophisticated machine learning techniques in the autism research domain.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424348","autism spectrum disorder;machine learning;neural networks","Autism;Data models;Linear regression;Neural networks;Pediatrics;Training","learning (artificial intelligence);medical disorders;neural nets;patient treatment;regression analysis","artificial neural network;autism research domain;autism spectrum disorder treatment;behavioral therapy;linear regression model;sophisticated machine learning technique","","1","","18","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Mean-Reverting Portfolios","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","Mean-reverting assets, namely assets whose price oscillates predictably around a long-term mean, provide investors with an ideal investment opportunity. Statistical arbitrage strategies attempt to find portfolios that exhibit mean reversion. This chapter shows that the semidefinite programs (SDP) can handle sparsity and volatility constraints while still aiming at mean reversion. A common econometric tool to find mean reverting portfolios is based on co-integration. The chapter examines the problem of estimating baskets that have maximal mean reversion, while being at the same time sufficiently volatile and supported by as few assets as possible. It presents numerical evidence that taking into account sparsity and volatility can significantly boost the performance of mean-reverting trading strategies in trading environments where trading costs are not negligible. The chapter also shows that, under realistic trading costs assumptions, selecting sparse and volatile mean-reverting baskets translates into lower incurred costs and thus improves the performance of trading strategies.","","97811187455","10.1002/9781118745540.ch3","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7470981.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Multi-label Classification of Anemia Patients","C. Bellinger; A. Amid; N. Japkowicz; H. Victor","Sch. of Comput. Eng. & Electr. Eng., Univ. of Ottawa, Ottawa, ON, Canada","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","825","830","This work examines the application of machine learning to an important area of medicine which aims to diagnose paediatric patients with β-thalassemia minor, iron deficiency anemia or the co-occurrence of these ailments. Iron deficiency anemia is a major cause of microcytic anemia and is considered an important task in global health. Whilst existing methods, based on linear equations, are proficient at distinguishing between the two classes of anemia, they fail to identify the co-occurrence of this issues. Machine learning algorithms, however, can induce non-linear decision boundaries that enable accurate classification within complex domains. Through a multi-label classification technique, known as problem transformations, we convert the learning task to one that is appropriate for machine learning and examine the effectiveness of machine learning algorithms on this domain. Our results show that machine learning classifiers produce good overall accuracy and are able to identify instances of the co-occurrence class unlike the existing methods.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424424","Multi-label classification;anaemia;biomedical informatics;class imbalance","Complexity theory;Electronic mail;Iron;Machine learning algorithms;Principal component analysis;Reactive power;Standards","iron;medical computing;patient diagnosis;pattern classification","β-thalassemia minor;ailment co-occurrence;global health;iron deficiency anemia;linear equations;machine learning algorithms;machine learning application;machine learning classifiers;microcytic anemia;multilabel classification technique;nonlinear decision boundaries;paediatric patient diagnosis;problem transformations","","","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Superposed Naive Bayes for Accurate and Interpretable Prediction","T. Mori","IoT Technol. Center, TOSHIBA Corp., Kawasaki, Japan","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1228","1233","Background: Data mining and machine learning techniques have been widely applied in software engineering research. However, past research has mainly focused on only prediction accuracy. Aim: The interpretability of prediction results should be accorded greater emphasis in software engineering research. A prediction model that has high accuracy and explanatory power is required. Method: We propose a new algorithm of naïve Bayes ensemble, called superposed naïve Bayes (SNB), which firstly builds an ensemble model with high prediction accuracy and then transforms it into an interpretable naïve Bayes model. Results: We conducted an experiment with the NASA MDP datasets, in which the performance and interpretability of the proposed method were compared with those of other classification techniques. The results of the experiment indicate that the proposed method can produce balanced outputs that satisfy both performance and interpretability criteria. Conclusion: We confirmed the effectiveness of the proposed method in an experiment using software defect data. The model can be extensively applied to other application areas, where both performance and interpretability are required.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.147","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424489","bagging;boosting;ensemble method;interpretability;model transformatiomn;naive Bayes classifier;performance","Bagging;Boosting;Classification algorithms;Decision trees;Logistics;Predictive models;Software engineering","Bayes methods;data mining;learning (artificial intelligence);pattern classification;software reliability","Data mining;NASA MDP datasets;classification techniques;machine learning techniques;naïve Bayes ensemble;prediction accuracy;prediction interpretability;software defect data;software engineering research;superposed naïve Bayes model","","","","31","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Utilizing Ensemble, Data Sampling and Feature Selection Techniques for Improving Classification Performance on Tweet Sentiment Data","J. Prusa; T. M. Khoshgoftaar; A. Napolitano","Florida Atlantic Univ., Boca Raton, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","535","542","Sentiment analysis of tweets is a popular method of opinion mining social media. Many machine learning techniques exist that can improve the performance of classifiers trained to determine the sentiment or emotional polarity of a tweet, however, they are designed with different objectives and it is unclear which techniques are most beneficial. Additionally, these techniques may behave differently depending on quality of data issues, such as class imbalance, a common problem when using real world data. In an effort to determine which techniques are more important, we tested 12 techniques consisting of: eight feature selection techniques, bagging, boosting and data sampling with two post sampling class ratios. Using five base learners, we compare these techniques against each other and each base learners with no additional technique. We train and test each classifier on a balanced dataset and two imbalanced datasets with different class ratios. Additionally, we conduct statistical tests to determine if the differences observed between techniques are significant. Our results show that bagging and seven of the eight feature selection techniques significantly improve performance (compared to using no technique) on all three datasets, while boosting and data sampling are less beneficial for imbalanced tweet sentiment data. To the best of our knowledge, this is the first study comparing these three types of techniques on tweet sentiment data and the first to show that feature selection and ensemble techniques perform better than data sampling on tweet sentiment data.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424371","Bagging;Boosting;Classification;Feature Selection;Random Undersampling;Sentiment Analysis;Tweet Mining","Bagging;Boosting;Data mining;Robustness;Support vector machines;Training;Training data","data mining;feature selection;learning (artificial intelligence);sentiment analysis;social networking (online);statistical testing","bagging;data sampling technique;emotional polarity;feature selection technique;imbalanced tweet sentiment data;machine learning technique;opinion mining social media;sentiment analysis;statistical test;tweet sentiment data","","","","25","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Temporal Causal Modeling","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","Discovering causal relationships in multivariate time series data has important applications in finance. This chapter discusses temporal causal modeling (TCM), an approach that generalizes the notion of Granger causality to multivariate time series by linking the causality inference process to the estimation of sparse vector autoregressive (VAR) models. It extends TCM to identify regime changes by combining it with a Markov switching modeling framework. The chapter describes a Bayesian Markov switching model for estimating sparse dynamic Bayesian networks (MS-SDBN). The chapter defines the notion of causal strength for each causal relationship discovered when applying the group orthogonal patching pursuit algorithm (OMP) method to TCM. Causal strength is a concept that tells information about the significance of a causal relationship. The chapter also describes a computationally efficient methodology to model the time-varying dependency structure underlying multivariate time-series data, with a particular focus on regime change identification.","","97811187455","10.1002/9781118745540.ch4","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7470480.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"A Study of the Use of Complexity Measures in the Similarity Search Process Adopted by kNN Algorithm for Time Series Prediction","A. R. S. Parmezan; G. E. A. P. A. Batista","Inst. de Cienc. Matemeticas e de Comput., Univ. de Sao Paulo, Sao Carlos, Brazil","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","45","51","In the last two decades, with the rise of the Data Mining process, there is an increasing interest in the adaptation of Machine Learning methods to support Time Series non-parametric modeling and prediction. The non-parametric temporal data modeling can be performed according to local and global approaches. The most of the local prediction data strategies are based on the k-Nearest Neighbor (kNN) learning method. In this paper we propose a modification of the kNN algorithm for Time Series prediction. Our proposal differs from the literature by incorporating three techniques for obtaining amplitude and offset invariance, complexity invariance, and treatment of trivial matches. We evaluate the proposed method with six complexity measures, in order to verify the impact of these measures in the projection of the future values. Besides, we face our method with two Machine Learning regression algorithms. The experimental comparisons were performed using 55 data sets, which are available at the ICMC-USP Time Series Prediction Repository. Our results indicate that the developed method is competitive and the use of a complexity-invariant distance measure generally improves the predictive performance.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424284","Data Mining;Machine Learning;Similarity-Based Methods;Time Series Prediction","Complexity theory;Data models;Heuristic algorithms;Prediction algorithms;Predictive models;Shape;Time series analysis","data mining;learning (artificial intelligence);pattern classification;prediction theory;regression analysis;search problems;time series","amplitude;complexity invariance;complexity measures;data mining process;k-nearest neighbor learning method;kNN algorithm;kNN learning method;local prediction data strategies;machine learning methods;machine learning regression algorithms;nonparametric temporal data modeling;offset invariance;similarity search process;time series nonparametric modeling;time series prediction","","","","18","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Finite Gamma Mixture Model-Based Discriminative Learning Frameworks","F. R. Al-Osaim; N. Bouguila","Deptartment of Comput. Eng., Umm Al-Qura Univ., Makkah, Saudi Arabia","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","819","824","It is well-known that classification tasks can be approached using either generative models or discriminative ones. While the goal of generative approaches is to learn class-conditional densities, the main goal of discriminative techniques is to learn decision boundaries directly without taking into account class-conditional densities. In classic supervised learning, we would usually represent a given object (an image, for instance) by a vector of D real-valued features and then select a given generative or discriminative approach to perform classification. In many applications, however, the object can be represented by a set (or) bag of vectors. Recent developments in machine learning, along with powerful computational tools, have enabled researchers to develop more sophisticated models to handle such applications using the so-called hybrid generative discriminative models. The main idea is based on exploiting the advantages of both families of models. Thus, the success of such an approach depends on the choice of an appropriate discriminative technique and a suitable generative one. The goal of this paper is to develop a hybrid generative discriminative framework based on support vector machine and Gamma mixture. In particular, we focus on the generation of kernels when examples (images, for instance) are structured data (i.e. described by sets of vectors) modeled by Gamma mixtures. Experimental results on real-world challenging applications, namely 3D shape class recognition, object categorization, and video event analysis, show the effectiveness of the proposed framework.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424423","3D shapes;Gamma distribution;Mixture models;SVM;generative learning;object recognition;video event","Computational modeling;Kernel;Mixture models;Shape;Support vector machines;Three-dimensional displays","image classification;learning (artificial intelligence);mixture models;object recognition;support vector machines;video signal processing","3D shape class recognition;bag of vectors;class-conditional densities;decision boundaries;finite gamma mixture model-based discriminative learning frameworks;hybrid generative discriminative model;kernel generation;machine learning;object categorization;real-valued features;structured data;support vector machine;video event analysis","","","","24","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Effective User Authentications Using Keystroke Dynamics Based on Feature Selections","A. Darabseh; A. S. Namin","Dept. of Comput. Sci., Texas Tech Univ. Lubbock, Lubbock, TX, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","307","312","Efficient keystroke authentication systems should have the ability to capture and build the user's pattern in minimal time. These systems also should be able to achieve quickest detection while maintaining good detection accuracy. However, maintaining high detection accuracy and minimal detection delay are conflicting requirements that need to be balanced. A possible approach to tackle this problem is reducing the number of features that need to be learned by a classifier and thereby decreasing the processing time. A wrapper based feature subset selection approach is presented in this paper with the objective of reducing the dimensionality of the user data through identifying a smaller subset of features that represent the most discriminating features in keystrokes dynamic. Several features selection techniques such as genetic and greedy algorithms, best first search Algorithms, and Particle Swarm Optimization (PSO) are used to search for the best subset features. These selection techniques are integrated (Wrapped) with different machine learning classifiers namely Support Vector Machine (SVM), Naive Bayesian (NB), and K Nearest Neighbors (KNN) for feature subset selection procedure that can automatically select the most appropriate and representative subset of features.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.90","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424326","Authentication;Biometrics;Keystroke Dynamics;Keystroke Feature;Security","Authentication;Classification algorithms;Feature extraction;Filtering algorithms;Genetic algorithms;Kernel;Support vector machines","Bayes methods;authorisation;feature selection;genetic algorithms;greedy algorithms;learning (artificial intelligence);particle swarm optimisation;pattern classification;support vector machines;user interfaces","K nearest neighbors;KNN;NB;PSO;SVM;features selection techniques;first search algorithms;genetic algorithms;greedy algorithms;keystroke authentication systems;keystroke dynamics;machine learning classifiers;naive Bayesian;particle swarm optimization;quickest detection;support vector machine;user authentications;user pattern","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Deep learning architectures for tattoo detection and de-identification","T. Hrkać; K. Brkić; S. Ribarić; D. Marčetić","University of Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia","2016 First International Workshop on Sensing, Processing and Learning for Intelligent Machines (SPLINE)","20160804","2016","","","1","5","The widespread use of video recording devices to obtain recordings of people in various scenarios makes the problem of privacy protection increasingly important. Consequently, there is an increased interest in developing methods for de-identification, i.e. removing personally identifying features from publicly available or stored data. Most of related work focuses on de-identifying hard biometric identifiers such as faces. We address the problem of detection and de-identification of soft biometric identifiers - tattoos. We use a deep convolutional neural network to discriminate between tattoo and non-tattoo image patches, group the patches into blobs, and propose the de-identifying method based on replacing the color of pixels inside the tattoo blob area with a values obtained by interpolation of the surrounding skin color. Experimental evaluation on the contributed dataset indicates the proposed method can be useful in a soft biometric de-identification scenario.","","Electronic:978-1-4673-8917-4; POD:978-1-4673-8918-1; USB:978-1-4673-8916-7","10.1109/SPLIM.2016.7528402","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528402","","Image color analysis;Interpolation;Machine learning;Neural networks;Shape;Skin;Training","biometrics (access control);convolution;image colour analysis;interpolation;learning (artificial intelligence);neural nets;object detection","deep convolutional neural network;deep learning architectures;interpolation;nontattoo image patches;personally identifying features;pixel color;privacy protection;skin color;soft biometric deidentification;soft biometric identifiers;tattoo deidentification;tattoo detection;tattoo image patches;video recording devices","","","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"Front Matter","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","The prelims comprise: <br> Half-Title Page <br> Title Page <br> Copyright Page <br> Table of Contents <br> List of Contributors <br> Preface","","97811187455","10.1002/9781118745540.fmatter","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471031.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Unsupervised representation learning of structured radio communication signals","T. J. O'Shea; J. Corgan; T. C. Clancy","Bradley Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA","2016 First International Workshop on Sensing, Processing and Learning for Intelligent Machines (SPLINE)","20160804","2016","","","1","5","We explore unsupervised representation learning of radio communication signals in raw sampled time series representation. We demonstrate that we can learn modulation basis functions using convolutional autoencoders and visually recognize their relationship to the analytic bases used in digital communications. We also propose and evaluate quantitative metrics for quality of encoding using domain relevant performance metrics.","","Electronic:978-1-4673-8917-4; POD:978-1-4673-8918-1; USB:978-1-4673-8916-7","10.1109/SPLIM.2016.7528397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7528397","Cognitive Radio;Convolutional Autoencoders;Deep Learning;Machine Learning;Neural Networks;Radio communications;Software Radio","Convolution;Convolutional codes;Encoding;Frequency shift keying;Phase shift keying","convolution;encoding;radio networks;telecommunication computing;time series;unsupervised learning","convolutional autoencoders;digital communications;domain relevant performance metrics;modulation basis functions;raw sampled time series representation;structured radio communication signals;unsupervised representation learning","","","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"Low dimensional subspace finding via size-reducing dictionary learning","B. Dumitrescu; P. Irofti","Department of Automatic Control and Computers, University Politehnica of Bucharest, 313 Spl. Independen&#x0163;ei, 060042 Bucharest, Romania","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We present a dictionary learning algorithm that aims to reduce the size of the dictionary to a parsimonious value during the learning process. The sparse coding step uses a weighted Orthogonal Matching Pursuit favoring atoms that enter more representations. The dictionary update step optimizes a regularized error, encouraging the apparition of zero rows in the representation matrix; the corresponding unused atoms are eliminated. The algorithm is extended to the case of incomplete data. Besides dictionary learning, the algorithm is also shown to be useful for finding low-dimensional subspaces. Such versatility is a feature with little precedent. Numerical examples show good convergence properties.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738900","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738900","dictionary learning;low-rank representation;sparse representation","Complexity theory;Dictionaries;Encoding;Matching pursuit algorithms;Signal processing algorithms;Sparse matrices;Standards","convergence of numerical methods;data handling;iterative methods;learning (artificial intelligence);matrix algebra","convergence properties;dictionary update step;low-dimensional subspaces;parsimonious value;regularized error;representation matrix;size-reducing dictionary learning;weighted orthogonal matching pursuit","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Intelligent Bus Stop Identification Using Smartphone Sensors","K. Srinivasan; K. Kalpakis","Dept. of Comput. Sci. & Electr. Eng., Univ. of Maryland Baltimore County, Baltimore, MD, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","954","959","Intelligent transportation systems can be built by developing models that learn from the collected transport data. Data collection and implementation of such systems is often costly, and few countries have support for such systems in their transportation budgets. In places where maintaining currency and accuracy of information is difficult, many problems arise. For instance, in Chennai, India, real time bus transit data is not maintained, there is no proper communication about the bus schedules, bus stops are not regularly updated and inconsistent information about bus stops is observed in the transport authority's website. We are interested in developing models for identifying bus stops from trajectories for situations where accurate and current information is not available and traffic conditions are challenging, such as Chennai, India. We develop a simple yet easily accessible Android mobile application (App) to collect GPS traces of bus routes. We use our App to collect GPS trajectory data from Baltimore, Maryland, a place where there are facilities to access up-to-date information about bus stops. We also collect GPS trajectories from Chennai, India. We then develop a model using machine learning techniques to identify bus stops from the collected trajectories. We experimentally evaluate our model by training it on the Baltimore dataset and testing it on the Chennai dataset, achieving testing accuracy between 85 -- 90%. This is comparable to the accuracy of 95% achieved by both training and testing on the Chennai dataset. This illustrates that our approach is effective in helping maintain an accurate and current transport information system for resource constraint environments.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.209","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424444","Bus Transportation;GPS;Intelligent systems;Machine Learning;Sensors","Cities and towns;Feature extraction;Global Positioning System;Magnetic sensors;Trajectory;Vehicles","Android (operating system);Global Positioning System;intelligent transportation systems;learning (artificial intelligence);mobile computing","Android mobile application;Baltimore;Chennai;GPS trajectory data;India;Maryland;bus route GPS traces;bus schedules;bus stops;intelligent bus stop identification;intelligent transportation systems;machine learning techniques;smartphone sensors","","","","11","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Variance reduction for optimization in speech recognition","J. T. Chien; P. W. Huang","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Deep neural network (DNN) is trained according to a mini-batch optimization based on the stochastic gradient descent algorithm. Such a stochastic learning suffers from instability in parameter updating and may easily trap into local optimum. This study deals with the stability of stochastic learning by reducing the variance of gradients in optimization procedure. We upgrade the optimization from the stochastic dual coordinated ascent (SDCA) to the accelerated SDCA without duality (or dual-free ASDCA). This optimization incorporates the momentum method to accelerate the updating rule where the variance of gradients can be reduced. Using dual-free ASDCA, the optimization of dual function of SDCA in a form of convex loss is implemented by directly optimizing the primal function with respect to pseudo-dual parameters. The non-convex optimization in DNN training can be resolved and accelerated. Experimental results illustrate the reduction of training loss, variance of gradients and word error rate by using the proposed optimization for DNN speech recognition.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738864","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738864","Optimization algorithm;deep neural network;speech recognition;variance reduction","Acceleration;Convergence;Hidden Markov models;Optimization;Speech recognition;Stochastic processes;Training","gradient methods;learning (artificial intelligence);neural nets;optimisation;speech recognition;stochastic processes","DNN;SDCA;deep neural network;optimization algorithm;speech recognition;stochastic dual coordinated ascent;stochastic gradient descent algorithm;stochastic learning;variance reduction","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"ITEM2VEC: Neural item embedding for collaborative filtering","O. Barkan; N. Koenigstein","Tel Aviv University","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Many Collaborative Filtering (CF) algorithms are item-based in the sense that they analyze item-item relations in order to produce item similarities. Recently, several works in the field of Natural Language Processing (NLP) suggested to learn a latent representation of words using neural embedding algorithms. Among them, the Skip-gram with Negative Sampling (SGNS), also known as word2vec, was shown to provide state-of-the-art results on various linguistics tasks. In this paper, we show that item-based CF can be cast in the same framework of neural word embedding. Inspired by SGNS, we describe a method we name item2vec for item-based CF that produces embedding for items in a latent space. The method is capable of inferring item-item relations even when user information is not available. We present experimental results that demonstrate the effectiveness of the item2vec method and show it is competitive with SVD.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738886","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738886","collaborative filtering;item recommendations;item similarity;item-item collaborative filtering;market basket analysis;neural word embedding;recommender systems;skip-gram;word2vec","Collaboration;Context;Filtering;Hip;Metadata;Rocks;Signal processing algorithms","collaborative filtering;learning (artificial intelligence);natural language processing;neural nets","NLP;SGNS;collaborative filtering;item similarity;item-item relation inference;item2vec method;latent space;learning;linguistic task;natural language processing;neural embedding algorithm;neural item embedding;neural word embedding;skip-gram with negative sampling;word latent representation;word2vec","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Score-matching estimators for continuous-time point-process regression models","M. Sahani; G. Bohner; A. Meyer","University College London, Gatsby Computational Neuroscience Unit, 25 Howland Street, London W1T 4JG","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","5","We introduce a new class of efficient estimators based on score matching for probabilistic point process models. Unlike discretised likelihood-based estimators, score matching estimators operate on continuous-time data, with computational demands that grow with the number of events rather than with total observation time. Furthermore, estimators for many common regression models can be obtained in closed form, rather than by iteration. This new approach to estimation may thus expand the range of tractable models available for event-based data.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738848","estimation;neural data;point-process;score matching;spike train","Computational modeling;Correlation;Cost function;Data models;Maximum likelihood estimation;Writing","estimation theory;probability;regression analysis","continuous-time data;continuous-time point-process regression models;event-based data;probabilistic point process models;score-matching estimators","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Mixing model in slitless spectroscopy and resulting blind methods for separating galaxy spectra","A. Selloum; S. Hosseini; Y. Deville; T. Contini","IRAP, CNRS, Universit&#x00E9; de Toulouse, UPS-OMP. 14, av. Edouard Belin, 31400 Toulouse, France","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We first derive a mathematical model describing data generated by the spectrograph of the future Euclid space mission. Our model takes into account the special mixing effect resulting from slitless spectroscopy. We then propose two new blind source separation methods, exploiting the non-negativity of data involved in these mixtures and adapted to this special model, to separate the spectra from the mixed data. Our first simulations using realistic and highly noisy data confirm the effectiveness of the proposed methods.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738897","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738897","Astronomy;Blind source separation;Euclid mission;Non-negative matrix factorization (NMF);Slitless spectroscopy;Spectrum decontamination","Adaptation models;Blind source separation;Dispersion;Indexes;Mathematical model;Photonics;Two dimensional displays","astronomy computing;blind source separation;mathematical analysis;spectrometers;spectroscopy","Euclid space mission;blind source separation;galaxy spectra separation;mathematical model;slitless spectroscopy;spectrograph","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Combining clusterings with different detail levels","O. Kaminsky; J. Goldberger","Engineering Faculty, Bar-Ilan University, Israel","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this study we address the problem of recovering a clustering of a dataset based on several clusterings provided by different experts. These experts provide clusterings on different levels (coarser or finer than the others). We present an automatic algorithm that combines the information provided by the experts into a single clustering that can be viewed as the average point of the input clusterings. We formulate the problem as an instance of correlation clustering and apply integer linear programming to obtain the average clustering. As a byproduct, we also obtain for each expert its reliability and the detail level encoded in its clustering. We apply the proposed algorithm to the task of averaging several image segmentations. The average segmentation is efficiently computed by first grouping the image into superpixels and then applying the proposed algorithm on the superpixel map. The performance of the proposed algorithm is demonstrated on manually annotated images from the Berkeley segmentation dataset.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738888","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738888","Ensemble decision;ILP;segmentation","Clustering algorithms;Correlation;Image segmentation;Integer linear programming;Labeling;Reliability;Signal processing algorithms","correlation methods;expert systems;image segmentation;integer programming;linear programming;pattern clustering","correlation clustering;datast clustering;detail level;expert system;image segmentation;integer linear programming;superpixel map","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Proximal gradient-based step for brain distributed epileptic source imaging after tensor decomposition preprocessing","M. Saleh; A. Karfoul; L. Albera; A. Kachenoura; H. Becker; I. Merlet","Faculty of Mechanical and Electrical Engineering, AL-Baath University, Homs, Syria","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Recently, a new two-step tensor-based distributed epileptic source localization method was proposed. Firstly, it performs Canonically Polyiadic (CP) decomposition of a Space-Time-Spike (STS) tensor capturing the occurrence of epileptic events in the ElectroEncephaloGraphic (EEG) data. This with the aim at estimating the spatial map of those distributed sources. Secondly, a source localization step is performed using the well-known Alternating Direction Method of Multipliers (ADMM) algorithm. This paper investigates to what extent this brain epileptic source imaging problem could be properly solved when a proximal gradient-based algorithm, the Proximal Alternating Linearized Minimization (PALM) technique, is used instead of the ADMM when the source localization step is considered. The convergence issue of the PALM scheme in this particular problem is discussed and a link with the one of the ADMM method is established. Furthermore, realistic simulations with epileptic EEG data show the efficiency of the new proposed PALM-based scheme.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738850","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738850","Brain source imaging;PARAFAC;canonical polyadic decomposition;epilepsy;localization of spatially distributed sources;proximal optimization","Brain modeling;Convergence;Data models;Electroencephalography;Imaging;Minimization;Tensile stress","diseases;electroencephalography;gradient methods;matrix decomposition;medical image processing;minimisation;tensors","ADMM algorithm;CP decomposition;PALM;STS tensor;alternating direction method of multipliers;brain distributed epileptic source imaging;brain epileptic source imaging problem;canonically polyiadic decomposition;convergence issue;electroencephalographic data;epileptic EEG data;epileptic event occurrence;proximal alternating linearized minimization;proximal gradient-based algorithm;proximal gradient-based step;source localization step;space-time-spike tensor;spatial map estimation;tensor decomposition preprocessing;two-step tensor-based distributed epileptic source localization","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Explicit Kernel and Sparsity of Eigen Subspace for the AR(1) Process","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","Fast implementation of Karhunen-Loeve Transform (KLT) is of great interest to several disciplines, and there were attempts to derive closed-form kernel expressions for certain classes of stochastic processes. Random processes and information sources are described by stochasticsignal models, including autoregressive (AR), moving average (MA), and autoregressivemoving average (ARMA) types. This chapter focuses on the discrete autoregressive order one, AR(1), and the process and derivation of its explicit eigen kernel. It investigates the sparsity of eigen subspace and presents a rate-distortion theory-based sparsing method. The chapter then focuses on eigen subspace of a discrete AR(1) process with closed-form expressions for its eigenvectors and eigenvalues. It provides a comparative performance of the presented method along with the various methods reported in the literature. Finally, the chapter highlights the merit of the method for the AR(1) process as well as for the empirical correlation matrix of stock returns in the NASDAQ-100 index.","","97811187455","10.1002/9781118745540.ch5","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471002.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Deep Neural Networks with Parallel Autoencoders for Learning Pairwise Relations: Handwritten Digits Subtraction","T. Du; L. Liao","Dept. of Comput. & Inf. Sci., Univ. of Delaware, Newark, DE, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","582","587","Modelling relational data is a common task for many machine learning problems. In this work, we focus on learning pairwise relations between two entities, with deep neural networks. To incorporate the structural properties in the data that represent two entities concatenated together, two separate stacked autoencoders are introduced in parallel to extract individual features, which are then fed into a deep neural network for classification. The method is applied to a specific problem: whether two input handwritten digits differ by one. We tested the performance on a dataset generated from handwritten digits in MNIST, which is a widely used dataset for testing different machine learning techniques and pattern recognition methods. We compared with several different machine learning algorithms, including logistic regression and support vector machines, on this handwritten digit subtraction (HDS) dataset. The results showed that deep neural networks outperformed other methods, and in particular, the deep neural networks fitted with two separate autoencoders in parallel increased the prediction accuracy from 85.83%, which was achieved by a standard neural network with a single stacked autoencoder, to 88.27%.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424379","Deep learning;machine learning;neural networks;parallel autoencoders;relational learning","Biological neural networks;Feature extraction;Kernel;Machine learning;Machine learning algorithms;Support vector machines","handwritten character recognition;image classification;image coding;learning (artificial intelligence);neural nets;regression analysis;relational databases;support vector machines","HDS dataset;MNIST;classification;deep neural networks;handwritten digit subtraction dataset;logistic regression;machine learning techniques;pairwise relation learning;parallel stacked autoencoders;pattern recognition method;relational data modelling;stacked autoencoders;structural properties;support vector machines","","","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Approximate state-space Gaussian processes via spectral transformation","T. Karvonen; S. Sarkkä","Aalto University, Department of Electrical Engineering and Automation, Espoo, Finland","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","State-space representations of Gaussian process regression use Kalman filtering and smoothing theory to downscale the computational complexity of the regression in the number of data points from cubic to linear. As their exact implementation requires the covariance function to possess rational spectral density, rational approximations to the spectral density must be often used. In this article we introduce new spectral transformation based methods for this purpose: a spectral composition method and a spectral preconditioning method. We study convergence of the approximations theoretically and run numerical experiments to attest their accuracy for different densities, in particular the fractional Matern.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738812","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738812","Gaussian process regression;composite approximation;fractional Matérn;spectral preconditioning;state-space approximation","Automation;Computational modeling;Convergence;Electrical engineering;Frequency modulation;Gaussian processes;Taylor series","Gaussian processes;Kalman filters;approximation theory;covariance analysis;regression analysis","Gaussian process regression;Kalman filtering;approximate state-space Gaussian process;computational complexity;covariance function;rational approximation;smoothing theory;spectral composition method;spectral preconditioning method;spectral transformation;state-space representation","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Learning from the Crowd with Neural Network","J. Li; V. S. Sheng; Z. Shu; Y. Cheng; Y. Jin; Y. f. Yan","Dept. of Manage., Wuhan Univ. of Technol. Hubei Univ. of Econ., Wuhan, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","693","698","In general, the first step for supervised learning from crowdsourced data is integration. To obtain training data as traditional machine learning, the ground truth for each example in the crowdsourcing dataset must be integrated with consensus algorithms. However, some information and correlations among labels in the crowdsourcing dataset have discarded after integration. In order to study whether the information and correlations are useful for learning, we proposed three types of neural networks. Experimental results show that i) all the three types of neural networks have abilities to predict labels for future unseen examples, ii) when labelers have lower qualities, the information and correlations in crowdsourcing datasets, which are discarded by integration, does improve the performance of neural networks significantly, iii) when labelers have higher label qualities, the information and correlations have little impact on improving accuracy of neural networks.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424400","crowdsourcing;machine learning;neural network","BiCMOS integrated circuits;Biological neural networks;Correlation;Crowdsourcing;Labeling;Noise measurement","learning (artificial intelligence);neural nets","consensus algorithm;crowdsourced data;machine learning;neural network;supervised learning","","","","21","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Stochastic Volatility","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","Asymptotic methods can be used to analyze and simplify pricing and portfolio optimization problems. Broadly speaking, there are two methods of setting up asymptotic expansions for option pricing and implied volatility. In contract asymptotics, one considers extreme regimes specific to the option contract. In the model asymptotics approach, one views the complicated incomplete market model as a perturbation around a more tractable model, often the Black-Scholes model. This chapter concentrates on model asymptotics as they are adaptable to other option contracts and, moreover, are amenable to nonlinear portfolio optimization problems. Model coefficient polynomial expansions can be used to find closed-form asymptotic approximations for option prices and implied volatilities in a general d-dimensional Markov setting. The chapter focuses on two simple cases, namely general two-dimensional local-stochastic volatility models, and general scalar Levy-type models. It also presents some new approximations for the Merton problem with stochastic volatility.","","97811187455","10.1002/9781118745540.ch7","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471086.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Transfer Learning of Air Combat Behavior","A. Toubman; J. J. Roessingh; P. Spronck; A. Plaat; J. v. d. Herik","Dept. of Training, Simulation, & Operator Performance, Netherlands Aerosp. Centre NLR, Amsterdam, Netherlands","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","226","231","Machine learning techniques can help to automatically generate behavior for computer generated forces inhabiting air combat training simulations. However, as the complexity of scenarios increases, so does the time to learn optimal behavior. Transfer learning has the potential to significantly shorten the learning time between domains that are sufficiently similar. In this paper, we transfer air combat agents with experience fighting in 2-versus-1 scenarios to various 2-versus-2 scenarios. The performance of the transferred agents is compared to that of agents that learn from scratch in the 2v2 scenarios. The experiments show that the experience gained in the 2v1 scenarios is very beneficial in the plain 2v2 scenarios, where further learning is minimal. In difficult 2v2 scenarios transfer also occurs, and further learning ensues. The results pave the way for fast generation of behavior rules for air combat agents for new, complex scenarios using existing behavior models.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424313","air combat;computer generated forces;reinforcement learning;training simulations;transfer learning","Adaptation models;Atmospheric modeling;Computational modeling;Lead;Learning (artificial intelligence);Missiles;Training","aerospace computing;aerospace simulation;digital simulation;learning (artificial intelligence);military aircraft;military computing;multi-agent systems","2-versus-1 air combat scenarios;2-versus-2 air combat scenarios;air combat agents;air combat behavior;air combat training simulations;computer generated forces;machine learning techniques;transfer learning","","","","16","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Scalable transformed additive signal decomposition by non-conjugate Gaussian process inference","V. Adam; J. Hensman; M. Sahani","University College London, Gatsby Computational Neuroscience Unit, 25 Howland Street, London W1T 4JG","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Many functions and signals of interest are formed by the addition of multiple underlying components, often nonlinearly transformed and modified by noise. Examples may be found in the literature on Generalized Additive Models [1] and Underdetermined Source Separation [2] or other mode decomposition techniques. Recovery of the underlying component processes often depends on finding and exploiting statistical regularities within them. Gaussian Processes (GPs) [3] have become the dominant way to model statistical expectations over functions. Recent advances make inference of the GP posterior efficient for large scale datasets and arbitrary likelihoods [4,5]. Here we extend these methods to the additive GP case [6, 7], thus achieving scalable marginal posterior inference over each latent function in settings such as those above.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738855","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738855","","Additives;Bayes methods;Computational modeling;Gaussian processes;Kernel;Random variables;Splines (mathematics)","Gaussian processes;inference mechanisms;source separation","generalized additive model;mode decomposition;nonconjugate Gaussian process inference;nonlinear transformation;scalable marginal posterior inference;scalable transformed additive signal decomposition;statistical expectation;statistical regularity;underdetermined source separation","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Scale and shift invariant time/frequency representation using auditory statistics: Application to rhythm description","U. Marchand; G. Peeters","STMS IRCAM-CNRS-UPMC, 1 pl. Igor Stravinsky, 75004 Paris, France","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this paper we propose two novel scale and shift-invariant time-frequency representations of the audio content. Scale-invariance is a desired property to describe the rhythm of an audio signal as it will allow to obtain the same representations for same rhythms played at different tempi. This property can be achieved by expressing the time-axis in log-scale, for example using the Scale Transform (ST). Since the frequency locations of the audio content are also important, we previously extended the ST to the Modulation Scale Spectrum (MSS). However, this MSS does not allow to represent the inter-relationship between the audio content existing in various frequency bands. To solve this issue, we propose here two novel representations. The first one is based on the 2D Scale Transform, the second on statistics (inspired by the auditory experiments of McDermott) that represent the interrelationship between the various frequency bands. We apply both representations to a task of rhythm class recognition and demonstrates their benefits. We show that the introduction of auditory statistics allows a large increase of the recognition results.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738904","2D-Fourier;2D-Scale;Fourier-Mellin Transform;auditory statistics;rhythm description","Modulation;Proposals;Rhythm;Time-frequency analysis;Transforms;Two dimensional displays","Fourier transforms;audio signal processing;scaling phenomena;signal classification;statistics","2D Fourier transform;MSS;ST;audio content;audio signal;auditory statistics;modulation scale spectrum;rhythm class recognition;rhythm description;scale transform;scale-invariance;shift invariant time frequency representations","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"The influence of hyper-parameters in the infinite relational model","K. J. Albers; M. Mørup; M. N. Schmidt","Department of applied Mathematics and Computer Science, Section for Cognitive Science, Technical University of Denmark","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","The infinite relational model (IRM) is a Bayesian nonparametric stochastic block model; a generative model for random networks parameterized for uni-partite undirected networks by a partition of the node set and symmetric matrix of inter-partion link probabilities. The prior for the node clusters is the Chinese restaurant process, and the link probabilities are, in the most simple setting, modeled as iid. with a common symmetric Beta prior. More advanced priors such as separate asymmetric Beta priors for links within and between clusters have also been proposed. In this paper we investigate the importance of these priors for discovering latent clusters and for predicting links. We compare fixed symmetric priors and fixed asymmetric priors based on the empirical distribution of links with a Bayesian hierarchical approach where the parameters of the priors are inferred from data. On synthetic data, we show that the hierarchical Bayesian approach can infer the prior distributions used to generate the data. On real network data we demonstrate that using asymmetric priors significantly improves predictive performance and heavily influences the number of extracted partitions.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738908","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738908","Bayesian non-parametrics;Infinite relational model;hyper-parameter inference;link-prediction","Bayes methods;Computational modeling;Data models;Facebook;Mathematical model;Proposals;Stochastic processes","Bayes methods;complex networks;data analysis;network theory (graphs);nonparametric statistics;random processes;statistical analysis;stochastic processes","Bayesian hierarchical approach;Bayesian nonparametric stochastic block model;Chinese restaurant process;hyperparameters;infinite relational model;interpartion link probabilities;latent clusters;network data clustering;node clusters;node set;priors parameters;random networks;statistical tool;symmetric Beta prior;symmetric matrix;unipartite undirected networks","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Inertia Based Recognition of Daily Activities with ANNs and Spectrotemporal Features","O. Kilinc; A. Dalzell; I. Uluturk; I. Uysal","Electr. Eng. RFID Lab. for Appl. Res., Univ. of South Florida, Tampa, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","733","738","As mobile and personal health devices gain in popularity, increasing amounts of data is collected via their embedded sensors such as heart rate monitors and accelerometers. Data analytics and more specifically machine learning algorithms can transform this data into actionable information to improve personal healthcare and quality of life. The main objective of this study is to develop an algorithmic classification framework using feed-forward multilayer perceptrons and statistically rich spectrotemporal features to recognize daily activities based on 3-axis acceleration data. A multitude of MLP topologies and setups, such as different numbers and sizes of hidden layers, supervised output structuring, etc. are tested to comprehensively analyze the clustering capabilities of the artificial neural network for a wide-range of settings. In addition, the contribution of subset of features to classification accuracy is studied to identify respective information potentials and further improve accuracy. Publicly available wrist-worn accelerometer dataset from University of California Irvine's machine learning repository is used for fair comparison with the most recent literature published using the same dataset. Results indicate a significant improvement in recognition rate where the overall accuracy over seven selected activity classes is 91% compared to 54% of the latest publication using the same dataset.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424408","accelerometer;classification;daily activity;health;inertia;machine learning;recognition","Acceleration;Accelerometers;Artificial neural networks;Feature extraction;Mobile communication;Sensors;Time-domain analysis","data analysis;health care;learning (artificial intelligence);medical computing;multilayer perceptrons;pattern classification","3-axis acceleration data;ANN;University of California Irvine machine learning repository;algorithmic classification framework;artificial neural networks;daily activity recognition;data analytics;feedforward multilayer perceptrons;inertia based recognition;machine learning algorithm;mobile health devices;personal health devices;spectrotemporal features;wrist-worn accelerometer dataset","","1","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Energy performance prediction of lighting systems","D. Caicedo; A. Pandharipande","Philips Research, High Tech Campus, Eindhoven, The Netherlands","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We consider the problem of estimating lighting energy consumption in a lighting system upgrade scenario. In this scenario, a building has an existing lighting control system, denoted LCS1. We are interested in estimating the energy consumption if a more energy efficient lighting control system, denoted LCS2, had been installed. Lighting data is available from LCS2 for a specific monitored area and from LCS1 for the target upgrade area. A conventional method extrapolates the energy consumption from the monitoring area to the target area using surface area information. This has limited accuracy since differences in occupancy and daylight distribution across the two areas are not accounted for. To address this problem, we construct an energy model using support vector regression using lighting data from the monitored area. Lighting data from the target area is then used in the model to estimate the energy consumption. We show that the proposed method provides a better estimate of the energy consumption compared to the simple extrapolation method using data from an indoor office lighting system.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738858","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738858","Energy performance prediction;Lighting data analytics;Support vector regression","Energy consumption;Lighting;Lighting control;Monitoring;Sensors;Support vector machines;Training","daylighting;energy consumption;extrapolation;lighting control","LCS1;LCS2;daylight distribution;energy efficient lighting control system;energy performance prediction;extrapolation method;indoor office lighting system;lighting energy consumption estimation;lighting system upgrade scenario;surface area information","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Autosomal dominant nocturnal frontal lobe epilepsy seizure characterization through wavelet transform of eeg records and self organizing maps","B. Pisano; B. Cannas; G. Milioli; A. Montisci; F. Pisano; M. Puligheddu; G. Sias; A. Fanni","Department of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this paper, a Manifold Learning approach for the automatic detection of Autosomal Dominant Nocturnal Frontal Lobe Epilepsy seizures is presented, with the aim to support neurologists in the labelling efforts. Features extracted from polysomnography signals are used in order to detect and discriminate seizure epochs. This task has been addressed by mapping the electroencephalographic signal epochs in different regions of the features space. The result is a Self Organizing Map, which allows to investigate over not straightforward relations in the complex input space for the characterization of seizures.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738861","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738861","Autosomal Dominant Nocturnal Frontal Lobe Epilepsy;Self Organizing Map (SOM);Wavelet Decomposition","Brain modeling;Electroencephalography;Epilepsy;Feature extraction;Sleep;Standards;Wavelet transforms","electroencephalography;feature extraction;learning (artificial intelligence);medical disorders;medical signal detection;self-organising feature maps;wavelet transforms","EEG records;discriminate seizure epoch detection;dominant nocturnal frontal lobe epilepsy seizure characterization;electroencephalographic signal epochs;feature extraction;feature space;manifold learning;polysomnographic signals;self organizing maps;wavelet transform","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A model explanation system","R. Turner","Northrop Grumman Corporation","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We propose a new methodology for explaining the predictions of black box classifiers. We use the motivating paradigm that predictive performance is of primary importance but human analysts (e.g., in fraud detection) desire a classifier's predictions to be augmented with useful explanations. To be truly general and principled, we derive a scoring system for finding explanations based on formal requirements. In this system, the explanations are assumed to take the form of simple logical statements. We derive an efficient Monte Carlo algorithm to find explanations for black box classifiers with finite sample guarantees. The methodology is then applied to interesting examples in facial recognition and credit data.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738872","","Computational modeling;Credit cards;Data models;Decision trees;Face recognition;History;Monte Carlo methods","Monte Carlo methods;pattern classification","Monte Carlo algorithm;black box classifiers;classifier predictions;credit data;facial recognition;finite sample guarantees;formal requirements;logical statements;model explanation system;predictive performance;scoring system","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Toward a brain interface for tracking attended auditory sources","M. Haghighi; M. Moghadamfalahi; H. Nezamfar; M. Akcakaya; D. Erdogmus","Northeastern University Boston, MA 02115 USA","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","5","Auditory-evoked noninvasive electroencephalography (EEG) based brain-computer interfaces (BCIs) could be useful for improved hearing aids in the future. This manuscript investigates the role of frequency and spatial features of audio signal in EEG activities in an auditory BCI system with the purpose of detecting the attended auditory source in a cocktail party setting. A cross correlation based feature between EEG and speech envelope is shown to be useful to discriminate attention in the case of two different speakers. Results indicate that, on average, for speaker and direction (of arrival) of audio signals classification, the presented approach yields 91% and 86% accuracy, respectively.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738810","Auditory BCI;auditory attention","Acoustics;Brain-computer interfaces;Correlation;Ear;Electroencephalography;Feature extraction;Speech","audio signal processing;brain-computer interfaces;correlation methods;electroencephalography;hearing aids;signal classification;speech processing","BCIs;EEG activities;attended auditory source detection;attended auditory source tracking;audio signals classification;auditory BCI system;auditory-evoked noninvasive electroencephalography;brain interface;brain-computer interfaces;cocktail party setting;cross correlation based feature;frequency feature;hearing aids;spatial feature","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Filter bank extension for neural network-based motor imagery classification","P. Merinov; M. Belyaev; E. Krivov","Institute for Information Transmission Problems (Kharkevich Institute), Moscow, Russia 127051","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","One of the most successful Motor Imagery classification methods is the Common Spatial Pattern algorithm, which is used as a feature generation method, combined with the Linear Discriminant Analysis classifier. CSP parameters are estimated via optimizing of a criterion implicitly connected to classification accuracy. Many modifications of CSP were proposed, but almost all of them just adjust an objective function in an optimization problem. Another extension is the Filter Bank CSP algorithm, which combines CSP features calculated in different frequency bands. So, parameters of such classification pipelines are estimated in two steps: 1) solving an optimization problem to generate features and 2) create a linear classifier based on these features. In this work, we propose to combine these two steps into a single optimization problem to build an FBCSP-like model.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738835","","Band-pass filters;Brain modeling;Electroencephalography;Feature extraction;Linear programming;Neural networks;Optimization","electroencephalography;filtering theory;medical signal processing;neural nets;optimisation;parameter estimation;signal classification","CSP parameter estimation;EEG;FBCSP-like model;classification accuracy;common spatial pattern algorithm;feature generation method;filter bank CSP algorithm;filter bank extension;linear classifier;linear discriminant analysis classifier;motor imagery classification;neural network;single optimization problem","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Data privacy protection by kernel subspace projection and generalized eigenvalue decomposition","K. Diamantaras; S. Y. Kung","TEI of Thessaloniki, Dept. Information Technology, Sindos, 57400, Greece","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Various internet services, including cloud providers and social networks collect large amounts of information that needs to be processed for statistical or other reasons without breaching user privacy. We present a novel approach where privacy protection can be viewed as a data transformation problem. The problem is formulated as a pair of classification tasks, (a) a privacy-insensitive and (b) a privacy-sensitive task. Then privacy protection is the requirement that, given the transformed data, no classification algorithm may perform well on the sensitive task while hurting the performance on the insensitive task as little as possible. To that end, we introduce a novel criterion called Multiclass Discriminant Ratio which is optimized using the generalized eigenvalue decomposition of a pair of between class scatter matrices. We then formulate a nonlinear extension of this approach using the kernel GED method. Our proposed methods are evaluated using the Human Activity Recognition data set. Using the kernel projected data the performance of the User recognition task is reduced by 89% while the Activity recognition task is reduced only by 7.8%.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738831","Kernel Generalized Eigenvalue Decomposition;Privacy Protection;Subspace methods","Cloud computing;Data privacy;Eigenvalues and eigenfunctions;Kernel;Matrix decomposition;Privacy","Web services;cloud computing;data protection;eigenvalues and eigenfunctions;social networking (online)","Internet services;cloud providers;data privacy protection;data transformation problem;generalized eigenvalue decomposition;human activity recognition data set;kernel GED method;kernel subspace projection;multiclass discriminant ratio;privacy-insensitive task;privacy-sensitive task;social networks;user privacy protection;user recognition task","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A Novel Study for the Modeling of Monthly Evaporation Using K-Nearest Neighbor Algorithms for a Semi-Arid Continental Climate","O. Genc; A. Dag; M. Ardiclioglu","Dept. of Civil Eng., Meliksah Univ., Kayseri, Turkey","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","341","346","This study aims to reveal a reliable and efficient method for predicting the monthly evaporation. For this purpose, the accuracy of machine learning algorithms, MLA, that include k-nearest neighbor, k-NN, was used in modeling monthly evaporation. The tenfold cross-validation approach was employed to determine the performances of prediction methods for MLA. The results revealed that k-NN algorithms outperformed the other MLA (ANN and SVM), with the R value of 0.95, the RMSE value of 1.01 mm, MAE value of 0.78 mm, and RME value of 0.04 mm. It is concluded that the suggested k-NN model can be successfully employed for predicting monthly evaporation for a semi-arid continental climate.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424332","Machine learning algorithms;evaporation;k-NN;semi-arid climate","Data models;Meteorology;Prediction algorithms;Predictive models;Training;Water resources","climatology;evaporation;geophysical techniques;geophysics computing;learning (artificial intelligence)","MLA;k-NN algorithms;k-NN model;k-nearest neighbor algorithms;machine learning algorithms;monthly evaporation modeling;semiarid continental climate;tenfold cross-validation approach","","","","26","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Mini-batch stochastic approaches for accelerated multiplicative updates in nonnegative matrix factorisation with beta-divergence","R. Serizel; S. Essid; G. Richard","LTCI, CNRS, T&#x00E9;l&#x00E9;com ParisTech, Universit&#x00E9; Paris - Saclay, 75013, Paris, France","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Nonnegative matrix factorisation (NMF) with β-divergence is a popular method to decompose real world data. In this paper we propose mini-batch stochastic algorithms to perform NMF efficiently on large data matrices. Besides the stochastic aspect, the mini-batch approach allows exploiting intensive computing devices such as general purpose graphical processing units to decrease the processing time and in some cases outperform coordinate descent approach.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738818","GPGPU;Nonnegative matrix factorisation;multiplicative rules;online learning","Convergence;Cost function;Euclidean distance;Matrix decomposition;Radio frequency;Standards;Time series analysis","data handling;learning (artificial intelligence);matrix decomposition;stochastic processes","β-divergence;NMF;accelerated multiplicative updates;beta-divergence;general purpose graphical processing units;intensive computing devices;large data matrices;mini-batch stochastic algorithms;nonnegative matrix factorisation;online learning","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Correlated Poisson Processes and Their Applications in Financial Modeling","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","This chapter discusses some classes of risk factor models with jump processes and their existing and potential applications in different areas of financial risk management. It describes some technical obstacles in calibration associated with negative correlations. The chapter presents the common shock model and the mixed Poisson model in the bivariate case. It discusses the multivariate case of the CSM and describes the backward simulation (BS) algorithm and discusses the calibration problem for the parameters of the model. The chapter compares the backward simulation approach with the forward simulation. One of the ingredients of the solution, the computation of the lower and upper bounds for the correlation coefficient is described in the chapter, where the computation of the extreme joint distribution and its support is presented. It extends the BS approach to the processes having both Poisson and Wiener components.","","97811187455","10.1002/9781118745540.ch9","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471055.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Memory reduction method for deep neural network training","K. Shirahata; Y. Tomita; A. Ike","FUJITSU LABORATORIES LTD., 4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki, Kanagawa 211-8588, Japan","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Training deep neural networks requires a large amount of memory, making very deep neural networks difficult to fit on accelerator memories. In order to overcome this limitation, we present a method to reduce the amount of memory for training a deep neural network. The method enables to suppress memory increase during the backward pass, by reusing the memory regions allocated for the forward pass. Experimental results exhibit our method reduced the occupied memory size in training by 44.7% on VGGNet with no accuracy affection. Our method also enabled training speedup by increasing the mini batch size up to double.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738869","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738869","Accelerators;Deep Neural Networks;Memory Management","Backpropagation;Biological neural networks;Convolution;Graphics processing units;Memory management;Neurons;Training","learning (artificial intelligence);neural nets","VGGNet;accelerator memories;deep neural network training;memory reduction;memory regions reusing;memory suppression;occupied memory size reduction","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"The widely linear block quaternion least mean square algorithm for fast computation in 3D audio systems","F. Ortolani; D. Comminiello; A. Uncini","Dpt. of Information Engineering, Electronics and Telecommunications, Sapienza University of Rome via Eudossiana, 18, 00184, Rome, Italy","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this paper we propose an algorithm which operates weight adaptation by means of a periodic law and is based on the Widely Linear Quaternion Least Mean Square (WL-QLMS) algorithm. The WL-QLMS successfully handles real-world signals, either proper or improper. However, because of the introduction of full second order statistics into the algorithm, its computational cost is quadruplicated with respect to its precursor QLMS. The proposed Widely Linear Block Quaternion Least Mean Square (WL-BQLMS) algorithm speeds up the execution, thus revealing itself as a good solution in 3D audio signal processing applications, where huge amounts of data are usually treated and signals are typically improper. Simulations exploiting 3D Ambisonic B-Format audio signals provide a report of the WL-BQLMS behavior in comparison with BQLMS.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738842","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738842","3D audio;B-Format;Widely linear;adaptive filters;block algorithms;hypercomplex;quaternion Ambisonic representation;quaternions","Adaptation models;Algebra;Computational efficiency;Covariance matrices;Quaternions;Signal processing algorithms;Three-dimensional displays","audio signal processing;least mean squares methods","3D audio system;WL-BQLMS algorithm;widely linear block quaternion least mean square algorithm","","1","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A stable spline convex approach to hybrid systems identification","G. Pillonetto; A. Y. Aravkin","University of Padova, Dept. of Information Engineering, Padova (Italy)","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this paper we propose a new regularized technique for identification of piecewise affine systems which combines the ℓ<sub>1</sub> loss and the recently introduced stable spline kernel. This latter is used to define a quadratic penalty which embeds information on the stability of each isolated subsystem. Our procedure determines sequentially the complexity of each affine subsystem, and then its impulse response, estimating from data couples of hyperparameters. The algorithm involves a series of operations which promote intra-submodel regularization hence favoring subsystems detection and reconstruction. Numerical experiments involving high-order piecewise affine systems show the effectiveness of the new approach.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738883","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738883","","Atmospheric measurements;Indexes;Kernel;Optimization;Particle measurements;Robustness;Splines (mathematics)","estimation theory;splines (mathematics)","ℓ1 loss;affine subsystem complexity;high-order piecewise affine systems;hybrid systems identification;hyperparameter data couple estimation;impulse response;intra-submodel regularization;isolated subsystem stability;quadratic penalty definition;stable spline convex approach;stable spline kernel;subsystems detection;subsystems reconstruction","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A hypothesis testing approach for real-time multichannel speech separation using time-frequency masks","R. M. Corey; A. C. Singer","University of Illinois at Urbana-Champaign","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We propose a new approach to time-frequency mask generation for real-time multichannel speech separation. Whereas conventional approaches select the strongest source in each time-frequency bin, we perform a binary hypothesis test to determine whether a target source is present or not. We derive a generalized likelihood ratio test and extend it to underdetermined mixtures by aggregating the outputs of several tests with different interference models. This approach is justified by the nonstationarity and time-frequency disjointedness of speech signals. This computationally simple method is suitable for real-time source separation in resource-constrained and latency-critical applications.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738827","","Interference;Microphones;Real-time systems;Signal to noise ratio;Speech;Testing;Time-frequency analysis","interference (signal);real-time systems;speech processing","binary hypothesis test;generalized likelihood ratio test;hypothesis testing approach;latency critical applications;real-time multichannel speech separation;real-time source separation;resource constrained applications;speech signals;time frequency disjointedness;time frequency mask generation;underdetermined mixtures","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Overview","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","This introductory chapter presents a brief summary of basic concepts in finance and risk management, and provides overview of the concepts discussed in the chapters of this book. It provides the underlying technical themes, including sparse learning, convex optimization, and non-Gaussian modeling. Finance broadly deals with all aspects of money management, including borrowing and lending, transfer of money across continents, investment and price discovery, and asset and liability management by governments, corporations, and individuals. A unifying challenge for many applications of signal processing and machine learning is the high-dimensional nature of the data, and the need to exploit the inherent structure in those data. The book focuses on a set of topics revolving around the concepts of high-dimensional covariance estimation, applications of sparse learning in risk management and statistical arbitrage, and non-Gaussian and heavy-tailed measures of dependence.","","97811187455","10.1002/9781118745540.ch1","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471082.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Active object detection on graphs via locally informative trees","D. S. Zois; M. Raginsky","Coordinated Science Laboratory, University of Illinois at Urbana-Champaign, Urbana, IL 61801","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Active object detection refers to the problem of determining the existence and location of objects in an image by actively selecting which regions of the image to explore. Herein, an object detection algorithm is proposed that models image regions as vertices and overlap relationships as edges in a directed weighted graph. Information is propagated from labeled vertices through graph edges that operate as noisy channels via message passing over locally informative trees that are extracted from the original graph using an information-theoretic criterion. Influential vertices are determined by an appropriate centrality index. Our algorithm can be applied on top of any state-of-the-art region proposal method as it treats it as a black box. The effectiveness of the proposed algorithm is illustrated on different scenarios, where in some cases only 0.45% of the total regions is evaluated.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738876","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738876","active object detection;degree centrality;graphs;locally informative trees;mutual information","Detectors;Image edge detection;Mutual information;Noise measurement;Object detection;Proposals;Zirconium","directed graphs;object detection;trees (mathematics)","active object detection;centrality index;directed weighted graph;graph edges;image object existence;image object location;image regions;information-theoretic criterion;labeled vertices;locally informative trees;message passing;noisy channels","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A block-based combined scheme exploiting sparsity in nonlinear acoustic echo cancellation","D. Comminiello; M. Scarpiniti; L. A. Azpicueta-Ruiz; J. Arenas-García; A. Uncini","Dept. Inform. Eng., Electron. and Telecom, &#x201C;Sapienza&#x201D; University of Rome, 00184 Rome, Italy","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Nonlinear acoustic echo cancellation (NAEC) aims at estimating both the acoustic impulse response and the nonlinearities affecting the desired signal. Both the modeling processes show behaviors of sparse nature from an energy point of view. In this paper, we propose an adaptive NAEC algorithm that takes advantage of such sparsity behaviors to improve echo cancellation performance. The proposed scheme is characterized by two block-based adaptive combinations of proportionate adaptive filters, having different strategies, devoted respectively to the estimation of the linear and nonlinear responses. The proposed model is assessed in NAEC problems, where its advantages and effectiveness are shown.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738822","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738822","Adaptive Combination of Filters;Functional Links;Linear-in-the-Parameters Nonlinear Filters;Nonlinear Adaptive Filtering;Sparse Adaptive Filters","Adaptation models;Adaptive filters;Atmospheric modeling;Echo cancellers;Estimation;Indexes;Nonlinear acoustics","acoustic signal processing;adaptive filters;echo;nonlinear acoustics;transient response","acoustic impulse response;acoustic nonlinearities;adaptive NAEC algorithm;block-based adaptive combination;block-based combined scheme;nonlinear acoustic echo cancellation;nonlinear response estimation;proportionate adaptive filter;sparsity behavior","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Underwater target classification using a pose-invariant matched manifold classifier","P. Pakrooh; L. L. Scharf; M. R. Azimi-Sadjadi","Department of Mathematics, Colorado State University, Fort Collins, CO","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","5","One of the challenges in automatic detection and classification of underwater targets in sonar imagery is variation of the target returns and features with respect to target aspect. This paper adopts a framework for target classification that offers local invariance properties with respect to target aspect. Sonar image snippets of a target type at nearby aspects are related to each other via geometric deformations approximated by locally affine transformations. A transform is then used to map each such image into a low dimensional linear subspace locally invariant to affine geometric transformations of the image. These linear subspaces are subsequently averaged using an extrinsic subspace averaging to yield a subspace corresponding to this set of images. Class label of an unknown image is then decided using a geometrically invariant Matched Manifold Classifier that uses principal angles to measure distance between this average subspace and the subspace associated with the observed image. Results on synthesized sonar images of various underwater targets inserted in real backgrounds show the promise of this new method.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738891","","Detectors;Feature extraction;Manifolds;Orbits;Sonar detection;Transforms","affine transforms;image classification;pose estimation;sonar imaging","affine geometric transformations;affine transformations;distance measurement;extrinsic subspace averaging;geometric deformations;geometrically invariant matched manifold classifier;local invariance properties;pose-invariant matched manifold classifier;sonar image snippets;sonar imagery;underwater target classification;underwater target detection","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Decision Tree Learning for Fraud Detection in Consumer Energy Consumption","C. Cody; V. Ford; A. Siraj","Comput. Sci. Dept., North Carolina State Univ., Raleigh, NC, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1175","1179","The electrical grid is transitioning to new smart grid technology. With smart meters becoming an essential feature in smart homes, concerns regarding smart meters and the vast amount of consumer data that it captures are on the rise. While access to this fine-grained energy consumption data captured by smart meters can potentially violate consumer privacy, advanced analysis of this data can help to protect the interest of both the consumer and the utility company by enabling fraud detection at either end. The use of machine learning techniques has been a very common approach to energy fraud detection. Patterns in energy consumption can be recognized and used to detect anomalous behavior. This research reports on a novel application of decision tree learning technique to profile normal energy consumption behavior allowing for the detection of potentially fraudulent activity.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424479","decision trees;fraud detection;smart meter data","Decision trees;Energy consumption;Energy measurement;Prediction algorithms;Predictive models;Smart meters;Training","data analysis;decision trees;energy consumption;fraud;learning (artificial intelligence);power engineering computing;smart power grids","advanced data analysis;anomalous behavior detection;consumer energy consumption;consumer privacy;decision tree learning;electrical grid;energy fraud detection;machine learning technique;smart grid technology;smart homes;smart meters","","","","11","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Bayesian latent feature modeling for modeling bipartite networks with overlapping groups","P. H. Jørgensen; M. Mørup; M. N. Schmidt; T. Herlau","Technical University of Denmark, Department of Applied Mathematics and Computer Science, Kgs. Lyngby, Denmark","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Bi-partite networks are commonly modelled using latent class or latent feature models. Whereas the existing latent class models admit marginalization of parameters specifying the strength of interaction between groups, existing latent feature models do not admit analytical marginalization of the parameters accounting for the interaction strength within the feature representation. We propose a new binary latent feature model that admits analytical marginalization of interaction strengths such that model inference reduces to assigning nodes to latent features. We propose a constraint inspired by the notion of community structure such that the edge density within groups is higher than between groups. Our model further assumes that entities can have different propensities of generating links in one of the modes. The proposed framework is contrasted on both synthetic and real bi-partite networks to the infinite relational model and the infinite Bernoulli mixture model. We find that the model provides a new latent feature representation of structure while in link-prediction performing close to existing models. Our current extension of the notion of communities and collapsed inference to binary latent feature representations in bipartite networks provides a new framework for accounting for structure in bi-partite networks using binary latent feature representations providing interpretable representations that well characterize structure as quantified by link prediction.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738845","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738845","Latent feature modeling;bipartite graphs;complex networks;link prediction;relational modeling","Analytical models;Bayes methods;Computational modeling;Data models;Feature extraction;Mathematical model;Predictive models","Bayes methods;group theory;network theory (graphs)","Bayesian latent feature modeling;binary latent feature model;binary latent feature representations;bipartite network modeling;bipartite networks;community structure;in link-prediction;latent class model;link prediction;overlapping groups;real bi-partite network;synthetic bi-partite network","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Parallel and distributed training of neural networks via successive convex approximation","P. Di Lorenzo; S. Scardapane","Dept. of Engineering, University of Perugia","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","The aim of this paper is to develop a theoretical framework for training neural network (NN) models, when data is distributed over a set of agents that are connected to each other through a sparse network topology. The framework builds on a distributed convexification technique, while leveraging dynamic consensus to propagate the information over the network. It can be customized to work with different loss and regularization functions, typically used when training NN models, while guaranteeing provable convergence to a stationary solution under mild assumptions. Interestingly, it naturally leads to distributed architectures where agents solve local optimization problems exploiting parallel multi-core processors. Numerical results corroborate our theoretical findings, and assess the performance for parallel and distributed training of neural networks.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738894","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738894","Artificial neural networks;Distributed algorithms;Nonconvex optimization;Parallel algorithms","Artificial neural networks;Cost function;Distributed databases;Network topology;Training","approximation theory;convex programming;learning (artificial intelligence);multiprocessing systems;parallel processing;topology","NN model;convex approximation;distributed convexification technique;distributed training;dynamic consensus;neural network model;optimization problem;parallel multicore processor;parallel training;sparse network topology","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Doubly sparse structure in image super resolution","T. Kato; H. Hino; N. Murata","Waseda University, Shinjuku, Tokyo, Japan","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","There are a large number of image super resolution algorithms based on the sparse coding, and some algorithms realize multi-frame super resolution. For utilizing multiple low resolution observations, both accurate image registration and sparse coding are required. Previous study on multi-frame super resolution based on sparse coding firstly apply block matching for image registration, followed by sparse coding to enhance the image resolution. In this paper, these two problems are solved by optimizing a single objective function. The proposed formulation not only has a mathematically interesting structure called the double sparsity, but also offers improved numerical performance.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738902","Double Sparsity;Image Super Resolution;Sparse Coding","Degradation;Dictionaries;Encoding;Image coding;Image registration;Image resolution;Optimization","image coding;image matching;image registration;image resolution","block matching;doubly sparse structure;image registration;image super resolution;multiframe super resolution;sparse coding","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Application of a Multilayer Perceptron Neural Network for Classifying Software Platforms of a Powered Prosthesis through a Force Plate","R. LeMoyne; T. Mastroianni; A. Hessel; K. Nishikawa","Dept. of Biol. Sci., Northern Arizona Univ., Flagstaff, AZ, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","402","405","The amalgamation of conventional gait analysis devices, such as a force plate, with a machine learning platform facilitates the capability to classify between two disparate software platforms for the same bionic powered prosthesis. The BiOM powered prosthesis is applied with its standard software platform that incorporates a finite state machine control architecture and a biomimetic software platform that uniquely accounts for the muscle modeling history dependence known as the winding filament hypothesis. The feature set is derived from a series of kinetic and temporal parameters derived from the force plate recordings. The multilayer perceptron neural network achieves 91% classification between the software platforms for the BiOM powered prosthesis conventional finite state machine control architecture and biomimetic software platform based on the force plate derived feature set.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.211","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424345","BiOM Powered Prosthesis;Gait Analysis;Machine Learning;Multilayer Perceptron;Neural Network;Powered Prosthesis","Force;Multilayer perceptrons;Muscles;Prosthetics;Software;Windings","biomimetics;finite state machines;gait analysis;learning (artificial intelligence);multilayer perceptrons;muscle;prosthetics;software architecture","BiOM powered prosthesis;biomimetic software platform;bionic powered prosthesis;finite state machine control architecture;force plate recording;gait analysis device;kinetic parameter;multilayer perceptron neural network;muscle modeling history dependence;standard software platform classification;temporal parameter;winding filament hypothesis","","3","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Deep learning algorithms for signal recognition in long perimeter monitoring distributed fiber optic sensors","A. V. Makarenko","Constructive Cybernetics Research Group, Institute of Control Sciences RAS, P.O. Box 560, 10100, Moscow, Russia, Moscow, Russia","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this paper, we show an approach to build deep learning algorithms for recognizing signals in distributed fiber optic monitoring and security systems for long perimeters. Synthesizing such detection algorithms poses a non-trivial research and development challenge, because these systems face stringent error (type I and II) requirements and operate in difficult signal-jamming environments, with intensive signal-like jamming and a variety of changing possible signal portraits of possible recognized events. To address these issues, we have developed a two-level event detection architecture, where the primary classifier is based on an ensemble of deep convolutional networks, can recognize 7 classes of signals and receives time-space data frames as input. Using real-life data, we have shown that the applied methods result in efficient and robust multiclass detection algorithms that have a high degree of adaptability.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738863","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738863","deep learning;events classification;fiber optic vibration sensors;signal recognition;t-SNE visualization","Adaptive optics;Monitoring;Optical pulses;Optical pumping;Optical scattering;Optical sensors","distributed sensors;fibre optic sensors;learning (artificial intelligence);monitoring;neural nets;signal classification;signal detection","classifier;deep convolutional network;deep learning algorithm;distributed fiber optic monitoring;event recognition;long perimeter monitoring distributed fiber optic sensors;multiclass detection algorithm;security system;signal portrait;signal recognition;signal-jamming environment;signal-like jamming;time-space data frame;two-level event detection architecture","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Robust mixture models for anomaly detection","O. Barkan; A. Averbuch","Tel Aviv University","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We propose robust density estimation in a low dimensional space for anomaly detection. The outline of the method is as follows: first a low dimensional representation of the original data is learnt. Then, a robust density mixture model is estimated in the learnt space. Finally, the likelihood of a data point given the model parameters is used to apply anomaly detection. An efficient way for adapting the model parameters when the data distribution is changing with time is proposed. We further show how to identify the actual parameters in the original feature space that accounts for the occurrence of the anomaly. We present experimental results that demonstrate the effectiveness of the proposed methods.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738885","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738885","","Adaptation models;Data models;Estimation;Manifolds;Mixture models;Parameter estimation;Robustness","data handling;mixture models","anomaly detection;data distribution;data point;feature space;low dimensional representation;low dimensional space;robust density estimation;robust density mixture models","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A Code-Centric Cluster-Based Approach for Searching Online Support Forums for Programmers","C. Scaffidi; C. Chambers; S. Surisetty","Center for Appl. Syst. & Software, Oregon State Univ., Corvallis, OR, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1032","1037","Online forums provide peer-to-peer technical support for many user populations, including programmers struggling to master a new language. Programmers can help one another by uploading code samples to such a forum. Unfortunately, finding relevant code samples can prove difficult using existing search engines for large, diverse forums. Therefore, we have prototyped a new kind of code search engine for online forums that draws upon unsupervised machine learning in two ways. First, it displays code samples in visual groupings based on the mutual similarity of code samples. Second, it uses the assignment of code samples to clusters to achieve a form of query expansion, thereby identifying additional search results as potentially useful. We evaluated the system by running it on the forum for the LabVIEW programming language. A textual analysis of posts showed that the unsupervised machine learning algorithm successfully tended to assign code samples to clusters based on topical similarity. An empirical user evaluation confirmed that the new search engine improved on the forum's existing search engine by providing results for more queries, by generating more results per query, and by providing more relevant search results.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424456","forums;programmers;unsupervised machine learning","Clustering algorithms;Indexing;Instruments;Ports (Computers);Prototypes;Search engines;Visualization","pattern clustering;programming;programming languages;query processing;search engines;unsupervised learning","LabVIEW programming language;code search engine;code-centric cluster-based approach;mutual similarity;online support forums;peer-to-peer technical support;programmers;query expansion;textual analysis;topical similarity;unsupervised machine learning;user evaluation;user populations;visual groupings","","","","31","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Convolutional higher order matching pursuit","G. Bohner; M. Sahani","University College London, Gatsby Computational Neuroscience Unit, 25 Howland Street, London W1T 4JG","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We introduce a greedy generalised convolutional algorithm to efficiently locate an unknown number of sources in a series of (possibly multidimensional) images, where each source contributes a localised and low-dimensional but otherwise variable signal to its immediate spatial neighbourhood. Our approach extends convolutional matching pursuit in two ways: first, it takes the signal generated by each source to be a variable linear combination of aligned dictionary elements; and second, it executes the pursuit in the domain of high-order multivariate cumulant statistics. The resulting algorithm adapts to varying signal and noise distributions to flexibly recover source signals in a variety of settings.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738847","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738847","Matching pursuit;convolutional;feature decomposition;higher order;multi-sample","Convolution;Dictionaries;Indexes;Matching pursuit algorithms;Object recognition;Tensile stress;Zirconium","pattern matching;signal processing","convolutional higher order matching pursuit;dictionary elements;greedy generalised convolutional algorithm;multidimensional images;noise distributions;recover source signals;signal distributions;spatial neighbourhood;variable linear combination;variable signal","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Intra-cluster training strategy for deep learning with applications to language identification","A. J. Bekker; I. Opher; I. Lapidot; J. Goldberger","Engineering Faculty, Bar-Ilan University, Israel","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this study we address the problem of training a neural network for language identification using speech samples in the form of i-vectors. Our approach involves training a classifier and analyzing the obtained confusion matrix. We cluster the languages by simultaneously clustering the columns and the rows of the confusion matrix. The language clusters are then used to define a modified cost function for training a neural-network that focuses on distinguishing between the true language and languages within the same cluster. The results show enhanced language identification on the NIST 2015 language identification dataset.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738896","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738896","Confusion matrix;clustering;language identification","Acoustics;Clustering algorithms;Cost function;Neural networks;Speech;Speech recognition;Training","learning (artificial intelligence);matrix algebra;natural language processing;neural nets;pattern clustering;speech recognition","NIST 2015 language identification dataset;classifier training;confusion matrix;deep learning;i-vectors;intracluster training;language clusters;modified cost function;neural-network training;simultaneous column-row clustering;speech samples;true language","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Bayesian learning for speech dereverberation","J. T. Chien; Y. C. Chang","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","This study presents a Bayesian approach to enhance the magnitude spectra of single-channel reverberant speech signals. Speech dereverberation model is constructed by using a nonnegative convolutive transfer function (NCTF) and a nonnegative matrix factorization (NMF). NCTF is used to characterize the magnitude spectra of speech signal and room impulse response while NMF is applied to represent the fine structure of speech spectra. Importantly, we deal with the variations of dereverberation model by introducing the exponential priors for reverberation kernel and noise signal. A full Bayesian solution to speech dereverberation is obtained according to the variational Bayesian inference algorithm. Using this algorithm, the room configuration and the speaker characteristics are automatically learned from data. Such a general model can be reduced to the previous methods. Experimental results on both simulated data and real recordings from 2014 REVERB Challenge show the merit of the proposed method for single-channel speech dereverberation.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738865","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738865","Bayesian learning;nonnegative matrix factorization;speech dereverberation","Bayes methods;Kernel;Matrix decomposition;Probabilistic logic;Reverberation;Speech;Transfer functions","Bayes methods;inference mechanisms;learning (artificial intelligence);matrix decomposition;reverberation;speech processing;transfer functions","Bayesian learning;NCTF;magnitude spectra;noise signal;nonnegative convolutive transfer function;nonnegative matrix factorization;reverberation kernel;room configuration;room impulse response;single-channel reverberant speech signals;speaker characteristics;speech dereverberation;speech signal;speech spectra;variational Bayesian inference algorithm","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Exploiting ongoing EEG with multilinear partial least squares during free-listening to music","D. Wang; F. Cong; Q. Zhao; P. Toiviainen; A. K. Nandi; M. Huotilainen; T. Ristaniemi; A. Cichocki","Department of Biomedical Engineering, Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, China","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","During real-world experiences, determining the stimulus-relevant brain activity is excitingly attractive and is very challenging, particularly in electroencephalography. Here, spectrograms of ongoing electroencephalogram (EEG) of one participant constructed a third-order tensor with three factors of time, frequency and space; and the stimulus data consisting of acoustical features derived from the naturalistic and continuous music formulated a matrix with two factors of time and the number of features. Thus, the multilinear partial least squares (PLS) conforming to the canonical polyadic (CP) model was performed on the tensor and the matrix for decomposing the ongoing EEG. Consequently, we found that brain activity of majority of participants was significantly correlated with the musical features in time domain, and that such brain activity showed frontal or central or posterior or occipital distributions along the scalp, and that such brain activity could be of different oscillation bands in frequency domain.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738849","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738849","Ongoing EEG;multilinear partial least squares;music;tensor decomposition","Brain modeling;Electroencephalography;Matrix decomposition;Music;Tensile stress;Time-frequency analysis","electroencephalography;least squares approximations;matrix decomposition;medical image processing;music;tensors","EEG spectrograms;acoustical features;canonical polyadic model;continuous music;electroencephalography;free-listening;frequency;matrix decomposition;multilinear partial least squares;musical features;naturalistic music;ongoing EEG;space;stimulus data;stimulus-relevant brain activity;third-order tensor;time domain","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Evaluating the Uncertainty of a Bayesian Network Query Response by Using Joint Probability Distribution","Y. Shao; T. Miyoshi; Y. Hasegawa; H. Ban","R&D Group, Hitachi, Ltd., Kokubunji, Japan","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","76","81","Bayesian network is a powerful tool to represent patterns inside past data. It can be used to predict future by calculating the posterior probability of future events. Machine learning techniques that can construct a Bayesian network from past data automatically are well developed in recent years. If we consider past data as a sampling set from an original probabilistic distribution, the ""learning"" process is actually trying to reproduce the original probabilistic distribution from the sampling set. Therefore, the finiteness of size of sampling set will bring uncertainties to the reproduced parameters of constructed Bayesian network. When the constructed Bayesian network is used to predict future, the uncertainties of reproduced parameters will be transferred to the uncertainty of query response. Here, the query response is the posterior probability that we are interested in. Evaluating the uncertainty of query response is critical to some strict industrial applications. Previous researches have proposed a method to evaluate the uncertainty. The consequence is shown as a variance of the query response. However, the conventional method need to work together with the bucket elimination, an exact inference method. Therefore, the conventional method can not deal with large Bayesian networks that used in real applications because of its calculation cost. We proposed a new approach to calculate the uncertainty of query responses by using joint probability distribution in this research. The proposed method can work with any inference method. Therefore, it can give an approximate evaluation even when the Bayesian network is large by using an approximate inference method. To investigate the accuracy of our proposed method, six well used public Bayesian networks are used as test cases. By comparing the approximate results with the exact results, an average error of -13.60% is got.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424289","Bayesian network;approximate inference;effective sample size;machine learning;variance of query response","Bayes methods;Belief propagation;Mathematical model;Probabilistic logic;Probability distribution;Uncertainty","belief networks;inference mechanisms;learning (artificial intelligence);query processing;sampling methods;statistical distributions;uncertainty handling","Bayesian network;approximate inference method;bucket elimination;exact inference method;joint probability distribution;learning process;machine learning;posterior probability;query response;sampling set;uncertainty","","","","35","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Complex Decomposition of the Negative Distance Kernel","T. v. d. Brück; S. Eger; A. Mehler","CC Distrib. Secure Software Syst., Luzerne Univ. of Appl. Sci. & Arts, Lucerne, Switzerland","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","103","108","A Support Vector Machine (SVM) has become a very popular machine learning method for text classification. One reason for this relates to the range of existing kernels which allow for classifying data that is not linearly separable. The linear, polynomial and RBF (Gaussian Radial Basis Function) kernel are commonly used and serve as a basis of comparison in our study. We show how to derive the primal form of the quadratic Power Kernel (PK) -- also called the Negative Euclidean Distance Kernel (NDK) -- by means of complex numbers. We exemplify the NDK in the framework of text categorization using the Dewey Document Classification (DDC) as the target scheme. Our evaluation shows that the power kernel produces F-scores that are comparable to the reference kernels, but is -- except for the linear kernel -- faster to compute. Finally, we show how to extend the NDK-approach by including the Mahalanobis distance.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424293","Kernel functions;SVM;Text categorization","Conferences;Kernel;Optimization;Software systems;Support vector machines;Text categorization;Transforms","Gaussian processes;learning (artificial intelligence);pattern classification;polynomials;radial basis function networks;support vector machines;text analysis","DDC;Dewey document classification;F-scores;Gaussian radial basis function kernel;Mahalanobis distance;NDK;RBF kernel;SVM;complex decomposition;complex numbers;data classification;linear kernel;machine learning method;negative Euclidean distance kernel;polynomial kernel;quadratic power kernel;support vector machine;text categorization;text classification","","","","19","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Human Action Recognition Using Accelerated Variational Learning of Infinite Dirichlet Mixture Models","W. Fan; H. Sallay; N. Bouguila; J. X. Du","Dept. of Comput. Sci. & Technol., Huaqiao Univ., Xiamen, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","451","456","Exploiting Dirichlet process mixture models (also known as infinite mixture models) to model visual and textual data is now standard weapon in the arsenal of machine learning. This paper proposes a new accelerated variational inference approach to learn Dirichlet process mixture models with Dirichlet distributions. The choice of using Dirichlet distribution as the basic distribution is mainly due to its flexibility for modeling proportional data. Indeed, this kind of data is naturally generated by several applications involving the representation of texts, images and videos using the bag-of-words (or ""visual words"" in the case of images and videos) approach. The potential of the developed learning framework is shown using a challenging real application namely human action recognition in videos.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424356","Dirichlet process;Mixture models;clustering;human action recognition;nonparametric Bayesian;variational inference","Acceleration;Data models;Electronic mail;Mixture models;Videos;Visualization","image representation;inference mechanisms;learning (artificial intelligence);mixture models;video signal processing","Dirichlet distribution;accelerated variational inference approach;accelerated variational learning;bag-of-words approach;human action recognition;image representation;infinite Dirichlet mixture models;machine learning;text representation;textual data;video representation;visual data;visual words approach","","","","26","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Approaches to High-Dimensional Covariance and Precision Matrix Estimations","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","This chapter introduces several recent developments for estimating large covariance and precision matrices without assuming the covariance matrix to be sparse. It explains two methods for covariance estimation: namely covariance estimation via factor analysis, and precision Matrix Estimation and Graphical Models. The low rank plus sparse representation holds on the population covariance matrix. The chapter presents several applications of these methods, including graph estimation for gene expression data, and several financial applications. It then shows how estimating covariance matrices of high-dimensional asset excess returns play a central role in applications of portfolio allocations and in risk management. The chapter explains the factor pricing model, which is one of the most fundamental results in finance. It elucidates estimating risks of large portfolios and large panel test of factor pricing models. The chapter illustrates the recent developments of efficient estimations in panel data models.","","97811187455","10.1002/9781118745540.ch6","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7474316.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Variational Gaussian process for missing label crowdsourcing classification problems","P. Ruiz; E. Besler; R. Molina; A. K. Katsaggelos","Dpto. de Ciencias de la Computaci&#x00F3;n e I.A. Universidad de Granada","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this paper we address the crowdsourcing problem, where a classifier must be trained without knowing the real labels. For each sample, labels (which may not be the same) are provided by different annotators (usually with different degrees of expertise). The problem is formulated using Bayesian modeling, and considers scenarios where each annotator may label a subset of the training set samples only. Although Bayesian approaches have been previously proposed in the literature, we introduce Variational Bayes inference to develop an iterative algorithm where all latent variables are automatically estimated. In the experimental section the proposed model is evaluated and compared with other state-of-the-art methods on two real datasets.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738909","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738909","Bayesian modeling;Crowdsourcing;Gaussian process;classification;missing labels;multiple labels;variational inference","Bayes methods;Crowdsourcing;Gaussian processes;Noise measurement;Probabilistic logic;Reliability;Training","Bayes methods;Gaussian processes;estimation theory;inference mechanisms;iterative methods;outsourcing;pattern classification","Bayesian modelling;iterative algorithm;label crowdsourcing classification;variable estimation;variational Bayes inference;variational Gaussian process","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Tendencies regarding the effect of emotional intensity in inter corpus phoneme-level speech emotion modelling","B. Vlasenko; B. Schuller; A. Wendemuth","University of Passau, Chair of Complex & Intelligent Systems, Passau, Germany","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","As emotion recognition from speech has matured to a degree where it becomes suitable for real-life applications, it is time for developing techniques for matching different types of emotional data with multi-dimensional and categories-based annotations. The categorical approach is usually applied for acted `full blown' emotions and multi-dimensional annotation is often preferred for spontaneous real life emotions. A particularly realistic task we consider in this contribution is cross-corpus emotion recognition and its evaluation. General and phoneme-level emotional models on acted and spontaneous emotions (`very intense' and `intense') are used in our experimental study. The emotional models were trained on spontaneous emotions from the complete VAM dataset and subsets with variable emotional intensities and evaluated on acted emotions from the Berlin EMO-DB dataset. We observe a significant classification performance gap for general models trained on very intense spontaneous emotions. As a consequence, we address the importance of collecting large corpora with very intense emotional content for training more reliable phoneme-level emotional models.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738859","cross-corpus evaluation;emotion recognition;emotional intensity;phoneme-level emotional models;turn-level emotional models","Acoustics;Databases;Emotion recognition;Hidden Markov models;Reliability;Speech;Training","emotion recognition;speech processing","acted emotions;categories-based annotations;cross-corpus emotion recognition;emotional data matching;emotional intensities;emotional intensity;full blown emotions;intense spontaneous emotions;inter corpus phoneme-level speech emotion modelling;multidimensional annotations","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Unsupervised Learning and Image Classification in High Performance Computing Cluster","I. Itauma; M. S. Aslan; F. Villanustre; X. w. Chen","Comput. Sci. Dept., Wayne State Univ., Detroit, MI, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","576","581","Feature learning and object classification in machine learning have become very active research areas in recent decades. Identifying good features has various benefits for object classification in respect to reducing the computational cost and increasing the classification accuracy. We propose using a multimodal learning and object identification framework with an alternative platform, called High Performance Computing Cluster (HPCC Systems®), to speed up the optimization stages and to handle data of any dimension. Our framework first learns representative bases (or centroids) over unlabeled data for each model through the K-means unsupervised learning method. Then, to extract the desired features from the labeled data, the correlation between the labeled data and representative bases is calculated. These labeled features are fused to represent the identity and then fed to the classifiers to make the final recognition. In addition, many research studies have focused on improving optimization methods and the use of Graphics Processing Units (GPUs) to improve the training time for machine learning algorithms. This study is aimed at exploring feature learning and object classification ideas in HPCC Systems platform. HPCC Systems is a Big Data processing and massively parallel processing (MPP) computing platform used for solving Big Data problems. Algorithms are implemented in HPCC Systems® with a language called Enterprise Control Language (ECL) which is a declarative, data-centric programming language. It is a powerful, high-level, parallel programming language ideal for Big Data intensive applications. We evaluate our proposed framework in this new platform on various databases such as the CALTECH-101, AR databases, and a subset of wild PubFig83 data that we add multimedia content. For instance, we are able to improve on the classification accuracy result of [3] from 74.3% to 78.9% on AR database using Decision Tree C4.5 classifier.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424378","","Clustering algorithms;Databases;Feature extraction;High performance computing;Training;Unsupervised learning","Big Data;decision trees;graphics processing units;image classification;learning (artificial intelligence);optimisation;parallel processing","Big Data processing;ECL;GPU;HPCC systems;K-means unsupervised learning method;MPP computing;computational cost;data-centric programming language;decision tree;enterprise control language;feature learning;graphics processing units;high performance computing cluster;image classification;machine learning;massively parallel processing;multimodal learning;object classification;object identification;optimization","","","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Enhanced distance subset approximation using class-specific subspace kernel representation for kernel approximation","Y. Yu; K. I. Diamantaras; T. McKelvey; S. Y. Kung","Chalmers University of Technology, Gothenburg, Sweden","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","The computational complexity of kernel methods grows at least quadratically with respect to the training size and hence low rank kernel approximation techniques are commonly used. One of the most popular approximations is constructed by sub-sampling the training data. In this paper, we present a sampling algorithm called Enhanced Distance Subset Approximation (EDSA) based on a novel kernel function called CLAss-Specific Kernel (CLASK), which applies the idea of subspace clustering to low rank kernel approximation. By representing the kernel matrix based on a class-specific subspace model, it is allowed to use distinct kernel functions for different classes, which provides a better flexibility compared to classical kernel approximation techniques. Experimental results conducted on various UCI datasets are provided in order to verify the proposed techniques.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738811","Kernel approximation;class-specific subspace model;classification;discriminative representation","Approximation algorithms;Computational complexity;Indexes;Kernel;Support vector machines;Training;Training data","computational complexity;matrix algebra;pattern clustering;sampling methods;set theory","CLASK;EDSA;UCI datasets;class-specific kernel;class-specific subspace kernel representation;class-specific subspace model;computational complexity;distinct kernel functions;enhanced distance subset approximation;kernel function;low rank kernel approximation;sampling algorithm;subspace clustering","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Gaussian process regression for out-of-sample extension","O. Barkan; J. Weill; A. Averbuch","Tel Aviv University","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Manifold learning methods are useful for high dimensional data analysis. Many of the existing methods produce a low dimensional representation that attempts to describe the intrinsic geometric structure of the original data. Typically, this process is computationally expensive and the produced embedding is limited to the training data. In many real life scenarios, the ability to produce embedding of unseen samples is essential. In this paper we propose a Bayesian non-parametric approach for out-of-sample extension. The method is based on Gaussian Process Regression and independent of the manifold learning algorithm. Additionally, the method naturally provides a measure for the degree of abnormality for a newly arrived data point that did not participate in the training process. We derive the mathematical connection between the proposed method and the Nystrom extension and show that the latter is a special case of the former. We present extensive experimental results that demonstrate the performance of the proposed method and compare it to other existing out-of-sample extension methods.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738832","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738832","","Computational modeling;Gaussian processes;Ground penetrating radar;Kernel;Manifolds;Training;Training data","Bayes methods;Gaussian processes;data analysis;data structures;regression analysis","Bayesian nonparametric approach;Gaussian process regression;Nystrom extension;high dimensional data analysis;intrinsic geometric structure;low dimensional representation;manifold learning algorithm;manifold learning methods;mathematical connection;out-of-sample extension;training process","","1","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Restricted Boltzmann Machine for Nonlinear System Modeling","E. D. l. Rosa; W. Yu","Dept. de Control Automatico, CINVESTAV-IPN (Nat. Polytech. Inst.), Mexico City, Mexico","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","443","446","In this paper, we use a deep learning method, restricted Boltzmann machine, for nonlinear system identification. The neural model has deep architecture and is generated by a random search method. The initial weights of this deep neural model are obtained from the restricted Boltzmann machines. To identify nonlinear systems, we propose special unsupervised learning methods with input data. The normal supervised learning is used to train the weights with the output data. The modified algorithm is validated by modeling two benchmark systems.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424354","deep learning;modeling;restricted Boltzmann machine","Benchmark testing;Machine learning;Nonlinear systems;Probability distribution;Search methods;Training;Unsupervised learning","Boltzmann machines;identification;nonlinear systems;search problems;unsupervised learning","deep learning method;neural model;nonlinear system identification;nonlinear system modeling;normal supervised learning;random search method;restricted Boltzmann machine;unsupervised learning methods","","","","18","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Statistical Measures of Dependence for Financial Data","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","This chapter provides the statistical measures of dependence for financial data. The analysis of financial and econometric data is typified by non-Gaussian multivariate observations that exhibit complex dependencies: heavy-tailed and skewed marginal distributions are commonly encountered; serial dependence, such as autocorrelation and conditional heteroscedasticity. When data are assumed to be jointly Gaussian, all dependence is linear, and therefore only pairwise among the variables. In this setting, Pearson's product-moment correlation coefficient uniquely characterizes the sign and strength of any such dependence. The chapter shows that copulas can be used to model the dependence between random variables. It turns our attention to the dependence structure itself, and when appropriate makes connections to copulas. The chapter describes different types of dependence, and then provides theoretical background.","","97811187455","10.1002/9781118745540.ch8","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471040.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Binary independent component analysis: Theory, bounds and algorithms","A. Painsky; S. Rosset; M. Feder","Tel Aviv University, Statistics Department, Ramat Aviv, Israel","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Independent Component Analysis (ICA) is a statistical method for transforming an observable multi-dimensional random vector into components that are as statistically independent as possible from each other. The binary ICA (BICA) is a special case of ICA in which both the observations and the independent components are over a binary alphabet. The BICA problem has received a significant amount of attention in the past decade, mostly in the form of algorithmic approaches and heuristic solutions. However, BICA still suffers from a substantial lack of theoretical bounds and efficiency guarantees. In this work we address these concerns, as we introduce novel lower bounds and theoretical properties for the BICA problem, both under linear and non-linear transformations. In addition, we present simple algorithms which apply our methodology and achieve favorable merits, both in terms of their accuracy, and their practically optimal computational complexity.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738870","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738870","BICA;ICA;factorial codes;minimal redundancy representation;minimum entropy encoding","Algorithm design and analysis;Computational complexity;Encoding;Entropy;Independent component analysis;Signal processing algorithms;Two dimensional displays","computational complexity;independent component analysis;multidimensional signal processing;random processes","BICA;algorithms;binary ICA;binary alphabet;binary independent component analysis;linear transformations;observable multidimensional random vector transformation;optimal computational complexity;statistical method;statistically independent source signals;theoretical bounds","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Source-Aware Partitioning for Robust Cross-Validation","O. Kilinc; I. Uysal","Electr. Eng., Univ. of South Florida, Tampa, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1083","1088","One of the most critical components of engineering a machine learning algorithm for a live application is robust performance assessment prior to its implementation. Cross-validation is used to forecast a specific algorithm's classification or prediction accuracy on new input data given a finite dataset for training and testing the algorithm. Two most well known cross-validation techniques, random subsampling (RSS) and K-fold, are used to generalize the assessment results of machine learning algorithms in a non-exhaustive random manner. In this work we first show that for an inertia based activity recognition problem where data is collected from different users of a wrist-worn wireless accelerometer, random partitioning of the data, regardless of cross-validation technique, results in statistically similar average accuracies for a standard feed-forward neural network classifier. We propose a novel source-aware partitioning technique where samples from specific users are completely left out of the training/validation sets in rotation. The average error for the proposed cross-validation method is significantly higher with lower standard variation, which is a major indicator of cross-validation robustness. Approximately 30% increase in average error rate implies that source-aware cross validation could be a better indication of live algorithm performance where test data statistics would be significantly different than training data due to source (or user)-sensitive nature of process data.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.216","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424464","cross-validation;machine learning;robust learning;source-aware","Algorithm design and analysis;Feature extraction;Partitioning algorithms;Robustness;Testing;Time-domain analysis;Training","accelerometers;error statistics;feedforward neural nets;learning (artificial intelligence);pattern classification;sampling methods","RSS;average error rate;cross-validation method;cross-validation robustness;cross-validation technique;finite dataset;inertia based activity recognition problem;k-fold;live algorithm performance;machine learning algorithm;prediction accuracy;random data partitioning;random subsampling;robust cross-validation;robust performance assessment;source-aware cross validation;source-aware partitioning technique;specific algorithm classification;standard feedforward neural network classifier;test data statistics;wrist-worn wireless accelerometer","","","","12","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Sparse-coded net model and applications","Y. Gwon; M. Cha; W. Campbell; H. T. Kung; C. K. Dagli","MIT Lincoln Laboratory","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","As an unsupervised learning method, sparse coding can discover high-level representations for an input in a large variety of learning problems. Under semi-supervised settings, sparse coding is used to extract features for a supervised task such as classification. While sparse representations learned from unlabeled data independently of the supervised task perform well, we argue that sparse coding should also be built as a holistic learning unit optimizing on the supervised task objectives more explicitly. In this paper, we propose sparse-coded net, a feedforward model that integrates sparse coding and task-driven output layers, and describe training methods in detail. After pretraining a sparse-coded net via semi-supervised learning, we optimize its task-specific performance in a novel backpropagation algorithm that can traverse nonlinear feature pooling operators to update the dictionary. Thus, sparse-coded net can be applied to supervised dictionary learning. We evaluate sparse-coded net with classification problems in sound, image, and text data. The results confirm a significant improvement over semi-supervised learning as well as superior classification performance against deep stacked autoencoder neural network and GMM-SVM pipelines in small to medium-scale settings.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738828","","Data models;Dictionaries;Encoding;Feature extraction;Pipelines;Semisupervised learning;Training","backpropagation;encoding;feature extraction;feedforward neural nets;signal classification;signal representation;unsupervised learning","GMM-SVM pipelines;backpropagation algorithm;deep stacked autoencoder neural network;feature extraction;feedforward model;high-level representations;holistic learning unit;nonlinear feature pooling operators;semisupervised learning;sparse representations;sparse-coded net model;supervised dictionary learning;task-driven output layers;unsupervised learning","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"iClass: Combining Multiple Multi-label Classification with Expert Knowledge","M. Moussa; M. Maynard","Dept. of Comput. Sci. & Eng., Univ. of Connecticut, Storrs, CT, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","843","848","Roper Center is one of the largest public opinion data archives in the world. It collects data sets of polled survey questions from numerous media outlets and organizations. The volume of data introduces search complexities over survey questions and poses challenges when analyzing search trends. Roper Center question-level retrieval applications used human metadata experts to assign topics to content. This has been insufficient to reach required levels of consistency and provides an inadequate base for creating an advanced search experience. The objective of this work is to combine the human expert teams' knowledge of the nature of the survey questions and the concepts and topics these questions express, with the ability of multi-label classifiers to learn this knowledge and apply it to an automated, fast and accurate classification mechanism. This approach cuts down the question analysis and tagging time significantly as well as provides enhanced consistency and scalability for topics' descriptions. At the same time, creating an ensemble of machine learning classifiers combined with expert knowledge is expected to enhance the search experience and provide much needed analytic capabilities to the survey questions databases. In our design, we use classification from several machine learning algorithms like SVM and Decision Trees, combined with expert knowledge in form of handcrafted rules, data analysis and result review. We consolidate the different techniques into a Multipath Classifier with a Confidence point system that decides upon the relevance of topics assigned to survey questions with nearly perfect accuracy.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424427","ensembles;expert knowledge;knowledge base;machine learning;multi-label classifiers;supervised learning;survey datasets","Data analysis;Databases;Decision trees;Machine learning algorithms;Support vector machines;Testing;Training","data analysis;human factors;information retrieval;learning (artificial intelligence);pattern classification","Roper Center question-level retrieval application;confidence point system;data analysis;handcrafted rule;human metadata expert;iClass;machine learning algorithm;machine learning classifier;multiple multilabel classifiers ability;public opinion data;search experience","","","","9","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Combined unsupervised and semi-supervised learning for data classification","F. A. Breve; D. C. G. Pedronette","Department of Statistics, Applied Mathematics and Computing (DEMAC) State University of S&#x00E3;o Paulo (UNESP) Rio Claro - Brazil","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Semi-supervised learning methods exploit both labeled and unlabeled data items in their training process, requiring only a small subset of labeled items. Although capable of drastically reducing the costs of labeling process, such methods are directly dependent on the effectiveness of distance measures used for building the kNN graph. On the other hand, unsupervised distance learning approaches aims at capturing and exploiting the dataset structure in order to compute a more effective distance measure, without the need of any labeled data. In this paper, we propose a combined approach which employs both unsupervised and semi-supervised learning paradigms. An unsupervised distance learning procedure is performed as a pre-processing step for improving the kNN graph effectiveness. Based on the more effective graph, a semi-supervised learning method is used for classification. The proposed Combined Unsupervised and Semi-Supervised Learning (CUSSL) approach is based on very recent methods. The Reciprocal kNN Distance is used for unsupervised distance learning tasks and the semi-supervised learning classification is performed by Particle Competition and Cooperation (PCC). Experimental results conducted in six public datasets demonstrated that the combined approach can achieve effective results, boosting the accuracy of classification tasks.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738877","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738877","Data Classification;Semi-Supervised Learning;Unsupervised Learning","Computational modeling;Computer aided instruction;Euclidean distance;Labeling;Semisupervised learning;Supervised learning;Training","data handling;graph theory;pattern classification;unsupervised learning","CUSSL approach;PCC;combined unsupervised-semisupervised learning;data classification;dataset structure;distance measure;kNN graph;particle competition and cooperation;reciprocal kNN distance;unlabeled data;unsupervised distance learning","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"An Automatic Recognition for the Auditory Brainstem Response Waveform","B. Uragun","Physiol. Dept., Monash Univ. Clayton, Clayton, VIC, Australia","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","423","428","The Auditory Brainstem Response (ABR) is Brainstem Auditory Evoked potentials and often used in the neurophysiology. The waveform of ABR is usually recorded right after stimulation applied, as a response characteristic with a five peaks. These each peaks from the recording electrodes is identified by (a) neural transmission times and (b) amplitude in measured potentials. These sequential of few msec peaks with the amplitude are all correlated each other to form a unique-pattern and that can be observed as a health-monitoring indicator. In this paper, an automatic recognition pattern for ABR waveform is proposed. Firstly, diverse ABR applications and recent techniques reviewed. Than, knowledge based information obtained from these recent techniques to develop a similar methodology, secondly to model the complete set of peaks in the ABR waveform. Several curve fitted functions tested to narrow down the suitable function to be used for the ABR model. The outcome is the parameter of this mathematical modelling of ABR pattern, and put forward the use for an automatic health diagnostic tool as a machine learning application.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424350","Auditory Brainstem Response;Automatic Health Diagnostic System;Neurophysiology;machine learning;mathematical modelling","Auditory system;Electric potential;Electrodes;Mathematical model;Pediatrics;Rats;Speech","auditory evoked potentials;biomedical engineering;curve fitting;neurophysiology;pattern recognition","ABR applications;ABR waveform;auditory brainstem response waveform;automatic health diagnostic tool;automatic recognition pattern;brainstem auditory evoked potentials;curve fitted functions;health-monitoring indicator;machine learning application;mathematical modelling;msec peaks;neural transmission times;neurophysiology;recording electrodes","","","","73","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Improving speech recognition using limited accent diverse British English training data with deep neural networks","M. Najafian; S. Safavi; J. H. L. Hansen; M. Russell","Center for Robust Speech Systems, University of Texas at Dallas, Richardson, TX, USA","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Despite the recent advances in acoustic modelling tasks modelling speech data coming from different speakers with varying accents, age, and speaking styles is a fundamental challenge for Deep Neural Networks (DNNs) based Automatic Speech Recognition (ASR). A relative gain of 46.85% is achieved in recognising the Accents of British Isles corpus by applying a baseline DNN model rather than a Gaussian mixture model. However, even for powerful DNN based systems accents remain a challenge. Our study shows that for a `difficult' accent such as Glaswegian the relative word error rate is 78.9% higher than that of the standard southern English accent. In this work we propose four multi-accent learning strategies, and evaluate their effectiveness within the context of DNN based acoustic modelling framework. Using an i-vector based accent identification system with 78% accuracy to label the training data. We present a novel study on the effect of increase in the accent diversity, the `difficulty' and the amount of supplemented training data on the ASR performance. On average a further ASR gain of 27.24 % is achieved using the proposed strategies. Our results show that across all accent regions supplementing the training set with a small amount of data from the most `difficult' accent (2.25 hours of Glaswegian accent) leads to a similar gain in performance as using a large amount of accent diverse data (8.96 hours from 14 accent regions). Although the ideas presented are focused on DNN based analysis with limited amount of multi-accented data, they are applicable for training all classifiers with multi-conditional limited resources.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738854","British accents;Speech recognition;deep neural network;i-Vector;limited resources","Acoustics;Data models;Neural networks;Speech;Speech recognition;Training;Training data","Gaussian processes;acoustic signal processing;mixture models;natural language processing;neural nets;speech recognition","ASR;British Isles corpus;DNNs;Gaussian mixture model;Glaswegian accent;acoustic modelling;automatic speech recognition;deep neural networks;i-vector based accent identification system;multiaccent learning strategies","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"On the use of gradient information in Gaussian process quadratures","J. Prüher; S. Särkkä","University of West Bohemia, Pilsen, Czech Republic","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Gaussian process quadrature is a promising alternative Bayesian approach to numerical integration, which offers attractive advantages over its well-known classical counterparts. We show how Gaussian process quadrature can naturally incorporate gradient information about the integrand. These results are applied for the design of transformation of means and covariances of Gaussian random variables. We theoretically analyze connections between our proposed moment transform and the linearization transform based on Taylor series. Numerical experiments on common sensor network nonlinearities show that adding gradient information improves the resulting estimates.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738903","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738903","Bayesian quadrature;Gaussian process quadrature;derivative;gradient;moment transformation","Bayes methods;Gaussian processes;Kernel;Manganese;Random variables;Transforms;Uncertainty","Gaussian processes;covariance analysis;integration;random processes;series (mathematics);transforms","Gaussian process quadratures;Gaussian random variables;Taylor series;covariances;gradient information;integrand;linearization transform;moment transform;numerical integration;sensor network nonlinearities","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Detecting trends in twitter time series","T. De Bie; J. Lijffijt; C. Mesnage; R. Santos-Rodríguez","Data Science Lab, Ghent University - iMinds, Belgium","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Detecting underlying trends in time series is important in many settings, such as market analysis (stocks, social media coverage) and system monitoring (production facilities, networks). Although many properties of the trends are common across different domains, others are domain-specific. In particular, modelling human activities such as their behaviour on social media, often leads to sharply defined events separated by periods without events. This paper is motivated by time series representing the number of tweets per day addressed to a specific Twitter user. Such time series are characterized by the combination of (1) an underlying trend, (2) concentrated bursts of activity that can be arbitrarily large, often attributable to an event, e.g., a tweet that goes viral or a real-world event, and (3) random fluctuations/noise. We present a new probabilistic model that accurately models such time series in terms of peaks on top of a piece-wise exponential trend. Fitting this model can be done by solving an efficient convex optimization problem. As an empirical validation of the approach, we illustrate how this model performs on a set of Twitter time series, each one addressing a particular music artist, which we manually annotated with events as a reference.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738815","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738815","Trend detection;convexity;time series","Graphical models;Market research;Maximum likelihood estimation;Probabilistic logic;Time measurement;Time series analysis;Twitter","convex programming;information retrieval;music;probability;random noise;social networking (online);time series","Twitter time series;convex optimization;human activities;music artist;piece-wise exponential trend;probabilistic model;random fluctuations;random noise;trend detection","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Parameter estimation in conditionally Gaussian pairwise Markov switching models and unsupervised smoothing","F. Zheng; S. Derrode; W. Pieczynski","&#x00C9;cole Centrale de Lyon, LIRIS, CNRS UMR 5205, &#x00C9;cully, France","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Automatic identification of jump Markov systems (JMS) is known to be an important but difficult problem. In this work, we propose a new algorithm for the unsupervised estimation of parameters in a class of linear JMS called “conditionally Gaussian pairwise Markov switching models” (CGPMSMs), which extends the family of classic “conditionally Gaussian linear state-space models” (CGLSSMs). The method makes use of a particular CGPMSM called “conditionally Gaussian observed Markov switching model” (CGOMSM). The algorithm proposed consists in applying two EM algorithms sequentially: the first one is used to estimate the parameters and switches of the discrete pairwise Markov chain (PMC), which is a part of CGOMSM. Once estimated, it is used to sample switches and then the second one, called switching EM, is used to estimate the parameters of the distribution driving hidden states given the observations and the switches. The entire algorithm is evaluated with respect to data simulated according to CGPMSMs, and comparisons with several supervised methods attest its good efficiency.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738907","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738907","Expectation-Maximization;Jump Markov linear systems;parameter estimation","Approximation algorithms;Estimation;Markov processes;Parameter estimation;Signal processing algorithms;Smoothing methods;Switches","Gaussian processes;Markov processes;parameter estimation;smoothing methods;state-space methods","CGLSSM;CGOMSM;CGPMSM;PMC;automatic jump Markov system identification;conditionally Gaussian linear state-space models;conditionally Gaussian pairwise Markov switching models;discrete pairwise Markov chain;hidden states;switching EM;unsupervised parameter estimation;unsupervised smoothing","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Index","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","","","97811187455","10.1002/9781118745540.index","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471091.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Investigating Eating Behaviours Using Topic Models","R. White; W. S. Harwin; W. Holderbaum; L. Johnson","Sch. of Syst. Eng., Univ. of Reading, Reading, UK","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","265","270","Chronic conditions, such as diabetes and obesity are related to quality of diet. However, current research findings are conflicting with regards to the impact of snacking on diet quality. One reason for this is the lack of a clear definition of a snack or a meal. This paper presents a novel approach to understanding how foods are grouped together in eating events using a machine learning algorithm, topic models. Approaches for applying topic models to a nutrition application are discussed. A topic model is implemented for the UK National Diet and Nutrition Survey Rolling Programme dataset. The results demonstrate that the topics found are representative of typical eating events in terms of food group content and associated time of day. There is a strong potential for topic models to reveal useful patterns in food diary data that have not previously been considered.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424319","nutrition;routine behaviours;snacks;topic models;unsupervised learning","Data models;Graphical models;Machine learning algorithms;Mathematical model;Resource management;Vocabulary","health care;learning (artificial intelligence)","UK National Diet and Nutrition Survey Rolling Programme dataset;chronic conditions;diabetes;diet quality;eating behaviours;food diary data;machine learning algorithm;nutrition application;obesity;topic models","","","","18","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Dirichlet mixture allocation","J. T. Chien; C. H. Lee; Z. H. Tan","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","The topic model based on latent Dirichlet allocation relies on the prior statistics of topic proportionals for multinomial words. The words in a document are modeled as a random mixture of latent topics which are drawn from a single Dirichlet prior. However, a single Dirichlet distribution may not sufficiently characterize the variations of topic proportionals estimated from the heterogeneous documents. To deal with this concern, we present a Dirichlet mixture allocation (DMA) model which learns latent topics and their proportionals for topic and document clustering by using the prior based on a Dirichlet mixture model. Multiple Dirichlets pave a way to capture the structure of latent variables in learning representation from real-world documents covering a variety of topics. This paper builds a new latent variable model and develops a variational Bayesian inference procedure to learn model parameters consisting of mixture weights, Dirichlet parameters and word multinomials. Experiments on document representation show the merit of the proposed structural learning by increasing the number of Dirichlets in a DMA topic model.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738866","Bayesian learning;Dirichlet mixture model;structural learning;topic model","Bayes methods;Biological system modeling;Encoding;Mixture models;Probabilistic logic;Resource management;Signal processing","Bayes methods;inference mechanisms;learning (artificial intelligence);mixture models;pattern clustering;word processing","DMA topic model;Dirichlet mixture allocation;Dirichlet parameters;document clustering;document representation;latent topics;latent variable model;latent variables;learning representation;model parameters;random mixture;structural learning;variational Bayesian inference;word multinomials","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A Neural Network Based Handover Management Strategy for Heterogeneous Networks","N. M. Alotaibi; S. S. Alwakeel","Coll. of Comput. & Inf. Sci., Comput. Eng. Dept., King Saud Univ., Riyadh, Saudi Arabia","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1210","1214","One of the key challenges for improvement of quality of services (QoS) in Heterogeneous wireless networks is the design of Vertical Handover (VHO) Management strategy. VHO is required to guide the decision for a mobile terminal (MT) to handoff between different types of networks. This is an essential task to cope with various multimedia services QoS settings. In this paper, we present a machine learning scheme based on Neural Network for calls vertical handover in heterogeneous networks. The Neural Network Based Handover Management Scheme (NNBHMS) of this paper aims toward achieving seamless connectivity and Always Best Connected (ABC) call status for group mobility over a set of heterogeneous networks. The proposed scheme evaluates and creates relationships between different decision criteria related to heterogeneous networks conditions, terminal capabilities, application requirements, and user preferences. Afterward, the estimates of each attribute are forwarded to neural network to select the optimal access network. The proposed scheme is applied for vertical handover Management in heterogeneous networks offering both real time services (voice over IP services), and data Services (packet data traffic). Through the implementation of neural networks based machine learning approach, the proposed research scheme allows solving the complexity of the handover decision process resulting from the multitude dimensions of the decision criteria and the dynamicity of many of its components. The performance results evaluated through simulation show that the use of the a neural network based machine learning scheme to carry out the Handover process can enhance the QoS perceived by both types of voice and data service while fulfilling to great extent the user preference.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424486","Neural Network classifier;Neural network based Machine learning;QoS over heterogeneous networks;Vertical Handoff (VHO)","Artificial neural networks;Bandwidth;Handover;Quality of service;Wireless networks","learning (artificial intelligence);mobility management (mobile radio);neural nets;quality of service","QoS;always-best-connected call status;group mobility;heterogeneous wireless network;machine learning;multimedia service;neural network;packet data traffic;quality of service;seamless connectivity;vertical handover management strategy;voice over IP service","","","","18","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Convex nonnegative matrix factorization with missing data","R. Hamon; V. Emiya; C. Févotte","Aix Marseille Univ, CNRS, LIF, Marseille, France","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Convex nonnegative matrix factorization (CNMF) is a variant of nonnegative matrix factorization (NMF) in which the components are a convex combination of atoms of a known dictionary. In this contribution, we propose to extend CNMF to the case where the data matrix and the dictionary have missing entries. After a formulation of the problem in this context of missing data, we propose a majorization-minimization algorithm for the solving of the optimization problem incurred. Experimental results with synthetic data and audio spectrograms highlight an improvement of the performance of reconstruction with respect to standard NMF. The performance gap is particularly significant when the task of reconstruction becomes arduous, e.g. when the ratio of missing data is high, the noise is steep, or the complexity of data is high.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738910","low-rankness;matrix completion;matrix factorization;nonnegativity;spectrogram inpainting","Context;Dictionaries;Image reconstruction;Matrix decomposition;Minimization;Radio frequency;Spectrogram","audio signal processing;convex programming;matrix decomposition;minimisation","CNMF;audio spectrograms;convex combination;convex nonnegative matrix factorization;data matrix;dictionary;majorization-minimization algorithm;missing data","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Detection of SSH Brute Force Attacks Using Aggregated Netflow Data","M. M. Najafabadi; T. M. Khoshgoftaar; C. Calvert; C. Kemp","Florida Atlantic Univ., Boca Raton, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","283","288","The SSH Brute force attack is one of the most prevalent attacks in computer networks. These attacks aim to gain ineligible access to users' accounts by trying plenty of different password combinations. The detection of this type of attack at the network level can overcome the scalability issue of host-based detection methods. In this paper, we provide a machine learning approach for the detection of SSH brute force attacks at the network level. Since extracting discriminative features for any machine learning task is a fundamental step, we explain the process of extracting discriminative features for the detection of brute force attacks. We incorporate domain knowledge about SSH brute force attacks as well as the analysis of a representative collection of the data to define the features. We collected real SSH traffic from a campus network. We also generated some failed login data that a legitimate user who has forgotten his/her password can produce as normal traffic that can be similar to the SSH brute force attack traffic. Our inspection on the collected brute force Netflow data and the manually produced SSH failed login data showed that the Netflow features are not discriminative enough to discern brute force traffic from the failed login traffic produced by a legitimate user. We introduced an aggregation of Netflows to extract the proper features for building machine learning models. Our results show that the models built upon these features provide excellent performances for the detection of brute force attacks.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424322","Aggregated Netflows;Brute Force;Intrusion Detection;Machine Learning","Computational modeling;Computer networks;Data mining;Feature extraction;Force;Intrusion detection","computer network security;learning (artificial intelligence);telecommunication traffic","Netflow data;Netflow feature;SSH brute force attack traffic;SSH failed login data;SSH traffic;aggregated netflow data;campus network;computer network;discern brute force traffic;extracting discriminative feature;failed login traffic;host-based detection method;inspection;legitimate user;machine learning approach;machine learning model;machine learning task;network level;password combination;prevalent attack;representative collection","","1","","21","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Fully Bayesian tensor-based regression","F. Camarrone; M. M. Van Hulle","KU Leuven - University of Leuven, Laboratory for Neuro- & Psychophysiology, B-3000 Leuven, Belgium","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","N-way (or multiway) Partial Least Squares (NPLS) regression is a successful algorithm for solving ill-conditioned and high-dimensional problems. However, the selection of the latent space dimensionality, when performed manually, becomes a critical issue in the presence of irrelevant, redundant and noisy information and can lead to overfitting, and when using cross-validation one can still not guarantee a good predictive performance. We propose a fully Bayesian N-way partial least squares regression (BNPLS) with an automatic relevance determination (ARD) prior on the factor matrices so that the number of latent components can be determined automatically without requiring specific assumptions. Using synthetic data, we compare the performance of BNPLS with conventional NPLS, standard partial least squared (PLS) and state-of-the-art higher-order PLS (HOPLS). Results show that BNPLS consistently achieves a better or comparable performance.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738860","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738860","Bayesian learning;NPLS;PLS;multilinear regression;tensor-based regression","Bayes methods;Computational modeling;Convergence;Loading;Predictive models;Standards;Tensile stress","Bayes methods;belief networks;data handling;feature selection;learning (artificial intelligence);matrix algebra;regression analysis;tensors","ARD;BNPLS;Bayesian N-way partial least squares regression;Bayesian learning;Bayesian tensor-based regression;automatic relevance determination;data handling;factor matrix;latent space dimensionality selection","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Projection predictive model selection for Gaussian processes","J. Piironen; A. Vehtari","Helsinki Institute for Information Technology HIIT, Department of Computer Science, Aalto University","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We propose a new method for simplification of Gaussian process (GP) models by projecting the information contained in the full encompassing model and selecting a reduced number of variables based on their predictive relevance. Our results on synthetic and real world datasets show that the proposed method improves the assessment of variable relevance compared to the automatic relevance determination (ARD) via the length-scale parameters. We expect the method to be useful for improving explainability of the models, reducing the future measurement costs and reducing the computation time for making new predictions.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738829","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738829","ARD;Gaussian processes;model selection;variable selection","Computational modeling;Data models;Gaussian processes;Input variables;Mathematical model;Predictive models;Training","Gaussian processes","ARD;GP models;Gaussian processes;automatic relevance determination;computation time;full encompassing model;length-scale parameters;predictive relevance;projection predictive model selection;real world datasets","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Prediction of Users' Response Time in Q&A Communities","N. Burlutskiy; A. Fish; N. Ali; M. Petridis","Sch. of Comput., Eng. & Math., Univ. of Brighton, Brighton, UK","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","618","623","Social media and online Question and Answer (Q&A) communities in particular have become a successful solution for finding answers on diverse topics. However, not all questions are answered by these communities. Also, many questions are not answered quickly enough. In this paper, we propose a framework for predicting users' response time. The framework uses a diverse set of features including information on users, the content they generate while communicating, question tags, spatial and temporal features. Then these features are used as input for training predictive models by various machine learning algorithms. As a case study, three diverse Q&A communities from Stack Exchange are selected to test the framework. We demonstrate that Deep Belief Networks outperform Logistic Regression (LR), k-nearest neighbors (k-NN), and Decision Trees (DT) in the accuracy of the prediction across the three diverse Q&A communities.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424386","Social media;machine learning;temporal user behavior","Algorithm design and analysis;Context;Electronic mail;Prediction algorithms;Predictive models;Time factors;Twitter","belief networks;decision trees;learning (artificial intelligence);question answering (information retrieval);regression analysis;social networking (online)","DT;LR;Q&A communities;decision trees;deep belief networks;k-NN;k-nearest neighbors;logistic regression;machine learning algorithms;online question and answer communities;predictive modeltraining;social media;stack exchange;user response time prediction","","","","21","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Speaker identification and clustering using convolutional neural networks","Y. Lukic; C. Vogt; O. Dürr; T. Stadelmann","Zurich University of Applied Sciences, Winterthur, Switzerland","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Deep learning, especially in the form of convolutional neural networks (CNNs), has triggered substantial improvements in computer vision and related fields in recent years. This progress is attributed to the shift from designing features and subsequent individual sub-systems towards learning features and recognition systems end to end from nearly unprocessed data. For speaker clustering, however, it is still common to use handcrafted processing chains such as MFCC features and GMM-based models. In this paper, we use simple spectrograms as input to a CNN and study the optimal design of those networks for speaker identification and clustering. Furthermore, we elaborate on the question how to transfer a network, trained for speaker identification, to speaker clustering. We demonstrate our approach on the well known TIMIT dataset, achieving results comparable with the state of the art-without the need for handcrafted features.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738816","Convolutional Neural Network;Speaker Clustering;Speaker Identification","Convolution;Neural networks;Speaker recognition;Spectrogram;Speech;Speech recognition;Training","convolution;learning (artificial intelligence);neural nets;pattern clustering;speaker recognition","GMM-based models;MFCC features;TIMIT dataset;convolutional neural networks;deep learning;speaker clustering;speaker identification;spectrograms","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Regression Models in Risk Management","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","This chapter discusses theory and application of generalized linear regression that minimizes a general error measure of regression residual subject to various constraints on regression coefficients and includes least-squares linear regression, median regression, quantile regression, mixed quantile regression, and robust regression as special cases. Application of generalized linear regression includes examples of financial index tracking, sparse signal reconstruction, therapy treatment planning, collateralized debt obligation, mutual fund return-based style classification, and mortgage pipeline hedging. The chapter introduces risk envelopes and risk identifiers, and also states the error decomposition theorem. It discusses special types of unconstrained and constrained linear regressions encountered in statistical decision problems. Constrained least-squares linear regression is used in an intensity-modulated radiation therapy (IMRT) treatment-planning problem. Robust regression aims to reduce influence of sample outliers on regression parameters, especially when regression error has heavy tails.","","97811187455","10.1002/9781118745540.ch11","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7470994.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Flow of Renyi information in deep neural networks","C. W. Huang; S. S. S. Narayanan","Signal Analysis and Interpretation Laboratory (SAIL), University of Southern California","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","We propose a rate-distortion based deep neural network (DNN) training algorithm using a smooth matrix functional on the manifold of positive semi-definite matrices as the non-parametric entropy estimator. The objective in the optimization function includes not only the measure of performance of the output layer but also the measure of information distortion between consecutive layers in order to produce a concise representation of its input on each layer. An experiment on speech emotion recognition shows the DNN trained by such method reaches comparable performance with an encoder-decoder system.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738809","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738809","Deep learning;Information-theoretic learning;Renyi entropy;artificial neural network","Biological neural networks;Distortion;Distortion measurement;Entropy;Optimization;Random variables;Rate-distortion","entropy;estimation theory;learning (artificial intelligence);matrix algebra","DNN training algorithm;Renyi information flow;information distortion measure;nonparametric entropy estimator;optimization function;positive semi-definite matrices;rate-distortion based deep neural network;smooth matrix functional;speech emotion recognition","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"Bayesian nonparametric methods for discovering latent structures of rat hippocampal ensemble spikes","Z. Chen; S. W. Linderman; M. A. Wilson","Department of Psychiatry, NYU School of Medicine","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Hippocampal functions are responsible for encoding spatial and temporal dimensions of episodic memory, and hippocampal reactivation of previous awake experiences in sleep is important for learning and memory consolidation. Therefore, uncovering neural representations of hippocampal ensemble spike activity during various behavioral states would provide improved understanding of neural mechanisms of hippocampal-cortical circuits. In this paper, we propose two Bayesian nonparametric methods for this purpose: the Bayesian modeling allows to impose informative priors and constraints into the model, whereas Bayesian nonparametrics allows automatic model selection. We validate these methods to three different hippocampal ensemble recordings under different task behaviors, and provide interpretation and discussion on the derived results.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738867","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738867","Bayesian nonparametrics;hidden Markov model;hidden semi-Markov model;population codes","Bayes methods;Hidden Markov models;Integrated circuit modeling;Rats;Shape;Sociology;Statistics","Bayes methods;neural nets","Bayesian modeling;Bayesian nonparametric methods;Bayesian nonparametrics;automatic model selection;episodic memory;hippocampal ensemble recordings;hippocampal ensemble spike activity;hippocampal functions;hippocampal reactivation;hippocampal-cortical circuits;latent structure discovery;neural mechanisms;neural representations;rat hippocampal ensemble spikes;spatial dimension encoding;temporal dimension encoding","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A case study on feature sensitivity for audio event classification using support vector machines","I. Martín-Morató; M. Cobos; F. J. Ferri","Dept. Inform&#x00E0;tica. Universitat de Val&#x00E8;ncia, 46100 Burjassot, Spain","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","Automatic recognition of multiple acoustic events is an interesting problem in machine listening that generalizes the classical speech/non-speech or speech/music classification problem. Typical audio streams contain a diversity of sound events that carry important and useful information on the acoustic environment and context. Classification is usually performed by means of hidden Markov models (HMMs) or support vector machines (SVMs) considering traditional sets of features based on Mel-frequency cepstral coefficients (MFCCs) and their temporal derivatives, as well as the energy from auditory-inspired filterbanks. However, while these features are routinely used by many systems, it is not yet understood which is their relative importance in the classification task. This paper presents a preliminary study to assess the sensitivity of these features under a common SVM framework, aiming at providing deeper insight into appropriate low-level audio event representation for classification tasks.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738834","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738834","Audio event classification;feature selection;semantic audio;support vector machines","Feature extraction;Mel frequency cepstral coefficient;Sensitivity;Support vector machines;Training;Training data","acoustic signal processing;audio signal processing;audio streaming;cepstral analysis;channel bank filters;feature extraction;hidden Markov models;sensitivity analysis;signal classification;support vector machines","HMM;MFCC;Mel-frequency cepstral coefficients;SVM;audio event classification;auditory-inspired filterbanks;automatic acoustic event recognition;feature sensitivity;hidden Markov models;low-level audio event representation;machine listening;speech-music classification problem;speech-nonspeech classification problem;support vector machines;temporal derivatives","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A neural network based algorithm for speaker localization in a multi-room environment","F. Vesperini; P. Vecchiotti; E. Principi; S. Squartini; F. Piazza","Department of Information Engineering, Universit&#x00E0; Politecnica delle Marche Via Brecce Bianche, 60131, Ancona, Italy","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","A Speaker Localization algorithm based on Neural Networks for multi-room domestic scenarios is proposed in this paper. The approach is fully data-driven and employs a Neural Network fed by GCC-PHAT (Generalized Cross Correlation Phase Transform) Patterns, calculated by means of the microphone signals, to determine the speaker position in the room under analysis. In particular, we deal with a multi-room case study, in which the acoustic scene of each room is influenced by sounds emitted in the other rooms. The algorithm is tested against the home recorded DIRHA dataset, characterized by multiple wall and ceiling microphone signals for each room. In particular, we focused on the speaker localization problem in two distinct neighbouring rooms. We assumed the presence of an Oracle multi-room Voice Activity Detector (VAD) in our experiments. A three-stage optimization procedure has been adopted to find the best network configuration and GCC-PHAT Patterns combination. Moreover, an algorithm based on Time Difference of Arrival (TDOA), recently proposed in literature for the addressed applicative context, has been considered as term of comparison. As result, the proposed algorithm outperforms the reference one, providing an average localization error, expressed in terms of RMSE, equal to 525 mm against 1465 mm. Concluding, we also assessed the algorithm performance when a real VAD, recently proposed by some of the authors, is used. Even though a degradation of localization capability is registered (an average RMSE equal to 770 mm), still a remarkable improvement with respect to the state of the art performance is obtained.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738817","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738817","","Direction-of-arrival estimation;Estimation;Microphone arrays;Neural networks;Signal processing algorithms;Transforms","acoustic signal processing;mean square error methods;microphones;neural nets;optimisation;speaker recognition;time-of-arrival estimation","DIRHA dataset;GCC-PHAT patterns;Oracle multiroom voice activity detector;RMSE;TDOA;VAD;acoustic scene;ceiling microphone signals;generalized cross correlation phase transform patterns;multiroom domestic scenarios;multiroom environment;neural network;optimization;speaker localization;time difference of arrival;wall microphone signals","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"CVaR Minimizations in Support Vector Machines","A. N. Akansu; S. R. Kulkarni; D. M. Malioutov","","Financial Signal Processing and Machine Learning","20160518","2016","","","","","This chapter overview the connections between support vector machines (SVM) and conditional value at risk (CVaR) minimization and suggests further interactions beyond their similarity in appearance. It introduces several SVM formulations, whose relation to CVaR minimization. The chapter further discusses robust extensions of the CVaR formulation. It presents the dual problems of the CVaR-minimizing formulations, and shows that two kinds of robust modeling of the CVaR minimization for binary classification are tractable. Dual representations expand the range of algorithms and enrich the theory of SVM. SVMs are one of the most successful supervised learning methods that can be applied to classification or regression. The maximum margin hyperplane of hard-margin SVM classification (SVC) minimizes an upper bound of the generalization error. The support vector regression (SVR) method performs well in regression analysis and is a popular data analysis tool in machine learning and signal processing.","","97811187455","10.1002/9781118745540.ch10","http://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=7471095.pdf&bkn=7470479&pdfType=chapter","","","","","","","","","2016","","","","Wiley-IEEE Press","Wiley-IEEE Press eBook Chapters"
"Hyperspectral endmember spectra extraction based on constrained linear-quadratic matrix factorization using a projected gradient method","F. Z. Benhalouche; Y. Deville; M. S. Karoui; A. Ouamri","Institut de Recherche en Astrophysique et Plan&#x00E9;tologie (IRAP), Universit&#x00E9; de Toulouse, UPS-OMP, CNRS, Toulouse, France","2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)","20161110","2016","","","1","6","In this paper, a new projected-gradient method for linear-quadratic matrix factorization is proposed for extracting hyperspectral endmember spectra. The proposed method is designed for a linear-quadratic mixing model involved in urban hyperspectral remote sensing images. The reduction of the number of considered variables, when optimizing the used cost function, constitutes the main originality of the proposed method. The implemented optimization algorithm is suited for unsupervised processing of hyperspectral remote sensing images taking into account their nonnegativity. Experiments based on realistic synthetic data, formed according to the considered linear-quadratic mixing model, are carried out to evaluate the performance of the proposed method and compare it to that of other methods from the literature. The obtained results show that the proposed method yields better overall performance than the other approaches proposed in the literature, especially for urban spectra.","","Electronic:978-1-5090-0746-2; POD:978-1-5090-0747-9","10.1109/MLSP.2016.7738868","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738868","Hyperspectral imaging;endmember spectra extraction;linear-quadratic matrix factorization;projected gradient;unsupervised linear-quadratic spectral unmixing","Cost function;Data models;Hyperspectral imaging;Sensors","gradient methods;hyperspectral imaging;image processing;matrix decomposition;optimisation;remote sensing;spectral analysis","constrained linear-quadratic matrix factorization;cost function optimization;hyperspectral endmember spectra extraction;linear-quadratic mixing model;projected gradient method;unsupervised image processing;urban hyperspectral remote sensing image;urban spectra","","","","","","","13-16 Sept. 2016","","IEEE","IEEE Conference Publications"
"A Demonstration of Stability-Plasticity Imbalance in Multi-agent, Decomposition-Based Learning","S. C. Mondesire; R. P. Wiegand","Electr. Eng. & Comput. Sci., Univ. of Central Florida, Orlando, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","1070","1075","Layered learning is a machine learning paradigm used in conjunction with direct-policy search reinforcement learning methods to find high performance agent behaviors for complex tasks. At its core, layered learning is a decomposition-based paradigm that shares many characteristics with robot shaping, transfer learning, hierarchical decomposition, and incremental learning. Previous studies have provided evidence that layered learning has the ability to outperform standard monolithic methods of learning in many cases. The dilemma of balancing stability and plasticity is a common problem in machine learning that causes learning agents to compromise between retaining learned information to perform a task with new incoming information. Although existing work implies that there is a stability-plasticity imbalance that greatly limits layered learning agents' ability to learn optimally, no work explicitly verifies the existence of the imbalance or its causes. This work investigates the stability-plasticity imbalance and demonstrates that indeed, layered learning heavily favors plasticity, which can cause learned subtask proficiency to be lost when new tasks are learned. We conclude by identifying potential causes of the imbalance in layered learning and provide high level advice about how to mitigate the imbalance's negative effects.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424462","Decomposition-based Reinforcement Learning;Layered Learning;Stability-Plasticity Dilemma","Fuels;Learning (artificial intelligence);Navigation;Performance evaluation;Robots;Search problems;Training","learning (artificial intelligence);multi-robot systems;plasticity;stability","balancing stability;decomposition-based learning;decomposition-based paradigm;direct-policy search reinforcement learning method;hierarchical decomposition;high performance agent behavior;incoming information;incremental learning;layered learning agent ability;learned information;machine learning paradigm;multiagent learning;robot shaping;stability-plasticity imbalance;standard monolithic method;transfer learning","","","","12","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
