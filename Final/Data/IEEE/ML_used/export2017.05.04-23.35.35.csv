"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6728224,6656874,6722370,6720608,6720316,6723782,6724348,6722030,6724482,6724149,6720685,6724349,6721762,6723347,6717227,6710523,6714627,6712431,6713582,6688522,6706990,6707058,6703770,6587612,6701622,6707066,6701900,6707119,6701804,6698995,6698899,6699035,6692276,6697965,6558520,6612668,6693977,6691741,6691735,6689881,6685427,6687426,6681700,6685716,6568966,6680883,6679697,6479293,6680574,6596491,6678403,6676885,6676916,6676949,6674528,6675404,6676953,6666829,6560028,6576112,6531616,6459569,6531667,6661782,6664359,6661996,6662729,6662617,6657993,6657069,6653999,6649808,6651312,6650454,6649595,6646588,6648103,6642793,6645085,6646079,6635871,6635664,6635727,6632816,6631198,6514914,6633617,6635250,6632375,6632817,6634021,6628330,6630360,6628716,6625268,6625339,6623773,6619525,6627860,6622572",2017/05/04 23:35:35
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Machine Learning Based Knowledge Acquisition on Spectrum Usage for LTE Femtocells","G. Alnwaimi; T. Zahir; S. Vahid; K. Moessner","Centre for Commun. Syst. Res., Univ. of Surrey, Guildford, UK","2013 IEEE 78th Vehicular Technology Conference (VTC Fall)","20140102","2013","","","1","6","The decentralised and ad hoc nature of femtocell deployments calls for distributed learning strategies to mitigate interference. We propose a distributed spectrum awareness scheme for femtocell networks, based on combined payoff and strategy reinforcement learning (RL) models. We present two different learning strategies, based on modifications to the Bush Mosteller (BM) RL and the Roth-Erev RL algorithms. The simulation results show the convergence behaviour of the learning strategies under a dynamic robust game. As compared to the Bush Mosteller (BM) RL, our modified BM (MBM) converges smoothly to a stable satisfactory solution. Moreover, the MBM significantly reduces the interference collision cost during the learning process. Both the MBM and the modified Roth-Erev (MRE) algorithms are stochastic-based learning strategies which require less computation than the gradient follower (GF) learning strategy and have the capability to escape from suboptimal solution.","1090-3038;10903038","Electronic:978-1-4673-6187-3; POD:978-1-4673-6186-6","10.1109/VTCFall.2013.6692276","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6692276","","Convergence;Femtocell networks;Femtocells;Games;Heuristic algorithms;Interference;Macrocell networks","Long Term Evolution;ad hoc networks;femtocellular radio;interference suppression;knowledge acquisition;learning (artificial intelligence)","LTE femtocells;Roth-Erev RL algorithms;ad hoc nature;distributed spectrum awareness;dynamic robust game;femtocell deployments calls;femtocell networks;interference mitigation;knowledge acquisition;machine learning;modified Roth-Erev algorithms;reinforcement learning;spectrum usage","","4","","16","","","2-5 Sept. 2013","","IEEE","IEEE Conference Publications"
"FPGA prototype of machine learning analog-to-feature converter for event-based succinct representation of signals","S. M. del Campo; K. Albertsson; J. Nilsson; J. Eliasson; F. Sandin","SKF Univ. Technol. Center, Lulea Univ. of Technol., Lulea, Sweden","2013 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)","20131114","2013","","","1","6","Sparse signal models with learned dictionaries of morphological features provide efficient codes in a variety of applications. Such models can be useful to reduce sensor data rates and simplify the communication, processing and analysis of information, provided that the algorithm can be realized in an efficient way and that the signal allows for sparse coding. In this paper we outline an FPGA prototype of a general purpose “analog-to-feature converter”, which learns an over-complete dictionary of features from the input signal using matching pursuit and a form of Hebbian learning. The resulting code is sparse, event-based and suitable for analysis with parallel and neuromorphic processors. We present results of two case studies. The first case is a blind source separation problem where features are learned from an artificial signal with known features. We demonstrate that the learned features are qualitatively consistent with the true features. In the second case, features are learned from ball-bearing vibration data. We find that vibration signals from bearings with faults have characteristic features and codes, and that the event-based code enable a reduction of the data rate by at least one order of magnitude.","1551-2541;15512541","Electronic:978-1-4799-1180-6; POD:978-1-4799-1179-0; USB:978-1-4799-1178-3","10.1109/MLSP.2013.6661996","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6661996","","Dictionaries;Encoding;Field programmable gate arrays;MATLAB;Matching pursuit algorithms;Noise;Vibrations","blind source separation;field programmable gate arrays;iterative methods;learning (artificial intelligence);signal representation","FPGA prototype;Hebbian learning;ball-bearing vibration data;blind source separation;event-based code;event-based succinct representation;machine learning analog-to-feature converter;matching pursuit;morphological feature;neuromorphic processor;parallel processor;sensor data rate;sparse coding;sparse signal model","","1","","9","","","22-25 Sept. 2013","","IEEE","IEEE Conference Publications"
"Music classification using extreme learning machines","S. Scardapane; D. Comminiello; M. Scarpiniti; A. Uncini","Dept. of Inf. Eng., Electron. & Telecommun. (DIET), &#x201C;Sapienza&#x201D; Univ. of Rome, Rome, Italy","2013 8th International Symposium on Image and Signal Processing and Analysis (ISPA)","20140109","2013","","","377","381","Over the last years, automatic music classification has become a standard benchmark problem in the machine learning community. This is partly due to its inherent difficulty, and also to the impact that a fully automated classification system can have in a commercial application. In this paper we test the efficiency of a relatively new learning tool, Extreme Learning Machines (ELM), for several classification tasks on publicly available song datasets. ELM is gaining increasing attention, due to its versatility and speed in adapting its internal parameters. Since both of these attributes are fundamental in music classification, ELM provides a good alternative to standard learning models. Our results support this claim, showing a sustained gain of ELM over a feedforward neural network architecture. In particular, ELM provides a great decrease in computational training time, and has always higher or comparable results in terms of efficiency.","1845-5921;18455921","Electronic:978-953-184-194-8; POD:978-1-4799-3125-5; USB:978-953-184-187-0","10.1109/ISPA.2013.6703770","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703770","","Feature extraction;Multiple signal classification;Neural networks;Signal processing;Speech;Standards;Training","audio signal processing;feedforward neural nets;information retrieval;learning (artificial intelligence);music;signal classification","ELM;automated classification system;automatic music classification;automatic music retrieval;extreme learning machines;feedforward neural network architecture;learning tool","","6","","14","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Machine learning based fault prediction system for the primary heat transport system of CANDU type pressurized heavy water reactor","S. N. Ahsan; S. A. Hassan","Comput. Dev. Div., KANUPP Paradise Point, Karachi, Pakistan","2013 International Conference on Open Source Systems and Technologies","20140127","2013","","","68","74","In nuclear power reactor, temperature of the core has to be maintained within the safety limits. This can be achieved by monitoring and controlling the various system's parameter of nuclear reactor. One of the important system of nuclear reactor is primary heat transfer (PHT) system. Therefore, any fault in the PHT system may lead to the state where PHT parameters cross the safety limits, and reactor becomes unsafe for operation. To avoid such conditions various fault monitoring and controlling systems have been used in nuclear power reactors. In the recent years, machine learning techniques have been used to build automatic fault prediction system which can be used as a fault monitoring system of nuclear power plant. In this paper, we propose our approach to build machine learning based fault prediction system for the PHT system of CANDU (Canada Deuterium Uranium) type reactor. The proposed approach is based on the classification techniques of supervised machine learning. Whereas, to validate our approach, we performed an experiment by extracting the historical data of the following reactor's parameters: coolant flow rate, coolant header temperature, and neutron power rate. After extracting the parameter's data, we labeled the data with the following three plant statuses: running, transient and shutdown. Finally, we used the binary tree and artificial neural network techniques of machine learning and built models which successfully classified the three statuses of the plant. In our experiment, the maximum obtained accuracy of our model is 99%. It shows that our proposed system can be used to predict fault in PHT loop.","","CD-ROM:978-1-4799-2047-1; Electronic:978-1-4799-2046-4; POD:978-1-4799-2048-8","10.1109/ICOSST.2013.6720608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720608","formatting;insert;style;styling","Artificial neural networks;Coolants;Data mining;Fuels;Inductors;Temperature measurement;Transient analysis","fault tolerance;fission reactor coolants;fission reactors;learning (artificial intelligence);neural nets;nuclear power stations;pattern classification;power engineering computing;power system faults;trees (mathematics)","CANDU type pressurized heavy water reactor;Canada deuterium uranium;PHT parameters;PHT system;artificial neural network techniques;automatic fault prediction system;binary tree;classification techniques;coolant flow rate;coolant header temperature;data extraction;data labeling;fault control systems;fault monitoring systems;fault prediction system;neutron power rate;nuclear power reactor;plant running state;plant shutdown state;plant transient state;primary heat transport system;supervised machine learning","","0","","19","","","16-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Diffracted image restoration: A machine learning approach","V. Koudelka; C. del Rio Bocio; Z. Raida","Department of Radio-Electronics, Brno University of Technology, Technicka 12, 616 00 Brno, The Czech Republic","2013 International Conference on Electromagnetics in Advanced Applications (ICEAA)","20131017","2013","","","931","934","Image restoration issues are closely connected with imaging systems, where image resolution is limited by diffraction phenomenon. The presented work is motivated by the super acuity of the Human vision, where the restoration step is implemented by some kind of parallel processor unit - neural network. The de-convolution process is formulated as a machine learning problem and the inverse operator is interpreted as a connectionist model.","","Electronic:978-1-4673-5707-4; POD:978-1-4673-5706-7","10.1109/ICEAA.2013.6632375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6632375","","Diffraction;Image restoration;Imaging;Noise;Sensors;Stability analysis;Training","deconvolution;diffraction;image resolution;image restoration;learning (artificial intelligence);mathematical operators;neural nets;parallel processing","connectionist model;deconvolution process;diffracted image restoration;diffraction phenomenon;human vision;image resolution;imaging systems;inverse operator;machine learning approach;neural network;parallel processor unit;super acuity","","0","","5","","","9-13 Sept. 2013","","IEEE","IEEE Conference Publications"
"Rule weight update in parallel distributed fuzzy genetics-based machine learning with data rotation","H. Ishibuchi; M. Yamane; Y. Nojima","Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, 599-8531, Japan","2013 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","20131007","2013","","","1","8","In our former study, we have already proposed a parallel distributed model for the speedup of fuzzy genetics-based machine learning (GBML). Our model is an island model for parallel implementation of fuzzy GBML algorithms where a population is divided into multiple subpopulations. A single subpopulation is assigned to each island. Training data are also divided and distributed over the islands. When we have N islands (i.e., N CPUs for parallel computation), the speedup is the order of the square of N. This is because both the population and the training data are divided into N subsets. One characteristic feature of our parallel distributed model is training data rotation over the islands. Each of the N training data subsets is assigned to one of the N islands. The assigned training data subsets are rotated over the islands periodically (e.g., every 100 generations). This means that the environment of each island is changed periodically. The focus of this paper is how to update existing fuzzy rules at each island after the training data rotation. One extreme setting is to totally update fuzzy rules using the newly assigned training data subset. Another extreme setting is to use existing fuzzy rules with no changes. In this paper, we examine incremental learning, which can be viewed as an intermediate mechanism between the two extreme settings.","1098-7584;10987584","Electronic:978-1-4799-0022-0; POD:978-1-4799-0021-3","10.1109/FUZZ-IEEE.2013.6622572","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6622572","Genetics-based machine learning (GBML);Pittsburgh approach;fuzzy rule-based classifiers;genetic fuzzy systems (GFS);parallel evolutionary computation;pattern classification","Accuracy;Computational modeling;Data models;Sociology;Statistics;Training;Training data","genetic algorithms;knowledge based systems;learning (artificial intelligence);parallel algorithms","fuzzy GBML algorithms;fuzzy rules;incremental learning;island model;parallel distributed fuzzy genetics-based machine learning;parallel distributed model;rule weight update;subpopulations;training data rotation","","2","","44","","","7-10 July 2013","","IEEE","IEEE Conference Publications"
"Behavioral-based cheating detection in online first person shooters using machine learning techniques","H. Alayed; F. Frangoudes; C. Neuman","University of Southern California","2013 IEEE Conference on Computational Inteligence in Games (CIG)","20131017","2013","","","1","8","Cheating in online games comes with many consequences for both players and companies. Therefore, cheating detection and prevention is an important part of developing a commercial online game. Several anti-cheating solutions have been developed by gaming companies. However, most of these companies use cheating detection measures that may involve breaches to users' privacy. In our paper, we provide a server-side anti-cheating solution that uses only game logs. Our method is based on defining an honest player's behavior and cheaters' behavior first. After that, using machine learning classifiers to train cheating models, then detect cheaters. We presented our results in different organizations to show different options for developers, and our methods' results gave a very high accuracy in most of the cases. Finally, we provided a detailed analysis of our results with some useful suggestions for online games developers.","2325-4270;23254270","Electronic:978-1-4673-5311-3; POD:978-1-4673-5310-6","10.1109/CIG.2013.6633617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6633617","Cheating Detection;Machine Learning;Online Games","Accuracy;Feature extraction;Games;Logistics;Servers;Support vector machines;Weapons","computer games;data privacy;learning (artificial intelligence);pattern classification;security of data","behavioral-based cheating detection;cheating prevention;commercial online game;game logs;gaming companies;machine learning classifiers;machine learning techniques;online first person shooters;server-side anticheating solution;user privacy","","2","","17","","","11-13 Aug. 2013","","IEEE","IEEE Conference Publications"
"Utilisation of on-line machine learning for SCADA system alarms forecasting","T. Skripcak; P. Tanuska","Inst. of Appl. Inf., Autom. & Math., Slovak Univ. of Technol., Trnava, Slovakia","2013 Science and Information Conference","20131114","2013","","","477","484","This paper describes a prototype design and implementation of a real-time (on-line) knowledge generation component which can be utilised in industrial Supervisory Control and Data Acquisition (SCADA) systems. The overall architecture of our SCADA scenario, which utilise proposed knowledge generation is based on a multi-agent approach. This design is different from what we can see in conventional commercial SCADA solutions. Nowadays, there is a big pressure on operators to precisely analyse a huge amount of data coming from technological processes and make right decisions in the right time. This is where a real-time knowledge generation can highly improve decision making strategies in complex industrial processes. Nevertheless, the actual state of the art solutions are usually not using the knowledge generation directly, or there are often restricted so called off-line learning approaches. The recent development in the area of machine learning lead to the creation of distributed solutions which could process real-time data and dynamically adapt the generated knowledge. We applied this on-line machine learning approach in our proposed prototype. The experimental agent is focused on the specific scenario of the process alarm forecasting, which is considered to be a binary classification problem. We describe our solution for useful classifier feature vector construction. The classifier itself is based on Passive-Aggressive algorithm. Furthermore, in order to evaluate a performance of the classification the results from knowledge generation experiments were provided in form of Matthews Correlation Coefficient (MCC) together with Receiver Operating Characteristic (ROC). The proposed prototype shows how to design and implement an on-line knowledge generation component for novel SCADA solutions.","","Electronic:978-0-9893193-0-0; POD:978-1-4799-1272-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6661782","on-line machine learning;software agents;virtual factor","Data models;Forecasting;Real-time systems;Solid modeling;Support vector machine classification;Training;Virtual manufacturing","SCADA systems;alarm systems;decision making;forecasting theory;knowledge engineering;learning (artificial intelligence);multi-agent systems","MCC;ROC;SCADA solutions;SCADA systems;alarms forecasting;binary classification problem;classifier feature vector construction;decision making strategies;knowledge generation experiments;matthews correlation coefficient;multiagent approach;off-line learning approaches;on-line knowledge generation component;online knowledge generation component;online machine learning approach;online machine learning utilisation;passive-aggressive algorithm;process alarm forecasting;prototype design;real-time data;real-time knowledge generation component;receiver operating characteristic;supervisory control and data acquisition systems","","0","","13","","","7-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Very short term pitch angle optimization in wind turbines: A machine learning approach","M. Yesilbudak; E. Kabalci; S. Sagiroglu; I. Colak","Department of Electronics and Automation, Vocational College of Haci Bektas Veli, Nevsehir University, Nevsehir, Turkey","4th International Conference on Power Engineering, Energy and Electrical Drives","20131021","2013","","","886","889","This paper proposes a pitch angle forecasting model based on the k-nearest neighbor classification. Air temperature, atmosphere pressure, wind direction, wind speed, rotor speed and wind power parameters were represented as a 6-dimensional attribute tuple in the forecasting model. Euclidean, Manhattan and Minkowski distance metrics for measuring the proximity between training and test tuples, mean absolute, mean absolute percentage, and normalized root mean square error metrics for measuring the forecasting accuracy were embedded into the forecasting model. The k-nearest neighbor classifier with Manhattan distance metric for k=1 achieved MAE, MAPE and NRMSE as 0.001°, 0.245% and 0.324%, respectively as the best forecasting accuracy. However, as the worst forecasting accuracy, MAE, MAPE and NRMSE were achieved as 0.015°, 3.236% and 2.613%, respectively for Minkowski distance metric and k=10.","2155-5516;21555516","Electronic:978-1-4673-6392-1; POD:978-1-4673-6391-4; USB:978-1-4673-6390-7","10.1109/PowerEng.2013.6635727","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6635727","nearest neighbor classification;pitch angle forecasting;wind turbines","Atmospheric modeling;Control systems;Forecasting;Measurement;Predictive models;Wind speed;Wind turbines","learning (artificial intelligence);load forecasting;optimisation;power engineering computing;rotors;wind power plants;wind turbines","6 dimensional attribute tuple;Euclidean distance metrics;Manhattan distance metrics;Minkowski distance metrics;air temperature;atmosphere pressure;k-nearest neighbor classification;machine learning approach;mean absolute error metrics;mean absolute percentage error metrics;normalized root mean square error metrics;pitch angle forecasting model;rotor speed;very short term pitch angle optimization;wind direction;wind power parameter;wind speed;wind turbine","","0","","22","","","13-17 May 2013","","IEEE","IEEE Conference Publications"
"Applying Machine Learning Algorithm in Fall Detection Monitoring System","S. Khawandi; A. Ballit; B. Daya","Lebanese Univ., Saida, Lebanon","2013 5th International Conference and Computational Intelligence and Communication Networks","20131111","2013","","","247","250","Fall is a major health hazard for the elders when they live independently. Approximately a third of those aged 65 years and over fall each year. An automatic fall detector ensures the best possible chance of a full recovery following a fall. This paper presents new algorithm able to learn, classify and identify falls from data obtained by a multi-sensor monitoring system. The system, that uses a web cam and a heart rate sensor, is based on machine learning and data classification using decision trees. Our solution shows a satisfactory performance and gives interesting results.","","Electronic:978-0-7695-5069-5; POD:978-1-4799-1326-8","10.1109/CICN.2013.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6657993","decision tree;fall detection;heart rate;visual parameters","Biomedical monitoring;Conferences;Data mining;Decision trees;Heart rate;Monitoring;Senior citizens","assisted living;biomedical equipment;cameras;cardiology;computerised monitoring;decision trees;geriatrics;health hazards;image classification;image fusion;learning (artificial intelligence);sensors","automatic fall detector;data classification;decision trees;fall classification;fall detection monitoring system;fall identification;fall learning;health hazard;heart rate sensor;machine learning algorithm;multisensor monitoring system;webcam","","1","","23","","","27-29 Sept. 2013","","IEEE","IEEE Conference Publications"
"Revisiting Computational Thermodynamics through Machine Learning of High-Dimensional Data","S. Srinivasan; K. Rajan","","Computing in Science & Engineering","20131122","2013","15","5","22","31","A new perspective on alloy thermodynamics computation uses data-driven analysis and machine learning for the design and discovery of materials. The focus is on an integrated machine-learning framework, coupling different genres of supervised and unsupervised informatics techniques, and bridging two distinct viewpoints: continuum representations based on solid solution thermodynamics and discrete high-dimensional elemental descriptions.","1521-9615;15219615","","10.1109/MCSE.2013.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6576112","bandgap engineering;compound semiconductors;computational thermodynamics;data mining;high-dimensional model representation;machine learning;materials informatics","Atomic measurements;Computational modeling;Informatics;Machine learning;Principal component analysis;Semiconductor materials;Thermodynamics","alloys;data analysis;learning (artificial intelligence);materials science computing;thermal stability","alloy thermodynamics computation;computational thermodynamics;continuum representations;data-driven analysis;discrete high-dimensional elemental descriptions;high-dimensional data;integrated machine learning framework;material design;material discovery;solid solution thermodynamics;supervised informatics techniques;unsupervised informatics techniques","","1","","14","","20130807","Sept.-Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Dynamic Extreme Learning Machine and Its Approximation Capability","R. Zhang; Y. Lan; G. B. Huang; Z. B. Xu; Y. C. Soh","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Cybernetics","20131119","2013","43","6","2054","2065","Extreme learning machines (ELMs) have been proposed for generalized single-hidden-layer feedforward networks which need not be neuron alike and perform well in both regression and classification applications. The problem of determining the suitable network architectures is recognized to be crucial in the successful application of ELMs. This paper first proposes a dynamic ELM (D-ELM) where the hidden nodes can be recruited or deleted dynamically according to their significance to network performance, so that not only the parameters can be adjusted but also the architecture can be self-adapted simultaneously. Then, this paper proves in theory that such D-ELM using Lebesgue p-integrable hidden activation functions can approximate any Lebesgue p-integrable function on a compact input set. Simulation results obtained over various test problems demonstrate and verify that the proposed D-ELM does a good job reducing the network size while preserving good generalization performance.","2168-2267;21682267","","10.1109/TCYB.2013.2239987","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6459569","Dynamic learning;extreme learning machine (ELM);feedforward neural networks;universal approximation","Approximation methods;Computer architecture;Cybernetics;Educational institutions;Feedforward neural networks;Linear systems;Machine learning","learning (artificial intelligence);pattern classification;recurrent neural nets;regression analysis","D-ELM;Lebesgue p-integrable hidden activation functions;approximation capability;classification applications;dynamic ELM;dynamic extreme learning machine;generalized single-hidden-layer feedforward networks;network architectures;regression applications","0","22","","36","","20130211","Dec. 2013","","IEEE","IEEE Journals & Magazines"
"A machine learning regularization of the inverse problem in electrocardiography imaging","N. Zemzemi; R. Dubois; Y. Coudière; O. Bernus; M. Haissaguerre","INRIA, Bordeaux, France","Computing in Cardiology 2013","20140116","2013","","","1135","1138","Radio-frequency ablation is one of the most efficient treatments of atrial fibrillation. The idea behind it is to stop the propagation of ectopic beats coming from the pulmonary vein and the abnormal conduction pathways. Medical doctors need to use invasive catheters to localize the position of the triggers and they have to decide where to ablate during the intervention. ElectroCardioGraphy Imaging (ECGI) provides the opportunity to reconstruct the electrical potential and activation maps on the heart surface and analyze data prior to the intervention. The mathematical problem behind the reconstruction of heart potential is known to be ill posed. In this study we propose to regularize the inverse problem with a statistically reconstructed heart potential, and we test the method on synthetically data produced using an ECG simulator.","0276-6574;02766574","Electronic:978-1-4799-0886-8; POD:978-1-4799-0885-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6713582","","Biological system modeling;Electric potential;Electrocardiography;Heart;Inverse problems;Mathematical model;Torso","blood vessels;catheters;electrocardiography;inverse problems;learning (artificial intelligence);medical image processing;radiofrequency heating","ECG simulator;ECGI;abnormal conduction pathways;activation maps;atrial fibrillation;ectopic beats;electrical potential;electrocardiography imaging;heart potential reconstruction;heart surface;invasive catheters;inverse problem;machine learning regularization;medical doctors;pulmonary vein;radio-frequency ablation","","0","","9","","","22-25 Sept. 2013","","IEEE","IEEE Conference Publications"
"Predicting driver destination using machine learning techniques","C. Manasseh; R. Sengupta","Human Intellect Lab., Falls Church, VA, USA","16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)","20140130","2013","","","142","147","In this paper we present a method for predicting the driver's destination with 96% accuracy. Knowing the driver's destination has many useful applications in traffic safety, traffic mobility, and influencing driver behavior. Furthermore, a software application that can predict the driver's destination can reduce the burden on the driver from manually entering the destination address on small-screen mobile devices. Current methods for predicting driver destination do that by predicting the driver's route. Those methods result in 72% accuracy if relying only on GPS traces. By providing accurate map data, the accuracy of prediction in current methods can reach 98% in best case scenarios that were tested on one subject. We propose an alternate approach that separates the destination prediction problem from the route prediction problem. We provide ten subjects, of varying driving patterns, with a Smartphone equipped with a GPS tracking software application and ask them to turn on the tracking application for all their trips for a period ranging between 2 and 9 weeks. We apply an algorithm to detect Origins and Destination from GPS traces and feed that into several machine learning algorithms to model the destination. Given the current position of the driver, the position at which the driver was 5 min prior, the time of day, and the day of the week; the algorithm provides a prediction of the destination with a 1000m resolution. The Decision Tree with Pruning algorithm proves to be the most accurate resulting in an average 96 +/- 1.72 % accuracy of prediction across all subjects.","2153-0009;21530009","Electronic:978-1-4799-2914-6; POD:978-1-4799-2915-3; USB:978-1-4799-2913-9","10.1109/ITSC.2013.6728224","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728224","","Accuracy;Decision trees;Global Positioning System;Machine learning algorithms;Prediction algorithms;Software;Vehicles","Global Positioning System;decision trees;driver information systems;learning (artificial intelligence);smart phones;tracking;traffic engineering computing","GPS traces;GPS tracking software application;decision tree;driver behavior;driver destination prediction;machine learning techniques;pruning algorithm;route prediction problem;small-screen mobile devices;smartphone;traffic mobility;traffic safety","","2","","11","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Automatic classification for vulnerability based on machine learning","B. Shuai; H. Li; M. Li; Q. Zhang; C. Tang","Sch. of Electron. Sci. & Eng., Nat. Univ. of Defense Technol., Changsha, China","2013 IEEE International Conference on Information and Automation (ICIA)","20140127","2013","","","312","318","In order to solve the problems of traditional machine learning methods for automatic classification of vulnerability, this paper presents a novel machine learning method based on LDA model and SVM. Firstly, word location information is introduced into LDA model called WL-LDA (Weighted Location LDA), which could acquire better effect through generating vector space on themes other than on words. Secondly, a multi-class classifier called HT-SVM (Huffman Tree SVM) is constructed, which could make a faster and more stable classification by making good use of the prior knowledge about distribution of the number of vulnerabilities. Experiments show that the method could obtain higher classification accuracy and efficiency.","","Electronic:978-1-4799-1334-3; POD:978-1-4799-1332-9; USB:978-1-4799-1333-6","10.1109/ICInfA.2013.6720316","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720316","LDA model;SVM;Vulnerability classification;Vulnerability distribution;Words location","Classification algorithms;Databases;Educational institutions;Probabilistic logic;Support vector machine classification;Training","learning (artificial intelligence);pattern classification;support vector machines","HT-SVM;Huffman Tree SVM;WL-LDA model;automatic classification;machine learning methods;multiclass classifier;stable classification;vector space;weighted location LDA;word location information","","0","","28","","","26-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Power-Aware Multi-data Center Management Using Machine Learning","J. L. Berral; R. Gavaldà; J. Torres","Barcelona Supercomput. Center, Univ. Politec. de Catalunya, Barcelona, Spain","2013 42nd International Conference on Parallel Processing","20131219","2013","","","858","867","The cloud relies upon multi-data center (multi-DC) infrastructures distributed along the world, where people and enterprises pay for resources to offer their web-services to worldwide clients. Intelligent management is required to automate and manage these infrastructures, as the amount of resources and data to manage exceeds the capacities of human operators. Also, it must take into account the cost of running the resources (energy) and the quality of service towards web-services and clients. (De-)consolidation and priming proximity to clients become two main strategies to allocate resources and properly place these web-services in the multi-DC network. Here we present a mathematical model to describe the scheduling problem given web-services and hosts across a multi-DC system, enhancing the decision makers with models for the system behavior obtained using machine learning. After running the system on real DC infrastructures we see that the model drives web-services to the best locations given quality of service, energy consumption, and client proximity, also (de-)consolidating according to the resources required for each web-service given its load.","0190-3918;01903918","Electronic:978-0-7695-5117-3; POD:978-1-4799-1448-7","10.1109/ICPP.2013.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6687426","Machine Learning;Multi-DataCenter;Power-Aware;Virtualization;Web-Services","Energy consumption;Mathematical model;Measurement;Monitoring;Predictive models;Quality of service;Time factors","Web services;cloud computing;computer centres;energy consumption;learning (artificial intelligence);power aware computing;quality of service;resource allocation;scheduling","Web-services;client proximity;cloud computing;consolidation;energy consumption;intelligent management;machine learning;mathematical model;multiDC infrastructure;power-aware multidata center management;priming proximity;quality of service;resource allocation;scheduling problem","","4","1","25","","","1-4 Oct. 2013","","IEEE","IEEE Conference Publications"
"Using Big Data and predictive machine learning in aerospace test environments","T. Armes; M. Refern","IntraStage, Inc. San Diego, USA","2013 IEEE AUTOTESTCON","20131024","2013","","","1","5","It is estimated that in 2012 most mid-size companies in the USA generate the equivalent data of the US Library of Congress in 1 year. As a company, Wal-Mart creates the equivalent of 50 million filing cabinets worth of data every hour. While these numbers seem incredible, the trend for most companies is an increasing volume of data generation and storage. Test Data generated by Automatic Test Equipment (ATE) in R&D, manufacturing and Repair environments is no exception to this increased volume of data. The challenge of this enormous amount of Test Data is how to provide people with effective ways to make decisions from it. Data visualization through charts, graphs and reports has been, historically, one of the more effective ways to provide actionable intelligence because humans can readily make decisions based on patterns and comparisons. But as data volume goes up, even this method is reaching its limits. When one starts to combine large datasets like Manufacturing Test Data and Repair Data together, data visualization becomes problematic. More sophisticated algorithmic, machine learning and predictive approaches become critical. In this paper, we will explore the experiences of using predictive algorithms on ""Big Data"" from both Manufacturing Test and Repair Test environments in the complex mission critical aerospace industry. By effectively using datasets from different functional areas, we will be looking at applying SPC techniques to answer new questions about the correlation of Repair test data and manufacturing data with the end goal to predict number of returns in the future and minimize product escapes.","1088-7725;10887725","Electronic:978-1-4673-5683-1; POD:978-1-4673-5682-4","10.1109/AUTEST.2013.6645085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6645085","","Companies;Data handling;Data models;Data storage systems;Information management;Maintenance engineering;Manufacturing","aerospace computing;aerospace testing;automatic test equipment;automatic testing;data handling;learning (artificial intelligence)","aerospace test environments;automatic test equipment;complex mission critical aerospace industry;data generation;data storage;data visualization;predictive algorithms;predictive machine learning;test data","","1","","","","","16-19 Sept. 2013","","IEEE","IEEE Conference Publications"
"Meta-learning for large scale machine learning with MapReduce","X. Liu; X. Wang; S. Matwin; N. Japkowicz","Sch. of EECS, Univ. of Ottawa, Ottawa, ON, Canada","2013 IEEE International Conference on Big Data","20131223","2013","","","105","110","We have entered the big data age. Knowledge extraction from massive data is becoming more and more rewarding and urgent. MapReduce has provided a feasible framework for programming machine learning algorithms in Map and Reduce functions. The relatively simple programming interface has helped to solve machine learning algorithms' scalability problems. However, this framework suffers from an obvious weakness: it does not support iterations. This makes those algorithms requiring iterations difficult to fully explore the efficiency of MapReduce. In this paper, we propose to apply Meta-learning programmed with MapReduce to avoid parallelizing machine learning algorithms while also improving their scalability to big datasets. The experiments conducted on Hadoop fully distributed mode on Amazon EC2 demonstrate that our algorithm PML reduces the training computational complexity significantly when the number of computing nodes increases while gaining smaller error rates than those on one single node. The comparison of PML with the contemporary parallelized AdaBoost algorithm: AdaBoost.PL shows that PML has lower error rates.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691741","Adaboost;MapReduce;big data;meta-learning;parallel computing","Algorithm design and analysis;Classification algorithms;Computational modeling;Error analysis;Machine learning algorithms;Training;Training data","Big Data;application program interfaces;knowledge acquisition;learning (artificial intelligence);parallel programming","Amazon EC2;Map function;MapReduce;PML;Reduce function;big dataset scalability improvement;computational complexity;computing nodes;error rates;fully-distributed Hadoop mode;knowledge extraction;large-scale machine learning algorithm programming;machine learning algorithm scalability problems;massive data;meta-learning;programming interface","","3","","25","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"An examination of TNM staging of melanoma by a machine learning algorithm","D. Wu; C. Yang; S. Wong; J. Meyerle; B. Zhang; D. Chen","Dept. of Comput. Sci., George Washington Univ., Washington, DC, USA","2012 International Conference on Computerized Healthcare (ICCH)","20140127","2012","","","120","126","Accurate estimation of mortality in patients with cancer is important when discussing prognosis and selecting treatment. Survival estimation for many cancers is based on Tumor-Node-Metastasis (TNM) staging systems that involve three factors: tumor extent, lymph node involvement, and metastasis. The most recent clinical staging of melanoma uses TNM staging but does not include a growing number of other prognostic features. The Ensemble Algorithm of Clustering of Cancer Data (EACCD) by Chen et al. is a machine learning algorithm that regroups patients with different prognostic factors according to the survival dissimilarity. This algorithm has the potential to integrate emerging prognostic factors to more accurately stage melanoma. In this study, we use EACCD to examine the current AJCC staging of melanoma by analyzing a melanoma dataset from the National Cancer Centers Surveillance, Epidemiology, and End Rresults (SEER) database. Our results demonstrates that the EACCD algorithm generates results in-line with AJCC staging and may provide a mechanism to incorporate other prognostic factors to produce a more nuanced estimation of prognosis and survival.","","Electronic:978-1-4673-5129-4; POD:978-1-4673-5128-7","10.1109/ICCH.2012.6724482","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724482","Clustering;Melanoma;Prediction;Survival Function;TNM","Clustering algorithms;Lymph nodes;Malignant tumors;Metastasis;Prognostics and health management","cancer;learning (artificial intelligence);medical computing;patient diagnosis;patient treatment;pattern clustering;tumours","AJCC staging;EACCD algorithm;National Cancer Centers Surveillance Epidemiology and End Rresults database;SEER database;TNM staging systems;clinical staging;ensemble algorithm of clustering of cancer data;lymph node involvement;machine learning algorithm;melanoma dataset;patient treatment;patients mortality estimation;prognosis;prognostic factors;prognostic features;survival dissimilarity;survival estimation;tumor extent;tumor-node-metastasis staging systems","","2","","11","","","17-18 Dec. 2012","","IEEE","IEEE Conference Publications"
"Rapid Deployment for Machine Learning in Educational Cloud","Y. Takabe; M. Uehara","Dept. of Open Inf. Syst., Toyo Univ., Kawagoe, Japan","2013 16th International Conference on Network-Based Information Systems","20131219","2013","","","372","376","In the cloud era, the acquisition of new cloud skills is a constant requirement of IT specialists. Educational organizations such as universities have a need to provide educational cloud curriculums for their students. In our current research, we are constructing a private cloud based on super-saturation, which is defined as the allocation of a much greater amount of logical resources than physical resources. Super-saturated clouds therefore realize up to 10 times more running instances than conventional clouds. While the performance of super-saturated clouds decreases somewhat compared with conventional clouds, their costs also greatly decrease. Moreover, in the post-cloud era, i.e., the big data era, data scientists will be increasingly required to process big data in the cloud. Mahout and Hadoop are two popular tools used in the fields of data science and machine learning. However, a certain level of skill is required to build such machine learning systems, and because it takes a long time to build such systems, the curriculums available to learners are limited. In this paper, we propose a method of rapid deployment for machine learning systems in the educational cloud. We show that our proposed method can reduce the required preparation time.","2157-0418;21570418","Electronic:978-1-4799-2510-0; POD:978-1-4799-2511-7","10.1109/NBiS.2013.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6685427","Educational Cloud;Hadoop;Mahout","Cloud computing;Conferences;Data handling;Data storage systems;Information management","cloud computing;computer aided instruction;data privacy;educational institutions;learning (artificial intelligence);parallel processing","Hadoop;IT specialists;Mahout;cloud skills acquisition;data science;educational cloud curriculums;educational organizations;information technology;machine learning;private cloud;super-saturated clouds","","0","","13","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"CADdy — Colposcopy learning machine for computer aided diagnosis","M. Traversi; M. Falagario; C. Guaragnella","DEI - Dept. of Electrics and Information, Polytechnic University of Bari, Italy","2013 IEEE Third International Conference on Consumer Electronics ¿¿ Berlin (ICCE-Berlin)","20140102","2013","","","1","4","The study and development of a decision support system for doctors and students is presented, aiming to ease the diagnosis of the cervix cancer through an automated smart system: using a web application, a medical expert can upload colposcopie images feeding an expert system that carries out a deep analysis by a processing system on images uploaded by doctors; results coming out of the processing system are presented by a user friendly system suggesting the decision to the the medical expert who is able to confirm or change it, and annotate information. If changed, the diagnosis is sent to the expert system, developed on a reinforcement learning scheme, to tune decision parameters and enhance detection rates. The paper present the work in progress preliminary results of the system being developed.","2166-6814;21666814","Electronic:978-1-4799-1412-8; POD:978-1-4799-1410-4","10.1109/ICCE-Berlin.2013.6697965","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6697965","Machine learning;cervix cancer;colposcopy;images processing;neural network;web application","IEEE Xplore;Portable document format","","","","1","","","","","9-11 Sept. 2013","","IEEE","IEEE Conference Publications"
"Behaviour analysis of machine learning algorithms for detecting P2P botnets","S. Garg; A. K. Singh; A. K. Sarje; S. K. Peddoju","Dept. of Comput. Sci. & Eng., Indian Inst. of Technol. Roorkee, Roorkee, India","2013 15th International Conference on Advanced Computing Technologies (ICACT)","20140116","2013","","","1","4","Botnets have emerged as a powerful threat on the Internet as it is being used to carry out cybercrimes. In this paper, we have analysed some machine learning techniques to detect peer to peer (P2P) botnets. As the detection of P2P botnets is widely unexplored area, we have focused on it. We experimented with different machine learning (ML) algorithms to compare their ability to classify the botnet traffic from the normal traffic by selecting distinguishing features of the network traffic. Experiments are performed on the dataset containing the traces of various P2P botnets. Results and tradeoffs obtained of different ML algorithms on different metrics are presented at the end of the paper.","","CD-ROM:978-1-4673-2816-6; Electronic:978-1-4673-2818-0; POD:978-1-4673-2817-3","10.1109/ICACT.2013.6710523","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6710523","Behavior Analysis;Command & control;Machine learning;Network Security;P2P;P2P botnet","Algorithm design and analysis;Classification algorithms;Data mining;Feature extraction;Niobium;Testing;Training","Internet;computer crime;computer network security;invasive software;learning (artificial intelligence);peer-to-peer computing;telecommunication computing;telecommunication traffic","Internet;P2P botnet detection;botnet traffic classification;cybercrimes;feature selection;machine learning algorithms;machine learning techniques;network traffic;peer to peer botnet detection","","4","","21","","","21-22 Sept. 2013","","IEEE","IEEE Conference Publications"
"A machine learning-based faulty line identification for smart distribution network","H. Livani; C. Y. Evrenosoglu; V. A. Centeno","Electr. & Comput. Eng. Dept., Virginia Tech, Blacksburg, VA, USA","2013 North American Power Symposium (NAPS)","20131125","2013","","","1","5","This paper presents a machine learning-based faulty-line identification method in smart distribution networks. The proposed method utilizes postfault root-mean-square (rms) values of voltages measured at the main substation and at selected nodes as well as fault information obtained by fault current identifiers (FCIs) and intelligent electronic re-closers (IE-CRs). The information from FCIs and IE-RCs are first used to identify the faulty region in the network. The normalized rms values of voltages are then utilized as the input to the support vector machine (SVM) classifiers to identify the faulty-line according to the pre-determined fault type. The IEEE 123-node distribution test system is simulated in ATP software. MATLAB is used to process the simulated transients and to apply the proposed method. The performance of the method is tested for different fault inception angles (FIA) and different fault resistances with satisfactory results.","","Electronic:978-1-4799-1255-1; POD:978-1-4799-1253-7; USB:978-1-4799-1254-4","10.1109/NAPS.2013.6666829","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6666829","Distribution network;SVM;faulty line;smart grid","Accuracy;Fault location;Kernel;Substations;Support vector machines;Voltage measurement","fault currents;fault diagnosis;learning (artificial intelligence);pattern classification;power distribution faults;power engineering computing;substations;support vector machines","ATP software;FCIs;FIA;IE-CRs;IEEE 123-node distribution test system;Matlab;SVM classifiers;fault current identifiers;fault inception angles;fault information;fault resistances;intelligent electronic reclosers;machine learning-based faulty line identification method;normalized RMS values;postfault root-mean-square;smart distribution network;substation;support vector machine","","0","","19","","","22-24 Sept. 2013","","IEEE","IEEE Conference Publications"
"Code Smell Detection: Towards a Machine Learning-Based Approach","F. A. Fontana; M. Zanoni; A. Marino; M. V. Mäntylä","Dept. of Inf., Univ. of Milano-Bicocca, Milan, Italy","2013 IEEE International Conference on Software Maintenance","20131202","2013","","","396","399","Several code smells detection tools have been developed providing different results, because smells can be subjectively interpreted and hence detected in different ways. Usually the detection techniques are based on the computation of different kinds of metrics, and other aspects related to the domain of the system under analysis, its size and other design features are not taken into account. In this paper we propose an approach we are studying based on machine learning techniques. We outline some common problems faced for smells detection and we describe the different steps of our approach and the algorithms we use for the classification.","1063-6773;10636773","Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5","10.1109/ICSM.2013.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676916","code smells detection;machine learning techniques","Accuracy;Conferences;Detectors;Labeling;Machine learning algorithms;Measurement;Software","learning (artificial intelligence);pattern classification;program diagnostics","classification;code smell detection tools;machine learning-based approach","","7","","20","","","22-28 Sept. 2013","","IEEE","IEEE Conference Publications"
"Machine learning techniques for data mining: A survey","S. Sharma; J. Agrawal; S. Agarwal; S. Sharma","Sch. of Inf.. Technol., RGPV, Bhopal, India","2013 IEEE International Conference on Computational Intelligence and Computing Research","20140127","2013","","","1","6","Data mining (DM) is a most popular knowledge acquisition method for knowledge discovery. Classification is one of the data mining (machining learning) technique that maps the data into the predefined class and group's. It is used to predict group membership for data instance. There are many areas that adapt Data Mining techniques such as medical, marketing, telecommunications, and stock, health care and so on. This paper presents the various classification techniques including decision tree, Support vector Machine, Nearest Neighbor etc. This survey provides a comparative Analysis of various classification algorithms.","","Electronic:978-1-4799-1597-2; POD:978-1-4799-1596-5","10.1109/ICCIC.2013.6724149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724149","Bayesian network;Data Classification;Data Mining;Decision Tree;Nearest Neighbour;Support Vector Machine (SVM)","","data mining;decision trees;learning (artificial intelligence);pattern classification;support vector machines","classification algorithms;data instance;data mining;decision tree;group membership prediction;knowledge acquisition method;knowledge discovery;machine learning;nearest neighbor;support vector machine","","4","","25","","","26-28 Dec. 2013","","IEEE","IEEE Conference Publications"
"Intelligent Traffic Light Control of Isolated Intersections Using Machine Learning Methods","S. Araghi; A. Khosravi; M. Johnstone; D. Creighton","Centre for Intell. Syst. Res. (CISR), Deakin Univ., Geelong, VIC, Australia","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","3621","3626","Traffic congestion is one of the major problems in modern cities. This study applies machine learning methods to determine green times in order to minimize in an isolated intersection. Q-learning and neural networks are applied here to set signal light times and minimize total delays. It is assumed that an intersection behaves in a similar fashion to an intelligent agent learning how to set green times in each cycle based on traffic information. Here, a comparison between Q-learning and neural network is presented. In Q-learning, considering continuous green time requires a large state space, making the learning process practically impossible. In contrast to Q-learning methods, the neural network model can easily set the appropriate green time to fit the traffic demand. The performance of the proposed neural network is compared with two traditional alternatives for controlling traffic lights. Simulation results indicate that the application of the proposed method greatly reduces the total delay in the network compared to the alternative methods.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722370","Q-learning;machine learning;neural network;single intersection;traffic controlling","Artificial neural networks;Cost function;Delays;Green products;Learning (artificial intelligence);Vehicles","learning (artificial intelligence);multi-agent systems;neurocontrollers;road traffic control;traffic engineering computing","Q-learning;green times;intelligent agent learning;intelligent traffic light control;isolated intersections;machine learning methods;neural networks;signal light times;total delay minimization;traffic congestion","","1","","27","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Wireless Tomography in Noisy Environments Using Machine Learning","Z. Hu; S. Hou; M. C. Wicks; R. C. Qiu","Dept. of Electr. & Comput. Eng., Tennessee Technol. Univ., Cookeville, TN, USA","IEEE Transactions on Geoscience and Remote Sensing","20131212","2014","52","2","956","966","This paper, one in a continuing series, describes a new initiative in wireless tomography. Our goal is to combine two technologies: wireless communication and radio frequency tomography, for the close-in remote sensing. The hybrid system, including wireless communication devices for wireless tomography is proposed in this paper. Noise reduction, modified standard phase reconstruction, and imaging are exploited sequentially to perform wireless tomography in noisy environments. The performance given in this paper illustrates the significance and prospect of wireless tomography. The contributions of this paper are threefold: 1) the hybrid system provides a strong and flexible infrastructure for wireless tomography; 2) machine learning, especially nonlinear dimensionality reduction, is explored to execute noise reduction and combat the nonlinear noise effect; and 3) modified standard phase reconstruction is well achieved using the de-noised amplitude-only total fields from the simple sensors and the received accurate full-data total fields from the advanced sensors. Experimental data provided by the Institute Fresnel in Marseille, France are used to demonstrate the concept of wireless tomography and validate the corresponding algorithms.","0196-2892;01962892","","10.1109/TGRS.2013.2245904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479293","Imaging;machine learning;noise reduction;phase reconstruction;wireless tomography","Image reconstruction;Kernel;Noise reduction;Sensors;Tomography;Wireless communication;Wireless sensor networks","cognitive radio;learning (artificial intelligence);noise (working environment);noise measurement;remote sensing;signal reconstruction","close in remote sensing;denoised amplitude only total fields;hybrid system;machine learning;modified standard phase reconstruction;noise reduction;noisy environments;nonlinear dimensionality reduction;nonlinear noise effect;radio frequency tomography;wireless communication;wireless tomography","","3","","48","","20130313","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Cone of Influence Analysis at the Electronic System Level Using Machine Learning","J. Stoppe; R. Wille; R. Drechsler","Cyber-Phys. Syst., DFKI GmbH, Bremen, Germany","2013 Euromicro Conference on Digital System Design","20131015","2013","","","582","587","Cone of influence analysis, i.e. determining the parts of the circuit which are relevant to a considered circuit signal, is an established methodology applied in several design tasks. In abstractions like the Register Transfer Level (RTL) or the gate level, cone of influence analysis is simple. However, the introduction of higher levels of abstractions, particularly the Electronic System Level (ESL), made it significantly harder to reliably extract a cone of influence. In this paper, we propose a methodology that enables cone of influence analysis at the ESL. Instead of a structural analysis, a behavioral scheme is proposed, i.e. stimuli representing different system executions are analyzed. To this end, machine learning techniques are exploited. This enables a very good approximation of the desired cone of influence which is non-invasive, does not rely on the availability of the source code, and performs fast. Case studies confirm the applicability of the proposed approach.","","Electronic:978-1-4799-2978-8; POD:978-1-4799-2979-5","10.1109/DSD.2013.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6628330","Cone of Influence;ESL;Machine Learning;SystemC","Approximation methods;Availability;Decision trees;Entropy;Libraries;Logic gates;Machine learning algorithms","electronic engineering computing;learning (artificial intelligence);logic gates","ESL;RTL;behavioral scheme;circuit signal;cone-of-influence analysis;design tasks;electronic system level;gate level;machine learning;noninvasive cone-of-influence approximation;register transfer level;source code;system executions","","0","","24","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Using machine learning to identify benign cases with non-definitive biopsy","F. Kuusisto; I. Dutra; H. Nassif; Y. Wu; M. E. Klein; H. B. Neuman; J. Shavlik; E. S. Burnside","Univ. of Wisconsin-Madison, Madison, WI, USA","2013 IEEE 15th International Conference on e-Health Networking, Applications and Services (Healthcom 2013)","20140127","2013","","","283","285","When mammography reveals a suspicious finding, a core needle biopsy is usually recommended. In 5% to 15% of these cases, the biopsy diagnosis is non-definitive and a more invasive surgical excisional biopsy is recommended to confirm a diagnosis. The majority of these cases will ultimately be proven benign. The use of excisional biopsy for diagnosis negatively impacts patient quality of life and increases costs to the healthcare system. In this work, we employ a multi-relational machine learning approach to predict when a patient with a non-definitive core needle biopsy diagnosis need not undergo an excisional biopsy procedure because the risk of malignancy is low.","","Electronic:978-1-4673-5801-9; POD:978-1-4673-5799-9","10.1109/HealthCom.2013.6720685","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720685","","Biomedical imaging;Heating;Medical services","cancer;health care;learning (artificial intelligence);mammography;medical diagnostic computing","benign case identification;healthcare system;invasive surgical excisional biopsy;mammography;multirelational machine learning approach;nondefinitive core needle biopsy diagnosis","","1","","19","","","9-12 Oct. 2013","","IEEE","IEEE Conference Publications"
"Learning from multiple data sets with different missing attributes and privacy policies: Parallel distributed fuzzy genetics-based machine learning approach","H. Ishibuchi; M. Yamane; Y. Nojima","Dept. of Comput. Sci. & Intell. Syst., Osaka Prefecture Univ., Sakai, Japan","2013 IEEE International Conference on Big Data","20131223","2013","","","63","70","This paper discusses parallel distributed genetics-based machine learning (GBML) of fuzzy rule-based classifiers from multiple data sets. We assume that each data set has a similar but different set of attributes. In other words, each data set has different missing attributes. Our task is the design of a fuzzy rule-based classifier from those data sets. In this paper, we first show that fuzzy rules can handle missing attributes easily. Next we explain how parallel distributed fuzzy GBML can handle multiple data sets with different missing attributes. Then we examine the accuracy of obtained fuzzy rule-based classifiers from various settings of available training data such as a single data set with no missing attribute and multiple data sets with many missing attributes. Experimental results show that the use of multiple data sets often increases the accuracy of obtained fuzzy rule-based classifiers even when they have missing attributes. We also discuss the learning from a data set under a severe privacy preserving policy where only the error rate of each candidate classifier is available. It is assumed that no information about each individual pattern is available. This means that we cannot use any information on the class label or the attribute values of each pattern. We explain how such a black-box data set can be utilized for classifier design.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691735","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691735","Evolutionary algorithms;fuzzy rule-based classifiers;genetics-based machine learning;horizontally partitioned data sets;parallel distributed implementation","Classification algorithms;Data privacy;Distributed databases;Fuzzy sets;Sociology;Statistics;Training data","data privacy;genetic algorithms;learning (artificial intelligence);parallel processing","black-box data set;classifier design;fuzzy rule-based classifiers;fuzzy rules;missing attributes;multiple data set learning;multiple data sets;parallel distributed fuzzy GBML;parallel distributed fuzzy genetics-based machine learning approach;parallel distributed genetics-based machine learning;privacy policies;privacy preserving policy;training data","","1","","25","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Multi-lingual author identification and linguistic feature extraction — A machine learning approach","H. Alam; A. Kumar","BCL Technol., San Jose, CA, USA","2013 IEEE International Conference on Technologies for Homeland Security (HST)","20140102","2013","","","386","389","Internet based services have emerged as one of the most effective platform to express and exchange views. Most of these services allow anonymous postings. Lately, it has been observed that anonymous postings responsible to instigate violence or cause panic. Some studies have been made to identify authors for such blogs, mostly target to English postings. Current author identification systems do not employ rich morphological features for languages such as Arabic (Modern Standard Arabic). In this study we develop a novel semantic feature to aid author identification system for Arabic. To completely exploit rich morphology of Arabic, we used parse tree intelligently as features. The overall approach uses language-specific NLP parsers, lexicons, semantic processing, thematic role assignment, semantic heuristics, and machine learning techniques to rapidly train systems for the subtleties mentioned above for Arabic. Our system identifies authors on the basis of stylistic and linguistic similarities between the author's existing works and the unidentified text in the form of online blogs and articles. We use support vector machine (SVM) to identify authors based on these novel features. Our approach yields accuracy of 98% in law and order and terrorism related Arabic blogs.","","CD-ROM:978-1-4799-3963-3; Electronic:978-1-4799-1535-4; POD:978-1-4799-3964-0","10.1109/THS.2013.6699035","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6699035","Author Identification;Feature Extraction;NLP;Semantic Features;Support Vector Machine","Blogs;Feature extraction;Labeling;Pragmatics;Semantics;Support vector machines;Syntactics","Web sites;feature extraction;learning (artificial intelligence);natural language processing;support vector machines","Arabic blogs;Arabic languages;English postings;Internet based services;SVM;anonymous postings;language-specific NLP parsers;lexicons;linguistic feature extraction;linguistic similarities;machine learning approach;morphological features;multilingual author identification;natural language processing;parse tree;semantic feature;semantic heuristics;semantic processing;stylistic similarities;support vector machine;thematic role assignment","","0","","16","","","12-14 Nov. 2013","","IEEE","IEEE Conference Publications"
"Using machine learning to blend human and robot controls for assisted wheelchair navigation","A. Goil; M. Derry; B. D. Argall","Department of Electrical Engineering and Computer Science, Northwestern University, Evanston, IL 60208","2013 IEEE 13th International Conference on Rehabilitation Robotics (ICORR)","20131031","2013","","","1","6","This work presents an algorithm for collaborative control of an assistive semi-autonomous wheelchair. Our approach is based on a statistical machine learning technique to learn task variability from demonstration examples. The algorithm has been developed in the context of shared-control powered wheelchairs that provide assistance to individuals with impairments that affect their control in challenging driving scenarios, like doorway navigation. We validate our algorithm within a simulation environment, and find that with relatively few demonstrations, our approach allows for safe traversal of the doorway while maintaining a high level of user control.","1945-7898;19457898","Electronic:978-1-4673-6024-1; POD:978-1-4673-6021-0","10.1109/ICORR.2013.6650454","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6650454","","Aerospace electronics;Mathematical model;Mobile robots;Navigation;Robot sensing systems;Wheelchairs","handicapped aids;learning (artificial intelligence);navigation;robots;safety;statistical analysis;wheelchairs","assisted wheelchair navigation;assistive semi-autonomous wheelchair;collaborative control;doorway navigation;doorway safe traversal;human controls;robot controls;shared-control powered wheelchairs;statistical machine learning technique","1","4","","16","","","24-26 June 2013","","IEEE","IEEE Conference Publications"
"Anomaly Detection in Sensor Systems Using Lightweight Machine Learning","H. H. W. J. Bosman; A. Liotta; G. Iacca; H. J. Wörtche","Dept. of Electr. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","7","13","The maturing field of Wireless Sensor Networks (WSN) results in long-lived deployments that produce large amounts of sensor data. Lightweight online on-mote processing may improve the usage of their limited resources, such as energy, by transmitting only unexpected sensor data (anomalies). We detect anomalies by analyzing sensor reading predictions from a linear model. We use Recursive Least Squares (RLS) to estimate the model parameters, because for large datasets the standard Linear Least Squares Estimation (LLSE) is not resource friendly. We evaluate the use of fixed-point RLS with adaptive thresholding, and its application to anomaly detection in embedded systems. We present an extensive experimental campaign on generated and real-world datasets, with floating-point RLS, LLSE, and a rule-based method as benchmarks. The methods are evaluated on prediction accuracy of the models, and on detection of anomalies, which are injected in the generated dataset. The experimental results show that the proposed algorithm is comparable, in terms of prediction accuracy and detection performance, to the other LS methods. However, fixed-point RLS is efficiently implement able in embedded devices. The presented method enables online on-mote anomaly detection with results comparable to offline LS methods.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6721762","Adaptive Systems;Anomaly detection;Embedded Systems;Recursive Least Squares","Adaptation models;Embedded systems;Least squares approximations;Noise;Prediction algorithms;Predictive models;Wireless sensor networks","embedded systems;floating point arithmetic;learning (artificial intelligence);least mean squares methods;telecommunication computing;wireless sensor networks","LLSE;WSN;embedded devices;embedded systems;fixed-point RLS;floating-point RLS;lightweight machine learning;lightweight online on-mote processing;linear least squares estimation;offline LS methods;online on-mote anomaly detection;recursive least squares;rule-based method;sensor reading predictions;sensor systems;wireless sensor networks","","3","","23","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Browserbite: Accurate Cross-Browser Testing via Machine Learning over Image Features","N. Semenenko; M. Dumas; T. Saar","Inst. of Comput. Sci., Univ. of Tartu, Tartu, Estonia","2013 IEEE International Conference on Software Maintenance","20131202","2013","","","528","531","Cross-browser compatibility testing is a time consuming and monotonous task. In its most manual form, Web testers open Web pages one-by-one on multiple browser-platform combinations and visually compare the resulting page renderings. Automated cross-browser testing tools speed up this process by extracting screenshots and applying image processing techniques so as to highlight potential incompatibilities. However, these systems suffer from insufficient accuracy, primarily due to a large percentage of false positives. Improving accuracy in this context is challenging as the criteria for classifying a difference as an incompatibility are to some extent subjective. We present our experience building a cross-browser testing tool (Browser bite) based on image segmentation and differencing in conjunction with machine learning. An experimental evaluation involving a dataset of 140 pages, each rendered in 14 browser-system combinations, shows that the use of machine learning in this context leads to significant accuracy improvement, allowing us to attain an F-score of over 90%.","1063-6773;10636773","Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5","10.1109/ICSM.2013.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676949","cross-browser testing;image processing;machine learning","Accuracy;Biological neural networks;Classification tree analysis;Neurons;Testing;Web pages","Internet;image segmentation;learning (artificial intelligence);online front-ends;program testing","Web pages;Web testers;automated cross-browser testing tools;browserbite;cross-browser compatibility testing;image features;image processing techniques;image segmentation;machine learning;multiple browser-platform combinations;page renderings","","2","","13","","","22-28 Sept. 2013","","IEEE","IEEE Conference Publications"
"Machines that learn and teach seamlessly","G. Stein; A. J. Gonzalez; C. Barham","Intell. Syst. Lab., Univ. of Central Florida, Orlando, FL, USA","IEEE Transactions on Learning Technologies","20131209","2013","6","4","389","402","This paper describes an investigation into creating agents that can learn how to perform a task by observing an expert, then seamlessly turn around and teach the same task to a less proficient person. These agents are taught through observation of expert performance and thereafter refined through unsupervised practice of the task, all on a simulated environment. A less proficient human is subsequently taught by the now-trained agent through a third approach-coaching, executed through a haptic device. This approach addresses tasks that involve complex psychomotor skills. A machine-learning algorithm called PIGEON is used to teach the agents. A prototype is built and then tested on a task involving the manipulation of a crane to move large container boxes in a simulated shipyard. Two evaluations were performed-a proficiency test and a learning rate test. These tests were designed to determine whether this approach improves the human learning more than self-experimentation by the human. While the test results do not conclusively show that our approach provides improvement over self-learning, some positive aspects of the results suggest great potential for this approach.","1939-1382;19391382","","10.1109/TLT.2013.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6596491","Machine learning;augmented feedback;haptic feedback;intelligent tutoring systems;learning agents;psychomotor skill learning;teaching agents","Adaptation models;Computer graphics;Haptic interfaces;Machine learning;Real-time systems","computer aided instruction;cranes;haptic interfaces;learning (artificial intelligence);learning by example;software agents;teaching","PIGEON;agents;coaching;complex psychomotor skills;container boxes;crane manipulation;haptic device;human learning;human self-experimentation;learning rate test;machine-learning algorithm;proficiency test;self-learning;shipyard;teaching","","1","","64","","20130912","Oct.-Dec. 2013","","IEEE","IEEE Journals & Magazines"
"Applications of the extension theory in machine learning field","O. I. Sandru; L. Vladareanu; P. Schiopu; A. Sandru; V. Vladareanu","Dept. of Math. Models & Methods, Politeh. Univ. Bucharest, Bucharest, Romania","Proceedings of the 2013 International Conference on Advanced Mechatronic Systems","20131219","2013","","","524","529","This paper presents a new type of genetic algorithm of environment exploration artificial intelligence automata based on various elements of Extenics theory.","2325-0682;23250682","Electronic:978-1-4799-2519-3; POD:978-1-4799-2520-9","10.1109/ICAMechS.2013.6681700","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681700","AI;cell decomposition;collision-free path;extenics theory;genetic algorithm;machine learning;robot motion planning","Extremities;Learning automata;Telecommunications","automata theory;genetic algorithms;learning (artificial intelligence)","Extenics theory;artificial intelligence automata;extension theory applications;genetic algorithm;machine learning field","","0","","12","","","25-27 Sept. 2013","","IEEE","IEEE Conference Publications"
"Exploring human behaviour models through causal summaries and machine learning","M. Kvassay; L. Hluchý; P. Krammer; B. Schneider","Institute of Informatics, Slovak Academy of Sciences, Bratislava, Slovakia","2013 IEEE 17th International Conference on Intelligent Engineering Systems (INES)","20131017","2013","","","231","236","This paper is a case study meant to demonstrate the relevance of causal summaries for exploratory analysis of human behaviour models. We broadly define a causal summary as a partition of the significant values of the analyzed variables (in our case the simulated motives fear and anger of human beings) into separate contributions by various “causing” factors, such as social influence or external events. We demonstrate that such causal summaries can be processed by machine learning techniques (e.g. clustering and classification) and facilitate meaningful interpretations of the emergent behaviours of complex agent-based models.","1543-9259;15439259","Electronic:978-1-4799-0830-1; POD:978-1-4799-0827-1; USB:978-1-4799-0829-5","10.1109/INES.2013.6632817","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6632817","","Analytical models;Data models;Equations;Iron;Mathematical model;Support vector machines;Vectors","behavioural sciences computing;human factors;learning (artificial intelligence);software agents","anger;causal summary;causing factors;complex agent-based models;exploratory analysis;fear;human behaviour models;human beings;machine learning;social influence","","1","","10","","","19-21 June 2013","","IEEE","IEEE Conference Publications"
"Climate Informatics: Accelerating Discovering in Climate Science with Machine Learning","C. Monteleoni; G. A. Schmidt; S. McQuade","George Washington Univ., Washington, DC, USA","Computing in Science & Engineering","20131122","2013","15","5","32","40","Given the impact of climate change, understanding the climate system is an international priority. The goal of climate informatics is to inspire collaboration between climate scientists and data scientists, in order to develop tools to analyze complex and ever-growing amounts of observed and simulated climate data, and thereby bridge the gap between data and understanding. Here, recent climate informatics work is presented, along with details of some of the remaining challenges.","1521-9615;15219615","","10.1109/MCSE.2013.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6531616","climate informatics;climate science;data mining;machine learning;statistics","Atmospheric measurements;Climate change;Informatics;Machine learning;Meteorology","climate mitigation;geophysics computing;learning (artificial intelligence)","climate change;climate informatics;climate science;machine learning","","2","","22","","20130613","Sept.-Oct. 2013","","IEEE","IEEE Journals & Magazines"
"About analysis and robust classification of searchlight fMRI-data using machine learning classifiers","M. Lange; M. Kästner; T. Villmann","Comput. Intell. Group at the Dept. for Math./Natural & Comput. Sci., Univ. of Appl. Sci. Mittweida, Mittweida, Germany","The 2013 International Joint Conference on Neural Networks (IJCNN)","20140109","2013","","","1","8","In the present paper we investigate the analysis of functional magnetic resonance image (fMRI) data based on voxel response analysis. All voxels in local spatial area (volume) of a considered voxel form its so-called searchlight. The searchlight for a presented task is taken as a complex pattern. Task dependent discriminant analysis of voxel is then performed by assessment of the discrimination behavior of the respective searchlight pattern for a given task. Classification analysis of these patterns is usually done using linear support vector machines (linSVMs) as a machine learning approach or another statistical classifier like linear discriminant classifier. The test classification accuracy determining the task sensitivity is interpreted as the discrimination ability of the related voxel. However, frequently, the number of voxels contributing to a searchlight is much larger than the number of available pattern samples in classification learning, i.e. the dimensionality of patterns is higher than the number of samples. Therefore, the respective underlying mathematical classification problem has not an unique solution such that a certain solution obtained by the machine learning classifier contains arbitrary (random) components. For this situation, the generalization ability of the classifier may drop down. We propose in this paper another data processing approach to reduce this problem. In particular, we reformulate the classification problem within the searchlight. Doing so, we avoid the dimensionality problem: We obtain a mathematically well-defined classification problem, such that generalization ability of a trained classifier is kept high. Hence, a better stability of the task discrimination is obtained. Additionally, we propose the utilization of generalized learning vector quantizers as an alternative machine learning classifier system compared to SVMs, to improve further the stability of the classifier model due to decreased model complexity.","2161-4393;21614393","Electronic:978-1-4673-6129-3; POD:978-1-4673-6127-9","10.1109/IJCNN.2013.6706990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6706990","","Accuracy;Complexity theory;Data models;Standards;Support vector machines;Training;Vectors","biomedical MRI;learning (artificial intelligence);medical image processing;pattern classification;statistical analysis;support vector machines","data processing approach;functional magnetic resonance image data;generalized learning vector quantizers;linSVM;linear discriminant classifier;linear support vector machines;local spatial area;machine learning classifiers;mathematical classification problem;model complexity;searchlight fMRI-data;statistical classifier;task dependent discriminant analysis;test classification accuracy;voxel response analysis","","0","","59","","","4-9 Aug. 2013","","IEEE","IEEE Conference Publications"
"Adaptive Process Execution in a Service Cloud: Service Selection and Scheduling Based on Machine Learning","D. S. Kang; H. Liu; M. P. Singh; T. Sun","Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA","2013 IEEE 20th International Conference on Web Services","20131031","2013","","","324","331","Given a process specification, it is a complex task to dynamically select constituent services and compose them in an execution plan to satisfy users' non-functional preferences. Process scheduling approaches assume users can clearly specify their non-functional preferences and there are formulas (e.g., utility functions) to compute process level QoS from the QoS of constituent services and their connections. However, these assumptions are not always true. Users' preferences can be subjective, implicit, vague, mixed and different for various types of processes. Besides, not all the preferences for example easy-to-use can be computed using formulas. We proposed a machine learning based approach to evolutionarily learn user preferences according to their ratings on historical execution plans, recommend existing or generate new execution plans for business processes that adapt to user preferences.","","Electronic:978-0-7695-5025-1; POD:978-1-4799-0489-1","10.1109/ICWS.2013.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6649595","","Adaptation models;Availability;Business;Cloud computing;Engines;Quality of service;Time factors","business data processing;cloud computing;learning (artificial intelligence)","adaptive process execution;business processes;complex task;constituent services;evolutionarily learn user preferences;historical execution plans;machine learning;nonfunctional preferences;process level QoS;process scheduling;process specification;service cloud;service selection","","0","","15","","","June 28 2013-July 3 2013","","IEEE","IEEE Conference Publications"
"Machine learning to predict extubation outcome in premature infants","M. Mueller; C. C. Wagner; R. Stanislaus; J. S. Almeida","Med. Univ. of South Carolina, Charleston, SC, USA","The 2013 International Joint Conference on Neural Networks (IJCNN)","20140109","2013","","","1","6","Though treatment of the ventilated premature infant has experienced many advances over the past decades, determining the best time point for extubation of these infants remains challenging and the incidence of extubation failures largely unchanged. The objective was to provide clinicians with a decision-support tool to determine whether to extubate a mechanically ventilated premature infant by using a set of machine learning algorithms on a dataset assembled from 486 premature infants receiving mechanical ventilation. Algorithms included artificial neural networks (ANN), support vector machine (SVM), naïve Bayesian classifier (NBC), boosted decision trees (BDT), and multivariable logistic regression (MLR). Results for ANN, MLR, and NBC were satisfactory (area under the curve [AUC]: 0.63-0.76); however, SVM and BDT consistently showed poor performance (AUC ~0.5). Complex medical data such as the data set used for this study require further preprocessing steps before prediction models can be developed that achieve similar or better performance than clinicians.","2161-4393;21614393","Electronic:978-1-4673-6129-3; POD:978-1-4673-6127-9","10.1109/IJCNN.2013.6707058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707058","","Artificial neural networks;Classification algorithms;Input variables;Machine learning algorithms;Pediatrics;Prediction algorithms;Support vector machines","Bayes methods;decision support systems;decision trees;medical computing;neural nets;paediatrics;regression analysis;support vector machines;ventilation","ANN;AUC;BDT;MLR;NBC;SVM;area under the curve;artificial neural networks;boosted decision trees;decision-support tool;extubation failures;extubation outcome;machine learning algorithms;mechanical ventilation;mechanically ventilated premature infant;medical data;multivariable logistic regression;naïve Bayesian classifier;prediction models;premature infants;support vector machine","","0","","14","","","4-9 Aug. 2013","","IEEE","IEEE Conference Publications"
"An Automatic Electronic Nursing Records Analysis System Based on the Text Classification and Machine Learning","Z. Wei; Z. X. Ju; X. Chun; J. Hua; P. Jin","Dept. of Comput. Eng., Chengdu Technol. Univ., Chengdu, China","2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics","20131024","2013","2","","494","498","Enormous amount of unstructured electronic health record are invaluable for the medical research in finding the relationship between the patient's disease and the final diagnosis. How to use computer automatically dig up these information has long been a hot spot. To get the relationship between the clinical outcomes and free text writing by nurse, we developed an automatic categorization system process natural language nursing record Based on vector space model. 210 cases of electronic nursing records, which were diagnosed as pancreatitis, were induced in this study. We filtered the restricted corpus for acute pancreatitis classification by information gain (information gain. IG), and construct a text classification system Based on Partial least squares discrimination algorithm (PLS-DA) and vector support machine (VSM). PLS loading value analysis found that there are 20 terms can be used to classify medical record text. Our innovative machine-learning algorithm effectively classified free texts of nurse care records associated with normal and acute pancreatitis diagnoses, after training on pre-classified test sets by PLS. This automatic identification technology focus in large-scale medical document may provide important clues to study the acute pancreatitis and other important common disease.","","Electronic:978-0-7695-5011-4; POD:978-1-4799-0236-1","10.1109/IHMSC.2013.265","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6642793","Information gain;Pancreatitis;Partial Least Squares;Text classification;Vector support machine","Accuracy;Computers;Medical diagnostic imaging;Medical services;Support vector machines;Text categorization;Vectors","learning (artificial intelligence);least squares approximations;medical information systems;natural language processing;pattern classification;support vector machines;text analysis","PLS loading value analysis;PLS-DA;VSM;acute pancreatitis classification;automatic categorization system;automatic electronic nursing records analysis system;information gain;large-scale medical document;machine learning;medical research;natural language nursing record;partial least squares discrimination algorithm;patients disease;text classification system;unstructured electronic health record;vector space model;vector support machine","","0","","7","","","26-27 Aug. 2013","","IEEE","IEEE Conference Publications"
"Extending a Distributed Online Machine Learning Framework for Streaming Video Analysis","Y. Tsuji; H. H. Huang; K. Kawagoe","Ritsumeikan Univ., Kusatsu, Japan","2013 Second IIAI International Conference on Advanced Applied Informatics","20131015","2013","","","279","283","With the advent of video processing and Internet technologies, tremendous number of video clips are now accessible on the Internet. However, due to large video sizes and real-time video streaming, it is very difficult to analyze video in real time, which is a necessary step in many video web services. In this paper, we propose a novel extension method for an existing distributed machine learning framework, Jubatus, which was mainly developed for analyzing textual data. With our extension, numerous video clips can be analyzed efficiently by a machine learning framework. We also describe some preliminary evaluation results to indicate the efficiency of our proposed extension.","","Electronic:978-0-7695-5071-8; POD:978-1-4799-2136-2","10.1109/IIAI-AAI.2013.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6630360","analysis;distributed framework;extension;machine learning;video","Computer architecture;Distributed databases;Feature extraction;Internet;Multimedia communication;Real-time systems;Streaming media","Internet;learning (artificial intelligence);video streaming","Internet technology;distributed online machine learning framework;real-time video streaming;video Web service;video clip;video processing","","0","","20","","","Aug. 31 2013-Sept. 4 2013","","IEEE","IEEE Conference Publications"
"Towards machine learning based design pattern recognition","S. Alhusain; S. Coupland; R. John; M. Kavanagh","Centre for Comput. Intell., De Montfort Univ., Leicester, UK","2013 13th UK Workshop on Computational Intelligence (UKCI)","20131031","2013","","","244","251","Software design patterns are abstract descriptions of best practice solutions for recurring design problems. The information about which design pattern is implemented where in a software design is very helpful and important for software maintenance and evolution. This information is usually lost due to poor, obsolete or lack of documentation, which raises the importance of automatic recognition techniques. However, their vague and abstract nature allows them to be implemented in various ways, which gives them resistance to be automatically and accurately recognized. This paper presents the first recognition approach to be solely based on machine learning methods. We build a training dataset by using several existing recognition tools and we use feature selection methods to select the input feature vectors. Artificial neural networks are then trained to perform the whole recognition process. Our approach is evaluated by conducting an experiment to recognize six design patterns in an open source application.","2162-7657;21627657","Electronic:978-1-4799-1568-2; POD:978-1-4799-1567-5","10.1109/UKCI.2013.6651312","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651312","Software design patterns;machine learning;pattern recognition;reverse engineering","Documentation;Learning systems;Measurement;Pattern recognition;Topology;Training;Vectors","learning (artificial intelligence);neural nets;pattern recognition;public domain software;software maintenance","artificial neural networks;automatic recognition techniques;feature selection methods;first recognition approach;input feature vectors;machine learning;open source application;pattern recognition;recurring design problems;software design pattern;software evolution;software maintenance","","4","","46","","","9-11 Sept. 2013","","IEEE","IEEE Conference Publications"
"Accelerated learning in machine learning-based resource allocation methods for Heterogenous Networks","J. R. Tefft; N. J. Kirsch","Dept. of Electr. & Comput. Eng., Univ. of New Hampshire, Durham, NH, USA","2013 IEEE 7th International Conference on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS)","20131114","2013","01","","468","473","Heterogeneous Networks, such as those with Femtocells and Macrocell Basestations, face the task of resource allocation to ensure all users, both primary (mobile user) and secondary (femtocell user), receive assurances of quality of service. One method of performing this allocation, Q-learning, involves the use of a reward function (defining objectives) and a Q-table (storing policy information). This Q-table can be shared between users to speed up convergence on a policy ensuring a desired quality of service. In this paper, a reward function and state structure are presented and compared to another Q-learning reward function. The designed RF is shown to increase the sum femtocell user capacity in most scenarios while maintaining the desired quality of service for the mobile user. The sharing of Q-tables formed using th e designed reward function and state structure with nodes entering the network is shown to significantly speed up convergence in most scenarios when compared to convergence without sharing Q-tables.","","Electronic:978-1-4799-1429-6; POD:978-1-4799-1425-8","10.1109/IDAACS.2013.6662729","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6662729","","Femtocells;Interference;Mathematical model;Mobile communication;Quality of service;Radio frequency;Resource management","femtocellular radio;learning (artificial intelligence);quality of service;resource allocation;telecommunication computing","Q-learning;Q-table;femtocell user;femtocells basestations;heterogenous networks;machine learning-based resource allocation methods;macrocell basestations;mobile user;quality of service;reward function","","1","","18","","","12-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"Evaluating machine learning for predicting next-day hot water production of a heat pump","T. Olsson","Swedish Institute of Computer Science (SICS), Isafjordsgatan 22, Box 1263, SE-164 29 Kista, Sweden","4th International Conference on Power Engineering, Energy and Electrical Drives","20131021","2013","","","1688","1693","This paper describes an evaluation of five machine learning algorithms for predicting the domestic space and hot-water heating production for the next day. The evaluated algorithms were the k-nearest neighbour algorithm, linear regression, regression tree, decision table and support vector machine regression. The hot water production was measured in the ME3Gas project, where data was collected from two Swedish households that use the same type of geothermal heat pumps for space heating and hot-water production. The evaluation consisted of four experiments where we compared the regression performance by varying the number of previous days and the number of time periods for each day as input features. In the experiments, the k-nearest neighbour algorithm, linear regression and support vector machine regression had the best performance.","2155-5516;21555516","Electronic:978-1-4673-6392-1; POD:978-1-4673-6391-4; USB:978-1-4673-6390-7","10.1109/PowerEng.2013.6635871","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6635871","","Heat pumps;Machine learning algorithms;Prediction algorithms;Production;Space heating;Temperature measurement;Water heating","heat pumps;learning (artificial intelligence);regression analysis;space heating;support vector machines;trees (mathematics)","ME3Gas project;Swedish households;decision table;domestic space heating;geothermal heat pumps;hot-water heating production;hot-water production;k-nearest neighbour algorithm;linear regression;machine learning;next-day hot water production;regression tree;support vector machine regression","","1","","23","","","13-17 May 2013","","IEEE","IEEE Conference Publications"
"Risk stratification for Arrhythmic Sudden Cardiac Death in heart failure patients using machine learning techniques","G. Manis; S. Nikolopoulos; P. Arsenos; K. Gatzoulis; P. Dilaveris; C. Stefanadis","Dept. of Comput. Sci. & Eng., Univ. of Ioannina, Ioannina, Greece","Computing in Cardiology 2013","20140116","2013","","","141","144","Arrhythmic Sudden Cardiac Death (SCD) is still a major clinical challenge even though much research has been done in the field. Machine learning techniques give a powerful tool for stratifying arrhythmic risk. We analyzed 40 Holter recordings from heart failure patients, 20 of which were characterized as high arrhythmia risk after 16 months follow up. The two groups (high and low risk) were not statistically different in basic clinical characteristics. We performed windowed analysis and computed 25 Heart Rate Variability (HRV) indices. We fed these indices as input to two classifiers: Support Vector Machines (SVM) and Random Forests (RF). The classification results showed that the automatic classification of the two groups of subjects is possible.","0276-6574;02766574","Electronic:978-1-4799-0886-8; POD:978-1-4799-0885-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6712431","","Accuracy;Educational institutions;Heart rate variability;Indexes;Support vector machines;Vegetation","cardiology;learning (artificial intelligence);patient treatment;support vector machines","HRV indices;Holter recordings;SCD;SVM;arrhythmia risk;arrhythmic risk stratification;arrhythmic sudden cardiac death;automatic classification;heart failure patients;heart rate variability indices;machine learning;random forests;support vector machines;windowed analysis","","0","","17","","","22-25 Sept. 2013","","IEEE","IEEE Conference Publications"
"Machine learning in radioactive nuclides identification","K. Peter; H. Ladislav; B. Juraj","Inst. of Inf., Bratislava, Slovakia","2013 IEEE 11th International Symposium on Intelligent Systems and Informatics (SISY)","20131114","2013","","","57","61","Chemistry and nuclear physics represent one of possible options of large area for practical data mining applications. Radio-active nuclides are related with many sectors, such as medicine or industry. Successful detection and identification of radio-nuclides allows the realization of specific safety precaution and then increasing of security level in nuclear power plants, or medicine institutes. Data obtained by radio spectroscopy method reach high level of relevancy. Thus these data are suitable for using data mining methods, because the presented problem corresponds with classification task. Two radio-nuclides identification methods were presented in this paper; the second method is designed specially for this purpose.","1949-047X;1949047X","Electronic:978-1-4799-0305-4; POD:978-1-4799-0302-3; USB:978-1-4799-0304-7","10.1109/SISY.2013.6662617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6662617","","Accuracy;Computational modeling;Computer architecture;Data mining;Data models;Servers;Training","chemistry computing;data mining;learning (artificial intelligence);nuclear engineering computing","chemistry physics;data mining applications;machine learning;nuclear physics;nuclear power plants;radio nuclides identification methods;radio spectroscopy method;radioactive nuclides identification;safety precaution","","0","","12","","","26-28 Sept. 2013","","IEEE","IEEE Conference Publications"
"Machine Learning Techniques for Cooperative Spectrum Sensing in Cognitive Radio Networks","K. M. Thilina; K. W. Choi; N. Saquib; E. Hossain","Department of Electrical and Computer Engineering at the University of Manitoba, Canada","IEEE Journal on Selected Areas in Communications","20131017","2013","31","11","2209","2221","We propose novel cooperative spectrum sensing (CSS) algorithms for cognitive radio (CR) networks based on machine learning techniques which are used for pattern classification. In this regard, unsupervised (e.g., K-means clustering and Gaussian mixture model (GMM)) and supervised (e.g., support vector machine (SVM) and weighted K-nearest-neighbor (KNN)) learning-based classification techniques are implemented for CSS. For a radio channel, the vector of the energy levels estimated at CR devices is treated as a feature vector and fed into a classifier to decide whether the channel is available or not. The classifier categorizes each feature vector into either of the two classes, namely, the ""channel available class"" and the ""channel unavailable class"". Prior to the online classification, the classifier needs to go through a training phase. For classification, the K-means clustering algorithm partitions the training feature vectors into K clusters, where each cluster corresponds to a combined state of primary users (PUs) and then the classifier determines the class the test energy vector belongs to. The GMM obtains a mixture of Gaussian density functions that well describes the training feature vectors. In the case of the SVM, the support vectors (i.e., a subset of training vectors which fully specify the decision function) are obtained by maximizing the margin between the separating hyperplane and the training feature vectors. Furthermore, the weighted KNN classification technique is proposed for CSS for which the weight of each feature vector is calculated by evaluating the area under the receiver operating characteristic (ROC) curve of that feature vector. The performance of each classification technique is quantified in terms of the average training time, the sample classification delay, and the ROC curve. Our comparative results clearly reveal that the proposed algorithms outperform the existing state-of-the-art CSS techniques.","0733-8716;07338716","","10.1109/JSAC.2013.131120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6635250","Cognitive radio;GMM;K-means clustering;K-nearest-neighbor;cooperative spectrum sensing;primary user detection;support vector machine (SVM)","Availability;Cascading style sheets;Energy states;Sensors;Support vector machines;Training;Vectors","cognitive radio;cooperative communication;learning (artificial intelligence);pattern classification;radio networks;radio spectrum management;signal detection;support vector machines;telecommunication computing","CSS algorithms;GMM;Gaussian density functions;Gaussian mixture model;K-means clustering;K-nearest-neighbor classification;KNN classification;ROC curve;SVM;cognitive radio networks;cooperative spectrum sensing;feature vector;machine learning;pattern classification;primary users;radio channel;receiver operating characteristic curve;support vector machine","","24","","24","","","November 2013","","IEEE","IEEE Journals & Magazines"
"Measurement of Carotid Intima-Media Thickness in ultrasound images by means of an automatic segmentation process based on machine learning","R. M. Menchón-Lara; M. C. Bastida-Jumilla; J. Larrey-Ruiz; R. Verdu-Monedero; J. Morales-Sánchez; J. L. Sancho-Gómez","Dpto. Tecnolog&#x00ED;as de la Informaci&#x00F3;n y las Comunicaciones, Universidad Polit&#x00E8;cnica de Cartagena Plaza del Hospital, 1, 30202, Cartagena (Murcia), Spain","Eurocon 2013","20131010","2013","","","2086","2093","The Intima-Media Thickness (IMT) of the Common Carotid Artery (CCA) is a reliable early indicator of atherosclerosis. Usually, it is manually measured by marking a few points on a B-mode ultrasound scan image of the CCA. By applying image segmentation techniques, the IMT can be detected along the artery length. A desirable feature of this process is the automation, avoiding the user dependence and the inter-rater variability. This work aims to find an effective segmentation method that allows the IMT measurement in an automatic way. Following this idea, this paper proposes an effective approach based on learning machines. The segmentation task is raised as a pattern recognition problem. Single Layer Feed-Forward Networks (SLFN) are designed and trained by means of the Optimally Pruned-Extreme Learning Machine (OP-ELM) algorithm to classify the pixels from a given ultrasound image, allowing the extraction of IMT boundaries. The proposed method has been tested using a set of 25 ultrasound images and several quantitative statistical evaluations have shown its accuracy and robustness.","","Electronic:978-1-4673-2232-4; POD:978-1-4673-2233-1","10.1109/EUROCON.2013.6625268","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6625268","Automated Measurement;Image Segmentation;Intima-Media Thickness;Learning Machines;Optimally Pruned-Extreme Learning Machine;Ultrasound Images","Arteries;Image segmentation;Neurons;Reliability;Training;Ultrasonic imaging;Ultrasonic variables measurement","biomedical ultrasonics;blood vessels;diseases;feature extraction;feedforward neural nets;image segmentation;learning (artificial intelligence);medical image processing;statistical analysis","B-mode ultrasound scan image;CCA;Carotid Intima-Media Thickness Measurement;Common Carotid Artery;IMT boundary extraction;IMT measurement;OP-ELM;Optimally Pruned-Extreme Learning Machine algorithm;SLFN;Single Layer Feed-Forward Networks;artery length;atherosclerosis early indicator;automatic segmentation process;image segmentation techniques;interrater variability;machine learning;pattern recognition problem;quantitative statistical evaluation;ultrasound images","","0","","16","","","1-4 July 2013","","IEEE","IEEE Conference Publications"
"On the Application of Supervised Machine Learning to Trustworthiness Assessment","S. Hauke; S. Biedermann; M. Mühlhäuser; D. Heider","Dept. of Comput. Sci., Tech. Univ. Darmstadt, Darmstadt, Germany","2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications","20131212","2013","","","525","534","State-of-the art trust and reputation systems seek to apply machine learning methods to overcome generalizability issues of experience-based Bayesian trust assessment. These approaches are, however, often model-centric instead of focussing on data and the complex adaptive system that is driven by reputation-based service selection. This entails the risk of unrealistic model assumptions. We outline the requirements for robust probabilistic trust assessment using supervised learning and apply a selection of estimators to a real-world dataset, in order to show the effectiveness of supervised methods. Furthermore, we provide a representational mapping of estimator output to a belief logic representation for the modular integration of supervised methods with other trust assessment methodologies.","2324-898X;2324898X","Electronic:978-0-7695-5022-0; POD:978-1-4799-1444-9","10.1109/TrustCom.2013.5","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680883","machine learning;supervised prediction;trust models","Aggregates;Bayes methods;Computational modeling;Data models;Estimation;Predictive models;Vegetation","Bayes methods;learning (artificial intelligence);trusted computing","belief logic representation;complex adaptive system;estimator output representational mapping;estimator selection;experience-based Bayesian trust assessment;generalizability issues;probabilistic trust assessment;reputation systems;reputation-based service selection;supervised machine learning;trustworthiness assessment","","1","","28","","","16-18 July 2013","","IEEE","IEEE Conference Publications"
"Machine learning methods for detecting anomalies in a power transformer by monitoring its hot-spot temperature","C. Brighenti; M. A. Sanz-Bobi","Institute of Technological Research - IIT, Engineering School, Comillas Pontifical University, Madrid, Spain","4th International Conference on Power Engineering, Energy and Electrical Drives","20131021","2013","","","528","533","This paper analyzes and compares different machine learning methods such as decision trees, SOMs, MLPs and rough sets for the classification of the operation condition of a power transformer. The purpose is to construct a classification model able to estimate the hot-spot temperature as a function of other external input variables. The classifier would then be used to detect anomalous operation conditions of the transformer by comparing the observed and estimated hot-spot temperatures.","2155-5516;21555516","Electronic:978-1-4673-6392-1; POD:978-1-4673-6391-4; USB:978-1-4673-6390-7","10.1109/PowerEng.2013.6635664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6635664","Classification methods;anomaly detection;decision trees;neural networks;power transformer;rough sets","Classification algorithms;Decision trees;Neurons;Power transformers;Temperature distribution;Temperature measurement;Training","computerised monitoring;decision trees;learning (artificial intelligence);multilayer perceptrons;pattern classification;power engineering computing;power transformers;rough set theory;self-organising feature maps","MLP;SOM;anomaly detection;decision trees;hot-spot temperature monitoring;machine learning methods;multilayer perceptrons;operation condition classification;power transformer;rough sets;self-organising maps","","0","","14","","","13-17 May 2013","","IEEE","IEEE Conference Publications"
"A novel NMF-based image quality assessment metric using extreme learning machine","S. Wang; C. Deng; W. Lin; G. B. Huang","School of Information and Electronics, Beijing Institute of Technology, China","2013 IEEE China Summit and International Conference on Signal and Information Processing","20131010","2013","","","255","258","In this paper, we propose a novel image quality assessment (IQA) metric based on nonnegative matrix factorization (NM-F). With nonnegativity and parts-based properties, NMF well demonstrates how human brain learns the parts of objects. This makes NMF distinguished from other feature extraction methods like singular value decomposition (SVD), principal components analysis (PCA), etc. Inspired by this, we adopt NMF to extract image features from reference and distorted images. Extreme learning machine (ELM) [10] is then employed for feature pooling to obtain the overall quality score. Compared with other machine learning techniques such as neural networks and support vector machines (SVMs), ELM provides better generalization performance with much faster learning speed and less human intervene. Experimental results with the TID database demonstrate that the proposed metric achieves better performance in comparison with the relevant state-of-the-art quality metrics and has lower computational complexity.","","Electronic:978-1-4799-1043-4; POD:978-1-4799-1041-0; USB:978-1-4799-1042-7","10.1109/ChinaSIP.2013.6625339","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6625339","Extreme Learning Machine;Image Quality Assessment;Nonnegative Matrix Factorization","Computational complexity;Feature extraction;Image quality;Measurement;Neurons;Noise;Vectors","computational complexity;feature extraction;generalisation (artificial intelligence);image processing;learning (artificial intelligence);matrix decomposition","NMF;TID database;computational complexity;distorted images;extreme learning machine;feature pooling;generalization performance;image feature extraction;image quality assessment metric;nonnegative matrix factorization;nonnegativity properties;parts-based properties","","0","","12","","","6-10 July 2013","","IEEE","IEEE Conference Publications"
"Interactive Machine Learning in Data Exploitation","R. Porter; J. Theiler; D. Hush","Los Alamos Nat. Lab., Los Alamos, NM, USA","Computing in Science & Engineering","20131122","2013","15","5","12","20","The goal of interactive machine learning is to help scientists and engineers exploit more specialized data from within their deployed environment in less time, with greater accuracy and fewer costs. A basic introduction to the main components is provided here, untangling the many ideas that must be combined to produce practical interactive learning systems. This article also describes recent developments in machine learning that have significantly advanced the theoretical and practical foundations for the next generation of interactive tools.","1521-9615;15219615","","10.1109/MCSE.2013.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6560028","interactive systems;machine learning;pattern recognition;scientific computing","Data processing;Image segmentation;Information processing;Interactive systems;Learning systems;Machine learning;Random variables;Vocabulary","data handling;human computer interaction;interactive systems;learning (artificial intelligence)","data exploitation;interactive machine learning system;interactive tools","","4","","18","","20130716","Sept.-Oct. 2013","","IEEE","IEEE Journals & Magazines"
"Keynote addresses: From auditory masking to binary classification: Machine learning for speech separation","D. Wang; R. Martin; P. Vary; P. Smaragdis","The Ohio State University, USA","2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics","20140109","2013","","","1","3","Speech separation, or the cocktail party problem, is a widely acknowledged challenge. Part of the challenge stems from the confusion of what the computational goal should be. While the separation of every sound source in a mixture is considered the gold standard, I argue that such an objective is neither realistic nor what the human auditory system does. Motivated by the auditory masking phenomenon, we have suggested instead the ideal time-frequency binary mask as a main goal for computational auditory scene analysis. This leads to a new formulation to speech separation that classifies time-frequency units into two classes: those dominated by the target speech and the rest. In supervised learning, a paramount issue is generalization to conditions unseen during training. I describe novel methods to deal with the generalization issue where support vector machines (SVMs) are used to estimate the ideal binary mask. One method employs distribution fitting to adapt to unseen signal-to-noise ratios and iterative voice activity detection to adapt to unseen noises. Another method learns more linearly separable features using deep neural networks (DNNs) and then couples DNN and linear SVM for training on a variety of noisy conditions. Systematic evaluations show high quality separation in new acoustic environments.","1931-1168;19311168","Electronic:978-1-4799-0972-8; POD:978-1-4799-0970-4","10.1109/WASPAA.2013.6701804","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701804","","","","","","0","","","","","20-23 Oct. 2013","","IEEE","IEEE Conference Publications"
"Static Prediction of Loop Iteration Counts Using Machine Learning to Enable Hot Spot Optimizations","D. Tetzlaff; S. Glesner","Dept. of oftware Eng. for Embedded Syst., Tech. Univ. Berlin, Berlin, Germany","2013 39th Euromicro Conference on Software Engineering and Advanced Applications","20131010","2013","","","300","307","In general, program execution spends most of the time in a small fraction of code called hot spots of the program. These regions where optimization would be most beneficial are mainly composed of loops and must be identified to enable hot spot optimizations. Consequently, identifying hot spots involves determining loop iteration counts arising at run-time of the program, which is often not knowable in advance at run-time and even less statically knowable at compile time of the application by using only static analyses. In this paper we present a sophisticated approach using machine learning techniques to automatically generate heuristics that provide the compiler with knowledge of this run-time behavior, hence yielding more precise heuristics than those generated by pure static analyses. Our experimental results demonstrate the accuracy of our approach and show the general applicability to a wide range of programs with different behavior as we have used 175 programs of 12 benchmark suites in total from different real-world application domains for our experiments. Among others, our approach eliminates the need for manual annotations of run-time information, which automates and facilitates the development of complex software, thus improving the software engineering process.","1089-6503;10896503","Electronic:978-0-7695-5091-6; POD:978-1-4799-1490-6","10.1109/SEAA.2013.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6619525","compiler optmization;machine learning;system analysis","Accuracy;Benchmark testing;Optimization;Program processors;Software engineering;Training","learning (artificial intelligence);optimising compilers;program control structures;program diagnostics","application compile time;automatic heuristics generation;benchmark suites;complex software development;hot-spot optimizations;machine learning;program execution;program run-time behavior;run-time information annotation;software engineering process improvement;static analysis;static loop iteration count prediction","","1","","35","","","4-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Keynote addresses: From auditory masking to binary classification: Machine learning for speech separation","D. Wang","Ohio State Univ., Columbus, OH, USA","2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics","20140109","2013","","","1","1","Summary form only given. Speech separation, or the cocktail party problem, is a widely acknowledged challenge. Part of the challenge stems from the confusion of what the computational goal should be. While the separation of every sound source in a mixture is considered the gold standard, I argue that such an objective is neither realistic nor what the human auditory system does. Motivated by the auditory masking phenomenon, we have suggested instead the ideal time-frequency binary mask as a main goal for computational auditory scene analysis. This leads to a new formulation to speech separation that classifies time-frequency units into two classes: those dominated by the target speech and the rest. In supervised learning, a paramount issue is generalization to conditions unseen during training. I describe novel methods to deal with the generalization issue where support vector machines (SVMs) are used to estimate the ideal binary mask. One method employs distribution fitting to adapt to unseen signal-to-noise ratios and iterative voice activity detection to adapt to unseen noises. Another method learns more linearly separable features using deep neural networks (DNNs) and then couples DNN and linear SVM for training on a variety of noisy conditions. Systematic evaluations show high quality separation in new acoustic environments.","1931-1168;19311168","Electronic:978-1-4799-0972-8; POD:978-1-4799-0970-4","10.1109/WASPAA.2013.6701900","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701900","","Acoustics;Awards activities;Biological neural networks;Conferences;Educational institutions;Speech;Speech processing","iterative methods;learning (artificial intelligence);neural nets;signal classification;signal detection;source separation;speech processing;support vector machines;time-frequency analysis","DNNs;acoustic environments;auditory masking phenomenon;binary classification;cocktail party problem;computational auditory scene analysis;deep neural networks;distribution fitting;human auditory system;ideal time-frequency binary mask estimation;iterative voice activity detection;linear SVM;machine learning;signal-to-noise ratio;sound source separation;speech separation;supervised learning;support vector machines;systematic evaluations;time-frequency unit classification","","0","","","","","20-23 Oct. 2013","","IEEE","IEEE Conference Publications"
"Improving Statistical Approach for Memory Leak Detection Using Machine Learning","V. Sor; P. Oü; T. Treier; S. N. Srirama","Software Technol. & Applic. Competence Center, Tartu, Estonia","2013 IEEE International Conference on Software Maintenance","20131202","2013","","","544","547","Memory leaks are major problems in all kinds of applications, depleting their performance, even if they run on platforms with automatic memory management, such as Java Virtual Machine. In addition, memory leaks contribute to software aging, increasing the complexity of software maintenance. So far memory leak detection was considered to be a part of development process, rather than part of software maintenance. To detect slow memory leaks as a part of quality assurance process or in production environments statistical approach for memory leak detection was implemented and deployed in a commercial tool called Plumbr. It showed promising results in terms of leak detection precision and recall, however, even better detection quality was desired. To achieve this improvement goal, classification algorithms were applied to the statistical data, which was gathered from customer environments where Plumbr was deployed. This paper presents the challenges which had to be solved, method that was used to generate features for supervised learning and the results of the corresponding experiments.","1063-6773;10636773","Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5","10.1109/ICSM.2013.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676953","","Aging;Java;Leak detection;Memory management;Resource management;Software;Training","learning (artificial intelligence);quality assurance;software maintenance;software metrics;statistical analysis","Java virtual machine;Plumbr;automatic memory management;classification algorithms;customer environments;machine learning;memory leak detection;production environment statistical approach;quality assurance process;software aging;software development process;software maintenance complexity;statistical data;supervised learning","","0","","25","","","22-28 Sept. 2013","","IEEE","IEEE Conference Publications"
"Machine learning methods for in vivo skin parameter estimation","S. Vyas; A. Banerjee; P. Burlina","Johns Hopkins Universiy, Applied Physics Laboratory, Laurel, MD, USA","Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems","20131010","2013","","","524","525","The WHO estimates three million new cases of skin cancer each year. Therefore, there exists a need for prescreening tools that can estimate the biological parameters of human skin, as they can help detect cancers before metastasis. In this paper, we present a novel inverse modeling technique based on Kubelka-Munk theory and machine learning to estimate biological skin parameters from in vivo hyperspec-tral imaging. We use the k-nearest neighbors (k-NN) algorithm in order to estimate skin parameters from their hy-perspectral signatures. We test our methods on 241 hyper-spectral signatures obtained from both genders and three ethnicities, and find encouraging results.","1063-7125;10637125","Electronic:978-1-4799-1053-3; POD:978-1-4799-1052-6","10.1109/CBMS.2013.6627860","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6627860","","Hyperspectral imaging;Mathematical model;Physiology;Skin;Testing;Training","biomedical optical imaging;cancer;hyperspectral imaging;inverse problems;learning (artificial intelligence);medical image processing;parameter estimation;skin","Kubelka-Munk theory;WHO;biological parameter estimation;cancer detection;human skin;hyperspectral signatures;in vivo hyperspectral imaging;in vivo skin parameter estimation;k-nearest neighbors algorithm;machine learning methods;metastasis;novel inverse modeling technique;prescreening tools;skin cancer","","1","","3","","","20-22 June 2013","","IEEE","IEEE Conference Publications"
"Hardware specialization of machine-learning kernels: Possibilities for applications and possibilities for the platform design space (Invited)","K. H. Lee; Z. Wang; N. Verma","Princeton University","SiPS 2013 Proceedings","20131202","2013","","","330","335","This paper considers two challenging trends affecting low-power sensing systems: (1) the applications of interest increasingly involve embedded signals that are very complex to analyze; and (2) the platforms themselves face elevating constraints in terms of energy and possibly cost. Motivated by the complexities of analyzing the application signals, we emphasize the benefits of data-driven approaches. Most notably, these approaches are based on machine learning, as opposed to traditional DSP. We consider how the algorithms lend themselves to specialized signal-analysis platforms. Hardware specialization is well-regarded as an approach to address issues of computational efficiency, performance, and capacity, thus playing a key role in leveraging Moore's Law. However, we describe how hardware specialization of machine-learning kernels, this time with an explicit focus on error resilience, can also play a powerful role in enabling system-wide fault tolerance, thereby aiding Moore's Law on another dimension.","2162-3562;21623562","Electronic:978-1-4673-6238-2","10.1109/SiPS.2013.6674528","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6674528","accelerators;embedded systems hardware resilience;machine learning","Brain modeling;Computer architecture;Data models;Feature extraction;Hardware;Kernel;Training","embedded systems;learning (artificial intelligence);signal processing","Moore's law;application signals;computational efficiency;embedded signals;error resilience;hardware specialization;low-power sensing systems;machine-learning kernels;platform design space;signal-analysis platforms;system-wide fault tolerance","","1","","27","","","16-18 Oct. 2013","","IEEE","IEEE Conference Publications"
"Cloud Client Prediction Models Using Machine Learning Techniques","S. A. Ajila; A. A. Bankole","Dept. of Syst. & Comput. Eng., Carleton Univ., Ottawa, ON, Canada","2013 IEEE 37th Annual Computer Software and Applications Conference","20131031","2013","","","134","142","One way to proactively provision resources and meet Service Level Agreements (SLA) is by predicting future resource demands a few minutes ahead because of Virtual Machine (VM) boot time. In this research, we have developed and evaluated cloud client prediction models for TPC-W benchmark web application using three machine learning techniques: Support Vector Machine (SVM), Neural Networks (NN) and Linear Regression (LR). We have included two SLA metrics -- Response Time and Throughput with the aim of providing the client with a more robust scaling decision choice. As an improvement to our previous work, we implemented our model on a public cloud infrastructure: Amazon EC2. Furthermore, we extended the experimentation time by over 200%. Finally, we have employed random workload pattern to reflect a more realistic simulation. Our results show that Support Vector Machine provides the best prediction model.","","Electronic:978-0-7695-4986-6; POD:978-1-4673-6494-2","10.1109/COMPSAC.2013.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6649808","Cloud Computing;Machine Learning;Resourde Peovisioning;Resourde Prediction","Business;Linear regression;Measurement;Predictive models;Support vector machines;Throughput;Time factors","cloud computing;contracts;learning (artificial intelligence);neural nets;regression analysis;resource allocation;support vector machines","Amazon EC2;LR;NN;SLA metrics;SVM;TPC-W benchmark Web application;VM boot time;cloud client prediction models;linear regression;machine learning techniques;neural networks;random workload pattern;resource demands;resource provision;response time metric;robust scaling decision choice;service level agreements;support vector machine;throughput metric;virtual machine","","6","","26","","","22-26 July 2013","","IEEE","IEEE Conference Publications"
"Scalable machine learning framework for behavior-based access control","J. Cleveland; M. J. Mayhew; A. Adler; M. Atighetchi","Raytheon BBN Technologies, Cambridge, MA","2013 6th International Symposium on Resilient Control Systems (ISRCS)","20131010","2013","","","181","185","Today's activities in cyber space are more connected than ever before, driven by the ability to dynamically interact and share information with a changing set of partners over a wide variety of networks. The success of approaches aimed at securing the infrastructure has changed the threat profile to point where the biggest threat to the US cyber infrastructure is posed by targeted cyber attacks. The Behavior-Based Access Control (BBAC) effort has been investigating means to increase resilience against these attacks. Using statistical machine learning, BBAC (a) analyzes behaviors of insiders pursuing targeted attacks and (b) assesses trustworthiness of information to support real-time decision making about information sharing. The scope of this paper is to describe the challenge of processing disparate cyber security information at scale, together with an architecture and work-in-progress prototype implementation for a cloud framework supporting a strategic combination of stream and batch processing.","","CD-ROM:978-1-4799-0501-0; Electronic:978-1-4799-0503-4; POD:978-1-4799-0502-7","10.1109/ISRCS.2013.6623773","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6623773","access control;cloud computing;machine learning;security reasoning;trust management","Access control;Feature extraction;Information management;Prototypes;Storms;Support vector machines;Training","authorisation;learning (artificial intelligence);statistical analysis","BBAC;US cyber infrastructure;batch processing;behavior based access control;cloud framework;cyber attacks;cyber security information;cyber space;information sharing;real-time decision making;scalable machine learning framework;statistical machine learning;stream processing","","0","","13","","","13-15 Aug. 2013","","IEEE","IEEE Conference Publications"
"Scalable trace signal selection using machine learning","K. Rahmani; P. Mishra; S. Ray","Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA","2013 IEEE 31st International Conference on Computer Design (ICCD)","20131107","2013","","","384","389","A key problem in post-silicon validation is to identify a small set of traceable signals that are effective for debug during silicon execution. Structural analysis used by traditional signal selection techniques leads to poor restoration quality. In contrast, simulation-based selection techniques provide superior restorability but incur significant computation overhead. In this paper, we propose an efficient signal selection technique using machine learning to take advantage of simulation-based signal selection while significantly reducing the simulation overhead. Our approach uses (1) bounded mock simulations to generate training vectors set for the machine learning technique, and (2) an elimination approach to identify the most profitable signals set. Experimental results indicate that our approach can improve restorability by up to 63.3% (17.2% on average) with a faster or comparable runtime.","1063-6404;10636404","Electronic:978-1-4799-2987-0; POD:978-1-4799-2988-7","10.1109/ICCD.2013.6657069","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6657069","Post-silicon;machine learning;signal selection","Computational modeling;Integrated circuit modeling;Predictive models;Runtime;Support vector machines;Training;Vectors","computer debugging;electronic engineering computing;formal verification;integrated circuit design;learning (artificial intelligence);monolithic integrated circuits;signal restoration;silicon","Si;bounded mock simulation;computation overhead;debugging;machine learning technique;post-silicon validation;restoration quality;scalable trace signal selection;silicon execution;simulation-based selection technique;simulation-based signal selection;structural analysis;traceable signal identification;training vector set generation","","6","","16","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"A Machine Learning and Wavelet-Based Fault Location Method for Hybrid Transmission Lines","H. Livani; C. Y. Evrenosoglu","Bradley Dept. of Electr. & Comput. Eng., Virginia Tech, Blacksburg, VA, USA","IEEE Transactions on Smart Grid","20140102","2014","5","1","51","59","This paper presents a single-ended traveling wave-based fault location method for a hybrid transmission line: an overhead line combined with an underground cable. Discrete wavelet transformation (DWT) is used to extract transient information from the measured voltages. Support vector machine (SVM) classifiers are utilized to identify the faulty-section and faulty-half. Bewley diagrams are observed for the traveling wave patterns and the wavelet coefficients of the aerial mode voltage are used to locate the fault. The transient simulation for different fault types and locations are obtained by ATP using frequency-dependent line and cable models. MATLAB is used to process the simulated transients and apply the proposed method. The performance of the method is tested for different fault inception angles (FIA), different fault resistances, non-linear high impedance faults (NLHIF), and non-ideal faults with satisfactory results. The impact of cable aging on the proposed method accuracy is also investigated.","1949-3053;19493053","","10.1109/TSG.2013.2260421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6558520","Alternative transients program (ATP);fault location;frequency-dependent line model;support vector machine;travelling waves;underground cable;wavelet transformation","Fault location;Power cables;Support vector machines;Transient analysis;Transmission line measurements","discrete wavelet transforms;fault location;learning (artificial intelligence);power cables;power engineering computing;power overhead lines;power transmission faults;power transmission lines;support vector machines;underground cables","ATP;Bewley diagrams;DWT;FIA;Matlab;NLHIF;SVM classifier;aerial mode voltage;cable aging impact;cable model;discrete wavelet transformation;fault inception angles;fault resistances;faulty-half identification;faulty-section identification;frequency-dependent line model;hybrid transmission lines;machine learning;nonideal fault;nonlinear high-impedance faults;overhead line;single-ended traveling wave-based fault location method;support vector machine classifier;transient information;transient simulation;traveling wave patterns;underground cable;wavelet coefficient;wavelet-based fault location method","","20","","35","","20130712","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"Sentiment polarity identification using machine learning techniques","R. S. Chiorean; M. Dînşoreanu; D. I. Faloba; R. Potolea","Technical University of Cluj-Napoca Cluj-Napoca, Romania","2013 IEEE 9th International Conference on Intelligent Computer Communication and Processing (ICCP)","20131024","2013","","","47","50","The paper proposes an improved approach to the problem of sentiment polarity identification. Its main focus is on identifying and extracting the relevant information from natural language texts in order to obtain a set of best predictive features to be used for the classification task. Our approach of determining the polarity of a text consists of a combination of several processing techniques that obtains an efficient set of appropriate information for the underlying text. Among techniques, we have considered pruning the feature set to discard features without polarity or with less discriminative power, since their presence tend to mislead the learning process. Moreover, using word co-occurrence techniques, new composed bi-grams with high discriminative power are added which enhances the classification process. The best results are obtained using different combinations of techniques, depending on the dataset's homogeneity. On a homogeneous dataset, the performance in terms of precision is approximately 88% and, in terms of recall, a value of 93% is reached. In the case of a diverse dataset, the performance attained is 100%.","","Electronic:978-1-4799-1494-4; POD:978-1-4799-1492-0","10.1109/ICCP.2013.6646079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6646079","Feature Selection;Machine Learning Techniques;Natural Language Processing;Sentiment Analysis","Data mining;Feature extraction;Motion pictures;Natural language processing;Support vector machine classification;Vectors","learning (artificial intelligence);natural language processing;pattern classification;text analysis","bi-grams;classification process enhancement;dataset homogeneity;discriminative power;feature set;information extraction;information identification;machine learning techniques;natural language texts;precision value;predictive features;processing techniques;recall value;sentiment polarity identification;word co-occurrence techniques","","0","","11","","","5-7 Sept. 2013","","IEEE","IEEE Conference Publications"
"Applying machine learning methods and time series analysis to create a National Dynamic Land Cover Dataset for Australia","P. Tan; L. Lymburner; N. Mueller; F. Li; M. Thankappan; A. Lewis","Nat. Earth Obs. Group, Geosci. Australia, Canberra, ACT, Australia","2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS","20140127","2013","","","4289","4292","The National Dynamic Land Cover Dataset (DLCD) classifies Australian land cover into 34 categories, which conform to 2007 International Standards Organisation (ISO) Land Cover Standard (19144-2). The DLCD has been developed by Geoscience Australia and the Australian Bureau of Agricultural and Resource Economics and Sciences (ABARES), aiming to provide nationally consistent land cover information to federal and state governments and general public. This paper describes the modeling procedure to generate the DLCD, including machine learning methodologies and time series analysis techniques involved in the process.","2153-6996;21536996","Electronic:978-1-4799-1114-1; POD:978-1-4799-1112-7","10.1109/IGARSS.2013.6723782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6723782","Landcover;MODIS;Machine Learning;Time Series Analysis","Australia;Clustering algorithms;MODIS;Noise measurement;Static VAr compensators;Support vector machines;Time series analysis","ISO standards;environmental science computing;land cover;learning (artificial intelligence);time series","ABARES;AD 2007;Australian Bureau of Agricultural and Resource Economics and Sciences;Australian land cover;DLCD;Geoscience Australia;ISO Land Cover Standard;International Standards Organisation;National Dynamic Land Cover Dataset;land cover information;machine learning methods;modeling procedure;time series analysis","","1","","6","","","21-26 July 2013","","IEEE","IEEE Conference Publications"
"Machine Learning for Supporting Diagnosis of Amyotrophic Lateral Sclerosis Using Surface Electromyogram","X. Zhang; P. E. Barkhaus; W. Z. Rymer; P. Zhou","Institute of Biomedical Engineering, University of Science and Technology of China, Hefei, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","20140109","2014","22","1","96","103","Needle electromyogram (EMG) is routinely used in clinical neurophysiology for examination of neuromuscular diseases. This study presents a noninvasive surface EMG method for supporting diagnosis of amyotrophic lateral sclerosis (ALS). Three diagnostic markers including the clustering index, the kurtosis of EMG amplitude histogram, and the kurtosis of EMG crossing-rate expansion, were used respectively to characterize surface EMG patterns recorded during different levels of voluntary muscle contraction. We then applied a linear discriminant analysis classifier to discriminate the ALS subjects from the neurologically intact subjects, using the statistics derived from all the three markers as input feature sets to the classifier. The method was tested in 10 ALS subjects and 11 neurologically intact subjects. Combination of the three surface EMG markers achieved 90% diagnostic sensitivity and 100% diagnostic specificity, which were higher than solely using a single surface EMG marker. Given the high diagnostic yield, the proposed surface EMG analysis can be used as a supplement to needle EMG examination in supporting the diagnosis of ALS.","1534-4320;15344320","","10.1109/TNSRE.2013.2274658","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6587612","Amyotrophic lateral sclerosis (ALS);clustering index;kurtosis;machine learning;surface electromyogram (EMG)","Electrodes;Electromyography;Indexes;Interference;Linear regression;Muscles;Surface treatment","diseases;electromyography;feature extraction;learning (artificial intelligence);medical signal processing;neurophysiology;sensitivity;signal classification;statistical analysis","EMG amplitude histogram kurtosis;EMG crossing-rate expansion kurtosis;amyotrophic lateral sclerosis diagnosis;clinical neurophysiology;clustering index;diagnostic markers;diagnostic sensitivity;diagnostic specificity;input feature sets;linear discriminant analysis classifier;machine learning;needle electromyogram;neurologically intact subjects;neuromuscular diseases;noninvasive surface EMG method;statistics;surface EMG pattern recording;surface electromyogram;voluntary muscle contraction","0","3","","21","","20130828","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"Nelder-mead enhanced extreme learning machine","P. Reiner; B. M. Wilamowski","Department of Electrical and Computer Engineering, Auburn University, USA","2013 IEEE 17th International Conference on Intelligent Engineering Systems (INES)","20131017","2013","","","225","230","Many algorithms such as Support Vector Regression (SVR), Incremental Extreme Learning Machine (I-ELM), Convex Incremental Extreme Learning Machine (CI-ELM), and Enhanced random search based Incremental Extreme Learning Machine (EI-ELM) are being used in current research to solve various function approximation problems. This paper presents a modification to the I-ELM family of algorithms targeted specifically at Single Layer Feedforward Networks (SLFN) using Radial Basis Function (RBF) nodes. The modification includes eliminating randomness in both the center positions of the RBF units as well as the widths of the RBF units. This is accomplished by assigning the center of each incrementally added node to the highest point in the residual error surface and using Nelder-Mead's Simplex method to iteratively select an appropriate radius for the added node. Using this technique, the properties of I-ELM that allow for universal approximation and appropriate generalization are preserved, while the sizes of the RBF networks are greatly reduced.","1543-9259;15439259","Electronic:978-1-4799-0830-1; POD:978-1-4799-0827-1; USB:978-1-4799-0829-5","10.1109/INES.2013.6632816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6632816","Function Approximation;Machine Learning;Neural Networks;RBF Networks;Radial Basis Function;Support Vector Machines","Approximation algorithms;Equations;Function approximation;Mathematical model;Radial basis function networks;Training","function approximation;learning (artificial intelligence);radial basis function networks","CI-ELM;EI-ELM;Nelder-Mead enhanced extreme learning machine;Nelder-Mead simplex method;RBF nodes;SLFN;SVR;convex incremental extreme learning machine;enhanced random search based incremental extreme learning machine;function approximation problems;radial basis function nodes;residual error surface;single layer feedforward networks;support vector regression","","2","","16","","","19-21 June 2013","","IEEE","IEEE Conference Publications"
"Analysis of Android malware detection performance using machine learning classifiers","Hyo-Sik Ham; Mi-Jung Choi","Dept. of Comput. Sci., Kangwon Nat. Univ., Chuncheon, South Korea","2013 International Conference on ICT Convergence (ICTC)","20131202","2013","","","490","495","As mobile devices have supported various services and contents, much personal information such as private SMS messages, bank account information, etc. is scattered in mobile devices. Thus, attackers extend the attack range not only to the existing environment of PC and Internet, but also to the mobile device. Previous studies evaluated the malware detection performance of machine learning classifiers through collecting and analyzing event, system call, and log information generated in Android mobile devices. However, monitoring of unnecessary features without understanding Android architecture and malware characteristics generates resource consumption overhead of Android devices and low ratio of malware detection. In this paper, we propose new feature sets which solve the problem of previous studies in mobile malware detection and analyze the malware detection performance of machine learning classifiers.","2162-1233;21621233","Electronic:978-1-4799-0698-7; POD:978-1-4799-0696-3; USB:978-1-4799-0697-0","10.1109/ICTC.2013.6675404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6675404","Android;Detection Performance;Machine Learning Classifiers;Malware Detection","","Internet;invasive software;learning (artificial intelligence);mobile computing;operating systems (computers);software architecture","Android architecture;Android devices;Android malware detection performance;Android mobile devices;Internet;PC;bank account information;log information;machine learning classifiers;malware characteristics;mobile malware detection;private SMS messages;resource consumption overhead;system call","","3","","14","","","14-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"A random-forest-based efficient comparative machine learning predictive DNA-codon metagenomics binning technique for WMD events & applications","H. Saghir; D. B. Megherbi","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts, Lowell, MA, USA","2013 IEEE International Conference on Technologies for Homeland Security (HST)","20140102","2013","","","171","177","In many counter-terrorism, or natural disasters, geographically distributed large scale sensor-based bio-chemicals agent or microorganisms target identification and prediction applications, such as in WMD events, as well as in many health care and medical applications, efficient large scale metagenomics is crucial for purpose such as rapid and timely decontamination for normal environment restoration, or rapid and timely discovery of the right drug/therapy for the injured individuals. Metagenomics is the study of all bio-chemical and organisms collected directly from large natural environments including geographically distributed disastrous ones. Most of these collected bio-chemical and organisms cannot be cultivated in a laboratory and hence cannot be sequenced as individual organisms. Thus, metagenomics methods allow relatively rapid sequencing of organism genomes obtained directly from a natural environment, and which cannot be cultured in a laboratory. Sequencing random fragments obtained from whole genome shotgun into taxa-based groups is known as binning. Currently, there are two different methods of binning: sequence similarity methods and sequence composition methods. Sequence similarity methods are usually based on sequence alignment to known genome like BLAST, or MEGAN. Sequence composition methods are based on compositional features of a given DNA sequence like K-mers, or other genomic signature(s) like TETRA, Phylopythia, CompostBin, likelyBin. In this paper we propose a machine learning predictive DNA sequence feature selection algorithms to solve binning problems. In our prior work we showed feature selection/reduction and binning prediction based on direct nucleotide k-mers. Here we use a combination of 2 Codons (amino acids) as features to differentiate between sequences. There are 20 different amino acids which are found proteins. The combination of 2 amino acids produce 400 features which we use to differentiate between the metagenomics sequence. - he data reads used in this work has an average length of 250, 500, 1000, and 2000 base pairs. Experimental results of the codon-based feature reduction and binning prediction algorithms, namely using respectively a Random forest classifier and a Bayes classifier, are presented along with their comparison to their DNA-based k-mers counterparts. The proposed algorithm accuracy is tested on a variety of data sets and our findings show that the classification/prediction accuracy achieved is between 59%-92% for various data sets using Random forest classifier and 44%-64% using Naïve Bayes classifier. Random forest Classifier did better in classification in all the datasets compared to Naïve Bayes.","","CD-ROM:978-1-4799-3963-3; Electronic:978-1-4799-1535-4; POD:978-1-4799-3964-0","10.1109/THS.2013.6698995","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698995","Binning;Bioinformatics;Computational intelligence;Machine learning;Metagenomics;Next generation Sequencing;Pattern Classification;Random forest;Reduction methods;bagged decision tree;codon;forwaord sequential feature selection;k-mers","Accuracy;Amino acids;DNA;Genomics;Organisms;Sequential analysis;Testing","biology computing;genomics;learning (artificial intelligence);molecular biophysics;pattern classification","BLAST genome;Bayes classifier;CompostBin genomes;DNA sequence;MEGAN genome;Phylopythia genomes;TETRA genomes;WMD applications;WMD events;amino acids;binning methods;counter-terrorism;data reads;direct nucleotide k-mers;drug discovery;health care applications;likelyBin genomes;medical applications;metagenomics sequence;microorganisms;natural disasters;organism genomes;predictive DNA-codon metagenomics;proteins;random forest classifier;random-forest-based comparative machine learning;sensor-based biochemicals agent;sequence composition methods;sequence similarity methods","","0","","28","","","12-14 Nov. 2013","","IEEE","IEEE Conference Publications"
"Machine learning based prediction of warfarin optimal dosing for African American patients","A. Sharabiani; H. Darabi; A. Bress; L. Cavallari; E. Nutescu; K. Drozda","","2013 IEEE International Conference on Automation Science and Engineering (CASE)","20131107","2013","","","623","628","This paper proposes a new model for predicting the optimal warfarin dosing for African American patients. The prediction model is created using the multivariable regression method. The accuracy of dosing prediction is directly related to patient's safety. We show that the proposed model has better accuracy compare to all other available prediction methods for optimal dosing of warfarin.","2161-8070;21618070","Electronic:978-1-4799-1515-6; POD:978-1-4799-1513-2; USB:978-1-4799-1514-9","10.1109/CoASE.2013.6653999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6653999","Warfarin dosing;machine learning;multivariable regression;neural networks;support vector machines","Artificial neural networks;Data models;Equations;Hemorrhaging;Mathematical model;Predictive models;Support vector machines","learning (artificial intelligence);medical computing;patient treatment;regression analysis","African American patients;machine learning based prediction;multivariable regression method;patient safety;warfarin optimal dosing prediction","","0","","21","","","17-20 Aug. 2013","","IEEE","IEEE Conference Publications"
"Differential Evolution Extreme Learning Machine for the Classification of Hyperspectral Images","Y. Bazi; N. Alajlan; F. Melgani; H. AlHichri; S. Malek; R. R. Yager","Adv. Lab. for Intell. Syst. Res. Lab., King Saud Univ., Riyadh, Saudi Arabia","IEEE Geoscience and Remote Sensing Letters","20140128","2014","11","6","1066","1070","Recently, a new machine learning approach that is termed as the extreme learning machine (ELM) has been introduced in the literature. This approach is characterized by a unified formulation for regression, binary, and multiclass classification problems, and the related solution is given in an analytical compact form. In this letter, we propose an efficient classification method for hyperspectral images based on this machine learning approach. To address the model selection issue that is associated with the ELM, we develop an automatic-solution-based differential evolution (DE). This simple yet powerful evolutionary optimization algorithm uses cross-validation accuracy as a performance indicator for determining the optimal ELM parameters. Experimental results obtained from four benchmark hyperspectral data sets confirm the attractive properties of the proposed DE-ELM method in terms of classification accuracy and computation time.","1545-598X;1545598X","","10.1109/LGRS.2013.2286078","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6656874","Differential evolution (DE);extreme learning machine (ELM);feature extraction;hyperspectral images","Hyperspectral imaging;Kernel;Support vector machines;Training;Vectors","evolutionary computation;geophysical image processing;hyperspectral imaging;image classification;learning (artificial intelligence);regression analysis","DE-ELM method;automatic solution-based differential evolution;binary classification;differential evolution extreme learning machine;evolutionary optimization algorithm;hyperspectral image classification;model selection;multiclass classification problem;regression classification","","32","","20","","20131106","June 2014","","IEEE","IEEE Journals & Magazines"
"Automated Plant Disease Analysis (APDA): Performance Comparison of Machine Learning Techniques","A. Akhtar; A. Khanum; S. A. Khan; A. Shaukat","Coll. of Electr. & Mech. Eng., Nat. Univ. of Sci. & Technol. (NUST), Islamabad, Pakistan","2013 11th International Conference on Frontiers of Information Technology","20140123","2013","","","60","65","Plant disease analysis is one of the critical tasks in the field of agriculture. Automatic identification and classification of plant diseases can be supportive to agriculture yield maximization. In this paper we compare performance of several Machine Learning techniques for identifying and classifying plant disease patterns from leaf images. A three-phase framework has been implemented for this purpose. First, image segmentation is performed to identify the diseased regions. Then, features are extracted from segmented regions using standard feature extraction techniques. These features are then used for classification into disease type. Experimental results indicate that our proposed technique is significantly better than other techniques used for Plant Disease Identification and Support Vector Machines outperforms other techniques for classification of diseases.","","Electronic:978-1-4799-2503-2; POD:978-1-4799-2700-5","10.1109/FIT.2013.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6717227","Artificial Intelligence;Classification;Machine Learning;Plant Disease Analysis","Accuracy;Discrete cosine transforms;Discrete wavelet transforms;Diseases;Feature extraction;Image segmentation;Support vector machines","agriculture;feature extraction;image segmentation;learning (artificial intelligence);optimisation;plant diseases","APDA;agriculture yield maximization;automated plant disease analysis;automatic classification;automatic identification;image segmentation;leaf images;machine learning technique;plant disease pattern;plant disease type;standard feature extraction technique","","1","","18","","","16-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Automatic Detection of Pseudocodes in Scholarly Documents Using Machine Learning","S. Tuarob; S. Bhatia; P. Mitra; C. L. Giles","Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA, USA","2013 12th International Conference on Document Analysis and Recognition","20131015","2013","","","738","742","A significant number of scholarly articles in computer science and other disciplines contain algorithms that provide concise descriptions for solving a wide variety of computational problems. For example, Dijkstra's algorithm describes how to find the shortest paths between two nodes in a graph. Automatic identification and extraction of these algorithms from scholarly digital documents would enable automatic algorithm indexing, searching, analysis and discovery. An algorithm search engine, which identifies pseudocodes in scholarly documents and makes them searchable, has been implemented as a part of the CiteSeerX suite. Here, we illustrate the limitations of start-of-the-art rule based pseudocode detection approach, and present a novel set of machine learning based techniques that extend previous methods.","1520-5363;15205363","Electronic:978-0-7695-4999-6; POD:978-1-4799-0193-7","10.1109/ICDAR.2013.151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6628716","Algorithm;Classification;Experiment;Machine Learning;Pseudocode","Algorithm design and analysis;Approximation algorithms;Feature extraction;Machine learning algorithms;Portable document format;Software algorithms;Standards","document handling;electronic publishing;indexing;information retrieval;learning (artificial intelligence);search engines","CiteSeer suite;algorithm search engine;automatic algorithm analysis;automatic algorithm discovery;automatic algorithm extraction;automatic algorithm identification;automatic algorithm indexing;automatic algorithm searching;automatic pseudocode detection;computer science;machine learning;pseudocode identification;scholarly articles;scholarly digital documents","","6","","16","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Statistical Features Identification for Sentiment Analysis Using Machine Learning Techniques","A. Kamal; M. Abulaish","Dept. of Math., Jamia Millia Islamia, New Delhi, India","2013 International Symposium on Computational and Business Intelligence","20140127","2013","","","178","181","Due to increasing fascinating trend of using internet and online social media, user-generated contents are growing exponentially on the Web, containing users' opinion on various products. In this paper, we have proposed a sentiment analysis system which combines rule-based and machine learning approaches to identify feature-opinion pairs and their polarity. The efficiency of the proposed system is established through experimentation over customer reviews on different electronic products.","","Electronic:978-0-7695-5066-4; POD:978-1-4799-0998-8","10.1109/ISCBI.2013.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724348","Feature identification;Machine learning;Opinion mining;Sentiment analysis;Text Mining","Computational linguistics;Context;Data mining;Feature extraction;Mutual information;Noise measurement;Semantics","Internet;consumer behaviour;data mining;electronic commerce;electronic products;feature extraction;knowledge based systems;learning (artificial intelligence);social networking (online);statistical analysis","Internet;customer reviews;electronic products;feature-opinion pairs;machine learning techniques;online social media;opinion mining;polarity;rule-based approaches;sentiment analysis system;statistical features identification;text mining;user-generated contents;users opinion","","0","","8","","","24-26 Aug. 2013","","IEEE","IEEE Conference Publications"
"An Analysis of Machine Learning Algorithms for Condensing Reverse Engineered Class Diagrams","M. H. Osman; M. R. V. Chaudron; P. v. d. Putten","Leiden Inst. of Adv. Comput. Sci., Leiden Univ., Leiden, Netherlands","2013 IEEE International Conference on Software Maintenance","20131202","2013","","","140","149","There is a range of techniques available to reverse engineer software designs from source code. However, these approaches generate highly detailed representations. The condensing of reverse engineered representations into more high-level design information would enhance the understandability of reverse engineered diagrams. This paper describes an automated approach for condensing reverse engineered diagrams into diagrams that look as if they are constructed as forward designed UML models. To this end, we propose a machine learning approach. The training set of this approach consists of a set of forward designed UML class diagrams and reverse engineered class diagrams (for the same system). Based on this training set, the method 'learns' to select the key classes for inclusion in the class diagrams. In this paper, we study a set of nine classification algorithms from the machine learning community and evaluate which algorithms perform best for predicting the key classes in a class diagram.","1063-6773;10636773","Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5","10.1109/ICSM.2013.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676885","Machine Learning;Program Comprehension;Reverse Engineering;Software Engineering;UML","Algorithm design and analysis;Couplings;Machine learning algorithms;Measurement;Prediction algorithms;Software;Unified modeling language","Unified Modeling Language;learning (artificial intelligence);software maintenance;systems re-engineering","UML models;classification algorithms;development phase;forward designed UML class diagrams;key classes prediction;machine learning algorithms;maintenance phase;program comprehension;reverse engineer software designs;reverse engineered class diagrams;software engineering;source code","","9","","33","","","22-28 Sept. 2013","","IEEE","IEEE Conference Publications"
"Board-Level Functional Fault Diagnosis Using Multikernel Support Vector Machines and Incremental Learning","F. Ye; Z. Zhang; K. Chakrabarty; X. Gu","Dept. of Electr. & Comput. Eng., Duke Univ., Durham, NC, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20140116","2014","33","2","279","290","Advanced machine learning techniques offer an unprecedented opportunity to increase the accuracy of board-level functional fault diagnosis and reduce product cost through successful repair. Ambiguous or incorrect diagnosis results lead to long debug times and even wrong repair actions, which significantly increase repair cost. We propose a smart diagnosis method based on multikernel support vector machines (MK-SVMs) and incremental learning. The MK-SVM method leverages a linear combination of single kernels to achieve accurate faulty-component classification based on the errors observed. The MK-SVMs thus generated can also be updated based on incremental learning, which allows the diagnosis system to quickly adapt to new error observations and provide even more accurate fault diagnosis. Two complex boards from industry, currently in volume production, are used to validate the proposed diagnosis approach in terms of diagnosis accuracy (success rate) and quantifiable improvements over previously proposed machine-learning methods based on several single-kernel SVMs and artificial neural networks.","0278-0070;02780070","","10.1109/TCAD.2013.2287184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714627","Board-level fault diagnosis;functional failures;incremental learning;kernel;machine learning;support-vector machines","Accuracy;Circuit faults;Fault diagnosis;Kernel;Maintenance engineering;Support vector machines;Training","electronic engineering computing;fault diagnosis;learning (artificial intelligence);neural nets;printed circuit testing;support vector machines","MK-SVM method;advanced machine learning technique;artificial neural network;board level functional fault diagnosis;faulty component classification;linear combination;multikernel support vector machine;smart diagnosis method","","11","","32","","","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Short-term vs. long-term analysis of diabetes data: Application of machine learning and data mining techniques","E. I. Georga; V. C. Protopappas; S. G. Mougiakakou; D. I. Fotiadis","Dept. of Mater. Sci. & Eng., Univ. of Ioannina, Ioannina, Greece","13th IEEE International Conference on BioInformatics and BioEngineering","20140109","2013","","","1","4","Chronic care of diabetes comes with large amounts of data concerning the self- and clinical management of the disease. In this paper, we propose to treat that information from two different perspectives. Firstly, a predictive model of short-term glucose homeostasis relying on machine learning is presented with the aim of preventing hypoglycemic events and prolonged hyperglycemia on a daily basis. Second, data mining approaches are proposed as a tool for explaining and predicting the long-term glucose control and the incidence of diabetic complications.","","Electronic:978-1-4799-3163-7; POD:978-1-4799-3164-4","10.1109/BIBE.2013.6701622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701622","","Data mining;Diabetes;Insulin;Monitoring;Predictive models;Sugar","data analysis;data mining;diseases;learning (artificial intelligence);medical computing;sugar","chronic diabetes care;data mining technique;disease clinical management;disease self-management;hypoglycemic event prevention;long-term data analysis;long-term glucose control prediction;machine learning technique;prolonged hyperglycemia prevention;short-term data analysis;short-term glucose homeostasis","","2","","18","","","10-13 Nov. 2013","","IEEE","IEEE Conference Publications"
"An Efficient Method for Antenna Design Optimization Based on Evolutionary Computation and Machine Learning Techniques","B. Liu; H. Aliakbarian; Z. Ma; G. A. E. Vandenbosch; G. Gielen; P. Excell","Dept. of Comput., Glyndwr Univ., Wrexham, UK","IEEE Transactions on Antennas and Propagation","20140102","2014","62","1","7","18","In recent years, various methods from the evolutionary computation (EC) field have been applied to electromagnetic (EM) design problems and have shown promising results. However, due to the high computational cost of the EM simulations, the efficiency of directly using evolutionary algorithms is often very low (e.g., several weeks' optimization time), which limits the application of these methods for many industrial applications. To address this problem, a new method, called surrogate model assisted differential evolution for antenna synthesis (SADEA), is presented in this paper. The key ideas are: (1) A Gaussian Process (GP) surrogate model is constructed on-line to predict the performances of the candidate designs, saving a lot of computationally expensive EM simulations. (2) A novel surrogate model-aware evolutionary search mechanism is proposed, directing effective global search even when a traditional high-quality surrogate model is not available. Three complex antennas and two mathematical benchmark problems are selected as examples. Compared with the widely used differential evolution and particle swarm optimization, SADEA can obtain comparable results, but achieves a 3 to 7 times speed enhancement for antenna design optimization.","0018-926X;0018926X","","10.1109/TAP.2013.2283605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6612668","Antenna design optimization;Gaussian process;antenna synthesis;differential evolution;efficient global optimization;expensive black-box optimization;surrogate model assisted evolutionary algorithm","Antennas;Computational modeling;Databases;Mathematical model;Optimization;Predictive models;Training data","Gaussian processes;antennas;evolutionary computation;particle swarm optimisation","EM simulations;Gaussian process surrogate model;SADEA;antenna design optimization;antenna synthesis;complex antennas;electromagnetic design problems;evolutionary algorithms;evolutionary computation field;machine learning techniques;particle swarm optimization;surrogate model assisted differential evolution;surrogate model aware evolutionary search mechanism","","11","","40","","20130926","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"Real-time road surface mapping using stereo matching, v-disparity and machine learning","V. B. Azevedo; A. F. De Souza; L. P. Veronese; C. Badue; M. Berger","Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil","The 2013 International Joint Conference on Neural Networks (IJCNN)","20140109","2013","","","1","8","We present and evaluate a computer vision approach for real-time mapping of traversable road surfaces ahead of an autonomous vehicle that relies only on a stereo camera. Our system first determines the camera position with respect to the ground plane using stereo vision algorithms and probabilistic methods, and then reprojects the camera raw image to a bidimensional grid map that represents the ground plane in world coordinates. After that, it generates a road surface grid map from the bidimensional grid map using an online trained pixel classifier based on mixture of Gaussians. Finally, to build a high quality map, each road surface grid map is integrated to a probabilistic bidimensional grid map using a binary Bayes filter for estimating the occupancy probability of each grid cell. We evaluated the performance of our approach for road surface mapping in comparison to manually classified images. Our experimental results show that our approach is able to correctly map regions at 50 m ahead of an autonomous vehicle, with True Positive Rate (TPR) of 90.32% for regions between 20 and 35 m ahead and False Positive Rate (FPR) not superior to 4.23% for any range.","2161-4393;21614393","Electronic:978-1-4673-6129-3; POD:978-1-4673-6127-9","10.1109/IJCNN.2013.6707066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707066","Road surface mapping;binary Bayes filter;machine learning;mixture of Gaussians;stereo matching;v-disparity","Cameras;Image color analysis;Mobile robots;Real-time systems;Roads;Sensors;Stereo vision","Bayes methods;Gaussian processes;cameras;image classification;image matching;learning (artificial intelligence);mixture models;mobile robots;probability;road vehicles;robot vision;stereo image processing;traffic engineering computing","FPR;Gaussian mixture;TPR;V-Disparity;autonomous vehicle;binary Bayes filter;camera position;camera raw image;computer vision approach;false positive rate;grid cell occupancy probability;ground plane;machine learning;manually classified images;online trained pixel classifier;probabilistic bidimensional grid map;probabilistic methods;real-time traversable road surface mapping;road surface grid map;stereo camera;stereo matching;stereo vision algorithms;true positive rate","","1","","17","","","4-9 Aug. 2013","","IEEE","IEEE Conference Publications"
"An adaptive prolog programming language with machine learning","B. Lu; Z. Liu; H. Gao","Comput. Go Res. Inst., Beijing Univ. of Posts & Telecommun., Beijing, China","2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems","20131114","2012","01","","21","24","Prolog is a well-known logic programming language. A Prolog program is essentially a set of knowledge predicates. A query can be executed on the knowledge set by the Prolog engine, which searches and matches the query against the knowledge set automatically by conducting a depth-first search (DFS). While deterministic, DFS does not always produce the best efficiency in Prolog execution. UCT, based on UCB algorithms, is a machine learning algorithm for solving multi-stage Markov Decision Process (MDP) problems, with a good balance between exploitation and exploration. This paper introduces a UCB gauge for each of the predicates, which can be used as a heuristic measurement for selection of predicate search. This results in a best-first search strategy for Prolog execution, which is referred to as Adaptive Prolog. Adaptive Prolog enhance its execution engine by adjusting its search path to reflect current machine learning results, and as such produce better execution efficiency than traditional Prolog.","2376-5933;23765933","Electronic:978-1-4673-1857-0; POD:978-1-4673-1856-3","10.1109/CCIS.2012.6664359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6664359","Adaptive prolog;Best-first search;Depth-First search;Heuristic function;UCB","Algorithm design and analysis;Engines;Knowledge based systems;Logic programming;Machine learning algorithms;Motion pictures;Search problems","PROLOG;heuristic programming;learning (artificial intelligence);search problems","Adaptive Prolog;Programming in Logic;Prolog engine;UCB gauge;adaptive Prolog programming language;best-first search strategy;execution engine;heuristic measurement;knowledge predicates;logic programming language;machine learning;predicate search selection","","0","","11","","","Oct. 30 2012-Nov. 1 2012","","IEEE","IEEE Conference Publications"
"Supervised machine learning scheme for tri-axial accelerometer-based fall detector","A. Leone; G. Rescio; P. Siciliano","Inst. for Microelectron. & Microsyst., Lecce, Italy","2013 IEEE SENSORS","20140116","2013","","","1","4","Fall events can cause trauma, disability and death among older people. Accelerometer-based devices are able to detect falls in controlled environments. The paper presents a computationally low-power approach for feature extraction and supervised clustering for people fall detection by using a 3-axial MEMS wearable accelerometer, managed by an stand-alone PC through ZigBee connection. The paper extends a previous work in which fall events were detected according to a threshold-based scheme. The proposed approach allows to generalize the detection of falls in several practical conditions, after a short period of calibration. The clustering scheme appears invariant to age, weight, height of people and relative positioning area (even in the upper part of the waist), overcoming the drawbacks of well-known threshold-based approaches in which several parameters need to be manually estimated, according to the specific features of the end-user. In order to limit the workload, the specific study on posture analysis has been avoided and a polynomial kernel function is used while maintaining high performance in terms of specificity and sensitivity. The supervised clustering step is achieved by implementing an One-Class Support Vector Machine classifier.","1930-0395;19300395","Electronic:978-1-4673-4642-9; POD:978-1-4673-4641-2; USB:978-1-4673-4640-5","10.1109/ICSENS.2013.6688522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6688522","","Acceleration;Accelerometers;Calibration;Feature extraction;Kernel;Polynomials;Support vector machines","Zigbee;accelerometers;biomedical telemetry;body sensor networks;calibration;computerised instrumentation;feature extraction;geriatrics;learning (artificial intelligence);medical computing;microsensors;pattern clustering;polynomials;support vector machines","3-axial MEMS wearable accelerometer;ZigBee connection;calibration;computationally low-power approach;feature extraction;one-class support vector machine classifier;polynomial kernel function;posture analysis;stand-alone PC;supervised clustering scheme;supervised machine learning scheme;threshold-based approach;triaxial accelerometer-based fall detector","","1","","13","","","3-6 Nov. 2013","","IEEE","IEEE Conference Publications"
"Telecommunication subscribers' churn prediction model using machine learning","S. A. Qureshi; A. S. Rehman; A. M. Qamar; A. Kamal; A. Rehman","Dept. of Comput., Nat. Univ. of Sci. & Technol. (NUST), Islamabad, Pakistan","Eighth International Conference on Digital Information Management (ICDIM 2013)","20140102","2013","","","131","136","During the last two decades, we have seen mobile communication becoming the dominant medium of communication. In numerous countries, especially the developed ones, the market is saturated to the extent that each new customer must be won over from the competitors. At the same time, public policies and standardization of mobile communication now allow customers to easily switch over from one carrier to another, resulting in a fluid market. Since the cost of winning a new customer is far greater than the cost of retaining an existing one, mobile carriers have now shifted their focus from customer acquisition to customer retention. As a result, churn prediction has emerged as the most crucial Business Intelligence (BI) application that aims at identifying customers who are about to transfer their business to a competitor i.e. to churn. This paper aims to present commonly used data mining techniques for the identification of customers who are about to churn. Based on historical data, these methods try to find patterns which can identify possible churners. Some of the well-known algorithms used during this research are Regression analysis, Decision Trees and Artificial Neural Networks (ANNs). The data set used in this study was obtained from Customer DNA website. It contains traffic data of 106,000 customers and their usage behavior for 3 months. We also discuss the use of re-sampling method in order to solve the problem of class imbalance. Our results show that in case of the data set used, decision trees is the most accurate classifier algorithm while identifying potential churners.","","Electronic:978-1-4799-0615-4; POD:978-1-4799-0614-7","10.1109/ICDIM.2013.6693977","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693977","Business Intelligence;Churn prediction;Data Mining","Correlation;Decision trees;Linear regression;Logistics;Prediction algorithms;Predictive models","competitive intelligence;customer profiles;data mining;decision trees;learning (artificial intelligence);mobile communication;neural nets;pattern classification;regression analysis;telecommunication services","ANN;artificial neural networks;business intelligence application;class imbalance;classifier algorithm;customer DNA Website;customer acquisition;customer identifcation;customer retention;customer switching;data mining technique;decision trees;fluid market;historical data;machine learning;market saturation;mobile carriers;mobile communication standardization;pattern finding;potential churner identification;public policies;regression analysis;resampling method;telecommunication subscriber churn prediction model;traffic data;usage behavior","","4","","16","","","10-12 Sept. 2013","","IEEE","IEEE Conference Publications"
"Self-adaptive erbium-doped fiber amplifiers using machine learning","E. d. A. Barboza; C. J. A. Bastos-Filho; J. F. Martins-Filho; U. C. de Moura; J. R. F. de Oliveira","Polytechnic School of Pernambuco, University of Pernambuco, Recife, Brazil","2013 SBMO/IEEE MTT-S International Microwave & Optoelectronics Conference (IMOC)","20131028","2013","","","1","5","This paper presents a method to autonomously adjust the operating point of amplifiers in a cascade using an approach based on machine learning. The goal is to smoothly adjust the gain of each amplifier in the cascade in order to reach predefined input and output power levels for the entire link, aiming to minimize both the noise figure and the gain flatness of the transmission system. The proposal uses an iterative method and performs feedforward and backward error adjustments based on local information. The experimental results indicate that our proposal can optimize the performance of the link ensuring predefined input and output power levels, which is important in a network scenario. As an example, our proposal was capable to define the gain of 6 amplifiers returning a link with a noise figure equal to 30.06 dB and a gain flatness equal to 5.26 dB, while maintaing the input and output powers around 3 dBm with an error lower than 0.1 dB.","","Electronic:978-1-4799-1397-8; POD:978-1-4799-1396-1; USB:978-1-4799-1395-4","10.1109/IMOC.2013.6646588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6646588","Backpropagation;Machine Learning;Noise Figure;Optical Amplifiers;Self-adaptation","Annealing;Libraries;Noise measurement","adaptive optics;erbium;iterative methods;laser noise;learning (artificial intelligence);optical communication equipment;optical fibre amplifiers;optical fibre networks","backward error adjustments;feedforward error adjustments;gain;gain 5.26 dB;gain flatness;input power levels;iterative method;machine learning;noise figure;noise figure 30.06 dB;output power levels;self-adaptive erbium-doped fiber amplifiers;transmission system","","4","","15","","","4-7 Aug. 2013","","IEEE","IEEE Conference Publications"
"Intelligent tuning for microwave filters based on multi-kernel machine learning model","J. Zhou; J. Huang","Key Lab. of Electron. Equip. Struct., Xidian Univ., Xi'an, China","2013 5th IEEE International Symposium on Microwave, Antenna, Propagation and EMC Technologies for Wireless Communications","20131223","2013","","","259","266","This paper presents an intelligent alignment method for the automatic tuning device of microwave filters. In the method, a model that reveals the relationships between the tunable screws and filter electrical performance is firstly developed by using an improved machine learning algorithm which can incorporate multi-kernel into the traditional linear programming support vector regression to improve the modeling accuracy. Then, a tuning procedure of filters is constructed by using the developed machine-learning model. Finally, some experiments are carried out, and the experimental results confirm the effectiveness of the method. The approach is particularly suited to the computer-aided tuning devices or an automatic tuning robot of volume-producing filters.","","Electronic:978-1-4673-6079-1; POD:978-1-4673-6076-0","10.1109/MAPE.2013.6689881","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6689881","intelligent tuning;machine learning;microwave filter;multi-kernel;support vector regression","Couplings;Fasteners;Kernel;Linear programming;Microwave filters;Support vector machines;Tuning","circuit tuning;electronic engineering computing;learning (artificial intelligence);linear programming;microwave filters;regression analysis;support vector machines","automatic tuning device;automatic tuning robot;computer-aided tuning devices;electrical performance;intelligent alignment method;linear programming;machine learning algorithm;microwave filters;multikernel machine learning model;support vector regression;tunable screws;tuning procedure;volume-producing filters","","1","","19","","","29-31 Oct. 2013","","IEEE","IEEE Conference Publications"
"Oil price prediction using ensemble machine learning","L. A. Gabralla; R. Jammazi; A. Abraham","Faculty of Computer Science & Information Technology, Sudan University of Science Technology, Khartoum, Sudan","2013 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRICAL AND ELECTRONIC ENGINEERING (ICCEEE)","20131017","2013","","","674","679","Crude oil price forecasting is a challenging task due to its complex nonlinear and chaotic behavior. During the last couple of decades, both academicians and practitioners devoted proactive knowledge to address this issue. A strand of them has focused on some key factors that may influence the crude oil price prediction accuracy. This paper extends this particular branch of recent works by considering a number of influential features as inputs to test the forecasting performance of daily WTI crude oil price covering the period 4th January 1999 through 10th October 2012. Empirical results indicate that the proposed methods are efficient and warrant further research in this field.","","Electronic:978-1-4673-6232-0; POD:978-1-4673-6230-6","10.1109/ICCEEE.2013.6634021","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6634021","crude oil price prediction;hybrid models;influential features","Biological system modeling;Economics;Forecasting;Gold;Prediction algorithms;Predictive models;Support vector machines","crude oil;learning (artificial intelligence);pricing","crude oil price forecasting;daily WTI crude oil price;ensemble machine learning;oil price prediction;prediction accuracy","","4","","30","","","26-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"The Relevance Sample-Feature Machine: A Sparse Bayesian Learning Approach to Joint Feature-Sample Selection","Y. Mohsenzadeh; H. Sheikhzadeh; A. M. Reza; N. Bathaee; M. M. Kalayeh","Department of Electrical Engineering, Amirkabir University of Technology (Tehran Polytechnic), Tehran, Iran","IEEE Transactions on Cybernetics","20131119","2013","43","6","2241","2254","This paper introduces a novel sparse Bayesian machine-learning algorithm for embedded feature selection in classification tasks. Our proposed algorithm, called the relevance sample feature machine (RSFM), is able to simultaneously choose the relevance samples and also the relevance features for regression or classification problems. We propose a separable model in feature and sample domains. Adopting a Bayesian approach and using Gaussian priors, the learned model by RSFM is sparse in both sample and feature domains. The proposed algorithm is an extension of the standard RVM algorithm, which only opts for sparsity in the sample domain. Experimental comparisons on synthetic as well as benchmark data sets show that RSFM is successful in both feature selection (eliminating the irrelevant features) and accurate classification. The main advantages of our proposed algorithm are: less system complexity, better generalization and avoiding overfitting, and less computational cost during the testing stage.","2168-2267;21682267","","10.1109/TCYB.2013.2260736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6531667","Joint feature selection and classifier design;relevance features;relevance sample feature machine (RSFM);relevance samples;sparse Bayesian learning","Bayes methods;Machine learning;Sampling methods","generalisation (artificial intelligence);learning (artificial intelligence);pattern classification;support vector machines","Bayesian approach;Gaussian priors;RSFM;RVM algorithm;classification tasks;feature selection;generalization;joint feature-sample selection;relevance sample-feature machine;relevance vector machines;sparse Bayesian learning approach","1","10","","36","","20130613","Dec. 2013","","IEEE","IEEE Journals & Magazines"
"Machine learning approaches for predicting software maintainability: a fuzzy-based transparent model","M. A. Ahmed; H. A. Al-Jamimi","Inf. & Comput. Sci. Dept., King Fahd Univ. of Pet. & Miner., Dhahran, Saudi Arabia","IET Software","20131212","2013","7","6","317","326","Software quality is one of the most important factors for assessing the global competitive position of any software company. Thus, the quantification of the quality parameters and integrating them into the quality models is very essential.Many attempts have been made to precisely quantify the software quality parameters using various models such as Boehm's Model, McCall's Model and ISO/IEC 9126 Quality Model. A major challenge, although, is that effective quality models should consider two types of knowledge: imprecise linguistic knowledge from the experts and precise numerical knowledge from historical data.Incorporating the experts' knowledge poses a constraint on the quality model; the model has to be transparent.In this study, the authorspropose a process for developing fuzzy logic-based transparent quality prediction models.They applied the process to a case study where Mamdani fuzzy inference engine is used to predict software maintainability.Theycompared the Mamdani-based model with other machine learning approaches.The resultsshow that the Mamdani-based model is superior to all.","1751-8806;17518806","","10.1049/iet-sen.2013.0046","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680574","","","DP industry;computational linguistics;fuzzy logic;fuzzy reasoning;learning (artificial intelligence);software maintenance;software quality","Mamdani fuzzy inference engine;Mamdani-based model;fuzzy logic-based transparent quality prediction model;imprecise linguistic knowledge;machine learning approach;software company;software maintainability prediction;software quality parameter quantification","","2","","","","","December 2013","","IET","IET Journals & Magazines"
"Personality Traits Identification Using Rough Sets Based Machine Learning","U. Gupta; N. Chatterjee","Dept. of Electr. Eng., Indian Inst. of Technol. Delhi, New Delhi, India","2013 International Symposium on Computational and Business Intelligence","20140127","2013","","","182","185","Prediction of human behavior from his/her traits has long been sought by cognitive scientists. Human traits are often embedded in one's writings. Although some work has been done on identification of traits from essays, very little work can be found on extracting personality traits from written texts. Psychological studies suggest that extraction and prediction of rules from a data has been long pursued, and several methods have been proposed. In the present work we used Rough sets to extract the rules for prediction of personality traits. Rough Set is a comparatively recent method that has been effective in various fields such as medical, geological and other fields where intelligent decision making is required. Our experiments with rough sets in predicting personality traits produced encouraging results.","","Electronic:978-0-7695-5066-4; POD:978-1-4799-0998-8","10.1109/ISCBI.2013.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6724349","big-five model of personality;machine learning;personality recongnition;rough sets","Accuracy;Approximation methods;Data mining;Feature extraction;Pragmatics;Psychology;Rough sets","behavioural sciences computing;decision making;learning (artificial intelligence);psychology;rough set theory","human behavior prediction;human traits;intelligent decision making;machine learning;personality trait prediction;personality traits identification;psychological studies;rough sets;rule extraction;rule prediction","","2","","13","","","24-26 Aug. 2013","","IEEE","IEEE Conference Publications"
"Using machine learning techniques to detect metamorphic relations for programs without test oracles","U. Kanewala; J. M. Bieman","Comput. Sci. Dept., Colorado State Univ., Fort Collins, CO, USA","2013 IEEE 24th International Symposium on Software Reliability Engineering (ISSRE)","20140102","2013","","","1","10","Much software lacks test oracles, which limits automated testing. Metamorphic testing is one proposed method for automating the testing process for programs without test oracles. Unfortunately, finding the appropriate metamorphic relations required for use in metamorphic testing remains a labor intensive task, which is generally performed by a domain expert or a programmer. In this work we present a novel approach for automatically predicting metamorphic relations using machine learning techniques. Our approach uses a set of features developed using the control flow graph of a function for predicting likely metamorphic relations. We show the effectiveness of our method using a set of real world functions often used in scientific applications.","1071-9458;10719458","Electronic:978-1-4799-2366-3; POD:978-1-5090-4462-7","10.1109/ISSRE.2013.6698899","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698899","Decision trees;Machine learning;Metamorphic relation;Metamorphic testing;Mutation analysis;Scientific software testing;Software testing;Support vector machines;Test oracles","Arrays;Decision trees;Feature extraction;Predictive models;Software;Support vector machines;Testing","data flow graphs;decision trees;learning (artificial intelligence);natural sciences computing;program testing;support vector machines","control flow graph;decision trees;machine learning techniques;metamorphic relation detection;metamorphic testing;mutation analysis;scientific software testing;support vector machines;testing process automation","","6","","43","","","4-7 Nov. 2013","","IEEE","IEEE Conference Publications"
"PANFIS: A Novel Incremental Learning Machine","M. Pratama; S. G. Anavatti; P. P. Angelov; E. Lughofer","School of Engineering and Information Technology, University of New South Wales, Australian Defence Force Academy, Canberra, Australia","IEEE Transactions on Neural Networks and Learning Systems","20131213","2014","25","1","55","68","Most of the dynamics in real-world systems are compiled by shifts and drifts, which are uneasy to be overcome by omnipresent neuro-fuzzy systems. Nonetheless, learning in nonstationary environment entails a system owning high degree of flexibility capable of assembling its rule base autonomously according to the degree of nonlinearity contained in the system. In practice, the rule growing and pruning are carried out merely benefiting from a small snapshot of the complete training data to truncate the computational load and memory demand to the low level. An exposure of a novel algorithm, namely parsimonious network based on fuzzy inference system (PANFIS), is to this end presented herein. PANFIS can commence its learning process from scratch with an empty rule base. The fuzzy rules can be stitched up and expelled by virtue of statistical contributions of the fuzzy rules and injected datum afterward. Identical fuzzy sets may be alluded and blended to be one fuzzy set as a pursuit of a transparent rule base escalating human's interpretability. The learning and modeling performances of the proposed PANFIS are numerically validated using several benchmark problems from real-world or synthetic datasets. The validation includes comparisons with state-of-the-art evolving neuro-fuzzy methods and showcases that our new method can compete and in some cases even outperform these approaches in terms of predictive fidelity and model complexity.","2162-237X;2162237X","","10.1109/TNNLS.2013.2271933","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6568966","Evolving neuro-fuzzy systems (ENFSs);incremental learning;sample-wise training","Covariance matrices;Ellipsoids;Fuzzy logic;Fuzzy sets;Fuzzy systems;Training;Vectors","computational complexity;fuzzy neural nets;fuzzy reasoning;fuzzy set theory;knowledge based systems;learning (artificial intelligence);statistical analysis","PANFIS;autonomous rule base assembling;computational load;degree of nonlinearity;empty rule base;fuzzy rule stitching;fuzzy sets;human interpretability escalation;incremental machine learning performance;memory demand;model complexity;modeling performance;nonstationary environment;omnipresent neurofuzzy system;parsimonious network based on fuzzy inference system;predictive fidelity;scratch;statistical fuzzy rule;transparent rule base","0","62","","57","","20130725","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"Flow-Based P2P Network Traffic Classification Using Machine Learning","S. Tapaswi; A. S. Gupta","ABV-IIITM Gwalior, Gwalior, India","2013 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","20131219","2013","","","402","406","With the introduction of new and new services in the market every day, the internet is growing rapidly. The network traffic generated by these network protocols and applications needs to be categorised which is an important task of network management. Among these, p2p has the largest share of the bandwidth. This great demand in the bandwidth has increased the importance of network traffic engineering. So, in order to meet the current demand and develop new architectures which help in improving the network performance, a broad understanding of the network traffic properties is required. The flow based methods classify p2p and non-p2p traffic using the characteristics of flows on the internet. In this paper, Naïve Bayes estimator is used to categorize the traffic into p2p and non-p2p. Our results show that with the right set of features and good training data, high level of accuracy is achievable with the simplest of Naïve Bayes estimator.","","Electronic:978-0-7695-5106-7; POD:978-1-4799-1327-5","10.1109/CyberC.2013.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6685716","Naive Bayesian Estimator;P2P;peer-to-peer;traffic classification","Accuracy;Bayes methods;Classification algorithms;Machine learning algorithms;Peer-to-peer computing;Ports (Computers);Telecommunication traffic","Bayes methods;Internet;learning (artificial intelligence);pattern classification;peer-to-peer computing;telecommunication traffic","Internet;flow-based P2P network traffic classification;machine learning;naïve Bayes estimator;network management;network protocols;network traffic engineering;nonP2P traffic","","0","","18","","","10-12 Oct. 2013","","IEEE","IEEE Conference Publications"
"A Machine Learning Method for Identification of Key Body Poses in Cyclic Physical Exercises","P. F. d. Dios; Q. Meng; P. W. H. Chung","Dept. of Comput. Sci., Loughborough Univ., Loughborough, UK","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","1605","1610","Motion segmentation plays an important role in human motion analysis. Understanding the intrinsic features of human activities represents a challenge for modern science. Current solutions usually involve computationally demanding processing and achieve the best results using expensive, intrusive motion capture devices. In this paper, a simple, affordable and effective method for human motion segmentation and alignment is presented. The approach follows a two-step process: first, the most salient principal components are calculated in order to reduce the dimension of the input motion data. Then, candidates of key body poses (landmarks) are inferred using multi-class, supervised machine learning techniques from a set of training samples. Finally, cluster analysis is used to refine the result. Predictions are guaranteed to be invariant to the repetitiveness and symmetry of the performance. Results show the effectiveness of the proposed approach by comparing it against the Dynamic Time Warping algorithm and Hierarchical Aligned Cluster Analysis.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722030","Temporal segmentation;human motion analysis;motion clustering;supervised machine learning","Accuracy;Feature extraction;Joints;Motion segmentation;Principal component analysis;Testing;Training","feature extraction;image motion analysis;image segmentation;learning (artificial intelligence);pattern clustering;pose estimation;time series","cyclic physical exercises;dynamic time warping algorithm;hierarchical aligned cluster analysis;human activities intrinsic features;human motion alignment;human motion analysis;human motion segmentation;intrusive motion capture devices;key body pose identification;salient principal components;supervised machine learning techniques","","0","","34","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"Autonomous robotic palpation: Machine learning techniques to identify hard inclusions in soft tissues","K. A. Nichols; A. M. Okamura","Department of Mechanical Engineering, Stanford University, CA, 94305, USA","2013 IEEE International Conference on Robotics and Automation","20131017","2013","","","4384","4389","Localizing tumors and measuring tissue mechanical properties can be useful for surgical planning and evaluating progression of disease. In this paper, supervised machine learning algorithms enable mechanical localization of stiff inclusions in artificial tissue after autonomous robotic palpation. Elastography is used to generate training data for the learning algorithms, providing a non-invasive, inclusion-specific characterization of tissue biomechanics. In particular, elastography was used to characterize the stiffness of artificial tissue with an embedded hard inclusion. Once the inclusion was identified on the elastographic image, machine learning methods identified the difference in stiffness between the inclusion and surrounding soft tissue and generated classifiers, which were used to label stiffness values as either part of the inclusion or soft tissue. Next, data acquired via autonomous robotic palpation of the artificial tissue created a map of the stiffness distributed over the surface of the tissue. The points in this map were thresholded against the classifiers trained by the machine learning algorithms, and points theorized to belong to the hard inclusion were labeled. Centroid approximations of the hard inclusion based on this labeling show that classifying stiffness data acquired by autonomous robotic palpation and labeled by a classifier trained from elastography data provides a more accurate method of localizing hard inclusions than using unclassified data.","1050-4729;10504729","Electronic:978-1-4673-5643-5; POD:978-1-4673-5640-4","10.1109/ICRA.2013.6631198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6631198","","Biological tissues;Logistics;Machine learning algorithms;Robot kinematics;Training;Tumors","biological tissues;image classification;learning (artificial intelligence);medical image processing;medical robotics;surgery","artificial tissue stiffness characterization;autonomous robotic palpation;centroid approximations;classifier generation;disease progression evaluation;elastographic image;elastography;embedded hard inclusion;soft tissues;supervised machine learning algorithms;surgical planning;tissue biomechanics;tissue mechanical properties measurement;training data generation;tumor localization","","5","","19","","","6-10 May 2013","","IEEE","IEEE Conference Publications"
"Data mining with machine learning applied for email deception","S. More; S. A. Kulkarni","Dept. of Comput. Sci. & Eng., Visvesvaraya Technol. Univ., Belgaum, India","2013 International Conference on Optical Imaging Sensor and Security (ICOSS)","20131205","2013","","","1","4","Spam is also known as junk mail or Unsolicited Commercial Email (UCE) which has become major problem for the sustainability of the internet and global commerce. Everyday millions of the spam mails are sent over internet to targeted population to advertise services, products and dangerous software etc. A number of spam detection algorithms have been proposed to classify emails on content based, but could not gain accuracy. Our proposed work mainly focuses on cognitive (spam) words for classification. This feature is sequential unique and closed patterns which are extracted from the message content. We show that this feature have good impact in classifying spam from legitimate messages. Our method, which can be easily implemented, compares amiably with respect to popular algorithms, like Logistic Regression, Neural Network, Naive Bayes and Random Forest using polynomial kernel as filter. We outperform the accuracy higher compared to related methods. In addition our method is resilient against irrelevant and bothersome words.","","Electronic:978-1-4799-0936-0; POD:978-1-4799-0934-6","10.1109/ICOISS.2013.6678403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6678403","Classification;Cognitive Words;Polynomial kernel;Spam Detection;Weka","","Internet;data mining;learning (artificial intelligence);unsolicited e-mail","Internet;UCE;data mining;email deception;global commerce;junk mail;logistic regression;machine learning;message content;naive Bayes;neural network;polynomial kernel;random forest;spam detection algorithms;spam mails;unsolicited commercial email","","3","","11","","","2-3 July 2013","","IEEE","IEEE Conference Publications"
"Start-Up Decision of a Rapid-Start Unit for AGC Based on Machine Learning","I. Saboya; I. Egido; L. Rouco","School of Engineering (ICAI) of Universidad Pontificia Comillas, Madrid, Spain","IEEE Transactions on Power Systems","20131017","2013","28","4","3834","3841","Units within a control area, participating in the secondary frequency control, are usually spinning generating units already connected to the network and operating outside their range of optimal performance. This paper deals with an alternative method of providing secondary frequency control called rapid-start (RS). It consists in assigning a regulation band to several offline units (RS units) which are capable of being started and connected rapidly, therefore allowing the online units to function more closely to their nominal power. RS units have commonly been used for peaking generation and for tertiary control reserve, and have been rarely used for secondary control reserve. As RS operation may have economic benefits, since it allows for better dispatch of the other units in the control area, an appropriate algorithm to start up an RS unit needs to be developed. This paper proposes a machine learning based system (MLBS) to be employed in the decision to start up an RS unit while being used to provide secondary frequency control. The decision-making procedure is carried out by a decision tree. The building and implementation of the RS machine learning based system is illustrated for a secondary frequency control zone within the Spanish power system.","0885-8950;08858950","","10.1109/TPWRS.2013.2259267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6514914","Clustering;decision tree;machine learning;rapid-start;secondary regulation","Clustering methods;Decision trees;Machine learning;Power system reliability","control engineering computing;decision trees;frequency control;learning (artificial intelligence);power system control","AGC;MLBS;RS operation;Spanish power system;control area;decision tree;decision-making procedure;machine learning based system;offline units;rapid-start unit;regulation band;secondary control reserve;secondary frequency control zone;spinning generating units;start-up decision;tertiary control reserve","","4","","38","","20130513","Nov. 2013","","IEEE","IEEE Journals & Magazines"
"Correcting errors in visually interpreted land use data — An machine learning approach","T. Zhang; X. Yang; Q. Li","State Key Lab. of Resources & Environ. Inf. Syst. (LREIS), Inst. of Geogr. Sci. & Natural Resources Res. (IGSNRR), Beijing, China","2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS","20140127","2013","","","2569","2572","As manually correcting error in visual interpretation data is both costly and labor intensive, the automated error detection and correction approaches is in need. In this paper, a prototype method is developed to detect and correct errors in visually interpreted landuse data. This method involves image segmentation, anomaly detection and decision tree classification techniques. The method is tested on landuse dataset with known accuracy (95%-50%). Result shows that the accuracy of landuse data can be greatly improved by the error correction method, and the approach can be practical when the accuracy of the interpretation data is no less than 70%.","2153-6996;21536996","Electronic:978-1-4799-1114-1; POD:978-1-4799-1112-7","10.1109/IGARSS.2013.6723347","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6723347","anomaly detection;decision tree classification;errors;image interpretation;land use","Accuracy;Data mining;Error correction;Image segmentation;Remote sensing;Training;Visualization","geophysical image processing;geophysical techniques;image classification;image segmentation;land use","anomaly detection;decision tree classification techniques;image segmentation;machine learning approach;prototype method;visually interpreted landuse data","","0","","11","","","21-26 July 2013","","IEEE","IEEE Conference Publications"
"Intelligent speed profile prediction on urban traffic networks with machine learning","J. Park; Y. L. Murphey; J. Kristinsson; R. McGee; M. Kuang; T. Phillips","Dept. of Electr. & Comput. Eng., Univ. of Michigan-Dearborn, Dearborn, MI, USA","The 2013 International Joint Conference on Neural Networks (IJCNN)","20140109","2013","","","1","7","Accurate prediction of traffic information such as flow, density, speed, and travel time is an important component for traffic control systems and optimizing vehicle operation. Prediction of an individual speed profile on an urban network is a challenging problem because traffic flow on urban routes is frequently interrupted and delayed by traffic lights, stop signs, and intersections. In this paper, we present an Intelligent Speed Profile Prediction on Urban Traffic Network (ISPP_UTN) that can predict a speed profile of a selected urban route with available traffic information at the trip starting time. ISPP_UTN consists of four speed prediction Neural Networks (NNs) that can predict speed in different traffic areas. ISPP_UTN takes inputs from three different categories of traffic information such as the historical individual driving data, geographical information, and traffic pattern data. Experimental results show that the proposed algorithm gave good prediction results on real traffic data and the predicted speed profiles are close to the real recorded speed profiles.","2161-4393;21614393","Electronic:978-1-4673-6129-3; POD:978-1-4673-6127-9","10.1109/IJCNN.2013.6707119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6707119","","Artificial neural networks;Shape;Testing;Traffic control;Training;Vehicles","learning (artificial intelligence);traffic control","geographical information;intelligent speed profile prediction;machine learning;real recorded speed profiles;real traffic data;speed prediction neural networks;traffic control systems;traffic flow;traffic information;traffic pattern data;urban routes;urban traffic networks;vehicle operation optimization","","0","","17","","","4-9 Aug. 2013","","IEEE","IEEE Conference Publications"
"Machine learning algorithms for quality control in plastic molding industry","A. Tellaeche; R. Arana","Tekniker-IK4, Calle I&#x00F1;aki Goenaga, 5, 20600, Eibar, Gipuzkoa, Spain","2013 IEEE 18th Conference on Emerging Technologies & Factory Automation (ETFA)","20131028","2013","","","1","4","Injection molding is a very complicated process to monitor and control. With its high complexity and many process parameters, the optimization of these systems is a very challenging problem. To meet the requirements and costs demanded by the market, there has been an intense development and research with the aim to maintain the process under control. This paper outlines the latest advances in algorithms for plastic injection process and monitoring, and presents a real case of application that verifies their performance.","1946-0740;19460740","Electronic:978-1-4799-0864-6; POD:978-1-4799-0863-9","10.1109/ETFA.2013.6648103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648103","","Injection molding;Machine learning algorithms;Monitoring;Optimization;Plastics;Process control","injection moulding;learning (artificial intelligence);plastics industry;process monitoring;production engineering computing;quality control","machine learning algorithms;plastic injection monitoring;plastic injection process;plastic molding industry;quality control","","0","","17","","","10-13 Sept. 2013","","IEEE","IEEE Conference Publications"
"Computation using mismatch: Neuromorphic extreme learning machines","E. Yao; S. Hussain; A. Basu; G. B. Huang","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","2013 IEEE Biomedical Circuits and Systems Conference (BioCAS)","20131212","2013","","","294","297","In this paper, we describe a low power neuromorphic machine learner that utilizes device mismatch prevalent in today's VLSI processes to perform a significant part of the computation while a digital back end enables precision in the final output. The particular machine learning algorithm we use is extreme learning machine (ELM). Mismatch in silicon spiking neurons and synapses are used to perform the vector-matrix multiplication (VMM) that forms the first stage of this classifier and is the most computationally intensive. System simulations are presented to evaluate the dependence of performance (in a classification and a regression task) on analog and digital parameters like weight resolution, maximum spike frequency etc. SPICE simulations show that the proposed implementation is ≈ 92X more energy efficient as opposed to custom digital implementations for a classification task with 100 dimensional inputs. Measurement results for a regression task from a field programmable analog array (FPAA) fabricated in 0.35μm CMOS are presented as a proof of concept.","2163-4025;21634025","Electronic:978-1-4799-1471-5; POD:978-1-4799-1469-2; USB:978-1-4799-1470-8","10.1109/BioCAS.2013.6679697","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6679697","","Biomedical measurement;Computational modeling;Hardware;Mirrors;Neurons;Transistors;Very large scale integration","CMOS integrated circuits;SPICE;VLSI;bioelectric potentials;biomedical electronics;cellular biophysics;field programmable analogue arrays;learning (artificial intelligence);medical computing;regression analysis","CMOS;SPICE simulations;VLSI processes;analog parameters;classification task;digital back end;digital parameters;field programmable analog array;machine learning algorithm;mismatch computation;neuromorphic extreme learning machines;regression task;silicon spiking neurons;silicon spiking synapses;vector-matrix multiplication;weight resolution","","5","","11","","","Oct. 31 2013-Nov. 2 2013","","IEEE","IEEE Conference Publications"
