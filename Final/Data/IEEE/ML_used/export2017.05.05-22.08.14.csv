"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6241527,6241673,6239820,6236010,6226823,6236461,6235527,6176215,6234504,6233768,6234430,6234299,6233833,6233911,6234422,6234223,6234667,6231450,6229541,6229334,6227104,6225610,5765955,6224284,6222690,6223132,6099561,6217750,6217211,6216625,6217475,6216580,6217244,6216599,6215730,6215470,6212153,6212067,6211581,6212015,6211960,6207737,6209083,6208312,6208164,6208385,6207714,6156808,6204977,6203913,6200362,6200136,6200550,6201808,6200112,6190870,6095567,6168273,6148303,6198848,6121955,6096441,6169943,6196887,6194818,6189064,6153377,6157630,6190565,6190308,6188085,6187494,6185576,5551110,6111216,6042869,6181917,6182361,6181018,6181671,6181040,6182488,6174795,6175690,6173608,6138848,6169591,6169461,6169587,6046146,6169483,6169132,6169674,6169516,6166601,6081929,6167503,6104179,6164956,6163143",2017/05/05 22:08:14
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Cognitive radio technology: Principles and practice","Y. Zhao; L. Morales-Tirado","School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing, China, 100044","2012 International Conference on Computing, Networking and Communications (ICNC)","20120312","2012","","","650","654","This position paper first briefly reviews the basic concepts about cognitive radio (CR) technology, and then discusses the differentiating features of CR and the fundamental theories or principles behind CR, especially from the artificial intelligence and machine learning perspective. A survey on the state-of-the-art development on CR testbeds around the world is presented, which indicates the trend of future development. A lot of emerging research topics in various areas are also discussed, which could be further investigated in an innovative CR approach.","","Electronic:978-1-4673-0009-4; POD:978-1-4673-0008-7; USB:978-1-4673-0723-9","10.1109/ICCNC.2012.6167503","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6167503","artificial intelligence;cognitive engine;cognitive radio;cognitive radio network;machine learning","Cognition;Cognitive radio;Engines;Genetic algorithms;Learning systems","cognitive radio;learning (artificial intelligence)","CR testbeds;artificial intelligence;cognitive radio technology;innovative CR approach;machine learning perspective;state-of-the-art development","","2","","39","","","Jan. 30 2012-Feb. 2 2012","","IEEE","IEEE Conference Publications"
"Fast Bundle Algorithm for Multiple-Instance Learning","C. Bergeron; G. Moore; J. Zaretzki; C. M. Breneman; K. P. Bennett","Rensselaer Polytechnic Institute, Troy","IEEE Transactions on Pattern Analysis and Machine Intelligence","20120418","2012","34","6","1068","1079","We present a bundle algorithm for multiple-instance classification and ranking. These frameworks yield improved models on many problems possessing special structure. Multiple-instance loss functions are typically nonsmooth and nonconvex, and current algorithms convert these to smooth nonconvex optimization problems that are solved iteratively. Inspired by the latest linear-time subgradient-based methods for support vector machines, we optimize the objective directly using a nonconvex bundle method. Computational results show this method is linearly scalable, while not sacrificing generalization accuracy, permitting modeling on new and larger data sets in computational chemistry and other applications. This new implementation facilitates modeling with kernels.","0162-8828;01628828","","10.1109/TPAMI.2011.194","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6042869","Artificial intelligence;bundle methods;machine learning;medicine and science.;multiple-instance learning;nonsmooth optimization;ranking","Compounds;Computational modeling;Drugs;Kernel;Microwave integrated circuits;Optimization;Support vector machines","convex programming;gradient methods;learning (artificial intelligence);pattern classification","bundle algorithm;computational chemistry;linear-time subgradient-based methods;multiple-instance classification;multiple-instance learning;multiple-instance loss functions;multiple-instance ranking;nonconvex bundle method;smooth nonconvex optimization problems;support vector machines","Algorithms;Artificial Intelligence;Humans;Neural Networks (Computer);Pattern Recognition, Automated;Support Vector Machines","25","","37","","20111013","June 2012","","IEEE","IEEE Journals & Magazines"
"Analysis of classification learning based on estimation of distribution algorithms","J. Fan; Q. Xu; Y. Liang","College of Information Science and Engineering, Shandong University of Science and Technology, Qingdao, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","855","859","Estimation of distribution algorithms (abbr. EDAs) is a relatively new branch of evolutionary algorithms. EDAs replace search operators with the estimation of the distribution of selected individuals + sampling from the population. In an EDAs, this explicit representation of the population is replaced with a probability distribution over the choices available at each position in the vector that represents a population member. In this paper, the explicit probability basis about the semi-supervised learning and unsupervised learning is analyzed, and the mathematical properties analysis of the implicit EDAs learning algorithms is provided.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233911","estimation of distribution algorithm;evolutionary computation;machine learning","Algorithm design and analysis;Classification algorithms;Equations;Estimation;Evolutionary computation;Mathematical model;Unsupervised learning","distributed algorithms;evolutionary computation;learning (artificial intelligence);mathematical analysis;pattern classification;probability;unsupervised learning","EDA learning algorithms;classification learning;estimation of distribution algorithms;evolutionary algorithms;individuals distribution;mathematical properties analysis;population member;population representation;population sampling;probability distribution;semisupervised learning;unsupervised learning","","0","","28","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Protein model assessment using extented fuzzy decision tree with spatial neighborhood features","A. Chida; R. Harrison; Y. Q. Zhang","Department of Computer Science at Georgia State University Atlanta, 30302-3994, USA","2012 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20120614","2012","","","54","60","Automatic prediction of protein three dimensional structures from its amino acid sequence has become one of the most important and researched fields in bioinformatics We attempt to solve this problem using machine learning technique and information from both sequence and structure of the protein. Information like amino acid substitution matrix, polarity, secondary structure information and relative distance between alpha carbon atoms etc is collected through spatial traversing of the 3D structure to form training vectors. This guarantees that the properties of alpha carbon atoms that are close together in 3D space and thus interacting are used in vector formation. The goal is to generate a machine that understands structures from PDB and when given a new model, predicts whether it belongs to the same class as the PDB structures (correct or incorrect protein models). Improved fuzzy decision tree algorithm is used to build the machine, for the rules generated and high prediction accuracy it is favored over other machine learning techniques. Different subsets of PDB are considered for evaluating the prediction potential of the machine learning methods. With the use of machine learning technique, fuzzy decision tree, we obtained a training accuracy around 90%. There is significant improvement compared to previous encoding technique in prediction accuracy and execution time. This outcome motivates to continue to explore effective machine learning algorithms for accurate protein model quality assessment.","","Electronic:978-1-4673-1191-5; POD:978-1-4673-1190-8","10.1109/CIBCB.2012.6217211","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6217211","decision tree;feature selection;fuzzy ID3;machine learning;protein 3D structures;protein model assessment","Accuracy;Amino acids;Carbon;Decision trees;Encoding;Proteins;Vectors","bioinformatics;biological techniques;decision trees;fuzzy reasoning;learning (artificial intelligence);molecular biophysics;proteins","3D protein structures;alpha carbon atom distance;amino acid sequence;amino acid substitution matrix;automatic prediction;bioinformatics;extented fuzzy decision tree;machine learning technique;polarity;protein model assessment;protein sequence;relative distance;secondary structure information;spatial neighborhood features;training accuracy;training vector;vector formation","","0","","30","","","9-12 May 2012","","IEEE","IEEE Conference Publications"
"Automatic liver segmentation in CT images based on Support Vector Machine","Jie Lu; Defeng Wang; Lin Shi; Pheng Ann Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong","Proceedings of 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics","20120607","2012","","","333","336","Accurate and fully automated segmentation of liver parenchyma in medical images is necessary prerequisites for a variety of clinical and research applications, such as constructing three dimension anatomical model. In this paper, an automatic liver segmentation method based on Support Vector Machines (SVM) has been proposed. Segmentation is started by wavelet transform for image feature extraction. Subsequently, SVM is applied on the feature vectors for training and testing to realize pixel classification. Finally, region-growing is used to refine the result of SVM. Experiments have been conducted on different training-test partitions of the CT image datasets. Compared to manual segmentation provided by medical experts, our experimental results demonstrated the effectiveness of the proposed method.","2168-2194;21682194","Electronic:978-1-4577-2177-9; POD:978-1-4577-2176-2; USB:978-1-4577-2175-5","10.1109/BHI.2012.6211581","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6211581","Liver segmentation;machine learning;support vector machine","Biomedical imaging;Computed tomography;Image segmentation;Kernel;Manuals;Shape;Support vector machines","computerised tomography;feature extraction;image resolution;liver;medical image processing;support vector machines;wavelet transforms","Automatic liver segmentation;CT images;SVM;feature vectors;image feature extraction;liver parenchyma;medical images;pixel classification;region-growing;support vector machine;three dimension anatomical model;wavelet transform","","0","","11","","","5-7 Jan. 2012","","IEEE","IEEE Conference Publications"
"Real-Time Sleep Apnea Detection by Classifier Combination","B. Xie; H. Minn","Department of Electrical Engineering , University of Texas at Dallas, Richardson, USA","IEEE Transactions on Information Technology in Biomedicine","20120501","2012","16","3","469","477","To find an efficient and valid alternative of polysomnography (PSG), this paper investigates real-time sleep apnea and hypopnea syndrome (SAHS) detection based on electrocardiograph (ECG) and saturation of peripheral oxygen (SpO<sub>2</sub>) signals, individually and in combination. We include ten machine-learning algorithms in our classification experiment. It is shown that our proposed SpO<sub>2</sub> features outperform the ECG features in terms of diagnostic ability. More importantly, we propose classifier combination to further enhance the classification performance by harnessing the complementary information provided by individual classifiers. With our selected SpO<sub>2</sub> and ECG features, the classifier combination using AdaBoost with Decision Stump, Bagging with REPTree, and either kNN or Decision Table achieves sensitivity, specificity, and accuracy all around 82% for a minute-based real-time SAHS detection over 25 sleep-disordered-breathing suspects' full overnight recordings.","1089-7771;10897771","","10.1109/TITB.2012.2188299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6153377","Classifier combination;electrocardiograph (ECG);feature selection;hypopnea;machine learning;saturation of peripheral oxygen (SpO<formula formulatype=""inline""><tex Notation=""TeX"">$_2$ </tex></formula>);sleep apnea","Accuracy;Electrocardiography;Feature extraction;Indexes;Real time systems;Sensitivity","electrocardiography;feature extraction;learning (artificial intelligence);medical disorders;medical signal processing;pneumodynamics;sleep","AdaBoost;ECG features;REPTree;classifier combination;decision stump;electrocardiography;hypopnea syndrome detection;machine-learning algorithms;minute-based real-time SAHS detection;peripheral oxygen signals;polysomnography;real-time sleep apnea detection;sleep-disordered-breathing suspects","Adult;Aged;Artificial Intelligence;Computer Systems;Electrocardiography;Female;Humans;Male;Middle Aged;Monitoring, Physiologic;Oximetry;Signal Processing, Computer-Assisted;Sleep Apnea Syndromes","45","","37","","20120216","May 2012","","IEEE","IEEE Journals & Magazines"
"Utilizing region cardinality and dependency for object categorization in non-parametric Bayesian framework","Kristo; C. S. Chua","School of Electrical and Electronic Engineering, Nanyang Technological University (NTU), Singapore","2011 8th International Conference on Information, Communications & Signal Processing","20120403","2011","","","1","5","The “bag of words” model has enjoyed much attention in the studies of object categorization. As implied by the name, the images under consideration are modeled as a bag containing multiple features. Despite its simplicity, this model has been able to achieve great performances in many state of the art object categorization datasets. Using this model, we extract patches from an image and categorize them as codewords, forming the “bag of words”, which then used for object categorization. This model tends to assume the independence between patches, which greatly reduces the complexity. However, in this paper we take out the independence assumption and model the dependencies of the local regions. We move further by taking into account the cardinality of the patches to reduce the effect of noise patches. This collection of codewords acts as the building block of latent themes shared among images and categories, which distribution is learnt using a variation of the Hierarchical Dirichlet Process. In this paper, we introduce the contribution of region cardinality in the linkage of the latent themes to improve the learning and detection performance. The result of modeling the image, as obtained from our experiment, shows that our proposed model handles the presence of noise patches robustly with a more discriminative in categorizing the objects. All experiments are executed on the Caltech-4 datasets.","","Electronic:978-1-4577-0031-6; POD:978-1-4577-0029-3","10.1109/ICICS.2011.6173608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173608","bag of words;computer vision;hierarchical dirichlet process;machine learning;non-parametric bayesian;object categorization","Couplings;Detectors;Dictionaries;Feature extraction;Noise;Training;Vocabulary","Bayes methods;computer vision;image denoising;nonparametric statistics;object detection","Caltech-4 datasets;bag of words model;computer vision;hierarchical Dirichlet process;image modeling;noise patch effect reduction;nonparametric Bayesian framework;object categorization datasets;region cardinality","","0","","9","","","13-16 Dec. 2011","","IEEE","IEEE Conference Publications"
"Evaluating Stratification Alternatives to Improve Software Defect Prediction","L. Pelayo; S. Dick","Dept. of Electr. &amp; Comput. Eng., Univ. of Alberta, Edmonton, AB, Canada","IEEE Transactions on Reliability","20120529","2012","61","2","516","525","Numerous studies have applied machine learning to the software defect prediction problem, i.e. predicting which modules will experience a failure during operation based on software metrics. However, skewness in defect-prediction datasets can mean that the resulting classifiers often predict the faulty (minority) class less accurately. This problem is well known in machine learning, and is often referred to as “learning from imbalanced datasets.” One common approach for mitigating skewness is to use stratification to homogenize class distributions; however, it is unclear what stratification techniques are most effective, both generally and specifically in software defect prediction. In this article, we investigate two major stratification alternatives (under-, and over-sampling) for software defect prediction using Analysis of Variance. Our analysis covers several modern software defect prediction datasets using a factorial design. We find that the main effect of under-sampling is significant at α = 0.05, as is the interaction between under- and over-sampling. However, the main effect of over-sampling is not significant.","0018-9529;00189529","","10.1109/TR.2012.2183912","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6156808","Learning in imbalanced datasets;machine learning;non-parametric models;software fault-proneness;software reliability;stratification","Accuracy;Algorithm design and analysis;Analysis of variance;Machine learning;Measurement;Object oriented modeling;Software","learning (artificial intelligence);software metrics;software quality;statistical analysis","analysis of variance;factorial design;imbalanced datasets;machine learning;software defect prediction;software metrics;stratification alternatives;stratification techniques","","8","","103","","20120223","June 2012","","IEEE","IEEE Journals & Magazines"
"Variational Regularized 2-D Nonnegative Matrix Factorization","B. Gao; W. L. Woo; S. S. Dlay","School of Electrical and Electronic Engineering, Newcastle University, Newcastle upon Tyne, U.K.","IEEE Transactions on Neural Networks and Learning Systems","20120427","2012","23","5","703","716","A novel approach for adaptive regularization of 2-D nonnegative matrix factorization is presented. The proposed matrix factorization is developed under the framework of maximum a posteriori probability and is adaptively fine-tuned using the variational approach. The method enables: (1) a generalized criterion for variable sparseness to be imposed onto the solution; and (2) prior information to be explicitly incorporated into the basis features. The method is computationally efficient and has been demonstrated on two applications, that is, extracting features from image and separating single channel source mixture. In addition, it is shown that the basis features of an information-bearing matrix can be extracted more efficiently using the proposed regularized priors. Experimental tests have been rigorously conducted to verify the efficacy of the proposed method.","2162-237X;2162237X","","10.1109/TNNLS.2012.2187925","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6157630","Audio process machine learning;nonnegative matrix factorization;single channel blind source separation;sparsity-aware learning;variational regularization","Adaptation models;Correlation;Cost function;Covariance matrix;Feature extraction;Gaussian distribution;Vectors","blind source separation;feature extraction;matrix decomposition;maximum likelihood estimation;probability;variational techniques","adaptive regularization;channel source mixture;feature extraction;generalized criterion;information-bearing matrix;maximum a posteriori probability;variable sparseness;variational regularized 2D nonnegative matrix factorization","","31","","39","","20120224","May 2012","","IEEE","IEEE Journals & Magazines"
"Learning invariants using association rules technique","M. A. Souaiaia; T. Benouhiba","LRI laboratory, Department of computer science, University Badji Mokhtar, Annaba, Algeria","2012 International Conference on Information Technology and e-Services","20120614","2012","","","1","6","Dynamic invariant detection is the identification of properties of programs by analyzing execution traces. Traditional dynamic invariant detectors, such as Daikon, use naive techniques based on verification of predefined invariant forms. Unfortunately, this may discard many useful knowledge such as relationship between variables. This kind of knowledge can be helpful to understand hidden dependencies in the program. In this paper, we propose to model invariant detection as a machine learning process. We intend to use learning algorithms to find out correlation between variables. We are particularly interested by association rules since they are suitable to detect such relationship. We propose an adaptation to existing learning techniques as well as some pruning algorithms in order to refine the obtained invariants. Compared to the traditional Daikon tool, our approach has successfully inferred many meaningful invariants about variables relationship.","","Electronic:978-1-4673-1166-3; POD:978-1-4673-1167-0","10.1109/ICITeS.2012.6216625","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216625","Association rules;Daikon;Machine learning;dynamic invariant detection","Association rules;Itemsets;Machine learning;Merging;Reverse engineering;Software algorithms","data mining;learning (artificial intelligence)","Daikon;association rules technique;dynamic invariant detectors;execution traces;learning algorithms;learning invariants;machine learning process;model invariant detection;naive techniques;pruning algorithms","","0","","16","","","24-26 March 2012","","IEEE","IEEE Conference Publications"
"The research progress of Text Classification Techniques","Kuifeng Dong; Jun Gao; Ming Zhang","Department of Computer Science and Engineering, Information Engineering College, Shanghai Maritime University, 1550 Haigang Ave, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","3","","1988","1991","With the rapid development of global information technology and networking, text categorization has become more popular areas for researchers in the research field. The article describes the framework, the classic models and some new text categorization models which current emerged in text categorization, and then summarizes technology advances in recent years and some research work on the future about basic text categorization technology.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182361","Classified Methods;Classified Models;Machine Learning;Text Classification","Accuracy;Classification algorithms;Computational modeling;Information filters;Text categorization","pattern classification;text analysis","classic models;text categorization models;text categorization technology;text classification techniques","","2","","30","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Peek-a-Boo, I Still See You: Why Efficient Traffic Analysis Countermeasures Fail","K. P. Dyer; S. E. Coull; T. Ristenpart; T. Shrimpton","Dept. of Comput. Sci., Portland State Univ., Portland, OR, USA","2012 IEEE Symposium on Security and Privacy","20120709","2012","","","332","346","We consider the setting of HTTP traffic over encrypted tunnels, as used to conceal the identity of websites visited by a user. It is well known that traffic analysis (TA) attacks can accurately identify the website a user visits despite the use of encryption, and previous work has looked at specific attack/countermeasure pairings. We provide the first comprehensive analysis of general-purpose TA countermeasures. We show that nine known countermeasures are vulnerable to simple attacks that exploit coarse features of traffic (e.g., total time and bandwidth). The considered countermeasures include ones like those standardized by TLS, SSH, and IPsec, and even more complex ones like the traffic morphing scheme of Wright et al. As just one of our results, we show that despite the use of traffic morphing, one can use only total upstream and downstream bandwidth to identify -- with 98% accuracy - which of two websites was visited. One implication of what we find is that, in the context of website identification, it is unlikely that bandwidth-efficient, general-purpose TA countermeasures can ever provide the type of security targeted in prior work.","1081-6011;10816011","Electronic:978-07695-4681-0; POD:978-1-4673-1244-8","10.1109/SP.2012.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234422","encrypted traffic;machine learning;padding;privacy;traffic analysis countermeasures","Accuracy;Bandwidth;Encryption;Support vector machines;Vectors;Web pages","Web sites;cryptography;hypermedia;telecommunication traffic","HTTP traffic;IPsec;SSH;TA attack;TLS;Web site identification;attack/countermeasure pairings;downstream bandwidth;encrypted tunnel;encryption;general-purpose TA countermeasures;security;traffic analysis attack;traffic analysis countermeasures;traffic morphing scheme;upstream bandwidth","","45","","23","","","20-23 May 2012","","IEEE","IEEE Conference Publications"
"E-behavior general screening for personality disorders","K. Zakir Hussain; M. Durairaj; G. Rabia Jahani Farzana","Indian Air Force, Air Force Station, Thanjavur, India","2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET)","20120524","2012","","","1000","1003","Mental disorder of criminals can be defined according to a combination of factors which can be grouped into 4 entities. These groups can be viewed as levels of requirements. The levels are Background Information, Screening Questions, Pre-requisites Questions and Other Questions. Color interactions are used to identify the nature of the criminals'. Criminals' suffering from personality disorders should not be remanded to institutions that know no efficient way of reducing relapses into destructive behavior.","","DVD:978-1-4673-0210-4; Electronic:978-1-4673-0212-8; POD:978-1-4673-0211-1","10.1109/ICCEET.2012.6203913","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6203913","Behavioral Profiling;entities and color interactions;machine learning","Animals;Atmospheric measurements;Color;Indexes;Machine learning;Neural networks;Particle measurements","behavioural sciences computing","background information;color interactions;criminals;destructive behavior;e-behavior;general screening;mental disorder;personality disorders;prerequisites questions;screening questions","","0","","13","","","21-22 March 2012","","IEEE","IEEE Conference Publications"
"EPIC: Efficient prediction of IC manufacturing hotspots with a unified meta-classification formulation","Duo Ding; Bei Yu; J. Ghosh; D. Z. Pan","ECE Dept. Univ. of Texas at Austin, 78712, USA","17th Asia and South Pacific Design Automation Conference","20120309","2012","","","263","270","In this paper we present EPIC, an efficient and effective predictor for IC manufacturing hotspots in deep sub-wavelength lithography. EPIC proposes a unified framework to combine different hotspot detection methods together, such as machine learning and pattern matching, using mathematical programming/optimization. EPIC algorithm has been tested on a number of industry benchmarks under advanced manufacturing conditions. It demonstrates so far the best capability in selectively combining the desirable features of various hotspot detection methods (3.5-8.2% accuracy improvement) as well as significant suppression of the detection noise (e.g., 80% false-alarm reduction). These characteristics make EPIC very suitable for conducting high performance physical verification and guiding efficient manufacturability friendly physical design.","2153-6961;21536961","Electronic:978-1-4673-0772-7; POD:978-1-4673-0770-3","10.1109/ASPDAC.2012.6164956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6164956","Design for Manufacturability;Lithography Hotspots;Machine Learning;Meta Classification;Pattern Matching","Accuracy;Calibration;Layout;Lithography;Machine learning;Pattern matching","circuit optimisation;electronic engineering computing;integrated circuit design;integrated circuit manufacture;mathematical programming;pattern classification;photolithography","EPIC effective predictor algorithm;IC manufacturing hotspots;deep sub-wavelength lithography;detection noise suppression;hotspot detection methods;machine learning;mathematical programming-optimization;pattern matching;unified meta-classification formulation","","12","","20","","","Jan. 30 2012-Feb. 2 2012","","IEEE","IEEE Conference Publications"
"Large Margin Gaussian Mixture Models with Differential Privacy","M. A. Pathak; B. Raj","Carnegie Mellon University, Pittsburgh","IEEE Transactions on Dependable and Secure Computing","20120511","2012","9","4","463","469","As increasing amounts of sensitive personal information is aggregated into data repositories, it has become important to develop mechanisms for processing the data without revealing information about individual data instances. The differential privacy model provides a framework for the development and theoretical analysis of such mechanisms. In this paper, we propose an algorithm for learning a discriminatively trained multiclass Gaussian mixture model-based classifier that preserves differential privacy using a large margin loss function with a perturbed regularization term. We present a theoretical upper bound on the excess risk of the classifier introduced by the perturbation.","1545-5971;15455971","","10.1109/TDSC.2012.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6198848","Differential privacy;machine learning.","Classification algorithms;Data models;Data privacy;Optimization;Privacy;Training;Training data","Gaussian processes;data privacy;learning (artificial intelligence);pattern classification","classifier excess risk;data processing;data repositories;differential privacy model;large margin Gaussian mixture models;large margin loss function;multiclass Gaussian mixture model-based classifier learning;perturbed regularization term;sensitive personal information","","3","","19","","","July-Aug. 2012","","IEEE","IEEE Journals & Magazines"
"CrossCheck: Combining Crawling and Differencing to Better Detect Cross-browser Incompatibilities in Web Applications","S. R. Choudhary; M. R. Prasad; A. Orso","Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA","2012 IEEE Fifth International Conference on Software Testing, Verification and Validation","20120517","2012","","","171","180","One of the consequences of the continuous and rapid evolution of web technologies is the amount of inconsistencies between web browsers implementations. Such inconsistencies can result in cross-browser incompatibilities (XBIs)-situations in which the same web application can behave differently when run on different browsers. In some cases, XBIs consist of tolerable cosmetic differences. In other cases, however, they may completely prevent users from accessing part of a web application's functionality. Despite the prevalence of XBIs, there are hardly any tools that can help web developers detect and correct such issues. In fact, most existing approaches against XBIs involve a considerable amount of manual effort and are consequently extremely time consuming and error prone. In recent work, we have presented two complementary approaches, WEBDIFF and CROSST, for automatically detecting and reporting XBIs. In this paper, we present CROSSCHECK, a more powerful and comprehensive technique and tool for XBI detection that combines and adapts these two approaches in a way that leverages their respective strengths. The paper also presents an empirical evaluation of CROSSCHECK on a set of real-world web applications. The results of our experiments show that CROSSCHECK is both effective and efficient in detecting XBIs, and that it can outperform existing techniques.","2159-4848;21594848","Electronic:978-0-7695-4670-4; POD:978-1-4577-1906-6","10.1109/ICST.2012.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200112","dynamic analysis;machine learning;web testing","Browsers;Cascading style sheets;Engines;HTML;Machine learning;Visualization;Web pages","Internet;online front-ends;program testing","CrossT;Crosscheck;Web applications;Web browsers;Web technologies;WebDiff;XBI;crawling;cross-browser incompatibilities","","10","1","22","","","17-21 April 2012","","IEEE","IEEE Conference Publications"
"Pattern Detection Model for Monitoring Distributed Systems","C. M. Dinu; F. Pop; V. Cristea","Fac. of Autom. Control & Comput. Sci., Politeh. Univ. of Bucharest, Bucharest, Romania","2011 13th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing","20120315","2011","","","268","275","The ever-increasing size, variety and complexity of distributed systems necessitate the development of highly automated and intelligent solutions for monitoring system parameters. In the context of Large Scale Distributed Systems, automatically detecting events and activity patterns will provide self-organization abilities and increase the dependability of these systems. We present in this paper a model for representing a wide variety of patterns in the parallel time series describing the distributed system parameters and states. Based on this model, we outline an application architecture for a system that employs advanced machine learning techniques for detecting and learning patterns in a distributed system with only minimal user input. The application is implemented as an add-on to the highly successful MonALISA monitoring framework for distributed systems. We test and validate the proposed model in real-time using the large amount of monitoring data provided by the MonALISA system. The novelty of this solution consists of the expressiveness of the model and the advanced automated data analysis for pattern learning and recognition in a long-time monitored system.","","Electronic:978-0-7695-4630-8; POD:978-1-4673-0207-4","10.1109/SYNASC.2011.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169591","Large-Scale Distributed Systems;Machine Learning;MonALISA;Monitoring;Pattern Detection;Resource Allocation","Computer architecture;Feature extraction;Machine learning;Monitoring;Program processors;Shape;Time series analysis","data analysis;distributed processing;learning (artificial intelligence);pattern recognition;time series","MonALISA monitoring framework;application architecture;data analysis;large scale distributed system monitoring;machine learning techniques;model expressiveness;parallel time series;pattern detection model;pattern learning;pattern recognition;selforganization abilities;system dependability","","2","","12","","","26-29 Sept. 2011","","IEEE","IEEE Conference Publications"
"A review of early detection of cancers using breath analysis","D. A. P. Daniel; K. Thangavel; R. S. C. Boss","Department of Computer Science, Periyar University, Salem - 636 011, India","International Conference on Pattern Recognition, Informatics and Medical Engineering (PRIME-2012)","20120531","2012","","","433","438","Authentic and accurate information is basic to any disease control initiative. More than 70% of diseases are related to life-style factors such as food and beverage practices, personal habits, infections, tobacco consumption and social customs. In addition, urbanization, industrialization and increasing life-span are also known to influence the cancer pattern globally. This necessitates proper appreciation of risk factors and other causes of cancer by the people. Various modalities for early detection through screening are being investigated. Majority of the patients have locally advanced or disseminated disease at presentation and are not candidates for surgery. Chemotherapy applied as an adjunct with radiation improves survival and the quality of life. New anticancer drugs, which have emerged during the last decade, have shown an improved efficacy toxicity ratio. This review is more about the diagnosing cancer at an early stage using invasive electronic sensors and intelligent computing methods by capturing only the breath of the human being. Strengthening the methods for early diagnosis of cancers and improved treatments will have a significant impact on cutting death rates.","","Electronic:978-1-4673-1039-0; POD:978-1-4673-1037-6","10.1109/ICPRIME.2012.6208385","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6208385","Breath Analysis;Cancers Biomarker;Early Detection of Cancers;Machine Learning;VOC","Biopsy;Breast;Cancer;Diseases;Lungs;Sensor arrays","biosensors;cancer;diseases;medical diagnostic computing;patient diagnosis;pneumodynamics","anticancer drugs;beverage practices;breath analysis;cancer pattern;chemotherapy;death rates;disease control;early cancer detection;food practices;improved efficacy toxicity ratio;infections;intelligent computing methods;invasive electronic sensors;life-style factors;personal habits;risk factors;social customs;tobacco consumption","","0","","50","","","21-23 March 2012","","IEEE","IEEE Conference Publications"
"Detecting Hoaxes, Frauds, and Deception in Writing Style Online","S. Afroz; M. Brennan; R. Greenstadt","Dept. of Comput. Sci., Drexel Univ., Philadelphia, PA, USA","2012 IEEE Symposium on Security and Privacy","20120709","2012","","","461","475","In digital forensics, questions often arise about the authors of documents: their identity, demographic background, and whether they can be linked to other documents. The field of stylometry uses linguistic features and machine learning techniques to answer these questions. While stylometry techniques can identify authors with high accuracy in non-adversarial scenarios, their accuracy is reduced to random guessing when faced with authors who intentionally obfuscate their writing style or attempt to imitate that of another author. While these results are good for privacy, they raise concerns about fraud. We argue that some linguistic features change when people hide their writing style and by identifying those features, stylistic deception can be recognized. The major contribution of this work is a method for detecting stylistic deception in written documents. We show that using a large feature set, it is possible to distinguish regular documents from deceptive documents with 96.6% accuracy (F-measure). We also present an analysis of linguistic features that can be modified to hide writing style.","1081-6011;10816011","Electronic:978-07695-4681-0; POD:978-1-4673-1244-8","10.1109/SP.2012.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234430","deception;machine learning;privacy;stylometry","Accuracy;Blogs;Context;Feature extraction;Pragmatics;Privacy;Writing","Internet;data privacy;document handling;forensic science;fraud;learning (artificial intelligence);linguistics","F-measure;deceptive documents;digital forensics;frauds;hoaxes detection;linguistic features;machine learning techniques;nonadversarial scenarios;random guessing;regular documents;stylistic deception;stylometry techniques;writing style online;written documents","","28","","30","","","20-23 May 2012","","IEEE","IEEE Conference Publications"
"Dual-stage hardware architecture of on-line clustering with high-throughput parallel divider for low-power signal processing","T. W. Chen; M. Ikeda","VLSI Design and Education Center, the University of Tokyo, Takeda Bldg., Yayoi 2-11-16, Bunkyo-ku, 113-0032, Japan","2012 IEEE COOL Chips XV","20120614","2012","","","1","3","Different from previous works that focus on the iterative clustering algorithm, a dual-stage hardware architecture that supports two kinds of moving averages for the on-line clustering algorithm is proposed. The architecture includes a set of memories that operates in ping-pong mode, so that distance computations and centroid updating can be processed in pipeline. The high-throughput parallel divider in the moving-average engine is a new solution to reduce the overhead of divisions to only 1 clock cycle and to calculate cumulative moving averages with no precision loss. The experiments show that when the operating frequency is 400MHz, the gate count and the average power consumption are 16K and 6.02mW, respectively. The normalized power consumption of this work is the lowest among previous works.","","Electronic:978-1-4673-1202-8; POD:978-1-4673-1201-1; USB:978-1-4673-1200-4","10.1109/COOLChips.2012.6216580","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216580","Architectural analysis;digital circuits;logic design;machine learning;signal processing","Algorithm design and analysis;Clustering algorithms;Computer architecture;Engines;Hardware;Signal processing algorithms;Vectors","logic design;moving average processes;signal processing","centroid updating;distance computation;dual-stage hardware architecture;frequency 400 MHz;gate count;high-throughput parallel divider;iterative clustering algorithm;low-power signal processing;moving-average engine;online clustering;ping-pong mode;power 6.02 mW;power consumption","","1","","5","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"Analysis of supervised text classification algorithms on corporate sustainability reports","A. M. Shahi; B. Issac; J. R. Modapothala","School of Engineering, Computing and Science, Swinburne University of Technology (Sarawak Campus), Kuching, Malaysia","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","1","","96","100","Machine Learning approach to text classification has been the dominant method in the research and application field since it was first introduced in the 1990s. It has been proven that document classification applications based on Machine Learning produce competitive results to those based on the Knowledge Based approaches. This approach has been widely researched upon as well as applied in various applications to solve various text categorization problems. In this research we have applied such techniques in a novel effort to find out which document classification algorithms perform best on Corporate Sustainability Reports.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6181917","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181917","Corporate Sustainability Report;Document Categorization;Feature Selection;GRI;Machine Learning;Supervised Learning;Text Classification","Artificial neural networks;Niobium","learning (artificial intelligence);pattern classification;report generators;text analysis","corporate sustainability reports;document classification algorithm;knowledge based approach;machine learning;supervised text classification algorithm;text categorization problem","","3","","34","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Studying the Effect of Tutor Learning Using a Teachable Agent that Asks the Student Tutor for Explanations","N. Matsuda; W. W. Cohen; K. R. Koedinger; V. Keiser; R. Raizada; E. Yarzebinski; S. P. Watson; G. Stylianides","Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA","2012 IEEE Fourth International Conference On Digital Game And Intelligent Toy Enhanced Learning","20120419","2012","","","25","32","We have built Sim Student, a computational model of learning, and applied it as a peer learner that allows students to learn by teaching. Using Sim Student, we study the effect of tutor learning. In this paper, we discuss an empirical classroom study where we evaluated whether asking students to provide explanations for their tutoring activities facilitates tutor learning - the self-explanation effect for tutor learning. The results showed that students in the self-explanation condition displayed the same amount of learning gain as students in the non-self-explanation condition, but with a significantly smaller number of problems tutored (during the same time). The study also showed an apparent increase in effectiveness relative to a prior study, which is arguably due to improvement of the system based on the iterative system-engineering effort.","","Electronic:978-0-7695-4663-6; POD:978-1-4673-0885-4","10.1109/DIGITEL.2012.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185576","Sim Student;learning by teaching;machine learning;teachable agent;tutor learning effect","Algebra;Computational modeling;Education;Equations;Humans;Machine learning;Production","intelligent tutoring systems;iterative methods","SimStudent;computational learning model;empirical classroom study;iterative system-engineering effort;nonself-explanation condition;peer learner;self-explanation condition;self-explanation effect;student tutor learning gain;teachable agent;tutoring activity","","8","","25","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"Voting Among Virtually Generated Versions of a Classification Problem","A. Hosseinzadeh; A. M. Reza","Department of Electrical Engineering, Amirkabir University of Technology , Tehran, Iran","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20120511","2012","42","3","754","763","A classifier combining strategy, virtual voting by random projection (VVRP), is presented. VVRP takes advantage from the bounded distortion incurred by random projection in order to improve accuracies of stable classifiers like discriminant analysis (DA) where existing classifier combining strategies are known to be failed. It uses the distortion to virtually generate different training sets from the total available training samples in a way that does not have the potential for overfitting. Then, a majority voting combines the base learners trained on these versions of the original problem. VVRP is very simple and just needs determining a proper dimensionality for the versions, an often very easy task. It is shown to be stable in a very large region of the hyperplane constructed by the dimensionality and the number of the versions. VVRP improves the best state-of-the-art DA algorithms in both small and large sample size problems in various classification fields.","1083-4419;10834419","","10.1109/TSMCB.2011.2177084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121955","Classifier combining;compressive sensing (CS);discriminant analysis (DA);face recognition (FR);feature extraction;machine learning;manifold learning;object recognition;pattern recognition;random projection (RP)","Accuracy;Boosting;Kernel;Manifolds;Optimized production technology;Support vector machines;Training","feature extraction;learning (artificial intelligence);pattern classification;random processes","base learners;bounded distortion;classification problem;classifier combining strategy;data dimensionality;discriminant analysis;feature extraction;hyperplane;majority voting;random projection;version dimensionality;virtual voting;virtually generated versions","Algorithms;Artificial Intelligence;Computer Simulation;Decision Support Techniques;Models, Theoretical;Pattern Recognition, Automated;Politics","2","","39","","20120102","June 2012","","IEEE","IEEE Journals & Magazines"
"Joint waveform and firing rate spike-sorting for continuous extracellular traces","B. Matthews; M. Clements","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA","2011 Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)","20120426","2011","","","1689","1693","This paper discusses recent work in automatic spike-sorting for continuous extra-cellular cortical traces. Our spike-sorting framework jointly models neuronal firing times and corresponding action potential waveforms as a discrete-state latent variable process. We model the likelihood of the observed firing occurrence times as the aggregation of multiple hidden point processes based on inter-arrival probability distributions. We evaluate our method on two real, continuous, partially labeled recordings of extracellular traces from rat hippocampus obtaining total error rates (false positives + false negatives) of 5.60% and 1.86% in clean conditions, outperforming both a Gaussian mixture model (GMM) baseline and the state-of-the-art WaveClus method. Our method continues to outperform in the presence of added noise on the same data. We then perform an empirical study of two free parameters for our method on a semi-artificial dataset. We find that our method is more sensitive to parameter tuning in more difficult data and noise conditions.","1058-6393;10586393","Electronic:978-1-4673-0323-1; POD:978-1-4673-0321-7","10.1109/ACSSC.2011.6190308","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6190308","BCIs;Spike-sorting;machine learning","Accuracy;Error analysis;Extracellular;Integrated circuits;Neurons;Signal to noise ratio;Sorting","Gaussian processes;brain-computer interfaces;medical signal processing;neurophysiology","Gaussian mixture model;automatic spike-sorting;continuous extra-cellular cortical traces;discrete-state latent variable process;inter-arrival probability distributions;neuronal firing times;parameter tuning;rat hippocampus;state-of-the-art WaveClus method","","0","","14","","","6-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"Sequence learning: analysis and solutions for sparse data in high dimensional spaces","Z. Bai; S. C. Kremer","School of Computer Science, University of Guelph, ON, CA, USA","2012 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20120614","2012","","","298","305","We examine the problem of classifying biological sequences, and in particular the challenge of generalizing to novel input data. The high dimensionality of sequence results in an extremely sparsely populated input space. This motivates a need for regularization (a form of inductive bias), in order to achieve generalization. We discuss regularization in the context of regular Neural Networks and Deep Belief Networks, and provide experimental results on an example problem of DNA barcoding classification. Our results support the importance of using an effective regularization method, and indicate the adaptive, data-depended regularization mechanism of a DBN is more powerful than the simple methods of model selection / weight decay / early stopping.","","Electronic:978-1-4673-1191-5; POD:978-1-4673-1190-8","10.1109/CIBCB.2012.6217244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6217244","DNA barcoding;deep architecture;generalization;generative model;machine learning;neural network;reuglarization","Complexity theory;Correlation;DNA;Feature extraction;Neural networks;Noise;Training","DNA;belief networks;bioinformatics;biological techniques;data handling;learning (artificial intelligence);molecular biophysics;molecular configurations;neural nets","DNA barcoding classification;adaptive data dependent regularization mechanism;biological sequence classification;deep belief networks;high dimensional spaces;inductive bias;regular neural networks;sequence learning;sparse data analysis;sparsely populated input space","","0","","20","","","9-12 May 2012","","IEEE","IEEE Conference Publications"
"Dynamic prediction of energy delivery capacity of power networks: Unlocking the value of real-time measurements","P. Schell; L. Jones; P. Mack; B. Godard; J. L. Lilien","Ampacimon S.A, Belgium","2012 IEEE PES Innovative Smart Grid Technologies (ISGT)","20120403","2012","","","1","6","The paper focuses on advances in short-term prediction (1-4 Hours) of dynamic line rating as an example of what can be achieved by the combination of advanced network sensors and the latest machine learning, data-mining tools. Combining these tools has allowed us to achieve reliable and usable predictions that allow the network operators to switch from a static approach to a manageable dynamic one that significantly increases asset utilisation without reducing security of supply.","","Electronic:978-1-4577-2159-5; POD:978-1-4577-2158-8","10.1109/ISGT.2012.6175690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175690","Dynamic Line Rating;Machine Learning;Overheadline monitoring;Short-term predictions;smart grid","Forecasting;Real time systems;Security;Sensors;Uncertainty;Weather forecasting","data mining;distributed sensors;learning (artificial intelligence);power engineering computing;power overhead lines;power system measurement;smart power grids","asset utilisation;data mining tool;dynamic energy delivery capacity prediction;machine learning;network operators;power networks;real-time measurement;sensor networks;short-term dynamic line rating prediction","","2","","6","","","16-20 Jan. 2012","","IEEE","IEEE Conference Publications"
"Hyperspectral Unmixing Overview: Geometrical, Statistical, and Sparse Regression-Based Approaches","J. M. Bioucas-Dias; A. Plaza; N. Dobigeon; M. Parente; Q. Du; P. Gader; J. Chanussot","Instituto de Telecomunica&#x00E7;&#x00F5;es, Instituto Superior T&#x00E9;cnico, Technical University of Lisbon, Portugal","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20120523","2012","5","2","354","379","Imaging spectrometers measure electromagnetic energy scattered in their instantaneous field view in hundreds or thousands of spectral channels with higher spectral resolution than multispectral cameras. Imaging spectrometers are therefore often referred to as hyperspectral cameras (HSCs). Higher spectral resolution enables material identification via spectroscopic analysis, which facilitates countless applications that require identifying materials in scenarios unsuitable for classical spectroscopic analysis. Due to low spatial resolution of HSCs, microscopic material mixing, and multiple scattering, spectra measured by HSCs are mixtures of spectra of materials in a scene. Thus, accurate estimation requires unmixing. Pixels are assumed to be mixtures of a few materials, called endmembers. Unmixing involves estimating all or some of: the number of endmembers, their spectral signatures, and their abundances at each pixel. Unmixing is a challenging, ill-posed inverse problem because of model inaccuracies, observation noise, environmental conditions, endmember variability, and data set size. Researchers have devised and investigated many models searching for robust, stable, tractable, and accurate unmixing algorithms. This paper presents an overview of unmixing methods from the time of Keshava and Mustard's unmixing tutorial to the present. Mixing models are first discussed. Signal-subspace, geometrical, statistical, sparsity-based, and spatial-contextual unmixing algorithms are described. Mathematical problems and potential solutions are described. Algorithm characteristics are illustrated experimentally.","1939-1404;19391404","","10.1109/JSTARS.2012.2194696","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200362","Hyperspectral imaging;hyperspectral remote sensing;image analysis;image processing;imaging spectroscopy;inverse problems;linear mixture;machine learning algorithms;nonlinear mixtures;pattern recognition;remote sensing;sparsity;spectroscopy;unmixing","Educational institutions;Hyperspectral imaging;Mortar;Vectors","cameras;electromagnetic wave scattering;geophysical image processing;regression analysis;spectral analysis;spectrometers","Imaging spectrometers;data set size;electromagnetic energy scattering;endmember variability;endmembers;environmental conditions;geometrical-based approach;hyperspectral cameras;hyperspectral unmixing overview;ill-posed inverse problem;instantaneous field view;material identification;materials spectra;mathematical problems;microscopic material mixing;mixing models;multispectral cameras;observation noise;signal-subspace unmixing algorithm;sparse regression-based approach;sparsity-based unmixing algorithm;spatial resolution;spatial-contextual unmixing algorithm;spectral channels;spectral signatures;spectroscopic analysis;statistical-based approach;unmixing tutorial","","529","","223","","20120515","April 2012","","IEEE","IEEE Journals & Magazines"
"Improving motion vector prediction using linear regression","R. A. Farrugia","Department of Communications and Computer Engineering, University of Malta, Msida, MSD 2080, Malta","2012 5th International Symposium on Communications, Control and Signal Processing","20120621","2012","","","1","4","The motion vectors take a large portion of the H.264/AVC encoded bitstream. This video coding standard employs predictive coding to minimize the amount of motion vector information to be transmitted. However, the motion vectors still accounts for around 40% of the transmitted bitstream, which suggests further research in this area. This paper presents an algorithm which employs a feature selection process to select the neighboring motion vectors which are most suitable to predict the motion vectors mv being encoded. The selected motion vectors are then used to approximate mv using Linear Regression. Simulation results have indicated a reduction in Mean Squared Error (MSE) of around 22% which results in reducing the residual error of the predictive coded motion vectors. This suggests that higher compression efficiencies can be achieved using the proposed Linear Regression based motion vector predictor.","","Electronic:978-1-4673-0276-0; POD:978-1-4673-0274-6","10.1109/ISCCSP.2012.6217750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6217750","H.264/AVC;linear regression;machine learning;motion vector prediction;video compression","Correlation;Genetics;Linear regression;Standards;Training;Vectors;Video coding","image motion analysis;mean square error methods;regression analysis;video coding","H.264/AVC encoded bitstream;MSE;feature selection process;linear regression;mean squared error;motion vector information;motion vector prediction;predictive coding;video coding","","0","","16","","","2-4 May 2012","","IEEE","IEEE Conference Publications"
"A learning method of Bayesian network structure","X. Lin; X. Li; N. Xiao; P. Ma; J. Jiang; F. Yang","School of Computer Science and Technology, Dalian University of Technology, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","666","670","Bayesian networks are efficient classification techniques, and widely applied in many fields, however, their structure learning is NP-hard. In this paper, a Bayesian network structure learning method called Tree-like Bayesian network (BN-TL) was proposed, which constructs the network by estimating the correlation between the features and the correlation between the class label and the features. Two metabolomics datasets about liver disease and five public datasets from the University of California at Irvine repository (UCI) were used to demonstrate the performance of BN-TL. The result shows that BN-TL outperforms the other three classifiers, including Naïve Bayesian classifier (NB), Bayesian network classifier whose structure is learned by using K2 greedy search strategy (BN-K2) and a method proposed by Kuschner in 2010 (BN-BMC) in most cases.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234299","Bayesian networks;classifier;machine learning;mutual information","Bayesian methods;Computer science;Educational institutions;Learning systems;Machine learning;Mutual information;Niobium","Bayes methods;computational complexity;greedy algorithms;learning (artificial intelligence);search problems","BN-BMC;BN-K2;BN-TL;Bayesian network structure learning method;K2 greedy search strategy;NB;NP-hard;Naïve Bayesian classifier;UCI;University of California at Irvine repository;classification techniques;liver disease;metabolomics datasets;public datasets;tree-like Bayesian network","","0","","28","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Evaluation of support vector machine with universal kernel for hand-geometry based identification","E. S. M. El-Alfy; G. M. Bin Makhashen","College of Computer Sciences and Engineering, King Fahd University of Petroleum and Minerals, Dhahran 31261, Saudi Arabia","2012 International Conference on Innovations in Information Technology (IIT)","20120531","2012","","","117","122","Hand-geometry based authentication is gaining widespread application in a number of security systems. It can be operating in either verification or identification mode. Although the verification mode has received great attention in research in the past, the identification mode is still an open research area and new innovative solutions are needed to reduce the computational time and enhance accuracy. In this paper, we explore and evaluate a new approach based on support vector machines with universal kernel for addressing this problem. We also compare its performance with some other kernel functions and common classifiers including rule based and decision-tree based classifiers. Our experiments reveal significant improvements in the performance of hand geometry based identification for the proposed approach on the adopted dataset as compared to other approaches. More than 98% average identification accuracy can be achieved with less than 0.04% average false acceptance rate and 2% average false rejection rate.","","Electronic:978-1-4673-1101-4; POD:978-1-4673-1100-7","10.1109/INNOVATIONS.2012.6207714","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6207714","authentication;biometrics;hand geometry;identification;machine learning;support vector machine;universal kernels","Biometrics;Databases;Feature extraction;Geometry;Kernel;Support vector machines;Thumb","decision trees;program verification;security of data;support vector machines","decision tree based classifiers;hand geometry based authentication;hand geometry based identification;identification mode;security systems;support vector machine;universal kernel;verification mode","","1","","22","","","18-20 March 2012","","IEEE","IEEE Conference Publications"
"Stochastic Gradient Descent Inspired Training Technique for a CMOS/Nano Memristive Trainable Threshold Gate Array","H. Manem; J. Rajendran; G. S. Rose","College of Nanoscale Science and Engineering, University at Albany, Albany, NY, USA","IEEE Transactions on Circuits and Systems I: Regular Papers","20120503","2012","59","5","1051","1060","Neuromorphic computing is an attractive avenue of research for processing and learning complex real-world data. With technology migration into nano and molecular scales several area and power efficient approaches to the design and implementation of artificial neural networks have been proposed. The discovery of the memristor has further enabled the realization of denser nanoscale logic and memory systems by facilitating the implementation of multilevel logic. Specifically, the innate reconfigurability of memristors can be exploited to realize synapses in artificial neural networks. This work focuses on the development of a variation-tolerant training methodology to efficiently reconfigure memristive synapses in a Trainable Threshold Gate Array (TTGA) system. The training process is inspired from the gradient descent machine learning algorithm commonly used to train artificial threshold neural networks, perceptrons. The design and CMOS/Nano implementation of the TTGA system from trainable perceptron based threshold gates is detailed and results are provided to showcase the training process and performance characteristics of the proposed system. Also shown are the results for training a 1T1M (1 Transistor and 1 Memristor) multilevel memristive memory and its performance characteristics.","1549-8328;15498328","","10.1109/TCSI.2012.2190665","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189064","Digital integrated circuits;VLSI;machine learning;memristor;nanoelectronics;neural networks","Boolean functions;CMOS integrated circuits;Hardware;Logic gates;Memristors;Training;Vectors","CMOS logic circuits;electronic engineering computing;gradient methods;learning (artificial intelligence);logic gates;memristors;multivalued logic;neural nets","CMOS;artificial neural network;artificial threshold neural network training;complex real-world data learning;gradient descent machine learning algorithm;memory system;memristor reconfigurability;multilevel logic;multilevel memristive memory;nanomemristive trainable threshold gate array;nanoscale logic;neuromorphic computing;perceptron training;reconfigure memristive synapses;stochastic gradient descent inspired training technique;technology migration;transistor;variation-tolerant training methodology","","8","","30","","20120426","May 2012","","IEEE","IEEE Journals & Magazines"
"Automatically detecting developer activities and problems in software development work","T. Roehm; W. Maalej","Technische Universit&#x00E4;t M&#x00FC;nchen, Munich, Germany","2012 34th International Conference on Software Engineering (ICSE)","20120628","2012","","","1261","1264","Detecting the current activity of developers and problems they are facing is a prerequisite for a context-aware assistance and for capturing developers' experiences during their work. We present an approach to detect the current activity of software developers and if they are facing a problem. By observing developer actions like changing code or searching the web, we detect whether developers are locating the cause of a problem, searching for a solution, or applying a solution. We model development work as recurring problem solution cycle, detect developer's actions by instrumenting the IDE, translate developer actions to observations using ontologies, and infer developer activities by using Hidden Markov Models. In a preliminary evaluation, our approach was able to correctly detect 72% of all activities. However, a broader more reliable evaluation is still needed.","0270-5257;02705257","Electronic:978-1-4673-1067-3; POD:978-1-4673-1066-6","10.1109/ICSE.2012.6227104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227104","activity detection;context-aware software engineering;machine learning;ontologies;task management","Context;Hidden Markov models;Ontologies;Search problems;Software;Software engineering;Switches","hidden Markov models;ontologies (artificial intelligence);software engineering;ubiquitous computing","Hidden Markov Models;Web searching;automatically detecting developer activities;automatically detecting developer problems;context-aware assistance;ontologies;recurring problem solution cycle;software development work","","2","","12","","","2-9 June 2012","","IEEE","IEEE Conference Publications"
"Voting multiple classifiers decisions for spam detection","N. Barigou; F. Barigou; B. Atmani","Computer Science Department, University Of Oran, Oran, Algeria","2012 International Conference on Information Technology and e-Services","20120614","2012","","","1","6","A considerable amount of research and technology development has been emerged to address the problem of spam detection. Based on a Boolean cellular approach and naïve Bayes technique built as individual classifiers, we evaluate a novel method that combines these two classifiers to determine whether we can more accurately detect Spam. Experimental results show that the proposed combination increases the classification performance as measured on LingSpam dataset.","","Electronic:978-1-4673-1166-3; POD:978-1-4673-1167-0","10.1109/ICITeS.2012.6216599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216599","Cellular automaton;Naïve Bayes;Spam e-mails;classifiers combination;machine learning;subsets features","Automata;Classification algorithms;Filtering;Learning automata;Niobium;Unsolicited electronic mail","Bayes methods;cellular automata;learning (artificial intelligence);pattern classification;unsolicited e-mail","Boolean cellular approach;LingSpam dataset;individual classifiers;multiple classifiers decisions voting;naive Bayes technique;research and technology development;spam detection","","1","","23","","","24-26 March 2012","","IEEE","IEEE Conference Publications"
"Learning for Meta-Recognition","W. J. Scheirer; A. d. R. Rocha; J. Parris; T. E. Boult","Department of Computer Science, University of Colorado at Colorado Springs, Colorado Springs, CO, USA","IEEE Transactions on Information Forensics and Security","20120710","2012","7","4","1214","1224","In this paper, we consider meta-recognition, an approach for postrecognition score analysis, whereby a prediction of matching accuracy is made from an examination of the tail of the scores produced by a recognition algorithm. This is a general approach that can be applied to any recognition algorithm producing distance or similarity scores. In practice, meta-recognition can be implemented in two different ways: a statistical fitting algorithm based on the extreme value theory, and a machine learning algorithm utilizing features computed from the raw scores. While the statistical algorithm establishes a strong theoretical basis for meta-recognition, the machine learning algorithm is more accurate in its predictions in all of our assessments. In this paper, we present a study of the machine learning algorithm and its associated features for the purpose of building a highly accurate meta-recognition system for security and surveillance applications. Through the use of feature- and decision-level fusion, we achieve levels of accuracy well beyond those of the statistical algorithm, as well as the popular “cohort” model for postrecognition score analysis. In addition, we also explore the theoretical question of why machine learning-based algorithms tend to outperform statistical meta-recognition and provide a partial explanation. We show that our proposed methods are effective for a variety of different recognition applications across security and forensics-oriented computer vision, including biometrics, object recognition, and content-based image retrieval.","1556-6013;15566013","","10.1109/TIFS.2012.2192430","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6176215","Content-based image retrieval;face recognition;fingerprint recognition;machine learning;meta-recognition;multibiometric fusion;object recognition;performance modeling;similarity scores","Accuracy;Algorithm design and analysis;Face recognition;Image recognition;Machine learning;Machine learning algorithms;Prediction algorithms","image fusion;image matching;image recognition;learning (artificial intelligence);statistical analysis","biometrics;content-based image retrieval;decision-level fusion;distance scores;extreme value theory;feature-level fusion;forensics-oriented computer vision;machine learning algorithm;matching accuracy;object recognition;postrecognition score analysis;recognition algorithm;security applications;similarity scores;statistical algorithm;statistical meta-recognition;surveillance applications","","6","","36","","20120403","Aug. 2012","","IEEE","IEEE Journals & Magazines"
"Beyond seed match: Improving miRNA target prediction using PAR-CLIP data","M. Lu; C. L. P. Chen; Y. Huang","Department of Electrical and Computer Engineering, The University of Texas at San Antonio, USA","2011 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)","20120315","2011","","","127","130","Since miRNA plays an important role in post-transcript regulation, many computational approaches have been proposed for miRNA target prediction. Yet, the existing algorithms lack the capability to predict the true target when the perfect seed match presents in mRNA sequences and methods based on seed-match still suffer from a high false positive rate. Therefore, this paper proposes a new prediction method that exploits the data produced by the PAR-CLIP, which is a recent high throughput, high precision technology for genome-wide miRNA targets. This algorithm searches true miRNA targets among the candidates with seed-matches by using machine learning approaches. The target prediction results on top 20 expressed miRNAs in HEK293 cells of AGO1-4 proteins PAR-CLIP data show that given presence of seed pairing, the proposed method greatly outperforms the traditional miRNA target prediction algorithms and improve the precision significantly. Because biologists usually need to mutate the seed region to validation the miRNA targets, and only capable of conducting biological experiments on limited miRNA and mRNA sequences due to the time and cost, the proposed approach will make significant impact on the biology and healthcare fields.","2150-3001;21503001","Electronic:978-1-4673-0490-0; POD:978-1-4673-0491-7","10.1109/GENSiPS.2011.6169461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169461","Gaussian Process;MicroRNA target prediction;PAR-CLIP;machine learning;seed matches","Bioinformatics;Context;Feature extraction;Genomics;Prediction algorithms;Training data","RNA;biology computing;data handling;genomics;learning (artificial intelligence)","AGO1-4 proteins;HEK293 cells;PAR-CLIP data;mRNA sequences;machine learning;miRNA sequences;miRNA target prediction algorithms;post-transcript regulation;seed match;seed region;single-stranded ~22 nucleotides noncoding RNA","","0","","16","","","4-6 Dec. 2011","","IEEE","IEEE Conference Publications"
"Evolving Signal Processing for Brain–Computer Interfaces","S. Makeig; C. Kothe; T. Mullen; N. Bigdely-Shamlo; Z. Zhang; K. Kreutz-Delgado","Swartz Center for Computational Neuroscience, Institute for Neural Computation, University of California San Diego (UCSD), La Jolla, CA, USA","Proceedings of the IEEE","20120510","2012","100","Special Centennial Issue","1567","1584","Because of the increasing portability and wearability of noninvasive electrophysiological systems that record and process electrical signals from the human brain, automated systems for assessing changes in user cognitive state, intent, and response to events are of increasing interest. Brain-computer interface (BCI) systems can make use of such knowledge to deliver relevant feedback to the user or to an observer, or within a human-machine system to increase safety and enhance overall performance. Building robust and useful BCI models from accumulated biological knowledge and available data is a major challenge, as are technical problems associated with incorporating multimodal physiological, behavioral, and contextual data that may in the future be increasingly ubiquitous. While performance of current BCI modeling methods is slowly increasing, current performance levels do not yet support widespread uses. Here we discuss the current neuroscientific questions and data processing challenges facing BCI designers and outline some promising current and future directions to address them.","0018-9219;00189219","","10.1109/JPROC.2012.2185009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169943","Blind source separation (BSS);brain–computer interface (BCI);cognitive state assessment;effective connectivity;electroencephalogram (EEG);independent component analysis (ICA);machine learning (ML);multimodal signal processing;signal processing;source-space modeling;transfer learning","Biomedical signal processing;Brain computer interfaces;Brain models;Computer interfaces;Data models;Electroencephalography;Scalp;Signal processing","bioelectric phenomena;brain-computer interfaces;cognition;electroencephalography;medical signal processing;neurophysiology","BCI modeling methods;accumulated biological knowledge;brain-computer interface system;data processing challenges;electrical signal processing;electrical signal recording;human-machine system;multimodal physiological data;noninvasive electrophysiological systems;relevant feedback;user cognitive state","","37","","227","","20120314","May 13 2012","","IEEE","IEEE Journals & Magazines"
"Sentiment classification for Indonesian message in social media","A. R. Naradhipa; A. Purwarianti","School of Electrical and Informatics Engineerng, Bandung Institute of Technology Bandung, Indonesia","2012 International Conference on Cloud Computing and Social Networking (ICCCSN)","20120614","2012","","","1","5","Nowadays, classifying sentiment from social media has been a strategic thing since people can express their feeling about something in an easy way and short text. Mining opinion from social media has become important because people are usually honest with their feeling on something. In our research, we tried to identify the problems of classifying sentiment from Indonesian social media. We identified that people tend to express their opinion in text while the emoticon is rarely used and sometimes misleading. We also identified that the Indonesian social media opinion can be classified not only to positive, negative, neutral and question but also to a special mix case between negative and question type. Basically there are two levels of problem: word level and sentence level. Word level problems include the usage of punctuation mark, the number usage to replace letter, misspelled word and the usage of nonstandard abbreviation. In sentence level, the problem is related with the sentiment type such as mentioned before. In our research, we built a sentiment classification system which includes several steps such as text preprocessing, feature extraction, and classification. The text preprocessing aims to transform the informal text into formal text. The word formalization method in that we use is the deletion of punctuation mark, the tokenization, conversion of number to letter, the reduction of repetition letter, and using corpus with Levensthein to formalize abbreviation. The sentence formalization method that we use is negation handling, sentiment relative, and affixes handling. Rule-based, SVM and Maximum Entropy are used as the classification algorithms with features of count of positive, negative, and question word in sentence and bigram. From our experimental result, the best classification method is SVM that yields 83.5% accuracy.","","Electronic:978-1-4673-1816-7; POD:978-1-4673-1815-0","10.1109/ICCCSN.2012.6215730","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6215730","Machine Learning;Sentiment Classification;Social Media","Accuracy;Companies;Dictionaries;Entropy;Media;Noise measurement;Support vector machines","classification;natural language processing;text analysis","Indonesian message;Indonesian social media opinion;SVM;bigram;emoticon;feature extraction;informal text;maximum entropy;mining opinion;misspelled word;negation handling;nonstandard abbreviation;number usage;punctuation mark;sentence formalization;sentence level;sentiment classification system;text preprocessing;tokenization;word formalization method;word level problems","","4","","10","","","26-27 April 2012","","IEEE","IEEE Conference Publications"
"Multiple view learning based on tabular data","Z. Wang; Zengxin Niu; Jianhua Huang; Daqi Gao","Department of Computer Science & Engineering, East China University of Science & Technology; Shanghai, 200237, China","IET International Communication Conference on Wireless Mobile and Computing (CCWMC 2011)","20120507","2011","","","127","132","Comparing with single-view learning algorithm, multi-view learning algorithm has more powerful classification performance. However, multi-view learning algorithm needs multiple source patterns. Features of those multiple source information must satisfy with some independent conditions. In most real world case, it is easier for us to gain single source patterns. So it will be necessary for us to design multi-view learning algorithms that are on the basis of single source patterns. In our previous research, we proposed a multi-view learning algorithm which is named MultiV-MHKS and found that MultiV-MHKS can efficiently improve the recognition rate in multi-view learning. In the paper, on the basis of MultiV-MHKS, we propose a novel classification method named MultiV-TMHKS, which adopts the tabularized data technique to matrixize single source patterns. By this multiviewization approach we can gain different kinds of matrixes that are used in different views and then design proper sub-classifiers in corresponding views. We come up with a new matrixizing method for multiple view learning which is based on single source patterns.","","Electronic:978-1-84919-505-8","10.1049/cp.2011.0861","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194818","Classifier Design;Machine Learning;Multiple View Learning;Tabular Data","","data handling;learning (artificial intelligence);matrix algebra;pattern classification","classification performance;matrixizing method;multiV-MHKS;multiple source information;multiple source patterns;multiple view learning algorithm;multiviewization approach;single source patterns;single-view learning algorithm;subclassifier design;tabularized data technique","","0","","","","","14-16 Nov. 2011","","IET","IET Conference Publications"
"Gaussian process learning for image classification based on low-level features","W. Wen; Z. Hao; R. Cai; Z. Shao","School of Computer Science, Guangdong University of Technology, Guangzhou, China","2012 8th International Conference on Natural Computation","20120709","2012","","","237","241","Recently, Gaussian Process for Machine Learning (GPML) has received increasing attention in the machine learning community. In this paper, a method implementing GPML for image classification is proposed. This algorithm uses low-level image features that can be easily and quickly extracted. The proposed algorithm is tested on the well-known object-category data sets (Caltech 256) and is compared with Least Squares Support Vector Machines (LSSVM). The major contributions of this paper is that it proposes a feasible framework to implement GPML for image classification and introduces a novel color feature extraction procedure based on color coherence vector, which is suitable for supervised learning. Influence of different low-level features on GPML and LSSVM is also investigated in the experiments.","2157-9555;21579555","Electronic:978-1-4577-2133-5; POD:978-1-4577-2130-4","10.1109/ICNC.2012.6234504","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234504","Gaussian process for machine learning;color coherence vector;image classification;support vector machines","Entropy;Feature extraction;Gaussian processes;Image classification;Image color analysis;Machine learning;Support vector machines","Gaussian processes;feature extraction;image classification;image colour analysis;learning (artificial intelligence);least squares approximations;support vector machines;vectors","GPML;Gaussian process for machine learning;LSSVM;color coherence vector;color feature extraction procedure;image classification;least squares support vector machines;low-level image features;object-category data sets;supervised learning","","0","","15","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Ensemble Classifiers for Steganalysis of Digital Media","J. Kodovsky; J. Fridrich; V. Holub","Department of Electrical and Computer Engineering, Binghamton University, NY, USA","IEEE Transactions on Information Forensics and Security","20120312","2012","7","2","432","444","Today, the most accurate steganalysis methods for digital media are built as supervised classifiers on feature vectors extracted from the media. The tool of choice for the machine learning seems to be the support vector machine (SVM). In this paper, we propose an alternative and well-known machine learning tool-ensemble classifiers implemented as random forests-and argue that they are ideally suited for steganalysis. Ensemble classifiers scale much more favorably w.r.t. the number of training examples and the feature dimensionality with performance comparable to the much more complex SVMs. The significantly lower training complexity opens up the possibility for the steganalyst to work with rich (high-dimensional) cover models and train on larger training sets-two key elements that appear necessary to reliably detect modern steganographic algorithms. Ensemble classification is portrayed here as a powerful developer tool that allows fast construction of steganography detectors with markedly improved detection accuracy across a wide range of embedding methods. The power of the proposed framework is demonstrated on three steganographic methods that hide messages in JPEG images.","1556-6013;15566013","","10.1109/TIFS.2011.2175919","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6081929","Ensemble classification;Fisher Linear Discriminant (FLD);high-dimensional features;random subspaces;scalable machine learning;steganalysis","Accuracy;Complexity theory;Feature extraction;Machine learning;Testing;Training;Vectors","learning (artificial intelligence);multimedia computing;steganography;support vector machines","JPEG images;SVM;digital media steganalysis;embedding methods;ensemble classifiers;feature vectors extraction;machine learning;steganalysis methods;steganographic algorithms;steganography detectors;supervised classifiers;support vector machine","","154","5","51","","20111115","April 2012","","IEEE","IEEE Journals & Magazines"
"Automated Tagging for the Retrieval of Software Resources in Grid and Cloud Infrastructures","I. Katakis; G. Pallis; M. D. Dikaiakos; O. Onoufriou","","2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)","20120614","2012","","","628","635","A key challenge for Grid and Cloud infrastructures is to make their services easily accessible and attractive to end-users. In this paper we introduce tagging capabilities to the Miner soft system, a powerful tool for software search and discovery in order to help end-users locate application software suitable to their needs. Miner soft is now able to predict and automatically assign tags to software resources it indexes. In order to achieve this, we model the problem of tag prediction as a multi-label classification problem. Using data extracted from production-quality Grid and Cloud computing infrastructures, we evaluate an important number of multi-label classifiers and discuss which one and with what settings is the most appropriate for use in the particular problem.","","Electronic:978-0-7695-4691-9; POD:978-1-4673-1395-7","10.1109/CCGrid.2012.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6217475","classification;cloud;grid;information retrieval;machine learning;mining;software;tagging","Cloud computing;Indexes;Libraries;Machine learning;Tagging;Training","cloud computing;grid computing;identification technology","Miner soft system;application software;automated tagging;cloud computing infrastructures;multilabel classification problem;multilabel classifiers;production quality grid computing infrastructures;software resource retrieval;software resources;software search;tag prediction;tagging capability","","0","","16","","","13-16 May 2012","","IEEE","IEEE Conference Publications"
"Research on the feature selection techniques used in text classification","Y. Li; C. Chen","School of Computer Science and Engineering, Xi'an University of Technology, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","725","729","With the ever-increasing number of digital documents, the ability to automatically classify those documents both quickly and accurately is becoming more critical and difficult. A text classification system for Chinese documents is developed in this paper. A HTF-WDF algorithm is proposed for feature selection. Different from other feature selection algorithms, this method considers the effect of term frequency. Using the idea of fuzzy feature, the terms with high term frequency (HTF) are distinguished and appended to the feature list. The features which can represent the topic of the documents are picked out according to the weighted document frequencies (WDF), which can avoid the problems of the traditional document frequency (DF) method. Then the Support Vector Machine (SVM) is used to training the classifier. The proposed algorithm is verified by representative Chinese documents. The experiment results manifest the superiority of the proposed algorithm to the traditional DF algorithm.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234223","feature selection;machine learning;support vector machine;text classification","Accuracy;Algorithm design and analysis;Classification algorithms;Support vector machine classification;Testing;Text categorization;Training","fuzzy set theory;natural language processing;pattern classification;support vector machines;text analysis","digital document;document classification;feature selection technique;fuzzy feature;high term frequency;representative Chinese document verification;support vector machine;text classification system;weighted document frequency","","2","","10","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"A mobile platform for real-time human activity recognition","Ó. D. Lara; M. A. Labrador","Department of Computer Science and Engineering, University of South Florida, Tampa, 33620, USA","2012 IEEE Consumer Communications and Networking Conference (CCNC)","20120412","2012","","","667","671","Context-aware applications have been the focus of extensive research yet their implementation in mobile devices usually becomes challenging due to restrictions in regards to processing power and energy. In this paper, we propose a mobile platform to provide real-time human activity recognition. Our system features (1) an efficient library, MECLA, for the mobile evaluation of classification algorithms; and (2) a mobile application for real-time human activity recognition running within a Body Area Network. The evaluation indicates that the system can be implemented in real scenarios meeting accuracy, response time, and energy consumption requirements.","2331-9852;23319852","Electronic:978-1-4577-2071-0; POD:978-1-4577-2070-3","10.1109/CCNC.2012.6181018","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181018","Body Area Networks;Human-centric sensing;Machine learning;Mobile applications","Acceleration;Accuracy;Feature extraction;Mobile communication;Mobile handsets;Sensors;Time factors","behavioural sciences computing;body area networks;mobile computing;pattern classification","MECLA;body area network;classification algorithm;context aware application;energy consumption requirement;energy processing;mobile devices;mobile evaluation of classifier;mobile platform;power processing;real-time human activity recognition;response time","","14","","13","","","14-17 Jan. 2012","","IEEE","IEEE Conference Publications"
"Short Text Categorization via Coherence Constraints","A. Dinu","Center for Comput. Linguistics, Univ. of Bucharest, Bucharest, Romania","2011 13th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing","20120315","2011","","","247","250","In this article we propose a quantitative approach to a relatively new problem: categorizing text as pragmatically correct or pragmatically incorrect (forcing the notion, coherent/incoherent). The typical text categorization criterions comprise categorization by topic, by style (genre classification, authorship identification), by expressed opinion (opinion mining, sentiment classification), etc. Very few approaches consider the problem of categorizing text by degree of coherence. One example of application of text categorization by its coherence is creating a spam filter for personal e-mail accounts able to cope with one of the new strategies adopted by spamers. This strategy consists of encoding the real message as picture (impossible to directly analyze and reject by the text oriented classical filters) and accompanying it by a text especially designed to surpass the filter. An important question for automatically categorizing texts into coherent and incoherent is: are there features that can be extracted from these texts and be successfully used to categorize them? We propose a quantitative approach that relies on the use of ratios between morphological categories from the texts as discriminant features. We use supervised machine learning techniques on a small corpus of English e-mail messages and let the algorithms extract important features from all the pos ratios. The results are encouraging.","","Electronic:978-0-7695-4630-8; POD:978-1-4673-0207-4","10.1109/SYNASC.2011.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169587","coherence;discriminant features;machine learning methods","Accuracy;Coherence;Electronic mail;Feature extraction;Kernel;Speech;Support vector machines","learning (artificial intelligence);text analysis;unsolicited e-mail","authorship identification;coherence constraints;genre classification;opinion mining;personal e-mail accounts;sentiment classification;short text categorization;spam filter;supervised machine learning;text categorization criterions","","0","","7","","","26-29 Sept. 2011","","IEEE","IEEE Conference Publications"
"A novel vision-based multi-hand tracking algorithm for human computer interface","B. Luo; Q. Huang; S. Bi; Y. Ma","School of Computer Science and Engineering, South China University of Technology, Guangzhou Higher Education mega center, Guangzhou 510006, China","2011 IEEE International Conference on Robotics and Biomimetics","20120412","2011","","","2441","2446","A novel multi-hand tracking algorithm for human computer interface (HCI) is proposed, to solve the problem caused by the incompletion of tracking, the overlap of multi-object, the lost of the object and the confusion from background. For tracking the hand completely and effectively, we propose a new region-connection-based tracking method. And a hand motion model is established for tracking failure detection, with the utility of Bayesian classifier. Furthermore, to recover tracking after failure, a monitoring windows method is designed.","","DVD:978-1-4577-2137-3; Electronic:978-1-4577-2138-0; POD:978-1-4577-2136-6","10.1109/ROBIO.2011.6181671","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181671","hand tracking;human computer interface;machine learning;multiple object tracking","Bayesian methods;Mathematical model;Monitoring;Nickel;Skin;Tracking;Vectors","Bayes methods;computer vision;human computer interaction;image classification;object tracking","Bayesian classifier;HCI;background confusion;hand motion model;human computer interface;monitoring windows method;multiobject overlapping;object lost;region-connection-based tracking method;tracking failure detection;tracking incompletion;vision-based multihand tracking algorithm","","0","","14","","","7-11 Dec. 2011","","IEEE","IEEE Conference Publications"
"Robust Filtering and Smoothing with Gaussian Processes","M. P. Deisenroth; R. D. Turner; M. F. Huber; U. D. Hanebeck; C. E. Rasmussen","University of Washington, Seattle, WA, USA","IEEE Transactions on Automatic Control","20120622","2012","57","7","1865","1871","We propose a principled algorithm for robust Bayesian filtering and smoothing in nonlinear stochastic dynamic systems when both the transition function and the measurement function are described by non-parametric Gaussian process (GP) models. GPs are gaining increasing importance in signal processing, machine learning, robotics, and control for representing unknown system functions by posterior probability distributions. This modern way of system identification is more robust than finding point estimates of a parametric function representation. Our principled filtering/smoothing approach for GP dynamic systems is based on analytic moment matching in the context of the forward-backward algorithm. Our numerical evaluations demonstrate the robustness of the proposed approach in situations where other state-of-the-art Gaussian filters and smoothers can fail.","0018-9286;00189286","","10.1109/TAC.2011.2179426","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6099561","Bayesian inference;Gaussian processes;filtering;machine learning;nonlinear systems;smoothing","Approximation methods;Covariance matrix;Noise;Robustness;Smoothing methods;Time measurement;Training","Bayes methods;Gaussian processes;identification;nonlinear dynamical systems;nonparametric statistics;smoothing methods;statistical distributions","GP dynamic systems;analytic moment matching;control systems;forward-backward algorithm;machine learning;measurement function;nonlinear stochastic dynamic systems;nonparametric Gaussian process;parametric function representation;point estimation;posterior probability distributions;robotics;robust Bayesian filtering;robust Bayesian smoothing;signal processing;system identification;transition function;unknown system function representation","","18","","31","","20111209","July 2012","","IEEE","IEEE Journals & Magazines"
"Search Bot: Search Intention Based Filtering Using Decision Tree Based Technique","V. Gupta; N. Garg; T. Gupta","Maharaja Agrasen Inst. Of Technol., GGSIPU, New Delhi, India","2012 Third International Conference on Intelligent Systems Modelling and Simulation","20120315","2012","","","49","54","Most web search engines use only the search keywords for searching. Due to the ambiguity of semantics and usages of the search keywords, the results are noisy and many of them do not match the user's search goals. This paper presents the design of an intelligent Search Bot, which operates as an agent for a user by simulating the user activity of filtering only the relevant search results. It learns from experience and improves its performance with time. The focus is to obtain a user's search intention or requirement from the search query, and then to deliver results accordingly. The user first trains the system according to his search intention, by doing binary classification of the search results. Training is followed by knowledge representation and extraction, and then reasoning and analyzing the new search results to determine their relevance classification. The technique is based on the construction of decision trees. It also finds application in news searching, information retrieval from databases and spam mail detection.","2166-0662;21660662","Electronic:978-0-7695-4668-1; POD:978-1-4673-0886-1","10.1109/ISMS.2012.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169674","data mining;information retrieval;machine learning;search intention;web searching","Accuracy;Decision trees;Entropy;Filtering;Google;Palladium;Training","Internet;decision trees;information filtering;knowledge acquisition;knowledge representation;pattern classification;query processing;search engines;software agents;user interfaces","Web search engines;binary classification;decision tree based technique;information retrieval;intelligent search bot;knowledge extraction;knowledge representation;news searching;performance improvement;search intention;search intention based filtering;search keywords;search query;spam mail detection;user activity","","1","","25","","","8-10 Feb. 2012","","IEEE","IEEE Conference Publications"
"Exploiting developmental plasticity in Cartesian Genetic Programming","U. Fahad; M. K. Gul; M. Sahibzada A.","Department of Computer System Engineering, UET Peshawar, Pakistan","2012 IEEE Symposium on Computers & Informatics (ISCI)","20120625","2012","","","180","184","In this paper, the effect of developmental plasticity is investigated in Cartesian Genetic Programming (CGP); an evolutionary algorithm that uses a directed graph to represent its genetic architecture. Developmental Plasticity is the adaptability of an organism to change in its surrounding environment. A Developmental Output is used to computationally develop the phenotype that has already been passed through a genetic evolution. To manifest the idea of developmental plasticity in the form of digital circuits, binary multiplexing functions are used in the CGP implementation. Two experiments-prime number test and image recognition test-are conducted so that to analyze the effect of Developmental Plasticity in CGP. Simulation results demonstrate that the plasticity based CGP achieves better performance when compared to conventional CGP in terms of its adaptability and learning in general.","","Electronic:978-1-4673-1686-6; POD:978-1-4673-1685-9","10.1109/ISCI.2012.6222690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6222690","computational development;developmental plasticity;genetic programming;machine learning","Biological cells;Evolutionary computation;Genetic programming;Real time systems;Testing;Training","directed graphs;genetic algorithms","Cartesian genetic programming;binary multiplexing functions;developmental plasticity;digital circuits;directed graph;evolutionary algorithm;genetic architecture;genetic evolution;image recognition test;phenotype;prime number test","","0","","12","","","18-20 March 2012","","IEEE","IEEE Conference Publications"
"Kernel Sparse Representation-Based Classifier","L. Zhang; W. D. Zhou; P. C. Chang; J. Liu; Z. Yan; T. Wang; F. Z. Li","Research Center of Machine Learning and Data Analysis, School of Computer Science and Technology, Soochow University, Suzhou, China","IEEE Transactions on Signal Processing","20120309","2012","60","4","1684","1695","Sparse representation-based classifier (SRC), a combined result of machine learning and compressed sensing, shows its good classification performance on face image data. However, SRC could not well classify the data with the same direction distribution. The same direction distribution means that the sample vectors belonging to different classes distribute on the same vector direction. This paper presents a new classifier, kernel sparse representation-based classifier (KSRC), based on SRC and the kernel trick which is a usual technique in machine learning. KSRC is a nonlinear extension of SRC and can remedy the drawback of SRC. To make the data in an input space separable, we implicitly map these data into a high-dimensional kernel feature space by using some nonlinear mapping associated with a kernel function. Since this kernel feature space has a very high (or possibly infinite) dimensionality, or is unknown, we have to avoid working in this space explicitly. Fortunately, we can indeed reduce the dimensionality of the kernel feature space by exploiting kernel-based dimensionality reduction methods. In the reduced subspace, we need to find sparse combination coefficients for a test sample and assign a class label to it. Similar to SRC, KSRC is also cast into an ℓ<sub>1</sub>-minimization problem or a quadratically constrained ℓ<sub>1</sub> -minimization problem. Extensive experimental results on UCI and face data sets show KSRC improves the performance of SRC.","1053-587X;1053587X","","10.1109/TSP.2011.2179539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6104179","<formula formulatype=""inline""> <tex Notation=""TeX"">$ell_{1}$</tex></formula>-norm;compressed sensing;kernel method;machine learning;sparse representation","Compressed sensing;Kernel;Learning systems;Machine learning;Sparse matrices;Training;Vectors","compressed sensing;face recognition;image classification;learning (artificial intelligence);minimisation","compressed sensing;face image data;kernel feature space;kernel function;kernel sparse representation-based classifier;kernel-based dimensionality reduction;machine learning;quadratically constrained l<sub>1</sub>-minimization problem;same direction distribution","","108","","49","","20111213","April 2012","","IEEE","IEEE Journals & Magazines"
"Towards Automated Anomaly Report Assignment in Large Complex Systems Using Stacked Generalization","L. Jonsson; D. Broman; K. Sandahl; S. Eldh","Ericsson AB, Stockholm, Sweden","2012 IEEE Fifth International Conference on Software Testing, Verification and Validation","20120517","2012","","","437","446","Maintenance costs can be substantial for organizations with very large and complex software systems. This paper describes research for reducing anomaly report turnaround time which, if successful, would contribute to reducing maintenance costs and at the same time maintaining a good customer perception. Specifically, we are addressing the problem of the manual, laborious, and inaccurate process of assigning anomaly reports to the correct design teams. In large organizations with complex systems this is particularly problematic because the receiver of the anomaly report from customer may not have detailed knowledge of the whole system. As a consequence, anomaly reports may be wrongly routed around in the organization causing delays and unnecessary work. We have developed and validated machine learning approach, based on stacked generalization, to automatically route anomaly reports to the correct design teams in the organization. A research prototype has been implemented and evaluated on roughly one year of real anomaly reports on a large and complex system at Ericsson AB. The prediction accuracy of the automation is approaching that of humans, indicating that the anomaly report handling time could be significantly reduced by using our approach.","2159-4848;21594848","Electronic:978-0-7695-4670-4; POD:978-1-4577-1906-6","10.1109/ICST.2012.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200136","Automatic Fault Localization;Bayesian Networks;Bug Assignment;Large Software Systems;Machine Learning;Naive Bayes;Stacked generalization;Support Vector Machines","Accuracy;Bayesian methods;Machine learning;Organizations;Routing;Support vector machines;Training","customer satisfaction;large-scale systems;learning (artificial intelligence);organisational aspects;software maintenance","automated anomaly report assignment;customer perception;large complex systems;machine learning;maintenance costs;organizations;software systems;stacked generalization","","5","","20","","","17-21 April 2012","","IEEE","IEEE Conference Publications"
"A hybrid multiple classifier system for recognizing usual and unusual drilling events","B. Esmael; A. Arnaout; R. K. Fruhwirth; G. Thonhauser","University of Leoben, Austria","2012 IEEE International Instrumentation and Measurement Technology Conference Proceedings","20120702","2012","","","1754","1758","Up to very recently, the applications of machine learning in the oil & gas industry were limited to using a single machine learning technique to solve problems in-hand. As the complexity of the demanded tasks being increased, the single techniques proved insufficient. This gave rise to intelligent systems that are hybrids of several machine learning techniques to solve the most challenging problems. In this paper we propose a hybrid multiple classifier approach for recognizing usual and unusual drilling events. We suggest using two different information sources namely: (1) real time data collected by sensors located around the drilling rig, and (2) daily morning reports written by drilling personnel to describe the drilling process. Text mining techniques were used to analysis the daily morning reports and to extract textual features that include keywords and phrases, whereas data mining techniques were used to analysis the sensors data and extracting statistical features. Three base classifiers were trained and combined in one ensemble to obtain better predictive performance. Experimental evaluation with real data and reports shows that the ensemble outperforms the base classifiers in every experiment, and the average classification accuracy is about 90% for usual events, and about 75% for unusual events.","1091-5281;10915281","Electronic:978-1-4577-1772-7; POD:978-1-4577-1773-4","10.1109/I2MTC.2012.6229541","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6229541","Classification;Machine learning;Multiple Classifiers;Unusual Events Detection","Accuracy;Data mining;Drilling machines;Feature extraction;Sensors;Support vector machines;Training","data mining;drilling (geotechnical);gas industry;oil drilling;petroleum industry","data mining technique;drilling oil wells;drilling rig;gas industry;hybrid multiple classifier system;oil industry;sensors;single machine learning technique;text mining technique;textual feature;unusual drilling events","","0","","12","","","13-16 May 2012","","IEEE","IEEE Conference Publications"
"Generating text description from content-based annotated image","Y. Zhu; H. Xiang; W. Feng","School of Computer Science and Technology, Shandong University, Jinan, China","2012 International Conference on Systems and Informatics (ICSAI2012)","20120625","2012","","","805","809","This paper proposes a statistical generative model to generate sentences from an annotated picture. The images are segmented into regions (using Graph-based algorithms) and then features are computed over each of these regions. Given a training set of images with annotations, we parse the image to get position information. We use SVM to get the probabilities of combinations between labels and prepositions, obtain the data to text set. We use a standard semantic representation to express the image message. Finally generate sentence from the xml report. In view of landscape pictures, this paper implemented experiments on the dataset we collected and annotated, obtained ideal results.","","Electronic:978-1-4673-0199-2; POD:978-1-4673-0198-5","10.1109/ICSAI.2012.6223132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6223132","cross-media retrieval;image annotation;machine learning;text generation","Accuracy;Educational institutions;Image segmentation;Probability;Semantics;Training;XML","XML;content-based retrieval;graph theory;image retrieval;image segmentation;probability;support vector machines;text analysis","SVM;XML report;annotated picture;content-based annotated image;graph-based algorithms;image message;image segmentation;labels;landscape pictures;position information;prepositions;probabilities;sentence generation;standard semantic representation;statistical generative model;text description generation","","0","","6","","","19-20 May 2012","","IEEE","IEEE Conference Publications"
"A learning feature engineering method for task assignment","D. Loewenstern; F. Pinel; L. Shwartz; M. Gatti; R. Herrmann; V. Cavalcante","IBM TJ Watson Research Center, Hawthorne, NY 10532 USA","2012 IEEE Network Operations and Management Symposium","20120607","2012","","","961","967","Multi-domain IT services are delivered by technicians with a variety of expert knowledge in different areas. Their skills and availability are an important property of the service. However, most organizations do not have a consistent view of this information because creation and maintenance of a skill model is a difficult task, especially in light of privacy regulations, changing service catalogs and worker turnover. We propose a method for ranking technicians on their expected performance according to their suitability for receiving the assignment of a service request without maintaining an explicit skill model describing which skills are possessed by each technician. We find appropriate assignees by making use of similarities between the assignees and previous tasks performed by them.","1542-1201;15421201","Electronic:978-1-4673-0269-2; POD:978-1-4673-0267-8; USB:978-1-4673-0268-5","10.1109/NOMS.2012.6212015","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6212015","SVM;adaptive features;feature engineering;machine learning;request fulfillment;service management;task assignment;ticket dispatching","Dispatching;Hidden Markov models;Organizations;Servers;Support vector machines;Training data;Vectors","expert systems;learning (artificial intelligence);personnel","expert knowledge;learning feature engineering method;multidomain IT services;privacy regulations;service catalogs;task assignment;technician ranking method;worker turnover","","1","","24","","","16-20 April 2012","","IEEE","IEEE Conference Publications"
"Single image depth estimation using local gradient-based features","D. Kostadinov; Z. Ivanovski","Department of Electronics, Faculty of Electrical Engineering and Information Technologies, Ss. Cyril and Methodius University, Skopje, Macedonia","2012 19th International Conference on Systems, Signals and Image Processing (IWSSIP)","20120531","2012","","","596","599","The paper considers single image depth estimation for urban outdoor content images. The proposed approach uses supervised machine learning to learn the relationships between low level image features and depth gradient. Brightness, color and texture gradient cues are used as features. Markov Random Field (MRF) model is employed to estimate depth gradient and the model parameters are learned trough linear regression. The depth gradient in horizontal and vertical direction is modeled independently. The estimation of the depth gradient is preformed using Maximum A Posteriori Probability (MAP) estimation. The final depth map for an image is calculated by integrating the estimated depth gradients. The experimental results show that the approach based on relatively simple model achieves very good results for urban outdoor images.","2157-8672;21578672","Electronic:978-3-200-02328-4; POD:978-1-4577-2191-5","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6208312","Single image depth estimation;computer vision;machine learning","Brightness;Estimation;Image color analysis;Image reconstruction;Mathematical model;Three dimensional displays;Vectors","Markov processes;feature extraction;gradient methods;image colour analysis;image texture;learning (artificial intelligence);maximum likelihood estimation;random processes;regression analysis","MAP estimation;MRF model;Markov random field;brightness cues;color gradient cues;depth gradient estimation;depth map;linear regression;local gradient-based features;low level image features;maximum a posteriori probability estimation;model parameters;single image depth estimation;supervised machine learning;texture gradient cues;urban outdoor content images","","0","","15","","","11-13 April 2012","","IEEE","IEEE Conference Publications"
"Self-organization for scheduling in agile manufacturing","A. Madureira; I. Pereira; N. Sousa","Computer Science Department, School of Engineering of Porto, Portugal","2011 IEEE 10th International Conference on Cybernetic Intelligent Systems (CIS)","20120315","2011","","","38","43","Agility refers to the manufacturing system ability to rapidly adapt to market and environmental changes in efficient and cost-effective ways. This paper addresses the development of self-organization methods to enhance the operations of a scheduling system, by integrating scheduling system, configuration and optimization into a single autonomic process requiring minimal manual intervention to increase productivity and effectiveness while minimizing complexity for users. We intend to conceptualize real manufacturing systems as interacting autonomous entities in order to build future Decision Support Systems (DSS) for Scheduling in agile manufacturing environments.","","Electronic:978-1-4673-0688-1; POD:978-1-4673-0687-4","10.1109/CIS.2011.6169132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169132","Agile Manufacturing;Machine Learning Techniques;Multi-Agent System;Self-configuration;Swarm Intelligence","Dynamic scheduling;Job shop scheduling;Optimization;Processor scheduling;Schedules","agile manufacturing;decision support systems;learning (artificial intelligence);multi-agent systems;scheduling","agile manufacturing scheduling;autonomic process;decision support system;machine learning;manufacturing system;multiagent system;self-organization method;swarm intelligence","","7","","18","","","1-2 Sept. 2011","","IEEE","IEEE Conference Publications"
"Characterizing and Extracting Multiplex Patterns in Complex Networks","B. Yang; J. Liu; D. Liu","School of Computer Science and Technology, Key Laboratory of Symbol Computation and Knowledge Engineering of the Ministry of Education, Jilin University, Changchun, China","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20120315","2012","42","2","469","481","Complex network theory provides a means for modeling and analyzing complex systems that consist of multiple and interdependent components. Among the studies on complex networks, structural analysis is of fundamental importance as it presents a natural route to understanding the dynamics, as well as to synthesizing or optimizing the functions, of networks. A wide spectrum of structural patterns of networks has been reported in the past decade, such as communities, multipartites, bipartite, hubs, authorities, outliers, and bow ties, among others. In this paper, we are interested in tackling the challenging task of characterizing and extracting multiplex patterns (multiple patterns as mentioned previously coexisting in the same networks in a complicated manner), which so far has not been explicitly and adequately addressed in the literature. Our work shows that such multiplex patterns can be well characterized as well as effectively extracted by means of a granular stochastic blockmodel, together with a set of related algorithms proposed here based on some machine learning and statistical inference ideas. These models and algorithms enable us to further explore complex networks from a novel perspective.","1083-4419;10834419","","10.1109/TSMCB.2011.2167751","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6046146","Complex networks;machine learning;multiplex patterns;pattern analysis;statistical inference","Channel coding;Communities;Complex networks;Couplings;Multiplexing;Organizations","complex networks;inference mechanisms;learning (artificial intelligence);statistical analysis","complex network theory;complex systems;granular stochastic block model;machine learning;multiplex pattern characterization;multiplex pattern extraction;network structural patterns;statistical inference;structural analysis","","11","","39","","20111014","April 2012","","IEEE","IEEE Journals & Magazines"
"Self-adaptive large neighborhood search algorithm for parallel machine scheduling problems","P. Wang; G. Reinelt; Y. Tan","College of Information Systems and Management, National University of Defense Technology, Changsha 410073, P. R. China; Discrete Optimization Research Group, Ruprecht-Karls Universit&#x00E4;t Heidelberg, Heidelberg 69120, Germany","Journal of Systems Engineering and Electronics","20120516","2012","23","2","208","215","A self-adaptive large neighborhood search method for scheduling n jobs on m non-identical parallel machines with multiple time windows is presented. The problems' another feature lies in oversubscription, namely not all jobs can be scheduled within specified scheduling horizons due to the limited machine capacity. The objective is thus to maximize the overall profits of processed jobs while respecting machine constraints. A first-in-first-out heuristic is applied to find an initial solution, and then a large neighborhood search procedure is employed to relax and re-optimize cumbersome solutions. A machine learning mechanism is also introduced to converge on the most efficient neighborhoods for the problem. Extensive computational results are presented based on data from an application involving the daily observation scheduling of a fleet of earth observing satellites. The method rapidly solves most problem instances to optimal or near optimal and shows a robust performance in sensitive analysis.","","","10.1109/JSEE.2012.00027","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6190870","machine learning;non-identical parallel machine scheduling problem with multiple time windows (NPMSPMTW);oversubscribed;self-adaptive large neighborhood search (SALNS)","Nearest neighbor searches;Parallel machines;Satellites;Schedules;Scheduling;Search problems;Temperature measurement","","","","0","","","","","April 2012","","BIAI","BIAI Journals & Magazines"
"Low-Complexity Video Quality Assessment Using Temporal Quality Variations","M. Narwaria; W. Lin; A. Liu","School of Computer Engineering, Nanyang Technological University, Singapore, Singapore","IEEE Transactions on Multimedia","20120511","2012","14","3","525","535","Objective video quality assessment (VQA) is the use of computational models to evaluate the video quality in line with the perception of the human visual system (HVS). It is challenging due to the underlying complexity, and the relatively limited understanding of the HVS and its intricate mechanisms. There are three important issues that arise in objective VQA in comparison with image quality assessment: 1) the temporal factors apart from the spatial ones also need to be considered, 2) the contribution of each factor (spatial and temporal) and their interaction to the overall video quality need to be determined, and 3) the computational complexity of the resultant method. In this paper, we seek to tackle the first issue by utilizing the worst case pooling strategy and the variations of spatial quality along the temporal axis with proper analysis and justification. The second issue is addressed by the use of machine learning; we believe this to be more convincing since the relationship between the factors and the overall quality is derived via training with substantial ground truth (i.e., subjective scores). Experiments conducted using publicly available video databases show the effectiveness of the proposed full-reference (FR) algorithm in comparison to the relevant existing VQA schemes. Focus has also been placed on demonstrating the robustness of the proposed method to new and untrained data. To that end, cross-database tests have been carried out to provide a proper perspective of the performance of proposed scheme as compared to other VQA methods. The third issue regarding the computational costs also plays a key role in determining the feasibility of a VQA scheme for practical deployment given the large amount of data that needs to be processed/analyzed in real time. A limitation of many existing VQA algorithms is their higher computational complexity. In contrast, the proposed scheme is more efficient due to its low complexity without jeopardizing the predict- on accuracy.","1520-9210;15209210","","10.1109/TMM.2012.2190589","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6168273","Machine learning;spatial quality;temporal quality variations;video quality assessment (VQA)","Distortion measurement;Machine learning;Optical distortion;Quality assessment;Video sequences;Visualization","computational complexity;learning (artificial intelligence);video databases;video signal processing","HVS;VQA schemes;computational complexity;cross-database tests;full-reference algorithm;human visual system;image quality assessment;low-complexity video quality assessment;machine learning;spatial quality variations;temporal axis;temporal factors;temporal quality variations;video databases;worst case pooling strategy","","21","1","45","","20120312","June 2012","","IEEE","IEEE Journals & Magazines"
"A case study: Intelligent false alarm reduction using fuzzy if-then rules in network intrusion detection","Y. Meng; L. f. Kwok","Department of Computer Science, City University of Hong Kong, Hong Kong","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","505","509","Nowadays, network intrusion detection systems (NIDSs) have become an essential part for the network security infrastructure. However, the large number of false alarms is a big problem for these detection systems which greatly reduces their effectiveness and efficiency. To mitigate this problem, we have developed an intelligent false alarm filter to help filter out false alarms by adaptively and periodically selecting the most appropriate machine learning algorithms (e.g., support vector machine, decision tree, k-nearest neighbor) that conduct the best single-algorithm performance. Therefore, our intelligent false alarm filter can keep reducing the number of false alarms at a high and stable level. In this paper, we aim to conduct a case study in exploring the performance of our developed false alarm filter by implementing a fuzzy classifier based on if-then rules. By comparing with other algorithms that have been implemented in our false alarm filter, the experimental results show that the if-then rules based fuzzy algorithm performs a bit better than the baseline algorithm and can be improved by selecting an appropriate fuzzy partition.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233768","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233768","False alarm reduction;Intelligent fuzzy system;Machine learning;Network intrusion detection","Accuracy;Intrusion detection;Machine learning;Machine learning algorithms;Partitioning algorithms;Support vector machines","fuzzy set theory;learning (artificial intelligence);security of data","baseline algorithm;fuzzy algorithm;fuzzy classifier;fuzzy if-then rules;fuzzy partition;intelligent false alarm filter;intelligent false alarm reduction;machine learning algorithm;network intrusion detection system;network security infrastructure;single algorithm performance;stable level","","2","","25","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"A method for assessing quality of service in broadband networks","T. Bujlow; T. Riaz; Jens Myrup Pedersen","Section for Networking and Security, Department of Electronic Systems, Aalborg University, DK-9220, Aalborg East, Denmark","2012 14th International Conference on Advanced Communication Technology (ICACT)","20120403","2012","","","826","831","Monitoring of Quality of Service (QoS) in high-speed Internet infrastructure is a challenging task. However, precise assessments must take into account the fact that the requirements for the given quality level are service-dependent. Backbone QoS monitoring and analysis requires processing of large amount of the data and knowledge of which kind of application the traffic belongs to. To overcome the drawbacks of existing methods for traffic classification we proposed and evaluated a centralized solution based on C5.0 Machine Learning Algorithm (MLA) and decision rules. The first task was to collect and provide C5.0 high-quality training data, divided into groups corresponding to different types of applications. It was found that currently existing means of collecting data (classification by ports, Deep Packet Inspection, statistical classification, public data sources) are not sufficient and they do not comply with the required standards. To collect training data a new system was developed, in which the major role is performed by volunteers. Client applications installed on their computers collect the detailed data about each flow passing through the network interface, together with the application name taken from the description of system sockets. This paper proposes a new method for measuring the Quality of Service (QoS) level in broadband networks, based on our Volunteer-Based System for collecting the training data, Machine Learning Algorithms for generating the classification rules and application-specific rules for assessing the QoS level. We combine both passive and active monitoring technologies. The paper evaluates different implementation possibilities, presents the current implementation of particular parts of the system, their initial runs and obtained results, highlighting parts relevant from the QoS point of view.","1738-9445;17389445","Electronic:978-89-5519-163-9; POD:978-1-4673-0150-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6174795","Machine Learning Algorithms;Quality of Service;broadband networks;data collecting;performance monitoring;traffic classification;volunteer-based system","Decision trees;Delay;Jitter;Machine learning algorithms;Monitoring;Quality of service;Training","Internet;broadband networks;inspection;learning (artificial intelligence);monitoring;pattern classification;quality of service;statistical analysis;telecommunication computing;telecommunication traffic","C5.0 high-quality training data;C5.0 machine learning algorithm;MLA;backbone QoS analysis;backbone QoS monitoring;broadband networks;centralized solution;data collection;decision rules;deep packet inspection;flow passing;high-speed Internet infrastructure;network interface;ports classification;precise assessments;public data sources;quality level;quality of service assessment;quality of service monitoring;service-dependent;statistical classification;traffic classification;training data colleciton","","4","","23","","","19-22 Feb. 2012","","IEEE","IEEE Conference Publications"
"A mobile human activity recognition system","Ó. D. Lara; M. A. Labrador","Department of Computer Science and Engineering, University of South Florida, Tampa, 33620, USA","2012 IEEE Consumer Communications and Networking Conference (CCNC)","20120412","2012","","","38","39","Context-aware applications have been the focus of extensive research, yet their implementation in mobile devices usually becomes challenging due to restrictions of processing and energy. In this work, we present, demonstrate, and evaluate a mobile platform for real-time human activity recognition. The evaluation results indicate that the system can be implemented in real scenarios meeting accuracy, response time, and energy consumption requirements.","2331-9852;23319852","Electronic:978-1-4577-2071-0; POD:978-1-4577-2070-3","10.1109/CCNC.2012.6181040","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181040","Human-centric sensing;Machine learning","Accuracy;Feature extraction;Humans;Mobile communication;Real time systems;Sensors;Servers","behavioural sciences;mobile computing;mobile handsets;pattern recognition","context-aware application;energy consumption requirement;mobile device;mobile human activity recognition;mobile platform","","0","","5","","","14-17 Jan. 2012","","IEEE","IEEE Conference Publications"
"A supervised discretization algorithm for web page classification","J. A. Mangai; D. S. Kothari; V. S. Kumar","Dept. of Computer Science, BITS Pilani, Dubai Campus, DIAC, Dubai, UAE","2012 International Conference on Innovations in Information Technology (IIT)","20120531","2012","","","226","231","The search engines provide huge number of web pages for each user query making it difficult to get the desired relevant result. This is due to the exponential increase in the size of the information repository, the WWW. In this paper we have implemented a supervised discretization algorithm which is used for classifying large scale data base like web pages using an inconsistency measure. This algorithm does not require apriori knowledge about the data base used and therefore identifies the number of bins automatically. Experiments are done on WebKB, a benchmarking data set for the machine learning community. The results have shown a good improvement in classification accuracy with discretized features than with continuous features.","","Electronic:978-1-4673-1101-4; POD:978-1-4673-1100-7","10.1109/INNOVATIONS.2012.6207737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6207737","Discretization;Machine learning;Web Page Classification","Accuracy;Classification algorithms;Machine learning;Machine learning algorithms;Niobium;Numerical models;Web pages","Internet;learning (artificial intelligence);query processing;search engines;very large databases","WWW;Web page classification;WebKB;benchmarking data set;classifcation accuracy;inconsistency measure;information repository;large scale database classification;machine learning community;search engines;supervised discretization algorithm;user query","","0","","25","","","18-20 March 2012","","IEEE","IEEE Conference Publications"
"Localization and Classification through Adaptive Pathway Analysis","E. Bruns; O. Bimber","Bauhaus-University, Weimar, Germany","IEEE Pervasive Computing","20120419","2012","11","2","74","81","Evaluating user-generated spatiotemporal pathway data helps determine both the present and future location of museum visitors. The PhoneGuide adaptive mobile museum guidance system shows how this approach improves classification performance and achieves acceptable recognition rates.","1536-1268;15361268","","10.1109/MPRV.2010.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551110","PhoneGuide;machine learning;mobile applications;mobile phones;museum guidance;pathways.;person movement prediction;pervasive computing;spatio-temporal data","Artificial neural networks;Bluetooth;Clustering algorithms;Mobile communication;Mobile handsets;Object recognition;Spatiotemporal phenomena","mobile computing;museums;pattern classification","PhoneGuide adaptive mobile museum guidance system;adaptive pathway analysis;classification performance;museum visitors;user-generated spatiotemporal pathway data","","5","","12","","20100819","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Enhanced intelligent text categorization using concise keyword analysis","A. M. Shahi; B. Issac; J. R. Modapothala","School of Engineering, Computing and Science","2012 International Conference on Innovation Management and Technology Research","20120712","2012","","","574","579","Supervised learning is a popular approach to text classification among the research community as well as within software development industry. It enables intelligent systems to solve various text analysis problems such as document organization, spam detection and report scoring. However, the extremely difficult and time intensive process of creating a training corpus makes it inapplicable to many text classification problems. In this research, we explored the opportunities of addressing this pitfall by studying the ontological characteristics of document categories and grouping them under virtual super-categories to narrow down the search for a suitable category. Applying this method showed that classifier performance has greatly improved despite the relatively small size of the training corpus.","","Electronic:978-1-4673-0654-6; POD:978-1-4673-0655-3","10.1109/ICIMTR.2012.6236461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6236461","Categorization;Corporate Sustainability Report;Feature Selection;Global Reporting Initiative;Machine Learning;Supervised Learning;Text Ontology","Accuracy;Classification algorithms;Machine learning;Materials;Supervised learning;Text categorization;Training","Bayes methods;learning (artificial intelligence);ontologies (artificial intelligence);pattern classification;text analysis","classifier performance;concise keyword analysis;document category;document grouping;document organization;enhanced intelligent text categorization;intelligent system;naive Bayes classifier;ontological characteristics;report scoring;software development industry;spam detection;supervised learning;text analysis;text classification;training corpus;virtual super-categories","","0","","17","","","21-22 May 2012","","IEEE","IEEE Conference Publications"
"Connection of the beam width and the learning success rate in the phase transition framework for relational learning","Y. Li; M. Guo","College of computer science and technology, Harbin institute of technology, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","865","869","It is well-known that heuristic search in relation learning is prone to plateau phenomena. An explanation is that the relational learning covering test is NP-complete and therefore exhibits a sharp phase transition in its coverage probability. For heuristic value of a hypothesis depends on the amount of covered examples, the regions “yes” and “no” have no informative heuristic value, and the regions “yes” and “no” represent plateaus. Marco Botta et al. run several learning algorithms on a large data set of artificially generated problems and point out that the occurrence of phase transition dooms every learning algorithm to fail to identify the target concept. However, we note that they did not consider the influence of beam width on learning success rate. In this paper, we investigate the problem that whether the low learning success rate due to phase transition can be enhanced by enlarging the beam width. FOIL and KFOIL learning systems are respectively run on artificially generated data set according to different beam width 1, 5, 10, 20 and 30. Experiments show that beam width has almost no effect on learning success rate under phase transition framework.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6233833","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233833","beam width;heuristic search;machine learning;phase transition;relational learning","Accuracy;Algorithm design and analysis;Educational institutions;Heuristic algorithms;Learning systems;Machine learning;Structural beams","learning (artificial intelligence);optimisation;phase transformations;probability;search problems","KFOIL learning systems;NP-complete;artificially generated data set;artificially generated problems;beam width connection;coverage probability;heuristic search;informative heuristic value;large data set;learning algorithms;learning success rate;phase transition framework;plateau phenomena;relational learning;sharp phase transition;target concept","","0","","24","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Automated tuning of a vision-based inspection system for industrial food manufacturing","M. M. Chetima; P. Payeur","School of Electrical Engineering and Computer Science, University of Ottawa, Canada","2012 IEEE International Instrumentation and Measurement Technology Conference Proceedings","20120702","2012","","","210","215","Quality control in industrial food manufacturing can be reliably performed with computer vision systems that operate at high speed. However, most of these inspection stations need to be tuned manually and only perform well on a specific product. This research integrates machine learning techniques in the process to automate the initial tuning of real-time vision-based inspection systems for bakery products. The combination of feature selection techniques with machine learning is assessed in terms of classification performance. A formal automated tuning methodology is introduced and evaluated experimentally with data from industrial inspection stations. The work demonstrates that an inspection system automatically tuned with the proposed technique can systematically achieve 98% correct classification when compared with the classification generated with a manually tuned system.","1091-5281;10915281","Electronic:978-1-4577-1772-7; POD:978-1-4577-1773-4","10.1109/I2MTC.2012.6229334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6229334","Food inspection;automated tuning;feature selection;machine learning;machine vision;quality control","Accuracy;Decision trees;Feature extraction;Inspection;Machine learning;Training;Tuning","automatic optical inspection;computer vision;feature extraction;food processing industry;learning (artificial intelligence);production engineering computing;quality control","bakery products;classification performance;computer vision systems;feature selection techniques;industrial food manufacturing;machine learning techniques;quality control;tuning automation;vision-based inspection system","","0","","26","","","13-16 May 2012","","IEEE","IEEE Conference Publications"
"Compact single hidden layer feedforward network for mycobacterium tuberculosis detection","M. K. Osman; M. H. Mohd Noor; M. Y. Mashor; H. Jaafar","Faculty of Electrical Engineering, Universiti Teknologi MARA (UiTM), Malaysia","2011 IEEE International Conference on Control System, Computing and Engineering","20120426","2011","","","432","436","Advances in imaging technology and artificial intelligence have greatly enhanced the research and development of computer-aided tuberculosis (TB) diagnosis system. The system aims to assist medical technologist and improve the accuracy of clinical diagnosis. A typical architecture of a computer-aided TB diagnosis system consists of image processing, feature extraction and classification. Finding an effective classifier for the system has been regarded as a critical topic, in order to improve the detection performance and avoid making false decision. In this study, the recent method called compact single hidden layer feedforward neural network (C-SLFN) trained by an improved Extreme Learning Machine (ELM) is evaluated for detecting the TB bacilli. Six affine moment invariants are extracted from segmented tissue slide images and fed into the C-SLFN. The network is trained and classified the input patterns into three classes: `TB', `overlapped TB' and `non-TB'. Further, the study compares the network performance with a SLFN trained using the standard ELM algorithm. The results obtained from this study suggested that the standard ELM still outperformed the C-SLFN in term of classification accuracy. The standard ELM, however requires a large number of hidden nodes compares to the C-SLFN.","","Electronic:978-1-4577-1642-3; POD:978-1-4577-1640-9","10.1109/ICCSCE.2011.6190565","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6190565","Extreme Learning Machine;compact single hidden layer feedforward neural network;image processing;tuberculosis bacilli detection","Accuracy;Classification algorithms;Image segmentation;Joining processes;Machine learning;Training","biological tissues;diseases;feature extraction;feedforward neural nets;image classification;image segmentation;learning (artificial intelligence);medical image processing;microorganisms;object detection","C-SLFN;TB bacilli;affine moment invariant;artificial intelligence;classification accuracy;clinical diagnosis;compact single hidden layer feedforward neural network;computer-aided TB diagnosis system;computer-aided tuberculosis diagnosis system;detection performance;extreme learning machine;feature extraction;image processing;imaging technology;mycobacterium tuberculosis detection;network performance;nonTB;overlapped TB;standard ELM algorithm;tissue slide image segmentation","","3","","12","","","25-27 Nov. 2011","","IEEE","IEEE Conference Publications"
"A Transfer Learning Algorithm for Document Categorization Based on Clustering","W. Sun; Q. Xu","Coll. of Mech. Electron. & Inf. Eng., China Univ. of Min. & Technol.(Beijing), Beijing, China","2012 International Conference on Computer Science and Electronics Engineering","20120423","2012","2","","528","531","Traditional machine learning and data mining have achieved significant success in many knowledge engineering areas including classification, regression clustering and so on, but a major assumption in them is that the training and test data must be in the same feature space and follow the same distribution. However, in real applications, this assumption couldn't be satisfied for ever. In this case, the role of transfer learning can be highlight, because transfer learning does not make the same distributional assumptions as the traditional machine learning, and reduces the dependencies of the target task and training data, has a wider migration of knowledge. In this paper we will propose a transfer learning algorithm for document categorization based on clustering. We describe the main idea and the step of the algorithm. Then use experiment to test the algorithm and compare the algorithm with no-transfer algorithm. the experiment demonstrate that the algorithm we proposed in this paper is better than the others in some extent.","","Electronic:978-0-7695-4647-6; POD:978-1-4673-0689-8","10.1109/ICCSEE.2012.132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188085","clustering;document categorization;machine learning;transfer learning","Art;Classification algorithms;Clustering algorithms;Finance;Humans;Machine learning;Training data","data mining;document handling;learning (artificial intelligence);pattern classification;pattern clustering","clustering;data mining;document categorization;document classification;knowledge engineering;knowledge migration;machine learning;training data;transfer learning algorithm","","0","","10","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Automatic coronary extraction by supervised detection and shape matching","Y. Kitamura; Y. Li; W. Ito","Imaging Technology Center, FUJIFILM corporation, Tokyo, Japan","2012 9th IEEE International Symposium on Biomedical Imaging (ISBI)","20120712","2012","","","234","237","Automatic coronary extraction has great clinical importance in the effective handling and visualization of large amounts of 3D data. Despite tremendous previous research, coronary extraction remains difficult. Two such difficulties are extraction of both normal and abnormal vessels and reconstruction of exact tree structures based on anatomical knowledge. To solve the first difficulty, we propose a method to learn a classifier of a tubular 3D object with a dimension reduction approach using Hessian analysis. This enables detection of vessel candidate points despite variations in their appearances. Regarding the second difficulty, we propose an approach to apply the MRF framework for vascular structure segmentation. A novelty of the approach is incorporating constraints to avoid topological inconsistency. Correspondences between the candidate points and model points are found using a graph matching process during which, tree structures as per the shape model are simultaneously reconstructed. Experimental results show robustness of the method. The proposed method can improve clinical workflow.","1945-7928;19457928","Electronic:978-1-4577-1858-8; POD:978-1-4577-1857-1","10.1109/ISBI.2012.6235527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6235527","Machine learning;Shape matching;Vascular structure segmentation","Arteries;Computed tomography;Data mining;Detectors;Feature extraction;Image reconstruction;Shape","Hessian matrices;blood vessels;computerised tomography;data handling;data visualisation;diagnostic radiography;graph theory;image classification;image matching;image reconstruction;image segmentation;learning (artificial intelligence);medical image processing;trees (mathematics)","3D data handling;3D data visualization;Hessian analysis;MRF framework;anatomical knowledge;automatic coronary extraction;clinical workflow;dimension reduction approach;graph matching process;learning;shape matching;shape model;supervised detection;topological inconsistency;tree structure reconstruction;tubular 3D object;vascular structure segmentation","","4","1","17","","","2-5 May 2012","","IEEE","IEEE Conference Publications"
"An Investigation Into Feature Selection for Oncological Survival Prediction","D. Strunkin; B. M. Namee; J. D. Kelleher","Appl. Math. & Inf. Dept., Kazan State Tech. Univ., Kazan, Russia","2012 Ninth International Conference on Information Technology - New Generations","20120531","2012","","","764","768","In machine learning based clinical decision support (CDS) systems the features used to train prediction models are of paramount importance. Strong features will lead to accurate models, whereas as weak features will have the opposite effect. Feature sets can either be designed by domain experts, or automatically extracted for unstructured data that happens to be available from some process other than a CDS system. This paper compares the usefulness of structured expert-designed features to features extracted from unstructured data sources in an oncological survival prediction application scenario.","","Electronic:978-0-7695-4654-4; POD:978-1-4673-0798-7","10.1109/ITNG.2012.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6209083","feature selection;machine learning;oncology","Accuracy;Data models;Decision trees;Feature extraction;Machine learning;Medical diagnostic imaging;Predictive models","cancer;decision support systems;feature extraction;learning (artificial intelligence);medical expert systems;medical information systems","CDS systems;accurate models;clinical decision support system;domain experts;feature extraction;feature selection;feature sets;machine learning;oncological survival prediction application scenario;structured expert-designed features;train prediction models;unstructured data sources","","0","","20","","","16-18 April 2012","","IEEE","IEEE Conference Publications"
"Automatic identification of cross-document structural relationships","Y. J. Kumar; N. Salim; A. Hamza; A. Abuobieda","Faculty of Information and Communication Technology, University Teknikal Malaysia Melaka, 76100, Durian Tunggal, Malaysia","2012 International Conference on Information Retrieval & Knowledge Management","20120528","2012","","","26","29","Analysis on inter-document relationship is one of the important studies in multi document analysis. In this paper, we will focus on some special properties that multi document articles hold, specifically news articles. Information across news articles reporting on the same story are often related. Cross-document Structure Theory (CST) gives the relationship between pairs of sentences from different documents. For example, two sentences might have relationships such as identical, overlapping or contradicting. Our aim here is to automatically identify some of these CST relationships. We applied the well known machine learning technique, SVMs for this purpose and obtained some comparable results.","","Electronic:978-1-4673-1090-1; POD:978-1-4673-1091-8","10.1109/InfRKM.2012.6204977","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204977","Cross-document structure theory (CST);Machine learning;Multi document summarization;Rhetorical relation;Support vector machine (SVM)","Boosting;Classification algorithms;Computational modeling;Educational institutions;Support vector machines;Training","document handling;information resources;learning (artificial intelligence);support vector machines","CST relationships;SVM;cross-document structural relationship automatic identification;cross-document structure theory;interdocument relationship;machine learning technique;multidocument analysis;news articles","","0","","13","","","13-15 March 2012","","IEEE","IEEE Conference Publications"
"Monitoring and detecting abnormal behavior in mobile cloud infrastructure","T. Kim; Y. Choi; S. Han; J. Y. Chung; J. Hyun; J. Li; J. W. K. Hong","Division of IT Convergence Engineering, POSTECH, Pohang, Republic of Korea","2012 IEEE Network Operations and Management Symposium","20120607","2012","","","1303","1310","Recently, several mobile services are changing to cloud-based mobile services with richer communications and higher flexibility. We present a new mobile cloud infrastructure that combines mobile devices and cloud services. This new infrastructure provides virtual mobile instances through cloud computing. To commercialize new services with this infrastructure, service providers should be aware of security issues. In this paper, we first define new mobile cloud services through mobile cloud infrastructure and discuss possible security threats through the use of several service scenarios. Then, we propose a methodology and architecture for detecting abnormal behavior through the monitoring of both host and network data. To validate our methodology, we injected malicious programs into our mobile cloud test bed and used a machine learning algorithm to detect the abnormal behavior that arose from these programs.","1542-1201;15421201","Electronic:978-1-4673-0269-2; POD:978-1-4673-0267-8; USB:978-1-4673-0268-5","10.1109/NOMS.2012.6212067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6212067","Mobile cloud computing;abnormal behavior monitoring;machine learning;mobile cloud infrastructure;mobile cloud service scenarios","Cloud computing;IEEE 802.11 Standards;Malware;Mobile communication;Mobile computing;Mobile handsets;Monitoring","cloud computing;invasive software;learning (artificial intelligence);mobile computing","abnormal behavior detection;abnormal behavior monitoring;cloud computing;cloud-based mobile services;machine learning algorithm;malicious programs;mobile cloud infrastructure;mobile cloud test bed;network data;security issues;security threats;service providers;virtual mobile instances","","2","","24","","","16-20 April 2012","","IEEE","IEEE Conference Publications"
"GM-transfer: Graph-based model for transfer learning","Shizhun Yang; Chenping Hou; Yi Wu","Department of Mathematics and System Science, College of Science, National University of Defense Technology, Changsha Hunan Province, China","The First Asian Conference on Pattern Recognition","20120312","2011","","","37","41","Traditional data mining and machine learning technologies may fail when the training data and the testing data are drawn from different feature spaces and different distributions. Transfer learning, which uses the data from source domain and target domain, can tackle this problem. In this paper, we propose an improved Graph-based Model for Transfer learning (GM-Transfer). We construct a tripartite graph to represent the transfer learning problem and model the relations between the source domain data and the target domain data more efficiently. By learning the informational graph, the knowledge from the source domain data can be transferred to help improve the learning efficiency on the target domain data. Experiments show the effectiveness of our algorithm.","0730-6512;07306512","Electronic:978-1-4577-0121-4; POD:978-1-4577-0122-1","10.1109/ACPR.2011.6166601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166601","Graph-based Model;Machine Learning;Spectral Clustering;Transfer Learning","Machine learning","data mining;graph theory;learning (artificial intelligence)","GM-transfer model;data mining;graph-based model;informational graph;learning efficiency;machine learning;source domain;target domain;testing data;training data;transfer learning;tripartite graph","","0","","12","","","28-28 Nov. 2011","","IEEE","IEEE Conference Publications"
"Estimating data center thermal correlation indices from historical data","M. Marwah; C. Bash; R. Zhou; C. Felix; R. Shih; T. Christian","HP Labs, Palo Alto, CA 94304, USA","13th InterSociety Conference on Thermal and Thermomechanical Phenomena in Electronic Systems","20120705","2012","","","344","352","In order to better manage the cooling infrastructure in a data center with multiple computer room air conditioning (CRAC) units, the relationship between CRAC settings and temperature at various locations in the data center needs to be accurately and reliably determined. Usually this is done via a commissioning process which is both time consuming and disruptive. In this paper, we describe a machine learning based technique to model rack inlet temperature sensors in a data center as a function of CRAC settings. These models can then be used to automatically estimate thermal correlation indices (TCI) at any particular CRAC settings. We have implemented a prototype of our methodology in a real data center with eight CRACs and several hundred sensors. The temperature sensor models developed have high accuracy (mean RMSE error is 0.2°C). The results are validated using manual commissioning, demonstrating the effectiveness of our techniques in estimating TCI and in determining thermal zones or regions of influence of the CRACs.","1087-9870;10879870","Electronic:978-1-4244-9532-0; POD:978-1-4244-9533-7; USB:978-1-4244-9531-3","10.1109/ITHERM.2012.6231450","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6231450","CRAC;data center;machine learning;random forest;regression trees;temperature sensors;thermal correlation index;thermal zones","Atmospheric modeling;Computational modeling;Regression tree analysis;Temperature sensors;Vegetation","air conditioning;commissioning;computer centres;computerised instrumentation;learning (artificial intelligence);temperature sensors;thermal analysis","CRAC units;TCI estimation;commissioning process;cooling infrastructure management;data center thermal correlation indices estimation;historical data;machine learning based technique;multiple computer room air conditioning unit;rack inlet temperature sensors","","1","","","","","May 30 2012-June 1 2012","","IEEE","IEEE Conference Publications"
"Logistic regression classifier for palmprint verification","D. Kostadinov; S. Bogdanova","Department of Electronics, Faculty of Electrical Engineering and Information Technologies, Ss. Cyril and Methodius University, Skopje, Macedonia","2012 19th International Conference on Systems, Signals and Image Processing (IWSSIP)","20120531","2012","","","413","416","We propose a supervised machine learning approach for automatic palmprint verification. In our approach a pair of palmprint images is represented and characterized using a vector of regional similarity features. Every regional similarity feature is computed using local modified complex wavelet structural similarity indexes (CW-SSIM). The logistic regression classifier verifies whether two palmprints described by the feature vector belong to same person or not. The aim of our classifier is to improve the matching accuracy and robustness of the verification, based on learned knowledge about: 1) the local and global characterization of the errors arising due to inaccurate image registration (translations, rotations, and distortions), and 2) the underlying vector patterns of the two palmprint images. Our experimental results show that the proposed approach achieves high verification accuracy.","2157-8672;21578672","Electronic:978-3-200-02328-4; POD:978-1-4577-2191-5","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6208164","Biometrics;complex wavelet transform;machine learning;palmprint","Accuracy;Feature extraction;Indexes;Lighting;Logistics;Support vector machine classification;Vectors","feature extraction;image classification;image matching;image representation;learning (artificial intelligence);palmprint recognition;regression analysis;wavelet transforms","CW-SSIM;automatic palmprint verification;feature vector;global characterization;local characterization;local modified complex wavelet structural similarity indexes;logistic regression classifier;matching accuracy;palmprint image representation;regional similarity features;supervised machine learning approach;vector patterns;verification robustness","","0","","12","","","11-13 April 2012","","IEEE","IEEE Conference Publications"
"A methodology applicable to building a classifier of pavement roughness measurement methods and devices","A. Janota; J. Halgaš","University of &#x017D;ilina/Dept. of Control and Information Systems, &#x017D;ilina, Slovakia","2012 ELEKTRO","20120628","2012","","","311","315","The paper presents a methodological approach used by the authors in the process of design of a knowledge base for the domain related to measurement of different pavement characteristics. As the main representation formalism a rule is considered. Individual steps taken in the process of knowledge discovery in data are discussed. The process is demonstrated using limited sample data related to pavement roughness measurements processed by inductive learning algorithms. The paper emphasizes procedural aspects of the design process rather than presentation of complete results that are not fully available yet because of the early stage of the research project being in the background.","","Electronic:978-1-4673-1179-3; POD:978-1-4673-1180-9","10.1109/ELEKTRO.2012.6225610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6225610","Measurement;knowledge acquisition;machine learning algorithms;road","Atmospheric measurements;Computers;Manuals;Pollution measurement;Roads;Sensors;Vehicles","data mining;learning (artificial intelligence);roads","classifier;inductive learning algorithms;knowledge discovery;limited sample data;main representation formalism;pavement roughness measurement methods","","0","","12","","","21-22 May 2012","","IEEE","IEEE Conference Publications"
"DAE2FSM: Automatic generation of accurate discrete-time logical abstractions for continuous-time circuit dynamics","K. V. Aadithya; J. Roychowdhury","Department of Electrical Engineering and Computer Science, The University of California, Berkeley, CA, USA","DAC Design Automation Conference 2012","20120719","2012","","","311","316","We abstract the I/O functionality of continuous-time dynamical systems (e.g., SPICE netlists with combinational and sequential logic) as Finite State Machines (FSMs). This enables efficient simulation of large designs implemented with less-than-perfect devices and components, and also opens the door to formal verification of transistor-level designs against higher-level specifications. In particular, our automatically generated FSMs faithfully capture the behaviour of latches, flip-flops, and circuits constructed from them. Among other technical advances, we generalize an existing (binary-only) FSM-learning approach to arbitrary I/O alphabets, which empowers it to learn high-fidelity abstractions of multi-level-discretized, multi-input/multi-output systems. Our approach, when applied to correctly functioning latches and flip-flops, is able to learn compact, multi-input FSM abstractions whose predictions closely match SPICE simulations. In addition, we have also applied our technique to produce multi-level-discretized FSM representations of digital systems that nevertheless exhibit ""analogish"" traits, such as an over-clocked, error-prone D-flip-flop. For such circuits, the automatically learned FSM abstraction includes additional states that characterise ""failure modes"" of the circuit for specific input sequences (these failure modes are also confirmed by SPICE simulations). Finally, we demonstrate that our technique is also applicable to larger and more complex multi-input, multi-output systems; for example, we are able to automatically derive an accurate FSM abstraction of a 280-transistor (BSIM4), 0-to-5 increment/decrement counter.","0738-100X;0738100X","Electronic:978-1-4503-1199-1; POD:978-1-4503-1199-1","10.1145/2228360.2228418","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6241527","Circuit Simulation;Finite State Machine Learning","Clocks;Delay;Integrated circuit modeling;Latches;Machine learning;SPICE;Switches","SPICE;circuit simulation;combinational circuits;finite state machines;flip-flops;formal verification;integrated circuit design;learning (artificial intelligence);logic design;sequential circuits;transistor circuits","DAE2FSM;I/O alphabets;I/O functionality;SPICE netlist;SPICE simulation;automatic generation;binary-only FSM-learning approach;combinational logic;continuous-time circuit dynamics;continuous-time dynamical system;digital system;discrete-time logical abstraction;failure mode;finite state machine;flip-flop;formal verification;high-fidelity abstraction;latches;multiinput FSM abstraction;multiinput-multioutput system;multilevel-discretized FSM;multilevel-discretized system;sequential logic;transistor-level design","","2","","11","","","3-7 June 2012","","IEEE","IEEE Conference Publications"
"Traffic classification using cost based decision tree","Lin Wang; Xuan Zhou; Rentao Gu","School of Information and Communications, Beijing University of Posts and Telecommunications(BUPT), 100876, China","Proceedings of 2011 International Conference on Computer Science and Network Technology","20120412","2011","4","","2545","2550","A novel method for achieving practical real-time traffic classification is proposed in this paper, which is based on C4.5 decision tree. Most existing traffic classification algorithms only focus on accuracy of the classification results, but lack of considering the various costs in actual deployment. So they cannot guarantee that the obtained tree construction is optimal for hardware and software processing. To solve this problem, our Cost Based Feature Evaluation procedure defines UnitGainRatio as the metric of attributes to find the best tree construction when considering the attribute acquisition and processing cost. We also introduce another method called Fuzzy Delicacy Node Selection procedure to choose the more suitable node, when their UnitGainRatio are too close to each other. The experiment results show that the proposed method reduces the average cost compared with similar algorithm.","","Electronic:978-1-4577-1587-7; POD:978-1-4577-1586-0","10.1109/ICCSNT.2011.6182488","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182488","Computer networks;decision tree;machine learning;traffic classification","","Internet;decision trees;feature extraction;fuzzy set theory;pattern classification","C4.5 decision tree;UnitGainRatio;attribute acquisition;attribute metric;cost based feature evaluation;fuzzy delicacy node selection procedure;processing cost;real-time traffic classification;tree construction","","0","","10","","","24-26 Dec. 2011","","IEEE","IEEE Conference Publications"
"Validation of <formula formulatype=""inline""><tex Notation=""TeX"">$k$</tex></formula>-Nearest Neighbor Classifiers","E. Bax","Yahoo, Pasadena","IEEE Transactions on Information Theory","20120418","2012","58","5","3225","3234","This paper presents a method to compute probably approximately correct error bounds for <i>k</i>-nearest neighbor classifiers. The method withholds some training data as a validation set to bound the error rate of the holdout classifier that is based on the remaining training data. Then, the method uses the validation set to bound the difference in error rates between the holdout classifier and the classifier based on all training data. The result is a bound on the out-of-sample error rate for the classifier based on all training data.","0018-9448;00189448","","10.1109/TIT.2011.2180887","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111216","Learning systems;machine learning;nearest neighbor;statistical learning;supervised learning","Cancer;Error analysis;Machine learning;Training;Training data;Upper bound","learning (artificial intelligence);pattern classification","approximately correct error bounds;holdout classifier;k-nearest neighbor classifiers;out-of-sample error rate;training data","","4","","36","","20111221","May 2012","","IEEE","IEEE Journals & Magazines"
"Toward Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models","C. Li; A. Kowdle; A. Saxena; T. Chen","Cornell University, Ithaca","IEEE Transactions on Pattern Analysis and Machine Intelligence","20120516","2012","34","7","1394","1408","Scene understanding includes many related subtasks, such as scene categorization, depth estimation, object detection, etc. Each of these subtasks is often notoriously hard, and state-of-the-art classifiers already exist for many of them. These classifiers operate on the same raw image and provide correlated outputs. It is desirable to have an algorithm that can capture such correlation without requiring any changes to the inner workings of any classifier. We propose Feedback Enabled Cascaded Classification Models (FE-CCM), that jointly optimizes all the subtasks while requiring only a “black box” interface to the original classifier for each subtask. We use a two-layer cascade of classifiers, which are repeated instantiations of the original ones, with the output of the first layer fed into the second layer as input. Our training method involves a feedback step that allows later classifiers to provide earlier classifiers information about which error modes to focus on. We show that our method significantly improves performance in all the subtasks in the domain of scene understanding, where we consider depth estimation, scene categorization, event categorization, object detection, geometric labeling, and saliency detection. Our method also improves performance in two robotic applications: an object-grasping robot and an object-finding robot.","0162-8828;01628828","","10.1109/TPAMI.2011.232","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095567","Scene understanding;classification;machine learning;robotics.","Equations;Estimation;Inference algorithms;Mathematical model;Object detection;Robots;Training","image classification;robot vision","FE-CCM;black box interface;correlated outputs;depth estimation;event categorization;feedback enabled cascaded classification models;geometric labeling;holistic scene understanding;object detection;saliency detection;scene categorization;scene understanding","0","27","","71","","20111206","July 2012","","IEEE","IEEE Journals & Magazines"
"Exploiting spatiotemporal and device contexts for energy-efficient mobile embedded systems","B. Donohoo; C. Ohlsen; S. Pasricha; C. Anderson","Department of Electrical and Computer Engineering","DAC Design Automation Conference 2012","20120719","2012","","","1274","1279","Within the past decade, mobile computing has morphed into a principal form of human communication, business, and social interaction. Unfortunately, the energy demands of newer ambient intelligence and collaborative technologies on mobile devices have greatly overwhelmed modern energy storage abilities. This paper proposes several novel techniques that exploit spatiotemporal and device context to predict device interface configurations that can optimize energy consumption in mobile embedded systems. These techniques, which include variants of linear discriminant analysis, linear logistic regression, non-linear logistic regression with neural networks, and k-nearest neighbor are explored and compared on synthetic and user traces from real-world usage studies. The experimental results show that up to 90% successful prediction is possible with neural networks and k-nearest neighbor algorithms, improving upon prediction strategies in prior work by approximately 50%. Further, an average improvement of 24% energy savings is achieved compared to state-of-the-art prior work on energy-efficient location-sensing.","0738-100X;0738100X","Electronic:978-1-4503-1199-1; POD:978-1-4503-1199-1","10.1145/2228360.2228599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6241673","Energy Optimization;Machine Learning;Smartphone","Accuracy;Context;Global Positioning System;Machine learning algorithms;Mathematical model;Neural networks;Prediction algorithms","embedded systems;human factors;mobile computing;neural nets;pattern clustering;power aware computing;regression analysis;spatiotemporal phenomena","ambient intelligence;collaborative technologies;device context;device interface configurations;energy consumption optimization;energy demands;energy efficient location sensing;energy efficient mobile embedded systems;energy savings;energy storage abilities;k-nearest neighbor;linear discriminant analysis;linear logistic regression;mobile computing;mobile devices;neural networks;nonlinear logistic regression;real-world usage studies;spatiotemporal context;synthetic traces;user traces","","4","","27","","","3-7 June 2012","","IEEE","IEEE Conference Publications"
"Fast and parallelized greedy forward selection of genetic variants in Genome-wide association studies","S. Okser; T. Pahikkala; A. Airola; T. Aittokallio; T. Salakoski","University of Turku and Turku Centre for Computer Science, FI-20520, Finland","2011 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)","20120315","2011","","","214","217","We present the application of a regularized least-squares based algorithm, known as greedy RLS, to perform a wrapper-based feature selection on an entire genome-wide association dataset. Wrapper methods were previously thought to be computationally infeasible on these types of studies. The running time of the method grows linearly in the number of training examples, the number of features in the original data set, and the number of selected features. Moreover, we show how it can be further accelerated using parallel computation on multi-core processors. We tested the method on the Wellcome Trust Case Control Consortium's (WTCCC) Type 2 Diabetes - UK National Blood Service dataset consisting of 3,382 subjects and 404,569 single nucleotide polymorphisms (SNPs). Our method is capable of high-speed feature selection, selecting the top 100 predictive SNPs in under five minutes on a high end desktop and outperforms typical filter approaches in terms of predictive performance.","2150-3001;21503001","Electronic:978-1-4673-0490-0; POD:978-1-4673-0491-7","10.1109/GENSiPS.2011.6169483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169483","GWAS;Machine learning;SNP;feature selection;genome-wide association study;regularized least squares","Bioinformatics;Diseases;Genomics;Machine learning;Predictive models;Training","biology computing;genetics;genomics;greedy algorithms;learning (artificial intelligence);least squares approximations;multiprocessing systems","UK National Blood Service dataset;Wellcome Trust Case Control Consortium Type 2 Diabetes;fast greedy forward selection;genetic variants;genome-wide association dataset;genome-wide association studies;greedy RLS;machine learning;multicore processors;parallel computation;parallelized greedy forward selection;regularized least-squares based algorithm;single nucleotide polymorphisms;wrapper-based feature selection","","0","","13","","","4-6 Dec. 2011","","IEEE","IEEE Conference Publications"
"A Comparative Study on Filtering Protein Secondary Structure Prediction","P. Kountouris; M. Agathocleous; V. J. Promponas; G. Christodoulou; S. Hadjicostas; V. Vassiliades; C. Christodoulou","University of Cyprus, Nicosia","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20120322","2012","9","3","731","739","Filtering of Protein Secondary Structure Prediction (PSSP) aims to provide physicochemically realistic results, while it usually improves the predictive performance. We performed a comparative study on this challenging problem, utilizing both machine learning techniques and empirical rules and we found that combinations of the two lead to the highest improvement.","1545-5963;15455963","","10.1109/TCBB.2012.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6138848","Protein secondary structure prediction;bidirectional recurrent neural networks.;filtering;machine learning;structural bioinformatics","Accuracy;Filtering;Logistics;Machine learning;Machine learning algorithms;Proteins;Training","bioinformatics;filtering theory;learning (artificial intelligence);molecular biophysics;molecular configurations;proteins","empirical rule;machine learning technique;protein secondary structure prediction filtering","Animals;Artificial Intelligence;Databases, Protein;Humans;Protein Structure, Secondary;Proteins","3","","40","","20120124","May-June 2012","","IEEE","IEEE Journals & Magazines"
"EDISC: A Class-Tailored Discretization Technique for Rule-Based Classification","K. Shehzad","University of Engineering and Technology, Taxila","IEEE Transactions on Knowledge and Data Engineering","20120626","2012","24","8","1435","1447","Discretization is a critical component of data mining whereby continuous attributes of a data set are converted into discrete ones by creating intervals either before or during learning. There are many good reasons for preprocessing discretization, such as increased learning efficiency and classification accuracy, comprehensibility of data mining results, as well as the inherent limitation of a great majority of learning algorithms to handle only discrete data. Many preprocessing discretization techniques have been proposed to date, of which the Entropy-MDLP discretization has been accepted as by far the most effective in the context of both decision tree learning and rule induction algorithms. This paper presents a new discretization technique EDISC which utilizes the entropy-based principle but takes a class-tailored approach to discretization. The technique is applicable in general to any covering algorithm, including those that use the class-per-class rule induction methodology such as CN2 as well as those that use a seed example during the learning phase, such as the RULES family. Experimental evaluation has proved the efficiency and effectiveness of the technique as a preprocessing discretization procedure for CN2 as well as RULES-7, the latest algorithm among the RULES family of inductive learning algorithms.","1041-4347;10414347","","10.1109/TKDE.2011.101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5765955","Discretization;continuous values;data mining;data transformation;discrete values;inductive learning;machine learning;rule induction.;supervised learning","Accuracy;Algorithm design and analysis;Classification algorithms;Data mining;Decision trees;Entropy;Machine learning algorithms","data handling;data mining;decision trees;entropy;knowledge based systems;learning (artificial intelligence);pattern classification","EDISC;RULES family;class-per-class rule induction methodology;class-tailored discretization technique;continuous data set attributes;data mining;decision tree learning;discrete data handling;entropy-MDLP discretization;entropy-based principle;inductive learning algorithm;preprocessing discretization techniques;rule extraction system;rule induction algorithms;rule-based classification","","9","","43","","20110512","Aug. 2012","","IEEE","IEEE Journals & Magazines"
"Cognitive Radio Network as Wireless Sensor Network (III): Passive target intrusion detection and experimental demonstration","C. Zhang; Z. Hu; T. N. Guo; R. C. Qiu; K. Currie","Cognitive Radio Institute, Center for Manufacturing Research, Tennessee Technological University, Cookeville, TN 38505, USA","2012 IEEE Radar Conference","20120607","2012","","","0293","0298","A Cognitive Radio Network (CRN) based Wireless Sensor Network (WSN), as an extension of CRN, is explored for radio frequency (RF) passive target intrusion detection. Compared to a cheap WSN, the CRN based WSN is expected to deliver better results due to its strong communication functions and powerful computing ability. Issues addressed in this paper include experimental architecture, waveform design, and machine learning algorithm for classification. In particular, passive target intrusion is experimentally demonstrated using multiple WARP platforms that serve as the cognitive/sensor nodes. In contrast to traditional localization methods relying on radio propagation properties, the technique used in this research is based on machine learning with measured data, considering complicated multipath environment and high dimensional sensing data collected by the CRN based WSN. Preliminary experimental results are quite encouraging, suggesting that a large-scale CRN based WSN supported by machine learning techniques has promising potential for passive target intrusion detection in harsh RF environments.","1097-5659;10975659","Electronic:978-1-4673-0658-4; POD:978-1-4673-0656-0","10.1109/RADAR.2012.6212153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6212153","Dimensionality Reduction;Machine Learning;Multi-class Support Vector Machine;Passive Target Intrusion Detection","Cognitive radio;Kernel;Receivers;Sensors;Support vector machines;Training;Wireless sensor networks","cognitive radio;telecommunication security;wireless sensor networks","cheap WSN;cognitive radio network;high dimensional sensing data;localization method;machine learning algorithm;radio frequency passive target intrusion detection;radio propagation property;waveform design;wireless sensor network","","0","","37","","","7-11 May 2012","","IEEE","IEEE Conference Publications"
"A Data-Driven Approach to Kinematic Analysis in Running Using Wearable Technology","C. Strohrmann; M. Rossi; B. Arnrich; G. Troster","Wearable Comput. Lab., ETH Zurich, Zurich, Switzerland","2012 Ninth International Conference on Wearable and Implantable Body Sensor Networks","20120517","2012","","","118","123","Millions of people run. Movement scientists investigate the relationship of running kinematics to fatigue, injury, or running economy mainly using optical motion capture. It was found that running kinematics are highly individual and often cannot be summarized by single variables. We thus present a data-driven analysis of running technique using wearable technology, combining statistical features and machine learning techniques, which allows to identify non-linear, complex relationships. Wearable technology enables running kinematic analysis to a broad mass in unconstrained environments. 20 runners wore 12 sensor units during two experiments: an all out test and a fatiguing run. We used a Support Vector Machine (SVM) to distinguish skill level groups and achieved an accuracy of 76.92% with an acceleration sensor on the upper body. Sensor positions were ranked according to the movement change with fatigue using a feature selection. This ranking was consistent with visual annotations of a movement scientist. We propose a quantitative measure of movement change using a principal component analysis (PCA) and found an average correlation of 0.8369 for all runners with their perceived rating of fatigue.","2376-8886;23768886","Electronic:978-0-7695-4698-8; POD:978-1-4673-1391-3","10.1109/BSN.2012.1","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200550","machine learning;measurement;wearable sensors","Acceleration;Accuracy;Fatigue;Feature extraction;Kinematics;Sensor phenomena and characterization","acceleration measurement;body sensor networks;fatigue;gait analysis;injuries;kinematics;learning (artificial intelligence);principal component analysis;support vector machines;wearable computers","acceleration sensor;data-driven approach;fatigue;feature selection;injury;kinematic analysis;machine learning techniques;optical motion capture;principal component analysis;skill level;statistical features;support vector machine;upper body sensor;visual annotations;wearable technology","","1","","25","","","9-12 May 2012","","IEEE","IEEE Conference Publications"
"Linear Subclass Support Vector Machines","N. Gkalelis; V. Mezaris; I. Kompatsiaris; T. Stathaki","Information Technologies Institute/Centre for Research and Technology Hellas (CERTH), Thermi, Greece","IEEE Signal Processing Letters","20120716","2012","19","9","575","578","In this letter, linear subclass support vector machines (LSSVMs) are proposed that can efficiently learn a piecewise linear decision function for binary classification problems. This is achieved using a nongaussianity criterion to derive the subclass structure of the data, and a new formulation of the optimization problem that exploits the subclass information. LSSVMs provide low computation cost during training and evaluation, and offer competitive recognition performance in comparison to other popular SVM-based algorithms. Experimental results on various datasets confirm the advantages of LSSVMs.","1070-9908;10709908","","10.1109/LSP.2012.2207892","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6236010","Classification;machine learning;mixture of Gaussians;pattern recognition;subclasses;support vector machines","Machine learning;Optimization;Pattern recognition;Support vector machines;Training","","","","2","","16","","20120710","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Relation of home energy consumption and static properties of consumers","K. Tamano; H. Tsuji","Grad. Sch. of Eng., Osaka Prefecture Univ., Sakai, Japan","2011 3rd International Conference on Awareness Science and Technology (iCAST)","20120305","2011","","","215","220","In the current situation, we need efficient methods to save home energy. Home energy management systems (HEMS) are being now developed, but they require time to change people's style of consumption from the analysis of their behaviour. We analysed a data set with both the amount of consumption and consumers' information, to point out what kind of characteristics of consumers, we called them static properties, would affect the consumption. We use the methodology of machine learning. Here we make a naive Bayes classifier to tell the tendency of consumption from the consumer's static properties. After getting the accuracy of 0.4148, not so high, we estimate the importance of each static property with statistic measure such as χ<sup>2</sup> and so on, in order to improve the accuracy and to find the important static properties. Although this process does not bring a significant improvement of the accuracy, we have found several static properties to affect the consumption. We can add a quick diagnostic functionality to the HEMS with these results.","2325-5986;23255986","Electronic:978-1-4577-0888-6; POD:978-1-4577-0887-9","10.1109/ICAwST.2011.6163143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163143","classifier;energy saving;feature selection;machine learning","Electricity;World Wide Web","Bayes methods;energy conservation;energy consumption;energy management systems;learning (artificial intelligence);power engineering computing","Bayes classifier;HEMS;consumer static properties;home energy consumption;home energy management systems;machine learning","","0","","16","","","27-30 Sept. 2011","","IEEE","IEEE Conference Publications"
"Supervised classification algorithms based on artificial immune","S. Feng","School of Information, Guangdong Ocean University, GDOU, Zhanjiang, China","2012 8th International Conference on Natural Computation","20120709","2012","","","879","882","In order to explore more efficient classification method, this paper presents a supervised classification algorithm based on artificial immune. It describes the representation of antibody and antigen in the classification algorithm, mathematical model of antibody population reproduction and immune memory formation. The experimental results show that the algorithm can achieve high classification performance. The average classification accuracy is 89.3%, stable classification performance. It has non-linear and clone selection, immune regulation, immune memory and other features of biological immune system, which provides a new solution for supervised classification problem.","2157-9555;21579555","Electronic:978-1-4577-2133-5; POD:978-1-4577-2130-4","10.1109/ICNC.2012.6234667","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234667","artificial immune;classification algorithm;machine learning;supervised classification","Accuracy;Algorithm design and analysis;Cells (biology);Classification algorithms;Cloning;Immune system","artificial immune systems;biology computing;learning (artificial intelligence)","antibody population reproduction;antibody representation;antigen representation;artificial immune;biological immune system;biological information processing mechanism;clone selection;immune memory;immune memory formation;immune regulation;mathematical model;nonlinear selection;supervised classification algorithms","","1","","10","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Post-placement lithographic hotspot detection and removal in one-dimensional gridded designs","J. Y. Wuu; M. Simmons; M. Marek-Sadowska","Department of Electrical and Computer Engineering, University of California, Santa Barbara, CA USA","Thirteenth International Symposium on Quality Electronic Design (ISQED)","20120419","2012","","","193","199","As double patterning techniques mature, they become the primary approaches enabling feature size scaling beyond 32nm. Although it is possible to print dense patterns by splitting the design into two masks, printability problems and pattern distortion remains a major concern. In this paper, we study the potential lithographic hotspots that may occur between the line ends in one-dimensional gridded designs obtained with Line-End Cut (LEC) method [2]. We propose a post-placement hotspot detection and removal algorithm that perturbs the cell locations to eliminate all hotspots. Hotspot detection is performed using a pattern classifier based on machine learning techniques. Experimental results show that we can successfully eliminate all hotspots with excellent runtime efficiency and insignificant overhead on estimated wire lengths.","1948-3287;19483287","Electronic:978-1-4673-1036-9; POD:978-1-4673-1034-5","10.1109/ISQED.2012.6187494","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187494","DFM;Design for manufacturability;gridded design;hotspot detection;hotspot removal;machine learning;placement;printability","Classification algorithms;Context;Labeling;Layout;Machine learning algorithms;Robustness;Training","learning (artificial intelligence);masks;pattern classification;photolithography","LEC method;double patterning techniques;line-end cut method;machine learning techniques;masks;one-dimensional gridded designs;pattern classifier;pattern distortion;post-placement lithographic hotspot detection;printability problems;removal algorithm","","1","","17","","","19-21 March 2012","","IEEE","IEEE Conference Publications"
"Efficient Model Learning Methods for Actor–Critic Control","I. Grondman; M. Vaandrager; L. Busoniu; R. Babuska; E. Schuitema","Delft Center for Systems and Control, Delft University of Technology, Delft, The Netherlands","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","20120511","2012","42","3","591","602","We propose two new actor-critic algorithms for reinforcement learning. Both algorithms use local linear regression (LLR) to learn approximations of the functions involved. A crucial feature of the algorithms is that they also learn a process model, and this, in combination with LLR, provides an efficient policy update for faster learning. The first algorithm uses a novel model-based update rule for the actor parameters. The second algorithm does not use an explicit actor but learns a reference model which represents a desired behavior, from which desired control actions can be calculated using the inverse of the learned process model. The two novel methods and a standard actor-critic algorithm are applied to the pendulum swing-up problem, in which the novel methods achieve faster learning than the standard algorithm.","1083-4419;10834419","","10.1109/TSMCB.2011.2170565","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6096441","Actor–critic;inverse model;local linear regression (LLR);machine learning algorithms;reinforcement learning (RL)","Approximation algorithms;Encoding;Function approximation;Process control","control engineering computing;function approximation;learning (artificial intelligence);manipulators;pendulums;position control;regression analysis","actor-critic algorithm;actor-critic control;function approximation;learning policy update;local linear regression;model learning method;model-based update rule;pendulum swing-up problem;reference model learning;reinforcement learning;robotic arm","Algorithms;Artificial Intelligence;Computer Simulation;Decision Support Techniques;Models, Theoretical;Pattern Recognition, Automated","17","","26","","20111207","June 2012","","IEEE","IEEE Journals & Magazines"
"Determining a Failure Root Cause Distribution From a Population of Layout-Aware Scan Diagnosis Results","B. Benware; C. Schuermyer; M. Sharma; T. Herrmann","Mentor Graphics Corp., Wilsonville, OR, USA","IEEE Design & Test of Computers","20120511","2012","29","1","8","18","The yield of an integrated circuit (IC) is well known to be a critical factor in the success of an IC in the market place. Achieving high stable yields helps ensure that the product is profitable and meets quality and reliability objectives. When a new manufacturing process is introduced, or a new product is introduced on a mature manufacturing process, yields will tend to be significantly lower than acceptable. The ability to meet profitability and quality objectives, and perhaps more importantly, time-to-market and time-to-volume objectives depend greatly on the rate at which these low yields can be ramped up. While the yield ramp depends on both the yield learning and yield enhancement cycle times, this work focuses on significantly increasing the value of test data and the yield learning rate.","0740-7475;07407475","","10.1109/MDT.2011.2178386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6148303","ATPG;Bayesian Networks;Machine Learning;Scan Diagnosis;Yield Learning","Bayesian methods;Fault diagnosis;Feature extraction;Learning systems;Machine learning;Random variables","Bayes methods;expectation-maximisation algorithm;failure analysis;fault diagnosis;inference mechanisms;integrated circuit layout;integrated circuit reliability;integrated circuit testing;integrated circuit yield;learning (artificial intelligence);logic testing;production engineering computing;profitability;quality control;time to market","Bayes net model;IC yield;expectation-maximization principle;failure root cause distribution;integrated circuit yield;layout-aware scan diagnosis result population;learning algorithm;learning process;logic-test-failing die;manufacturing process;product profitability;quality objectives;reliability objectives;root cause inference;test data;time-to-market objectives;time-to-volume objectives;yield enhancement cycle time;yield learning rate;yield ramp","","9","","9","","20120207","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Architecture and Applications of Virtual Coaches","D. Siewiorek; A. Smailagic; A. Dey","Quality of Life Technology Engineering Research Center, Carnegie Mellon University, Pittsburgh","Proceedings of the IEEE","20120713","2012","100","8","2472","2488","The combination of sensors, perception algorithms, and mobile computing enables situationally aware systems that provide proactive assistance. This paper outlines the basic components of a virtual coach with illustrations in five applications ranging from reminders to advice to opportunities for personal reflection.","0018-9219;00189219","","10.1109/JPROC.2012.2200560","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226823","Context awareness;human-computer interaction;machine learning;mobile computing;pervasive computing;quality of life technology (QoLT);user-centered design;wearable computers","Computer architecture;Context awareness;Data models;Human computer interaction;Intelligent systems;Machine learning;Mobile computing;Monitoring;Quality assessment;Service robots;Wheelchairs","computer aided instruction;mobile computing;sensors;user interfaces;virtual reality","mobile computing;perception algorithm;personal reflection;proactive assistance;sensors;situationally-aware systems;virtual coach","","2","","20","","20120627","Aug. 2012","","IEEE","IEEE Journals & Magazines"
"Prediction of failure occurrence time based on system log message pattern learning","M. Sonoda; Y. Watanabe; Y. Matsumoto","Fujitsu Laboratories Limited, 4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki, Kanagawa 211-8588, Japan","2012 IEEE Network Operations and Management Symposium","20120607","2012","","","578","581","In order to avoid failures or diminish the impact of them, it is important to deal with them before its occurrence. Some existing approaches for online failure prediction are insufficient to handle the upcoming failures beforehand, because they cannot predict the failures early enough to execute workaround operations for failure. To solve this problem, we have developed a method to estimate the prediction period (the time period when a failure is expected to occur). Our method identifies the message patterns showing predictive signs of a certain failure through Bayesian learning from log messages and past failure reports. Using these patterns it predicts the occurrence of failures and their prediction period with sufficient interval. We conducted the evaluation of our approach with log data obtained from an actual system. The results shows that our method predicted the occurrence of failure with sufficient interval (60 minutes before the occurrence of failures) and sufficient accuracy (precision: over 0.7, recall: over 0.8).","1542-1201;15421201","Electronic:978-1-4673-0269-2; POD:978-1-4673-0267-8; USB:978-1-4673-0268-5","10.1109/NOMS.2012.6211960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6211960","analysis of system logs;failure prediction;machine learning;system failure management","Accuracy;Bayesian methods;Data mining;Estimation;Feature extraction;Lead;Predictive models","Bayes methods;learning (artificial intelligence);system recovery","Bayesian learning;failure occurrence time prediction;failure reports;prediction period estimation;predictive signs;system log message pattern learning","","3","","9","","","16-20 April 2012","","IEEE","IEEE Conference Publications"
"Use of learning, game theory and optimization as biomimetic approaches for Self-Organization in macro-femtocell coexistence","A. Imran; M. Bennis; L. Giupponi","Center for Communication Systems Research, University of Surrey, UK","2012 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)","20120614","2012","","","103","108","In this paper, we present the use of several Biomimetic approaches for Self Organization (SO) in heterogeneous scenarios where macrocell and femtocell networks coexist. Mainly these approaches are categorized in indirect biomimetics and direct biomimetics. Under indirect biomimetics we discuss 1) emerging paradigms in learning theory and 2) game theory for their potential to enable SO solutions in heterogeneous networks. By means of numerical results we demonstrate the pros and cons of these indirect biomimetic approaches for designing SO in macro-femto coexistence scenarios. Furthermore, we demonstrate the use of direct biomimetic approaches for designing SO by exploiting one to one mapping between a natural SO system and our system model for heterogeneous networks based on Outdoor Fixed Relays (OFR). Numerical results show that the proposed analytical solution can enhance wireless backhaul capacity of the OFR based femtocells by adapting the macro base station (BS) antenna tilts in a distributed and self organizing manner.","","Electronic:978-1-4673-0682-9; POD:978-1-4673-0681-2","10.1109/WCNCW.2012.6215470","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6215470","Biomimetics;game theory;machine learning;self-organization","Antennas;Convergence;Game theory;Interference;Macrocell networks;Vectors;Wireless communication","antennas;biomimetics;femtocellular radio;game theory;learning (artificial intelligence);optimisation;telecommunication computing","SO system;base station antenna;biomimetic approach;direct biomimetic;game theory;heterogeneous networks;indirect biomimetic;learning theory;macrocell-femtocell network coexistence;optimization;outdoor fixed relays;self organization;wireless backhaul capacity","","8","","13","","","1-1 April 2012","","IEEE","IEEE Conference Publications"
"Accelerating a Random Forest Classifier: Multi-Core, GP-GPU, or FPGA?","B. Van Essen; C. Macaraeg; M. Gokhale; R. Prenger","Lawrence Livermore Nat. Lab., Livermore, CA, USA","2012 IEEE 20th International Symposium on Field-Programmable Custom Computing Machines","20120716","2012","","","232","239","Random forest classification is a well known machine learning technique that generates classifiers in the form of an ensemble (""forest"") of decision trees. The classification of an input sample is determined by the majority classification by the ensemble. Traditional random forest classifiers can be highly effective, but classification using a random forest is memory bound and not typically suitable for acceleration using FPGAs or GP-GPUs due to the need to traverse large, possibly irregular decision trees. Recent work at Lawrence Livermore National Laboratory has developed several variants of random forest classifiers, including the Compact Random Forest (CRF), that can generate decision trees more suitable for acceleration than traditional decision trees. Our paper compares and contrasts the effectiveness of FPGAs, GP-GPUs, and multi-core CPUs for accelerating classification using models generated by compact random forest machine learning classifiers. Taking advantage of training algorithms that can produce compact random forests composed of many, small trees rather than fewer, deep trees, we are able to regularize the forest such that the classification of any sample takes a deterministic amount of time. This optimization then allows us to execute the classifier in a pipelined or single-instruction multiple thread (SIMT) fashion. We show that FPGAs provide the highest performance solution, but require a multi-chip / multi-board system to execute even modest sized forests. GP-GPUs offer a more flexible solution with reasonably high performance that scales with forest size. Finally, multi-threading via Open MP on a shared memory system was the simplest solution and provided near linear performance that scaled with core count, but was still significantly slower than the GP-GPU and FPGA.","","Electronic:978-0-7695-4699-5; POD:978-1-4673-1605-7","10.1109/FCCM.2012.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6239820","FPGA;GP-GPU;Machine learning;OpenMP","Acceleration;Decision trees;Field programmable gate arrays;Hardware;Pipelines;Training;Vegetation","decision trees;electronic engineering computing;field programmable gate arrays;learning (artificial intelligence);microprocessor chips;multi-threading;pattern classification;shared memory systems","CRF;FPGA;GP-GPU;SIMT;compact random forest;decision tree;ensemble;forest size;linear performance;machine learning;majority classification;memory bound;multiboard system;multichip system;multicore CPU;multithreading;open MP;random forest classifier;shared memory system;single-instruction multiple thread;training algorithm","","14","","11","","","April 29 2012-May 1 2012","","IEEE","IEEE Conference Publications"
"Can we predict types of code changes? An empirical analysis","E. Giger; M. Pinzger; H. C. Gall","University of Zurich","2012 9th IEEE Working Conference on Mining Software Repositories (MSR)","20120625","2012","","","217","226","There exist many approaches that help in pointing developers to the change-prone parts of a software system. Although beneficial, they mostly fall short in providing details of these changes. Fine-grained source code changes (SCC) capture such detailed code changes and their semantics on the statement level. These SCC can be condition changes, interface modifications, inserts or deletions of methods and attributes, or other kinds of statement changes. In this paper, we explore prediction models for whether a source file will be affected by a certain type of SCC. These predictions are computed on the static source code dependency graph and use social network centrality measures and object-oriented metrics. For that, we use change data of the Eclipse platform and the Azureus 3 project. The results show that Neural Network models can predict categories of SCC types. Furthermore, our models can output a list of the potentially change-prone files ranked according to their change-proneness, overall and per change type category.","2160-1852;21601852","Electronic:978-1-4673-1761-0; POD:978-1-4673-1760-3","10.1109/MSR.2012.6224284","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6224284","Machine Learning;Software maintenance;Software quality","Artificial neural networks;Computational modeling;Correlation;Measurement;Object oriented modeling;Predictive models;Semantics","learning (artificial intelligence);neural nets;object-oriented methods;software maintenance;software metrics;software quality","Azureus 3 project;Eclipse platform;SCC;change-prone file;change-proneness;condition change;fine-grained source code change;interface modification;machine learning;neural network model;object-oriented metrics;prediction model;semantics;social network centrality measures;software maintenance;software quality;software system;source file;statement change;statement level;static source code dependency graph","","14","","41","","","2-3 June 2012","","IEEE","IEEE Conference Publications"
"Regression as classification","R. Salman; V. Kecman","Computer Science Department, Virginia Commonwealth University, Richmond, 23284-3068, USA","2012 Proceedings of IEEE Southeastcon","20120510","2012","","","1","6","The paper presents how solving regression problems can be posed as finding solutions to multiclass classification tasks. The accuracy (averaged over several benchmarking data sets used in this study) of an approximating (hyper)surface to the data points over a given high-dimensional input space created by a nonlinear multiclass classifier is slightly superior to the solution obtained by regression (hyper)surface. In terms of the CPU time needed for training i.e., for tuning the hyperparameters of the models, the nonlinear classifier shows significant (order of magnitudes for large datasets) advantages too. Here, the support vector machine (SVM) has been solving given regression problems as a classic SVM regressor and as the SVM classifier. In order to transform a regression problem into a classification task two possible discretizations of a continuous output (target) vector y are presented and compared. A very strict double (nested) cross-validation technique has been used for measuring performances of regression and multiclass classification SVMs. A novel approach and the experimental results obtained for five benchmarking regression data sets warrant both further theoretical investigations and broad application in practice.","1091-0050;10910050","Electronic:978-1-4673-1375-9; POD:978-1-4673-1374-2","10.1109/SECon.2012.6196887","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6196887","Classification;Data mining;Discretization;Machine-Learning;Regression;Support Vector Machine","Accuracy;Benchmark testing;Concrete;Servomotors;Support vector machine classification;Training","pattern classification;regression analysis;support vector machines","CPU time;SVM;data points;nonlinear multiclass classifier;regression hypersurface;support vector machine","","0","","10","","","15-18 March 2012","","IEEE","IEEE Conference Publications"
"Study of P2P flow detection technology","B. Zhang; S. Xie; X. Yan","School of Information Engineering, Southwest University of Science and Technology, Mianyang, China","2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet)","20120517","2012","","","2106","2110","To identify and control P2Pflow more infectively, the industry went through Multi-level explores and put forward many infective P2P flow detection methods. They are the method based on the port, the method based on deep data, the method based on machine learning and the method based on network behavior. In the paper, we sumerize and analyze those methods, and compared both the advantages and disadvantages between them At last, it analyzed the further step of P2P Flow Detection Technology.","","DVD:978-1-4577-1413-9; Electronic:978-1-4577-1415-3; POD:978-1-4577-1414-6","10.1109/CECNet.2012.6201808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6201808","Deep Packet Inspection;Machine Learning;Network behavior;Peer network technology;Port identification","Feature extraction;Internet;Network topology;Peer to peer computing;Protocols;Servers;Topology","learning (artificial intelligence);peer-to-peer computing","P2P flow detection technology;deep data;machine learning;network behavior;port","","0","","12","","","21-23 April 2012","","IEEE","IEEE Conference Publications"
"Learning to Unlearn in Lattices of Concepts: A Case Study in Fluid Construction Grammars","L. Ciortuz; V. Saveluc","Dept. of Comput. Sci., Al. I. Cuza Univ. of Iasi, Iasi, Romania","2011 13th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing","20120315","2011","","","160","167","This paper outlines a couple of lattice-based (un)learning strategies proposed in a recent development of unification-based grammars, namely the Fluid Construction Grammar (FCG) setup. These (un)learning strategies are inspired by two linguistic phenomena occurring in a dialect spoken in the Banat area of Romania. Children from that region -- where influences produced over centuries by Serbian, a Slavic language, are obvious -- learn in school the modern Romanian language, which is a Romance language. This particular setup offers us the possibility to model in FCG a two-step learning process: the first step is that of learning a (perfective) verbal aspect similar to the one already presented by Kateryna Gerasymova in her MSc thesis, while the second one is concerned with un-learning (or, learning another linguistic ""construction'' over) this verbal aspect. Thus, the interesting issue here is how learning could continue beyond learning the verbal aspects. We will first give linguistic facts, after which we will outline the way in which FCG could model such a linguistic process. From the computational point of view, we show that the heuristics used in this grammar repairing process can be automatically derived since the meanings associated to words and phrases are organized in a lattice of feature structures, according to the underlying constraint logics. We will later discuss the case of another verbal marker in the dialect spoken in Banat. It will lead us to sketch a composite, quite elaborated (un)learning strategy.","","Electronic:978-0-7695-4630-8; POD:978-1-4673-0207-4","10.1109/SYNASC.2011.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6169516","Fluid Construction Grammar;learning in lattices of concepts;machine learning","Educational institutions;Frequency selective surfaces;Games;Grammar;Lattices;Mood;Pragmatics","computational linguistics;formal logic;grammars;learning (artificial intelligence);natural language processing","Banat area;FCG setup;Romance language;Serbian;Slavic language;concepts lattices;constraint logics;dialect spoken;feature structures;fluid construction grammars;grammar repairing process;lattice-based unlearning strategy;linguistic construction;linguistic facts;linguistic phenomena;linguistic process;modern Romanian language;perfective verbal aspect;two-step learning process;unification-based grammars;verbal marker","","1","","22","","","26-29 Sept. 2011","","IEEE","IEEE Conference Publications"
